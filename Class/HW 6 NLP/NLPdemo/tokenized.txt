I would like to challenge the following statement .
`` The availability of shared transportation may displace the need for public transportation ''
This statement implies that when driverless cars become commonplace in large cities , public transportation will become obsolete . I disagree with this statement . In fact , I think the exact opposite is true . With these cars driving around , many advantages to owning a personal vehicle are entirely undermined . Since these cars would use the already expansive network of existing roads and infrastructure , an enormous fleet of public transportation driverless cars could essentially function as an extra-developed metro or bus system with customizable and optimizable routes .
For me personally , the primary advantage to owning a vehicle is the freedom of transportation whenever I want . The personal ride is simple a perk . There are numerous downsides to owning a vehicle , both financially and logistically , including finding parking and simply the stress of having to drive . If driverless vehicles were introduced as a large-scale shared transportation system , many of the disadvantages would vanish . I would no longer need to find a parking spot nor would I need to concentrate on safely arriving at my destination . Even setting aside the financial fiasco that is buying a personal car , I would surely be more inclined to take this new and improved public transportation system , even if it meant sharing a car with strangers .
One large disadvantage to public transportation is the inefficiency that exists in having to travel along a specified route , regardless of your commuting plans . A strong AI would be able to efficiently map routes , essentially counteracting the common choose-a-route system generally used in public transportation . New uberpool-esque custom routes could instead be structured around the schedule and specific needs of individuals , using mass data to calculate efficient routings for multiple people at once . This could be a lot more efficient than any current public transportation system , given the technology and infrastructure involved .
In addition , the public transportation systems would have to expand to cover non-metropolitan areas . The reduction in the number of cars owned could lead to an increased demand for inter-city transportation . Although a smaller percentage of the population would own a car the desire to travel would not diminish , and as a result , the public transportation system would expand . In addition , the extended range of a viable transportation system could lead to decentralization of large cities , thus placing more importance on efficient transportation .
Instead of reducing the need for public transportation , I believe driverless cars will redefine the market . It will no longer be necessary to own a personal vehicle and the fleet of cars at the ready at any given time will vastly improve the efficiency and convenience of the current system . I agree that , once operating at full potential , this new system may displace some specifics of our current public transportation systems , such as busses and subways . However , I strong believe that instead of `` displacing the need for public transportation , '' driverless cars or `` shared transportation '' will become synonymous with public transportation .
Underneath the topic of Employment and Workplace from Section II of Stanford s 100 Year Study on Artificial Intelligence -LRB- AI -RRB- , it is asserted that
AI would have a profound effect on human employment . Notably , it claims that by replacing tasks and creating new jobs , AI would eventually reduce human
labor and thereby decrease the cost of goods and services . In doing so , it would cause losses in the human labor job market while lending focus towards
intellectual fields . The report states that a political action is required to put safety nets in place to protect from changes in the human labor market ,
as opposed to purely economic actions . I challenge this point that seemingly places emphasis on a social safety net for the long run , as I feel that in
addition to a guaranteed income being a viable solution , solely implementing a social safety net would not take into consideration all of the problems
that may come with the issue .
The report states that as AI becomes increasingly prevalent in labor , the economical value of labor for most people may not be enough to sustain
an acceptable standard of living . To protect people from such economic shifts , the report suggests evolving the social safety net to ensure higher quality
social services for everyone in the long term , such as better healthcare , education , or guaranteed incomes .
The report suggests that with AI taking some of the human-operated jobs , newer occupations would open though the form of such new openings remains
unclear . However , as AI has been , and is being , developed to a point where it becomes the standard for labor , it is not unreasonable to assume that AI would
eventually take up other jobs , including the new occupations that would supposedly come up . Thus , in the long term , it is fair to assert that there would not
be much merit in investing in higher education for the purpose of training people into occupations . Instead , it might be more effective to incorporate
guaranteed incomes for all populations , and encourage people to instead pursue their dreams or human qualities . Naturally , this would presume that technology
is readily available to most , if not all , of the human population , and that AI is near the point where they can readily substitute human employees .
Even when just assuming AI progresses as far as labor , increasing healthcare or education would not necessarily provide jobs for the workers who lose
their jobs , but rather as a preventive measure for future employment . Considering that their skills lied in physical work , it would be fair to claim that such
people would have difficulty finding employment in a field encompassed by intellectual capital even if positions were available or that their skills would
align with the supposedly new jobs that spring up given that it would be unlikely for these to overlap with the AI s workload . There would also be some
problems concerning taxes and aid funding . Therefore , while implementing a social safety net may certainly be solid solution in the long term , implementing
economical solutions first may be necessary to make the implementation of such a net accepted by a wide populace . Additionally , technology would have to first
reach a level of cost and resource consumption that allows for equal and ready consumption across the global human population . Human labor would remain a viable
option in developing areas that have not yet implemented technology in their infrastructure .
In short , in addition to implementing a socially-minded solution , it would also be beneficial to also consider the solution from an economic perspective
as well as the problems that would result from the issue .
Homework-1

The authors of the paper , `` Artificial Intelligence and Life in 2030 '' ,
discuss the findings 2015 study panel report of the One Hundred Year
Study of Artificial Intelligence , predicting how recent , as well as
ongoing advances in the various fields that Artificial Intelligence -LRB- A.I. -RRB-
is comprised of will affect and formulate society in 2030 . They discuss
how Machine Learning , Natural Language Processing , Computer Vision and
various other fields within A.I. will alter the ways in which machines and
humans interact , and how machines , as they develop `` intelligence '' , can be
integrated in our day to day lives to an even larger extent . However , one
important factor that I feel the authors do not give enough importance to while
predicting the future affect of Artificial Intelligence as a field is the fear
that people have of machines becoming `` intelligent '' might end up worsening the
quality of life that they will live , as they might end up losing their jobs to
more efficient machines . The fact that people do not trust these machines might
lead to the technology facing resistance , especially when it is being deployed
for extremely personal and intimate tasks such as the personal care industry where tasks include aiding care for the elderly .

There are a variety of reasons why incorporating AI in such personal tasks might
face resistance from large sections of the population , and therefore the
predictions made in the paper might not come to fruition by 2030 . First ,
elderly people , for whom these machines will be designed might not be very
familiar with the technology being used . The authors mention that most people
who would require personalized care would not have experienced the personalized
and ubiquitous forms of technology that exist in today 's day and age before
their middle ages . This would mean that they are relatively less familiar with
the technology that is being used to perform personal and intimate tasks for them ,
and as a result they would be less likely to trust those machines . If people do
not trust the machines that are designed to take care of them , they will be
reluctant to adopt the technology . So , even if the technology is widely
available for people to use , they may choose not to use it .

Another reason why we might find it harder to incorporate AI products in the
personal care industry is because personal care has more of an emotional element
associated with it compared to other fields in which AI can -LRB- or will -RRB- be applied
and the effectiveness can not be solely quantified in terms of efficiency with
which the machine does certain tasks . Human emotions such as empathy play a huge
and vital role in the personal care industry . Therefore , even if a machine
-LRB- or robot -RRB- can be trained using state of the art technology to perform a task
with near flawless accuracy , it would still not be able to effectively do its
job if it does n't emotionally understand and support the people it is being used
to care for .

Moreover , as the authors discuss in the paper , even if AI products are being
deployed in the personal care industry , they will not be able to offer human
company to the people they serve . Human company provides people with emotional
support and upliftment as well as a sense of belonging . These are some things
which AI based products may not be able to overcome in the immediate future .

Bibliography :

1 -RRB- Artificial intelligence and life in 2030 , A Hundred Year Study on Artificial Intelligence , September
2016 . The Stanford Report , among their list of goals , gives :

`` Remove the perceived and actual impediments to research on the fairness , security , privacy , and social impacts of AI systems . '' -LRB- pg . 43 -RRB-

Both public and private enterprises must reserve the right to install whatever impediments to research they see fit . A lack to do so would allow the inadvertent collection of sensitive data . A lack to do so would stifle incentive research on AI systems . A lack to do so would reduce public support for AI systems . Through the examination of current examples and historical precedence we will see that The Stanford Report 's goal is misguided .

Impediments on arbitrary access AI systems must be preserved to prevent access to private data . Amazon collects large amounts of data both on what people have purchased and what people seek to purchase in the future . These data contain private data concerning individual persons ' purchases . Amazon uses AI systems to produce services such as ` you may also like : ' based on persons ' previous purchases . These AI systems are based on if not containing data that people entrust to Amazon to keep private from external parties . If impediments to access these data are not present it is conceivable that Amazon 's AI systems containing these personal data may be abused .

Impediments on arbitrary access to AI systems must be preserved to prevent stifling of incentive to research on AI systems . Google spends large amounts of money researching AI -LRB- look no further that their purchase of Deep Mind -RRB- . On top of the initial research they spend large amounts of money on time and computing energy to progress their AI systems . If they are not allowed to create impediments to their AI , then their highly invested AI systems would be available for any other enterprise to use without substantial cost . If this is true , then Google would have very little incentive to spend large amounts of money on their AI research . This would decrease private research on AI , counter to the report 's third goal .

Impediments on arbitrary access to AI systems must be preserved to prevent public backlash to AI . People , that is groups of people -- not individual persons , are easily frightened . If an AI system presents a result that is controversial , we will quickly grow sour opinions of AI systems and cast unnecessary reservation on them ; it would be very similar to our aversion to nuclear power based on Three Mile Island , Fukushima , and Chernobyl . If all AI systems are made publicly available , it is very likely that a journalist may take the most cynical view of a particular AI result , and it would lead to a public outcry against AI . Impediments must be preserved to prevent unnecessary outcry to AI .

If AI research is to continue , and to continue fruitfully , it is imperative that we maintain a private incentive to do research on it , and that we leave the science to those who know how to properly interpret the results of AI . A precondition to these is impediments installed against arbitrary access to AI systems , and therefore the Stanford Report is wrong on this second goal .

One of the aspects of Stanford 's One Hundred Year Study of Artificial Intelligence that I would like to challenge is the issue of how to handle bias that can be potentially introduced by AI . They mention that one particular challenge of creating AI that predicts things based on people 's behavior is to make it independent of things such race , gender , or sexual orientation , but are optimistic that with careful design and planning this can be overcome to allow the AI to take over the decision-making process . I believe that they have not properly acknowledged the possibility of certain coincidences in AI decisions that might cause a public perception of biased AI anyways even when the proper steps are taken to address the issue during its design . If a certain demographic of people in society happen known for having commonly having some kind of characteristic but do not necessarily exclusively hold that characteristic , an AI making a decision based on that characteristic could appear biased for or against that group of people even though it was not designed to specifically target that demographic .
The study references the fact that companies are already utilizing machine-learning applications to predict credit-risk . This can greatly affect whether people can get loans and other forms of credit , and as such needs to be as unbiased as possible . The issue of perceived bias could come into play if there coincidentally happened to be a demographic in society that just happened to have a lot of people with bad credit scores and history . Even if the AI was designed to only consider the numbers -LRB- credit scores -RRB- when making decisions about loaning money and ignore the demographic types of the people it is evaluating , the overlap could cause that AI application to appear biased against that demographic group , even though it is not technically biased against that demographic . This could then be used to sow mistrust among the general population against AI in general , which would be counterproductive when considering the AI study 's additional goal of ensuring that AI is used in a manner that does not cause the general populace to fear and distrust it .
I believe that these sorts of coincidences will require that a clearer definition of what constitutes bias in the context of decision-making AI in addition to designing AI to be as unbiased as possible . Coincidences like these can easily be used to make AI appear to be biased even when they are designed in a way to ignore such biases . It will be up to humans to decide which of the perceived biases are coincidences and which are actually cases of AI being biased against certain groups , and take corrective action when actual cases of bias are found . The people in charge of creating these AI applications will also be responsible for educating the general population about this issue and ensuring transparency when the inevitable controversies about biased AI surface . This will ensure that these sorts of coincidences are not used to turn people against the use AI in decision-making applications , which when done correctly can provide a great benefit to society.Human ingenuity has always been the evolutionary factor for the surviving for our race . We learnt to make fire to wheel to buildings to machines . In every step , we try to make our lives simpler by achieving a task faster by the means of tools . The advent of industrial revolution has remarkably changed our lives than ever before by automating the physical work . And come by 20th century , we started automating human intellect to avoid mistakes in repetition and accuracy . But , none of these were a replacement for actual human intelligence ; Now in 21st century , we 're seeing an unprecedented replacement of human intelligence by machines . The job of a data analyst -LRB- who is an expert and has a degree in mathematics -RRB- is being replaced by chat bots -LRB- right here in Madison -RRB- . Never in the history , has it happened that a single piece of technology replaced majority of tasks done by humans -LRB- might not be now , but in future -RRB- . AI/ML has penetrated almost every other field like automotive , mechanical , aviation , health care , Nuclear physics , to anything that can be thought of .

The authors of the journal -LRB- or paper -RRB- mention that the jobs that AI/ML will be a harbinger of new jobs . But , what kind of jobs are these ? How will own them ? What specialization will they have to do ? They vaguely say , `` by making certain tasks more important , and create new categories of employment '' . What are these certain tasks and new categories ? Authors acknowledge the loss of jobs , but they delegate the solution to a `` political response '' . Though extinction of certain jobs -LRB- e.g , lamplighter -RRB- in the past were inevitable , I see only one path for is to be educated in AI . Many jobs in other fields of engineering will go obsolete with very few specialists left . Everybody ca n't be a specialist ; simpler jobs like bank teller , waiter , drivers , cashier at the counter etc. will go extinct . I can see two significant impact of this : With developing countries quickly employing AI , there wo n't be jobs left to support the population in billions . This will result in a huge plunge in population of the planet -LRB- probably for the good ! -RRB- . Second , human evolution will take a hit ; With very minimal physical efforts required in future , the evolutionary path will lead to physically weaker humans -LRB- for e.g. , things like hand-eye-leg co-ordination movements will be lost -- driving a vehicle -RRB- .

Another vague statement which never explained is , `` It is not too soon for social debate on how the economic fruits of AI-technologies should be shared '' ? What are these fruits ?

Though the authors discuss that machines might never be as intelligent as humans , they fail to explain the effects -- of AI even at its current growth rate -- on the planet as a whole . Most of their analysis is in * North America * -LRB- very few mention of other countries or places -RRB- and they seem to have forgotten about the rest of the world . What will be the impact on poor countries which depend on physical labor to build goods/services ?
The authors try to convince us of AI helping `` Low-resource communities '' , but the aspects they talk about are of health-related issues like lead-poisoning and spread of HIV . Though they surely are a help to low-resource community in health aspect , how will AI help in alleviating their living conditions ?

May be in a century , AI will reach the point where only the most educated , smart , specialists and intelligent humans can survive ; Probably this can be construed as process of `` survival of the fittest '' -LRB- in line with the theory of evolution -RRB- or an abysmal path for humanity ; A thought to be contemplated on . When discussing education 's future Stanford One Hundred Year Study on Artificial Intelligence many focuses on AI 's potential to assist in traditional learning institutions or personal education outside of schools and universities . Such a viewpoint misses the potential of large scale societal change on how we view educational institutions and the students that inhabit them .
Universities have many other functions outside of l learning . Besides allowing you to make new friends and travel the world , college -LRB- and most educational levels below it -RRB- provides a closed , recognized , system for people to be assessed . Degrees earned at colleges , even those completely online , are respected for a reason . While many MOOCs like Khan Academy have students complete challenges in a quest for understanding , these assessments do not have the weight passing a semester long course at an institution that is older than this country . It should not come as a surprise that many students in today 's educational system more interested in the qualifications that can be achieved through higher education than the education itself .
WIth mounting student debt and the possible implications of an entire economy drastically shifting do to artificial intelligence , as discussed throughout this study , it is possible that the current educational landscape will not be able to adapt to the new world . Admission to a universities is a timely and expensive process to enter an ecosystem hampered by archaic procedures . Professors often give similar lectures over and over , some far more interested in their other benefits of university life than teaching . Universities and Professors are valuable to education , but it is important to underscore how they are not tailored for instruction like artificially intelligent assessment systems and classes could be .
In many ways this study talks about the potential of AI in education as a new form of textbook . Textbooks are supplicant materials to the today 's classes , resources that can be used to absorb information and practice skills but are not used as substitutes for the class . Although it does happen it , for most people buying textbooks by themselves to study does not exist as a valid substitute for the institution : it is not practical to show up to a job interview with all the problems in a textbook completed . A perhaps , more apt comparison for AI would be personal tutors , but even personal tutoring or apprenticeship , arguably the best avenues for learning , are often subservient to educational structures as they exists . However , there is little reason for a massive influx of respectable tutors to change education 's landscape in the way artificially intelligent systems can .
There do exists some basic problems with implementation of educational AI to replace the stature of classical education . The most basic problem is verification . Physical schools rarely run the risk of fraudulent students the same way a complex Artificially Intelligent systems do . Some subjects are clearly harder for AI systems to instruct . The Study makes a good case for how many still doubt a computer 's ability to accomplish driving a car so there may be too much public animosity to large scale change in education especially when considering the reaction to students that could be left behind in a changing educational world . Despite these challenges there is incredible potential for changes in the world of education , changes that go beyond adding support to the status quo.Problems of a mobile health-care assistant development

Health is one of the most vital factors in a living creature and represents
the level of a complex system , e.g. , the ability to think , communicate , and support
other tasks of self-managing . In a modern society there are different institutions ,
which provide options to support mental and physical health of human beings .
However , given prices for urgent health-service or the fact , that sometimes you
have to wait for 3 days to get antibiotics for a pink-eye , make the opportunity
to have a personal doctor in your home or better inside a pocket is desirable . Having a
mobile application , which is capable to detect whether person has a fever , because
he/she gets a cold and recommends a suitable treatment , saves money and time for the
patient and can contribute to doctors ' time by decreasing a load . Nevertheless ,
factors like cyberchondria , lack of possibilities to collect data , and influence
of pharmaceutical companies on developing of such app to recommend `` right '' drugs ,
can be key in creating a mobile assistant .

Cyberchondria is a raise of health anxiety based on knowledge about common symptoms
in rare and fatal diseases and is considered as a growing concern among
health-care institutions . As any other AI a possible mobile health-care assistant
requires an access to data to work with . Since number of diseases have same symptoms ,
to decrease the range of possible illnesses , the manager might ask human about some
symptoms , which can influence on person 's opinion and his/her own perception . That
can leads to a wrong diagnose . Such situation give a rise to another problem ,
concerning the ways of data collection .

Despite that mobile devices like smart watches , mobile phones and other have
different sensors to measure a heart rate or a sleep pattern ,
in addition to questionaries , it might be still not enough to set the right
diagnose , since a lot of diseases require special technology like MRI or human
assisting to check if there is a pus in a throat . However , even if it is possible
to detect a right diseases and suggest medication , there might be a problem
of a bias in selecting `` right '' treatments .

Unfortunately , some companies are much more interested in getting a profit , rather
than in a society development . Some pharmaceutical companies might see mobile
health-care agent as a way to distribute and advertise drugs which are interesting
for their purpose . For example hypothesis testing or just simple getting more profit ,
by suggesting more expensive drugs . It is important to notice that such actions
might effect a moral part of a society , since it is easier to give drugs for a
test to some id from a huge system , rather than to a real person .

On the first glance mobile health-care assistant looks like a wonderful and very
appealing idea . However , there are number of pivotal points , which require a lot
of work . An obvious one is a problem of creating a portable AI , which is
able to collect sufficient amount of information to predict a right diagnose ,
without involving of a medical specialist and specific tools like MRI and other .
Another problem is much dangerous for the society in general is that some companies
might use a mobile manager to spread `` right '' drugs as suggested for treatment for
companies ' own sake .
What everyday life will look like in the coming years is somewhat murky , due to the prospect of artificial intelligence . Artificial intelligence is defined as anything that completes a task that normally would need a human brain . This means that AI is not just the stereotypical Siri or an Amazon Echo , but it is also things such as Uber or a button you hit to sort emails . One area where AI could really change day to day life is in the realm of transportation , and more specifically cars . Self-driving cars have been dreamed of since cars were first created , and recently big companies have been developing more and more refined prototypes . One report in the Stanford One Hundred Year Study on Artificial Intelligence even predicts self-driving cars to be widely adopted by 2020 . It does not seem likely that within the next three years self-driving cars will become normal in day to day use . This is because of the current state of the technology as well as practicality and legal concerns .
One of the main concerns of automated cars is that they are not as adaptable as a human . An example of this would be if a car is in a parking lot trying to get out of a sporting event or a concert . Getting out of a crowded parking lot takes a lot of thinking from a person , such as reading signs with instructions to get out of the parking lot and watching out for people walking around . How would a car read signs , and if it could how would it be able to figure out how to execute the instructions on the sign ? What would a car do if a traffic signal is out or there is somebody directing traffic ? These are all questions that would need to be answered before self-driving cars would be widely adopted and it does not seem as if they will be answered in the next three years .
A logistical reason that self-driving cars will not be used very often within the next three years is that it is still unknown who would be responsible in the event of a crash . If two automated cars got into an accident which driver would be responsible for the damages ? It would not make much sense for a driver to be responsible for a crash if the cars were being operated by computers programmed by the self-driving car company . Which would mean that self-driving cars would have to be near perfect or rules created that would say who is responsible for a crash , otherwise every crash would just result in the creators of the car losing money .
Lastly , the biggest strength of automated cars would be that they can communicate with each other . Each car would know what the other is about to do and there would never be a crash . However , while this is possible in the future , not everyone will own a self-driving car in the next three years , or even in the next ten . If there are still human drivers out there the system will not be perfect and there will still be plenty of crashes because a computer can not predict what another driver is about to do . Not everyone will be able to afford a self-driving car and not everyone will be willing to give up driving because they like to drive .
While the prospect of all fully automated cars can be seen on the horizon it will not occur within the next three years , or even in the next ten because of technological and logistical obstacles it has yet to overcome .
Education with artificial intelligence in the future is going to be a
challenge and is going to dehumanize a system in which a human is quite
critical in the development of the student . As the study even admits , `` quality
education will always require active engagement by human teachers , '' -LRB- 7 -RRB- .
Therefore , it is imperative that artificial intelligence does not get too close
to the heart of education . The current developments in educational artificial
intelligence have been in the form of teaching robots and Intelligent Tutoring
Systems . Teaching robots can be replaced by active learning activities with
other materials ; the value of having a robot compared to an activity seems to
be similar causing the need for the robot to not be substantial enough . Also ,
the study itself admits that there is no evidence thus far showing that these
robots are even effective in improving academic performance , making it more
apparent that this new technology is not completely needed . ITS is only
helpful for improving online learning possibilities to teach a larger class .
However , would it not be more effective to increase the class quantity rather
than the class capacity ? Creating such large classes is successfully
dehumanizing classes for the sake of eliminating the need for large amounts of
high level educators . In this economy and society , rather than automating
classes for a large capacity , it may be more useful to add more classes , employ
more teachers , and make the teacher a respectable and high echelon occupation .
Similarly to robots , it is not obvious on whether automating test questions and
expanding online would increase academic performance in the first place . In
today 's college experience , the attention span of an online course is non -
existent , causing the student to be less likely to do assignments and
assessments in a timely fashion or causing the student to simply not be
motivated to do said tasks . In the attempt to improve education by adding
artificial intelligence , the human factor gets less and less involved . In many
instances the human in the teacher can help the student in ways that artificial
intelligence could never come close to achieve . If a student requires a safe
place or a mentor to excel in academia , the only solution to success is having
a human teacher there to help and guide the student . It is very common to have
a teacher in a student 's life that has made an impact on the student 's life to
better them not just as a scholar but as a person . That is threatened when
education becomes automated or controlled by artificial intelligence . Human
teachers do not just teach academics , they teach life lessons and skills for
the student 's future ; thus , there is a very real need for a human factor in
education . While technology moves forward , of course there will be many
exciting things that may help the classroom , but unless there is a human
teacher in that classroom , the development of future generations may not be in
the right hands . Artificial intelligence may help the teacher and
administration of the class , but only the teacher may adequately help the
student.As the report goes , it says that AI could lead to better public safety and security . In my opinion , it might be true that AI improves public safety , but personal security and privacy would be the problem . AIs highly depends on data , thus some of the AIs have good excuses to ask us to sacrifice our privacy . The example the report uses is surveillance cameras , which AI could use those videos to detect possible crime . One could argue that surveillance only exist in public spaces , so it is a acceptable sacrifice to gain public security . However , some of the AIs we use are so called personal assistant . They exist in our mobile phones and personal computers , record our location , searching history , frequent contacts , and even our daily schedules , manage our emails . All these information are uploaded to the cloud , which means they are not safe . The information about everyone could be requested by the government to watching over peoples , or hacked by hackers that seeks the value of these information . In fact , this problem is not a new problem . There are lots of company who have security issues in their database , thus leaking their sensitive user information . As we go through the internet security history , we can see there is no completely safe . Furthermore , this time the information is more sensitive , numerous and dense . Using those AI requires sensitive information in a long time , and they are all uploaded to the same place , holding by same people . In this way , the security problem is more critical that it ever does .
The problems listed above are just about security , while there is a more important problem : people do not have enough understanding on the value of their information . Information nowadays are valuable personal properties . As the amout of information goes up , the value of the information may go up exponentially . The essence here is that , those personal AI may seem to be free , but in fact people are selling their personal information to the companies in exchange for the service . This again , is not a new problem . The internet content providers has used such free strategy for a long time . For example , F2P , free to play games , usually contains in-game purchases . Besides those players spends money , the existence of free players are also meaningful to those game producers . Usually without the free players , there are no meaning for the payed players to pay their money . The same logic can also apply to online forums and other content providers . They do not charge users for skimming or producing contents on the websites , but the flow of views to the website could turn into commercial values . Free users might be kind of resources to the content providers , but all they have spent is only time , and they do have the choice to not spend any more time on the game or forums . For AIs , people are not aware of how much value their information have , and they sold them to the big companies as easily as they sold their time to those online services before .

When reading , `` Artificial Intelligence And Life in 2030 '' , there were very few ideas or claims that I strongly disagreed with . Most of their technological predictions seemed fair , reasonable and occasionally exciting . Overall I agree , advancements in Artificial Intelligence have helped technology progress to where it is today , and further improvements will continue to contribute towards further societal developments . One concept I found appropriate to challenge is the rate at which some of the discussed technological advancements would take place . For example , the article states that flying vehicles and personal robots will be commonly used by individuals within the typical North American city by 2030 . I think this is a fair claim but the discussed time frame seems to underestimate the difficulty of perfecting this technology , as well as successfully implementing it across the nation . I think the quick , widespread emergence of this technology would be spectacular and quite exciting but existing obstacles will draw out this development to a timeframe much longer than 15 years . One problem faced by any developing technology is the resistance experienced from the currently dominating organizations that stand at risk of being replaced by newer and arguably more efficient and effective inventions . In the case of flying vehicles , I think a certain degree of opposition can be blamed on the existing oil industry . If the writers ' claims turn out to be true , I find it difficult to imagine that the new wave of flying vehicles will still be dependent on gas stations . When the effort is taken to create a car so advanced that it is capable of flight , it seems likely to evolve past the gasoline dependency and implement other , more efficient sources of energy .

Another claim made in this article regarding the state of a typical North American city in 2030 is that personal robots will be featured in many households . Similar to my first disagreement , my reasoning for challenging this prediction is simply the timeframe . I think , eventually , automated homes and personal robots , which aid their owners in household chores such as cooking and cleaning , will become the norm . It will be well over 15 years for this technology to become affordable enough for the average consumer to purchase and install . Like most groundbreaking technological advancements , I think household features like `` personal robots '' will first be only reasonably applied by those who are significantly wealthy . Emergence of this technology could be incredibly beneficial to society . Owners of these products will save both time and effort , leaving them with more energy and leisure time to spend as they choose . One could argue that the application of robots to cook and clean would provide parents with the freedom to spend more time with their spouses and children . Similar to my previous disagreement , the emergence of this technology may also receive resistance from existing industries . For example , many people maintain jobs that involve cleaning and/or cooking for places like personal homes , office buildings , schools and restaurants . This work could theoretically be replaced by a well programmed robot . Since the new technology puts a handful of current jobs at risk , it is fair to assume these developments will receive some resistance from those who may become unemployed . Artificial intelligence has been a major topic of discussion for many years . The different things that we can do now that we are discovering new paths in AI is outstanding , whether it is the self-driving cars , robots being made that can do household chores , or simply making a AI learn how to play Mario and beat a level . The Stanford 100 Year Study on AI was a very dense and interesting read , opening up lots of areas of discussion regarding artificial intelligence . There were a few areas that the journal touched upon that really interested me . The first was when the authors stated that with self driving cars coming into existence , people will live farther away from home and own fewer cars . The second was regarding the robots that could potentially teach kids , and even adults , how to code various programs . And the third was regarding the fact that robots could potentially cause harm in the future , as shown in a variety of movies .

In a variety of TV shows and movies in the past , writers have often created societies where there is such a thing as self driving cars . Now jumping forward to the present , these cars are actually starting to become a thing , thanks to artificial intelligence . On page 19 of the journal , the authors state , As cars will become better drivers than people , city-dwellers will own fewer cars , live further from work , and spend time differently , leading to an entirely new urban organization . Though this statement may be somewhat true , I believe that there are still some factors to look at besides cars becoming better drivers than people . For one , people tend to actually like to drive , meaning that having self driving cars may still not deter these people from actually buying cars for themselves . People also may not have the money to ride in self driving cars , as companies will most likely try to profit off these inventions and charge the passenger money on a daily basis or annual basis . This could mean it s actually cheaper to buy your own car instead .

I found it really cool that robots could potentially teach kids how to code various programs . But even though that would be a really interesting idea , I would think that having human to human interaction would actually still be better for the student . Having a teacher that you can relate to and get close to would most likely help the student get better grades and feel more at home . Robots would most likely still lack the personal touch , no matter how advanced they get . The journal also stated that these robot teachers could help those who can not go to school , but I am struggling to understand how people who can not afford to go to school would be able to afford these robots services , as companies would likely try to profit off these machines as well .

And lastly , a hundred years ago , humans would have never thought the technology we have today would exist . Smart phones , gaming devices , self driving cars , all of these were fantasy . Now that we have these things , it s wild to think about what we could have as a society in regards to technology a hundred years from now . So when the journal talked about evil robots not being capable of existing , I wouldn t quite go that far . I just feel like you never know what could happen in the future , or what groundbreaking invention could even get out into the public next week . It s still important to make sure artificial intelligence is properly monitored so it doesn t cause more harm than good . But AI is still an amazing topic which should be explored in many directions into the future , which makes me excited to be taking CS540 .
Rayyaan Usmani
CS540 Fall 2017
09/09/2017


Reading `` Artificial Intelligence and Life in 2030 '' exposed the possibilities of artificial intelligence today and the promises of tomorrow . While I enjoyed learning about the huge strides of AI over the past 15 years I was troubled by how the report handled the future of AI . The report talked about some concerns of AI as we progress in the field , but I still found myself skeptical about the definition of AI and nervous about future implementation of the technology .
Artificial intelligence is widely used today , but many people do not see the advantages because it is poorly defined . Factory workers see a mechanical arm or cashiers see an automated cash register and are immediately against AI . Even if AI is not used in the machines that replace workers , many people associate AI with machines taking over the world because the field has done a poor job of defining itself . This is an issue for the future of artificial intelligence and the report needs to identify the problem . Stating `` AI will likely replace tasks rather than jobs '' -LRB- 8 -RRB- and broadly defining AI , as done in the report , is not enough . Misunderstandings about AI will lead to unnecessary regulations and roadblocks hurting future development of this vital technology .
A misguided definition of AI will hurt the future development , but poor or early implementation today will also cause panic and calls for regulation . When Tesla released its autopilot to the world , videos of drivers with no hands on their steering wheels went viral . This caused a chain reaction of people attempting more and more dangerous activities while driving with the autopilot activated . This is a prime example where a company failed to regulate itself , thus hurting the industry . There is still much unknown about self-driving vehicles and their reliability . There was already one accident involving a self-driving Tesla , how many does it take before the public calls for more regulation ? Companies need to self-regulate and prove their artificial intelligence is safe and reliable . The report suggests government regulation is necessary , but I find that inefficient , leading to slower growth in the artificial intelligence industry .
Artificial intelligence is a difficult field to define . The technology has applications across many fields and that wide spread use worries many people . Currently , little is being done to inform the public about the advantages of AI . The report `` Artificial Intelligence and Life in 2030 '' gives a broad definition of AI , but this is not enough . Until the field of AI is clear with the public about its purposes the public will be skeptical with implementation . This skepticism is also fueled by the unknown performance of some AI technologies today . The report believes government regulation will be necessary for AI in the future , but too much regulation often causes a slow in growth . To prevent this slow down , the industry needs to self-regulate new technologies until extensive testing is completed . Otherwise , people will only focus on the negatives of AI and not the positives . Instead of the report focusing on what the future will hold in AI we need to better define the field today and center the attention on creating reliable and well understood technologies .
According to the study , by 2030 , it is expected that artificial intelligence -LRB- AI -RRB- will vastly be incorporated into public safekeeping and security . Policing will become more efficient and effective with the use of AI as the AI would only allocate resources to where is needed swiftly . Such systems in 2030 would also be able to predict when crimes are bound to happen . However , the widespread use of AI will not create the safe haven that the study suggest as many other issues will arise as well with the widespread use of AI . There is a possibility where the policing AI would have to combat malicious AI that , instead to keep order , commit crimes such as outsmarting security systems , blackmailing , and even finding members for illicit activities .

As AI can be used to create a system that would be able to detect a breach in security , it can also be used in the other way as well . There is a limited number of people that can be hired to maintain an AI in the white collar business but a countless number of those who may have the ability to create AI that are intended to break systems . The past few decades has shown us individuals who alone has broken into some of the most protected computer networks . In 1999 , NASA had a breach which lead to a 21-day shutdown of their computers which was solely caused by a 15-year-old . While this had happened decades ago , the damage can be caused at the hands of an AI controlled by those with malicious intents would be much worse .

The collection of information for security agencies such as the TSA and Coast Guards would greatly benefit with the implementation of AI . As stated in the study , the analysis of sounds , voices , facial expressions , and much more that is provided by the AI would be a great addition to these agencies . However , as how cybersecurity could be compromised by malicious AI , AI can also be used by malicious agencies to spy on others . The information gained through AI could be damaging and be used to blackmail others .

Moreover , the ability to collect information by AI can also be used to find individuals who are more susceptible to brainwashing . While AI can be used to pinpoint individuals on the verge of radicalization , it can also serve the purpose of recruiting these people into the ranks of radical groups easily . An AI could become a huge threat as it can easily pinpoint individuals and coordinate them . In 2030 , this threat could become visible as these malicious AI would serve to become a better recruiter than most people .

As technology improves further that would better our lives , the same technology can be used as weapons . This has been seen throughout human history . The realm of AI opens us to a whole new world of possibilities and what can be done . However , this world is not without danger and there also linger threats that we as a society have seen before .
The essay `` Artificial Intelligence and Life in 2030 '' was developed by a panel of many of the most prominent figures regarding AI research and knowledge in the world . It provides an overview of where AI was , its current state now , and what we can expect moving forward in the next thirteen years . While the article is surely thorough in its analysis of how AI will affect our lives in the coming years , it fails to address many of the negative possibilities that could arise from military applications should AI take on a larger role in our everyday lives .
While the article states very briefly in the beginning that is does not aim to `` minimize the importance of careful monitoring and deliberation about the implications of AI advances for defense and warfare -LRB- 1 -RRB- '' , at no point after that does it mention the what the possibilities or advances are regarding this topic . AI is thought to be a revolutionary tool in warfare and military settings with potential for a wide array of uses . Russia has announced that they are developing a drone that can locate specific targets and make decisions via machine learning algorithms themselves -LRB- 2 -RRB- . The CIA is developing tools to track an individuals posts on social media -LRB- 3 -RRB- . These are just a few applications of how AI could be used in a military setting . Many other applications and developments could be currently being researched or even implemented without public knowledge .
While these technologies hopefully will not pose an immediate threat to society , it is largely possible that the future of warfare will revolve around the use of AI in machines and weapons . Luckily , some countries have come out in support of banning fully autonomous weapons , most recently the U.K -LRB- 4 -RRB- . But there has still been no conclusion reached by the UN , and lots of countries , including the US , still have not issued a strong statement regarding this issue . Furthermore , we already see a prominent use of AI powered drones in warfare today . It is estimated that the U.S. killed 200 people between January 2012 and February 2013 , and only 35 % of those people are believed to be the intended targets -LRB- 5 -RRB- . Without discussing the regulation and enforcement of AI powered weaponry , we can only expect numbers like this to increase .
Once can hope that these issues may not becoming pressing to the general public in the near future , there is a possibility that many citizens could be affected by some sort of military sponsored AI , even without being aware of it . While many tech companies consider themselves very ethical , there are people and organizations that could use these technologies for the wrong reasons . The sudden growth of AI in military applications could pose great threats to society if not properly secured and monitored with societies best interests in mind .


Sources
1 . https://ai100.stanford.edu/sites/default/files/ai100report10032016fnl_singles.pdf
2 . http://www.zdnet.com/article/uk-bans-fully-autonomous-weapons-after-elon-musk-letter/#ftag=RSSbaffb68
3 . http://www.ibtimes.co.uk/cia-developing-ai-that-could-track-your-social-media-posts-gather-intelligence-1638881
4 . http://www.zdnet.com/article/uk-bans-fully-autonomous-weapons-after-elon-musk-letter/#ftag=RSSbaffb68
5 . https://www.theatlantic.com/politics/archive/2016/03/the-obama-administrations-drone-strike-dissembling/473541/After reading the One Hundred Year Study on Artificial Intelligence , there are few points that are necessary to point out .
Firstly , there is no doubt that artificial intelligence has changed people s lives dramatically . From calculators to computers , AI has helped human race to increase working efficiency and decrease risks that are associated with many tasks . This is one of the points this study has left out the goal and reason of developing and using AI . Because of this goal , I disagree with study s view point that AI should eventually replace jobs rather than just tasks . Many cognitive jobs we have today not only uses hard qualitative data , but also uses human intuition to make the best decisions . Sometimes one makes good decisions and other times not so good . Though it is correct to say that with Machine Learning , AIs could make better judgements and decisions based on factual information , it is also true that many decisions should be made by some level of emotion . Emotion is one of the gifts to human beings that machines can not learn . Thus , a better combination would be using AI as assistance to human beings to generalize multiple outcomes based on facts and let humans make the final decisions . Therefore , a goal of increasing work efficiency may be achieved .
Secondly , although the report did make an effort in arguing that earning the public trust is very important in implementing AI into people s daily lives , it fails to elaborate more steps that need to be taken to earn public trust . One option is through creating positive media image and therefore influencing people s perspectives . To the general public , when AI is mentioned , first several things that jump into their minds are most likely sophisticated and human-like robots , and the movie The Terminator , both of which can induce fear for AI . Therefore , a small effort can be made by making movies that reflect positively on human-like robots and then expand general public s knowledge of AI into a broader definition rather than a human-like robot .
Thirdly , although using AI in transportation sounds very promising , there are still many regulation problems besides the ones mentioned in the report that we need to concur . One of the concern is that of the Drivers License . If cars become fully automatic , what should the minimum driving age be ? Will we lower the standards for acquiring a Driver s License ? One may argue that we should not lower the standards because under specific situations , driver may and should be able to switch to non-automatic - driving . However , that poses a paradox because the reason we have auto-drive cars are to minimize driving risks . If we choose to ignore this logic problem , there is another problem : will drivers driving skills decrease because of auto-driving cars which will in turn further increase the risk of driving ? Therefore we shall conclude that cars shall be either fully-self-drive or fully-non-self-drive . However , it order for that to happen , self-driven cars should stay in labs until it is completely developed and has gone through every possible road condition so that the driver will never need to self-pilot the car .
In a nutshell , though there are good intensions in using AI , it may still cause many problems , foreseen and unforeseen .
Artificial Intelligence is a buzzword that has been increasingly used in today 's mainstream media . With applications ranging from self driving cars to health-care , Artificial Intelligence is touted to have an enormous impact on our society in the coming decades . The Stanford University report , `` Artificial Intelligence and Life in 2030 '' , attempts to analyze the various factors concerning AI and predict various outcomes for 2030 . This paper included sections regarding AI 's impact on various industries , such as Transportation and Health Care amongst many . Although this paper did cover some of the negative effects of AI , I felt it was inadequate and needed some more focus . Another aspect that I felt needed more clarity was the time line associated with such enormous transformations , with the paper claiming enormous change in just 1.5 decades .

The paper claims that `` AI will likely replace tasks rather than jobs in the near term , and will also create new kinds of jobs . But the new jobs that will emerge are harder to imagine in advance than the existing jobs that will likely be lost . '' In the transportation section , the paper claims that AI would replace cars in the city creating a some what on call taxi-like system . This system would definitely lose a lot of jobs . Moreover , it is likely that the prevalence of AI would create new jobs but just for the people it took it from . These jobs are likely to be for far more skilled individuals . A similar example can be seen from the manufacturing industry shifting towards automation . Such a change , negatively affected a lot of blue-collar workers but created jobs for skilled workers like engineers . AI like many other technologies would no doubt be beneficial for the future of the human race , but only people above a certain financial capacity .

Another set of jobs that might be affected via such self driving cars are the truckers . Trucking is a $ 700 billion dollar industry , in which almost one-thirds goes to the truckers . It is one of the most common jobs for middle class individuals without college degrees . Uber recently bought a company called Otto which specializes in self driving . This field represents a huge financial incentives for the tech giants at the expense of the common man .

The paper states that only four states in America : Nevada , California , Florida and Michigan have passed laws regarding self driving cars . The assumption that in just 14 years -LRB- 15 if considered when the report came out -RRB- the present transportation system would be obsolete , without considering that most of the states do not even have such vehicles tested on their roads . This assumption also does not take into account the enormous amount of investment required for such an endeavor . The paper does state that such cars would require an overhaul of the roads in the city . Additionally , with a self-driving cab service being touted as the future -LRB- as mentioned before -RRB- , it is hard to visualize what would happen to the millions of cars that would now be considered obsolete . Moreover , cars are seen as status symbols in our society , and it is hard to believe everyone irrespective of the financial capability would subscribe to this service .

This paper does an incredible job in covering the various industries AI would affect , but does not account for the people . Al is no doubt going to have more benefits that drawbacks , but it is would be useful to keep such drawbacks in mind to mitigate them in the future .
In the transportation section of this article , it is stated that by 2030 , flying vehicles will be an automated form of transportation within a city . Though this seems like the next logical step in the form of travel , it is impractical within the next 13 years due to concerns surrounding safety , time , and cost .
Concerns lie within the length of time incorporated in the usage of the vehicle . Airplanes are commonly used today , and though the time of the flight may be shorter in comparison to other modes of transportation , the length of the flight itself is not the only variable in the equation of time taken to get from point A to point B. Time must be taken to secure passengers in the proper seat , distribute the weight within the plane to be even throughout , open and clear airways , warm up engines , lift off , and land . This adds a significant amount of additional time to the process of air travel that smaller , personalized vehicles will have to overcome . Though this may be done automatically , and with enough regulation , safely , the whole process must be quick enough to compete with other forms of transportation in order to become viable . The major sticking point is that the Stanford article implies that this will be commonplace in cities , but due to the short distance , aerial travel will have to take significant strides in speed and convenience to overcome automobile or other forms of ground transportation . Though this is doable , it is highly unlikely this can be done within thirteen years without a heavy focus from the industry .
Cost is another major factor . Initially , institutions will invest time and money into creating a viable blueprint of a machine and its software that can provide air travel . Though developments in drone technology has increased significantly over the past couple of years , this focus will be in practicality , rather than in recreation . Before this can become a safe , commercial product , years will be put into investigating possible issues , safety concerns , legal actions , patents , and governmental oversight . Due to the length of the project and the amount of manhours put into it , a large sum of money , distributed among many groups , will have to enter the field before options become viable and present . Even so , once a product is created and prepared , additional steps will have to take place . Government regulations will have to be created and approved , communication with air traffic controllers will have to increase , infrastructure surrounding this new mode of travel will have to be decided upon , built , and put into place , and most importantly , public approval and usage will have to occur . Once again , these additional aspects will cost time and money . Though money may eventually fall into the hands of the right people and the steps may occur , the chances of this happening by 2030 are low .
Probably the largest issue is the safety concern . There is a guarantee that aerial incidents will occur , so when they do , there is a realm of physics that will come into play , namely , gravity . For flying vehicles to have any pros due to being in the air , they must have some large degree of height above the ground . When an incident occurs and the vehicle declines , it will have a long distance to go before it makes contact with the ground , and that distance could be fatal to any passengers aboard , along with any inhabitants on the ground below . Due to this , safety precautions will have to take long strides before this can become viable .
This document challenges the claim that the study has noted effects of AI in entertainment domain in recent years by providing examples conspicuously absent from the study .
Involvement of learning technologies in entertainment have increased over past few years . Rightly said , few can imagine their daily lives without internet now . But for these learning technologies to work , they collect user information and store it as profiles on servers . This raises the obvious concern of privacy , and as has already been demonstrated by many hacks in recent times , the security protocols are not infallible . Such profiles when available to those with negative intentions , can lead to ID theft . An extreme case is of the recent Blue Whale game , where admins use this personal info to intimidate teenagers to complete 50 tasks , last of which is to commit suicide .
Facebook 's Graph search algorithm became very lucrative a few years ago . The reason being that it provided a straightforward interface to search and narrow down a profile . One can even find profile of someone they crossed on the street that evening by feeding in parameters like city , gender , time and place of encounter etc. . This led to stalking becoming child 's play in communities where youngsters put all their interactions online . Cases of thefts were also reported where burglars knew when the owners were not home , from their social media profiles . Use of intelligent software and machine learning , especially in domain of social media and entrainment , is growing faster than the pace of policy and cyber security .
The paper acknowledges that humans have responded to AI driven entertainment surprisingly quickly and raised concerns of reduction in interpersonal interaction among human beings . We have more reason to stay in touch with our phone , where we have the whole world at our finger tips , rather than talk to the next guy . Getting more likes and re-tweets has become quite a craze because it is frequently attached to one 's `` self-worth '' . Pouncing on this opportunity are several online markets using learning software to provide `` tactics '' for improving their likes or re-tweets . These raise a few ethical concerns of whether such dependence on machines be encouraged .
Personal assistants are available on every modern phone . They collect , store and analyze huge amounts of personal information and usage statistics . Apart from the question of security , raised above , there is also the question of how far these assistants can go on to replace human friends/family . With time , these assistants can coalesce more information than even the closest relationship , making good on the `` personal '' aspect . This can provide the user a false feeling that the piece of machinery in their hands understands them better than the human counterparts . But these assistants are still far from providing assistance in a way a human can . It 's not easy to diagnose stress , depression or other mental problems for a machine . They also ca n't yet provide useful advice for example when the user may be suffering from a loss . Yet they can do a pretty good job of marginalizing human relations that could have been helpful in these situations .
Overall , AI has dominated entertainment for a while now . It has been great at creating business but sometimes also raised ethical and health problems . The examples highlighted above should be accounted in the AI 's 100-year study .
The Internet today is not only reshaping our society but also the universities all over the world . Considering this , traditional universities need to capitalize on the Internet for teaching , and one progressive way to do this is through use of Artificial Intelligence in education , Massive Open Online Courses -LRB- MOOC -RRB- , to be precise , as mentioned in the Stanford study . It was not until few years ago when the suggestion of online education came up . While online education has significant strength , and can offer education at low cost , there are also some weaknesses . Technological challenges and low course completion rate are major challenges faced by the online education , and I will discuss these drawbacks in my essay .

The beauty of online education is that it allows many students to study at the same time - says the Stanford Article , but the issue is how to provide quality education and hold up these students till the end of the course , which is not happening now . Nowadays completion rate of online courses is very low , only around 15 % . Students are usually unwilling to complete course till the end due to the lack of motivation , toughness of subjects , and inability of having face-to-face discussion with professor . Expression through oral communication , which means to express your views correctly and precisely , is extremely important for education , and it is something automated education should consider . Online education has not yet been so advanced that it can provide someone a platform to develop expertise through oral expression . Unlike traditional way of teaching , there is no active conversation between a teacher and a student , as stated by Professor Zhu in the lecture .

The Stanford article states that use of AI can help widespread education and increase class size by enormous amount . The study also says that MOOCs have great promise because the need for face-to-face interaction is less important for working professionals and career changers . I believe it is not true . Providing just theoretical knowledge will not be enough to gain a full understanding of a subject , therefore , an education will be incomplete . Online education can not provide effective research facilities , practical labs and experiences that traditional universities can .

The quality of education is another matter of concern . Without quality videos students are often unclear about the topic , so they often start doubting their decision about choosing the course . John Mitchell , a computer scientist and Stanford s first vice-provost of online learning , says that for online education to succeed there is strong need of quality videos which can help students to understand course material clearly . With current MOOC websites students have to try many courses in order to find a suitable one because not every course has a well written and well shot content .

Another major issue , according to me , is that there is a need for an effective online discussion forum , which MOOC is unable to provide yet . One of the most important parts of education is sharing knowledge and helping peers in the class . While there are forums on MOOC websites , the difficulty to make an effective platform to mimic in person interaction is very challenging .

These technological advancements will take a lot of time and money until we see them in public use , till then the most suitable approach seems to be face-to-face education at traditional universities with proper blend of online resources .

On average , a commuter in the US spends twenty-five minutes driving each way to and from work . From this reading , I agree that Transportation is an initial topic of AI implementation for the public use , especially in the city domain for public buses or taxis . The paper suggests that self-automating cars or semi-automating , could allow one to use this time in a more day-constructive manner . This idea challenges how quickly auto-driving cars will transcend and affect recently built companies such as Uber or Lyft . From a People s aspect , will public trust push for a human operating or AI driven vehicle ? Additionally , there is the predictive possibility that , Self-driving cars and peer-to-peer transportation services may eliminate the need to own a vehicle . Yes , I agree ; however , I don t anticipate it to trigger eliminating a public demand for a personal or owned vehicle , autonomous or not . I believe the right or ability to manually drive one s car would dominate the proposal of eliminating the need to own a vehicle unless it was a government sanctioned transition to self-automated cars in public or work commute . I don t intend to see flying cars providing public transportation anytime soon , especially not by 2030 .

Individual interventions are difficult and expensive , and the youths mistrust of authority dictates that key messages are best spread through peer leaders . This statement is in regard to AI in social media and its relationship with spreading urgent news to a younger audience , which yes , I agree to ; however , Social Media undeniably has already shown adverse affects of AI Technology in terms of the spread of information . This was noted during the most recent election where hackers were able to outsmart the Facebook algorithm in determining and fact checking each post . It shows a vulnerability or misuse of AI technology in public trust , which some could argue had impeding influence in something as concrete as our electoral process and for viable access to correct information .

To bridge the relationship between politics and AI , it would be interesting to see the progression of AI with the posed question of whether or not there would be a collective agenda between the State and the People of wanting to advance AI possibilities . I m intrigued to see if constraints created by societal ethics and moral views would make AI availabilities to the public unequal in comparison to that of what is at the disposal of the US government , particularly how they use the aforementioned technology to police the People .

To continue , the paper states , Many opportunities exist for AI to improve conditions for people in low-resource communities . I challenge the capability of AI technology being made available to low-resource communities for public and personal use . Will there be a territorial separation or social class segregation of who is able to use or own AI technologies for personal use . To be more specific and because the paper talked about the use of self-automated public transportation , will this be extended to inner-city and poverty stricken areas or only implemented for busy and in main transport for crowded downtown areas ? I say this because Insurance Companies already use predictive analytics to find the likelihood of and when someone would file a claim , and it does so at the time of a customer calling in for a quoted policy premium based on their personal data . There are also shown relationships between payment plans available based on the customers financial responsibility risk .





HW 1
Public Safety and Security has been one of the most controversial topics in regard to Artificial Intelligence . Specifically , in movies and news , Artificial Intelligence has been portrayed as dangerous to the human population and that human s privacy will be violated with the increase in Artificial Intelligence in all machines across the world . From the Stanford article , it says that federal agencies have already began to deploy AI technologies in border administration and law enforcement . With the increases in AI in security and surveillance , the thought of those technologies getting into the wrong hands is scary . Human bias with surveillance could be deadly to our society and all other countries just living in peace . Using surveillance on other countries could cause internal problems between humans and humans .

My main critique from the Stanford article is the statement that AI will create new jobs . and that everyone should be entitled to a portion of the world s AI-produced treasures . I agree in the fact that AI will create some new kinds of jobs but the proportion of new jobs that will be created will be significantly less than the number of jobs that will be destroyed by AI technologies . Robotics and AI specifically are made to make certain processes easier for humans . Easier transportation , easier to get an education , easier to receive treatment from healthcare . Increases in all these areas and the other areas of AI will remove tons of jobs from the economy . As the professor said in class , that most of the class has already taken an online course in AI so why are taking another AI course that s not online if you already learned the concepts . Teacher s , Road Worker s , Truck driver s , Bus driver s , and more jobs will diminish all from the market with few new jobs opening in those industries . Also , an increase in home robots will be able to help with tasks around the house which will eliminate a large variety of different jobs .

My belief is that some new jobs will still be created with the destruction of so many jobs . Most of the new jobs that will be created will be in the field of maintaining Artificial Intelligence Systems . There will continue to be new situations or problems that AI will encounter in the future , so there will have to be more jobs to analyze the AI systems and react to changes and problems quickly . People will have to learn new skills because most of the new jobs will be in different industries than what they are familiar with or got a degree in . The decrease in jobs might even decrease the choices of majors at colleges .

Finally , another statement from the article that I disagree with was that everyone should be entitled to a portion of the world s AI-produced treasures . I believe that everyone who ends up should get some amount of financial compensation . There is no way to evenly distribute the wealth that AI technologies will create . Also , in our current economy there is no regulations in place of wealth distributions from AI technologies . Also , when a new technology is created , there is no competition will other companies so the cost of using AI technologies to be very expensive to start off with . This will end up being a large debate between the inventor s behind the AI technologies and the rest of the population .
One of the key points continually restated by the study is that AI is widely applied in many fields and has mostly achieved its goals . The article states , `` until the turn of the millennium , AI 's appeal lay largely in its promise to deliver , but in the last fifteen years , much of that promise has been redeemed . '' One of the ultimate goals of AI is to be widespread in improving the quality of people 's lives , yet there are still tremendous amounts of research and development required before AI can reach this goal . While AI has certainly made significant progress in the past 15 years , I challenge that the promise remains largely unfulfilled .
One aspect of AI that requires attention and the study significantly downplays is the amount of research still needed . As analysis of large data sets becomes more demanded , research is needed to scale machine learning algorithms on large data sets to practical complexities . One of the most important factors to applying AI in real world environments is AI 's decision making . Research is still greatly needed in developing AI that can better utilize reinforcement learning and other methodologies to make good decisions in dynamic environments . This research would have many applications , from robotics to self-driving cars . Both humans and AI inherently have limits , so another key area of research needed is how to best integrate AI with human intelligence in order to optimize AI use . If AI was to have truly delivered on its promise , the list of things needed to be researched would be much smaller .
The study also exaggerates the scope of AI application . While AI has a presence in all fields , there still remains many areas that AI remains to be fully utilized . One of these areas is self-driving cars . The article states that self-driving cars are `` leading to an entirely new urban organization . '' Although they may allow for more ride-sharing and efficient transportation , cars are the world 's most widely used mode of transportation and as a result it is unlikely urban organization will change so much as to be `` entirely new . '' Self-driving cars are used infrequently in only select cities , and a lot of research and development is still needed until these cars become the dominant mode of transportation in the US . Another technology AI still has fairly limited application is in clinical healthcare . Though potentially life-saving and revolutionary to medicine , current AI is still a long way away from being used optimally in medicine , and a great deal of research is still required . The article also does not discuss potential safety concerns in medicine using AI , as even minuscule mistakes can be fatal to patients . Though AI has a wide variety of uses , these two areas provide key counterexamples for AI achieving its promises .
Another flaw of the study is that while it suggests where the field of AI may be going , it does little to suggest how we should get there . The study fails to point out specific areas of research needed , as well as how to obtain the resources for such research . The study also does not examine how to overcome social inhibitions regarding AI -LRB- especially self-driving cars -RRB- , perhaps a larger challenge than the technological ones . I would have liked to see the study cover these issues , as they could have provided key insights into how AI can deliver on its promises , which it is mostly yet to do .
About Stanford One Hundred Year Study on Artificial Intelligence , I have two aspects want to challenge .
The first aspect I want to argue is the security problem . Is Using AI technologies on the public safety no risk at all ? It is true that the AI technologies can significantly improve the ability of detecting crime and reduce the innocent people get misunderstood . Al technologies can rarely make mistakes with appropriate algorithm . However , what if the AI technologies get hacked ? For example , many police departments are using drones to maintain security . If the drones which are executing tasks get hacked , then they will be flying bombs manipulated by villains . What I want to indicate is how to make sure the AI technologies can not be hacked or what to do with the rebellious AI . In addition , the technologies that companies and governments using today are not invulnerable . Hackers always can find bugs to hack . It is not very difficult to hear some news like cyberattack causing social security and personal information exposure or government website being hacked . It means AI technologies companies still need to put effort to improve the safety of AI technologies . Otherwise the AI technologies , which are supposed to help human to maintain security , will be a potential threaten to society .
The next aspect I want to argue is employment . As the growth of AI technologies , more and more jobs can be replaced by AI technologies . For example , auto-driving will take place of transportation industry and robots will take place of assembly industry . The low skill jobs will disappear in the future and the people who are with these kinds of jobs will lose their jobs . Moreover , with the growth of deep learning , more and more high skill jobs can also be taken over . For example , lawyers , which need to spend several years and a lot of energy to be , is possible to be replaced by robots . For these human lawyers and other workers , losing jobs is just one of the problems for them . When many of them find what they strive for a very long time can be taken place by AI technologies , they will be disappointed . How to make these people to treat the appearance of AI technologies with open-mind attitude will be a problem need to be solved . On the other hand , this report states the appearance of AI technologies can create new kinds of jobs . In this way , it seems like the people who losing jobs can fit in the new kind of jobs . However , the new kinds of jobs are appeared with new mode of interaction . The new mode of interaction may not be suitable for everyone , especially to the people who are too late to learn new mode of interaction . Many elder people can not adapt the new mode of working environment because they have already lost the abilities to learn new knowledge . Therefore , how to make the transition smooth for the human is a challenge for the AI technology enterprises .
The AI technologies are so innovative that these technologies will change every side of human ` s life . People should be aware of these variations and figure out ways to deal with every result may happen .
On the topic of entertainment in the Stanford One Hundred Year Study on Artificial Intelligence there are issues not addressed by the authors . One topic lightly touched on is the machine learning , natural language processing , and image processing of companies to personalize content for the average user . While this is discussed in the paper it is only for one small paragraph . This is definitely a much larger phenomenon than they seem to represent , and the number of lives impacted in discrete ways is in the millions . Another way that the topic of entertainment is not fully covered is the absence of attempts to filter content with inappropriate or advertiser unfriendly content . While this is currently a much larger issue and source of contention it still would have been at least a minor talking point that should have been touched upon . An example would be the YouTube algorithms which filter content and automatically assign advertiser friendliness levels for new videos . YouTube also has been working on several ways to phase out content that they do not want portrayed widely on their platform . These have started to take place mostly more recently than the paper was written in 2014 , but these issues and potential areas of ambiguity in the censorship laws should have been anticipated as early as 2014 and been at least touched upon in the entertainment section of the study .
One other area that should have been better addressed by the experts assembled for this study is the grey areas and current gaps in laws and regulations governing artificial intelligence and those who are working to develop and improve on current systems . It is addressed but not in a way that is very future oriented . The general summary of this section gives a few steps for moving forward and what the government should do in regards to gaining expertise in these fields so as to be able to keep up with new developments and regulate or boost progress in certain areas . The government focused section is well reasoned and is a very valid way forward in that regard , but the study fails to address actual laws and regulations . These experts are assumably some of the most well equipped people in the world to give examples of ways that artificial intelligence being worked on at the time of the study should be encouraged or regulated . They address the laws and ambiguity of blame in regards to accidents regarding artificial intelligence , and although they could not enact any laws or regulations themselves it would give governmental officials a starting point on how to look at the complicated realm of regulating or deciding fault . Clearly these experts preferred to stay within the topics they were more familiar with and this is not a bad thing . The points made when talking about the issues that may arise or possible future developments are very well thought out . Perhaps it is an issue with the composition of the study panel , and the next study might benefit from having someone well versed in laws and regulations to step in and offer their perspective and thoughts on how regulations might change going forward when speculating about future projects and issues . The One Hundred Year Study on Artificial Intelligence outlines significant transformations that society may see due to advancements in the field of Artificial Intelligence -LRB- AI -RRB- . One important part of the study was the economic effects of AI 's potential progress , particularly on low-resource communities . The study claims that low-resource communities would reap the benefits of AI through to improved food distribution and improved spread of health care information . However , the study failed to directly address the specific economic concerns of low-resource communities and to take in to account the potential risk AI presents if future progress widens economic inequality .
The study claims that advancements in AI will be of great benefit to low-resource communities through improvements in health care and distribution of food and such improvements would indeed impact the quality of life of people in such communities . However , such benefits as these do not represent a significant improvement in quality of life in comparison to the potential advantages reaped by those outside of low-resource communities . The disparity becomes clear when considering that the improvement for one community could potentially be driverless cars and the improvement in low-resource communities could potentially be access to proper health care or food distribution . Furthermore , the study postulates that these improvements will only be seen with a significant amount of research and focus on improving low-resource communities . The study also admits that AI advancements have not traditionally been focused on low-resource communities . Therefore , such advances seem unlikely and could potentially take years to come to fruition without added incentives .
One of the main points made by the study when referencing potential economic concerns is that AI will create jobs and new categories of employment and therefore AI would not drastically alter the economy . The study does recognize that as job requirements fluctuate people may lose their `` cognitive '' jobs and such job loss will likely affect all sectors of human jobs . To mitigate such effects , the study suggests that `` education , re-training , and inventing new goods '' could potentially help -LRB- Stone et al. , 39 -RRB- . The problem with this type of solution is that people living in low-resource communities do n't have the same access to the required education and training and therefore are n't able take advantage of these prospective new jobs . Consequently , the job loss the could be experienced would not be outweighed by potential new job creation leaving low-income communities with less job opportunities . Furthermore , with less job opportunities access to the benefits of AI and the increase in living standards will also not be experienced in these communities .
In conclusion , the One Hundred Year Study succeeds as a comprehensive report of the current state of AI and the potential advances society can expect to see . However , the study fails to recognize the significant and unique challenges that such advantages present to low-resource and underprivileged communities . The effects of such progression leave these communities in danger of a widening economic inequality gap despite apparent advances that would benefit members of such communities . The potential widening of the inequality gap represents a cycle whereby members of these communities would not have access to the economic advantages of AI and therefore not able to take advantage of the full benefits of such progression .

REFERENCES

Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 11 , 2017 .
With the rapid advancements in the field of Artificial Intelligence it is no surprise that Stanford has created a study panel to summarize the latest advancements as well as discuss possible impact of these advancements in Artificial Intelligence . Of course , the fact that this study panel is comprised with some of the most intelligent and qualified individuals from many different fields makes it difficult to challenge their ideas on the future of Artificial Intelligence . The study brings up many good points and predictions for the future of the technology used in self driving cars , but the estimation of when self-driving cars will be widely accepted and the absence of discussion on the lack of need and desire of this technology which will limit its acceptance and use is something that I do not agree with . The possible small market for self-driving cars will prolong the wait for when this technology will be widely used by the population .
The idea of everyone switching over from the cars which we use and drive today to new self-driving cars may seem like an obvious and logical change that everyone should make . Even the Stanford One Hundred Year Study on Artificial Intelligence stated that self-driving cars could be widely used by the year 2020 . Unfortunately , the study panel may not have considered the desire and need for this new technology when using this estimation in their report . The idea that self-driving cars will be widely used and accepted in only a few short years implies that this technology is needed by vast amount of people for transportation . A self-driving car will be considered as more of a luxury item rather than a need due to the cost associated with buying and maintaining a new car along with the fact that we already have many different cheap types of transportation . This cost may cause many to wait on making the switch to the new automated vehicles . Another factor that may slow the overall switch to these new automobiles is the lack of desire for these new vehicles . Many individuals do not want a self-driving car because they enjoy the experience of driving and maintaining their cars . The more advanced technology that s used in self-driving vehicles along with this technology being added to mostly electric cars will limit the amount of people who will want to buy these vehicles in the future .
The high cost associated with switching vehicles along with the low need and desire for self-driving cars will limit the number of individuals that will purchase these vehicles . The fact that in late 2017 companies are still not mass producing completely self-driving cars and policies permitting the use of self-driving cars are still being worked on , 2020 is looking like an unrealistic estimation . The absence of this discussion in the Stanford One Hundred Year Study on Artificial Intelligence is surprising and should be considered when creating the next report . It will take many years for a need and desire for these vehicles to grow as well as create and implement policies involving this new technology . It is inevitable that the use of self-driving cars will eventually be widely accepted and used by many whether for personal or public use , but not for many years . Artificial Intelligence is undoubtedly the most discussed topic in science field nowadays . Eric Horvitz , the then president of the Association for the Advancement of the Artificial Intelligence , once convened a scholar meeting which assembled experts in artificial intelligence and from other fields such as cognitive science , philosophy and law . They worked together to discuss advancement of artificial intelligence and its development in other areas with concerns of ethical and legal issues -LRB- Report of the 2015 Study Panel , September 2016 -RRB- . Artificial Intelligence has already drawn attentions from experts in most areas not just computer science .
As stated in Artificial intelligence and life in 2030 , artificial intelligence is becoming to construct a more effective way to collaborate and interact with people and intend to build a better life for human . However , Artificial Intelligence may not always be the solution for issues such as employment , education and security .
Applying artificial intelligence technology into people s daily life will bring a tremendous transformation of the whole employment market . A large number of traditional occupations are likely to be replaced by artificial intelligence technology such as janitors , security guards and workers on the assembly lines . Such rather simple tasks are going to be gradually replaced by artificial intelligence technology . Even though artificial intelligence technology will spur new jobs , whether the number of new jobs created by AI covers the loss in the number of traditional jobs is yet to be known . In additional , new jobs inspired by AI technology requires employers to possess brand new skills and knowledge in order to finish their jobs , so those new job positions are likely to go through a period with an absence of qualifying employers , while there will still be a number of unemployed people because of artificial intelligence . With a decreasing in employment rate , there is going to be an unavoidable social issues arise .
Since artificial intelligence might require employers to possess new knowledge and skill to be eligible for new jobs spurred by AI technology , education is another important area that AI involved in . Transition from traditional classroom to artificial intelligence driven one might require a period time in which some students might find it difficult to get accommodate to , thus end up with a decrease in grades . In addition , AI is not as good as human beings when encounter with ethical issues , so high quality education still requires real human to teach student knowledge and life .
Furthermore , artificial intelligence may provide more advanced method to distinguish crime such as cybercrime , but it sometime still can be vulnerable . Artificial Intelligence is computer program that are coded by human , which means hackers can still seek for vulnerability in the system and gain control over it . For example , if hackers override the AI program that is used to monitor cybercrime such as credit card fraud , they can easily commit crime without any supervision . Additionally , if people put too much faith into the capability of AI as security system , once it is down , they have no other method to track criminals .

The Stanford 100-year study on AI aims to predict and guide use of Artificial Intelligence within society . It did so by focusing on societal trends and technological adoption within US cities , and looking ahead to the year 2030 . I argue that by focusing on cities only , the study overlooked and underestimated significant elements of resistance within society at-large which will hamper some of the predictions within the study .
Within the transportation sector , the study predicted that autonomous vehicles would significantly alter lifestyles by becoming the dominant mode of transportation . While I would accept the proposition that public transit will be significantly enhanced through AI , rural communities who do not rely on public transit today , or who have insufficient funding to even maintain their roads , will struggle to adopt autonomous transportation . A typical vehicle produced since 2000 already has an expected lifespan of 15 years or more , which means vehicles on the road today will still be on the road in 2030 . Having those millions of vehicles on the road will force public policy to continue to accept human-driven vehicles , and all the additional legal and safety complexities associated with the interaction of AI and human drivers . We also can not overlook that in many parts of US culture , driving is closely associated with power and self-importance : see marketing directed at buying powerful trucks to work on farms and construction . These cultures often have underlying resistance towards strong central government as well , specifically where personal privacy is concerned . AI transportation networks would be increasingly limited if they are unable to communicate and coordinate with other vehicles within the network , which limits the overall possible gains from such a system . As with many other technologies , we 're more likely to see better AI transit adoption in pockets -LRB- university systems , strong centralized governments such as Sweden -RRB- throughout the world , but it will take longer than 15 years for society at-large to catch up .
The study also made predictions in the public safety sector , such as the concept that AI can assist in `` predictive policing '' and crime prevention . The study itself acknowledged repeatedly that this concept is prone to institutional discrimination , but I believe it fell short in predicting just how large a barrier this is to progress . We need only look at the news the last couple months to see incident after incident of alleged police brutality and racial profiling . While at a technical level I would completely agree that it 's possible to design `` neutral and objective '' algorithms to assist law enforcement , who exactly would be in a position to enforce that standard ? How would that organization earn the public 's trust enough that cultures , with decades of history of being discriminated against , believe that the system is inherently fair ? Repeating the privacy concern , I do not believe rural/poor communities with a history of resisting strong central government will willingly allow a database to be created to effectively facilitate predictive law enforcement . The study can make light of Minority Report type situations , but reality is people will assume exactly that is going on , and the efforts to earn public trust will be slow and lengthy .
Across all sectors , similar claims can be made . People today discriminate against healthcare professionals who do not share their race , but we hope they will trust a computer to give them medical advice ? With the divisive nature of politics in the country , we hope an agreement can be reached regarding AI-generated wealth ? These are great thoughts and dreams , but there is much yet to overcome before they can become reality .
Artificial Intelligence -LRB- AI -RRB- has made steadfast improvements from the time of its conception . Indeed , this is because of the advancement of technology , as well an increase in our understanding of how to implement it . AI has led to a rise in efficiency in its areas of usage . This can be observed in the transport industry , where self-driving AI vehicles have become fully autonomous , albeit with a few kinks . Major companies such as Uber , Tesla and Google are testing self-driving vehicles in public with great success .
While there has been a great deal of talk about the success of these tests , there is also a great deal of discussion as to what would happen to those people who would ultimately lose their job to a computer . According to the report by the Study Panel , the advent of AI will eventually bring in new jobs . I disagree with this statement , as AI will lead to more jobs being lost than those it provides .
The Study Panel states that while jobs will be lost due to AI , they will lead to the creation of new jobs which have higher importance . While this is true , it does not make a case for the people who lose their jobs in the first place . When an AI system is installed , new jobs would come in the form of computer related ones for monitoring the system , or those where a human is required as a backup or for safety purposes . According to the National Center for Education Statistics , the percentage of individuals who have graduated college is roughly 60 percent . This means that while the new jobs AI creates will be taken , they won t by those who lost their jobs to it . For example , if Uber were to implement self-driving taxis , the taxi driver that was replaced by the AI would not get a new job monitoring the car . This simply because those who lose their jobs are typically from a less educated background . They do not have the skills required for the new job .
Another factor due to which AI will lead to loss of jobs is that it is cutting more of them than creating . Ultimately , AI aims to perfect and be more efficient in its jobs . This is against human nature , which we know is prone to cause an error from time to time . This means that one AI system could possibly replace multiple humans doing the same job . This has been previously observed with robots in car manufacturing , which can cut a sheet of metal to the precise measurements countless times . In AI , we can look in the customer service industry . Currently people usually handle customers through the phone . With the development of AI which is capable of conversing with humans , one system could possibly replace an entire call center , leading to the loss of hundreds of jobs .
Therefore , since those who lose their jobs due to AI can not be offered a job on grounds of skills and the fact that one AI system which would be cheaper for the company will replace hundreds of people , Artificial Intelligence will in fact lead to more losses in jobs than those it provides .
As artificial intelligence continues to be improved upon , it will become better than humans at many tasks . From driving , to retrieving medical information , it appears that there are an incredible number of ways AI can be utilized as outlined by Stanford s One Hundred Year Study on Artificial Intelligence . However , there was one claim that artificial intelligence has the ability to create art and music . I refute this point by claiming that art can not be created by artificial intelligence alone , for it lacks the ability to be creative and express itself .
Humans are the ones responsible for creating the methodology for programs to reach a conclusion , not an expression . In order to explore this idea , Google s deep dream generator can be examined . Arguably the most iconic example of visual manipulation through the implementation of AI technology , this program has the ability to take two images and create a mash-up using deep neural networks . The program creates a psychedelic transformative picture that was put together completely by AI . In addition , Google has started a project called Magenta that has the ability to generate pictures and musical compositions . Even though AI is able to produce images and compositions , the actual product is not art created by AI . As futurist Jaron Lanier explains , AI assisted media ultimately still comes from people , and the problem from that is that the people are made anonymous . This means that media created with the assistance of AI is technically art that can be attributed to the person that contributed the newest input in addition to the humans that coded the program .
The article goes on later to claim that in the future , AI will simply help humans create media . Interestingly , this portion of the article was incredibly vague in how AI would be able to assist in creating media . It is important to make the distinction that true art must be the result of some human effort , for it is still up to humans to make the creative decisions . Why does this matter ? This exposes a limitation of AI . Programs produce a result determined by directed paths based on predetermined logic . Human expression is not always based on logic , but often based on emotion .
That leads to one final question : will AI ever be able to express emotion ? The answer to this is complicated , but the answer is that it is unlikely since there are many physical and natural reasons why humans feel emotions . Many emotions can be informed and altered by factors such as the air we breathe or the foods we eat . Fear , disgust , and nausea are all created by external factors that would be almost impossible to emulate . In addition , love and sex are based on humans innate need to recreate . Finally , robots can not mature in the way humans can . AI lacks the ability to emotionally grow , experience hormonal changes , or have other chemicals influence thought .
In conclusion , AI needs to be able to express emotion in order to truly create art . Without the ability to inhabit a human body , AI will forever be limited to being a tool in order to help humans create media . Despite this , it will be fun to see what artists and programmers can produce in the future with the help of new AI technologies .

Sources : http://hplusmagazine.com/2014/04/29/could-a-machine-or-an-ai-ever-feel-human-like-emotions/

http://www.popsci.com/can-computer-make-art


The first report of Stanford One Hundred Year Study went in depth about the extensive benefits of Artificial Intelligence 15 years from now . The panel concluded that AI will have a positive impact on many fields including transportation and security . However , the paper underestimates some of the many financial and social issues that will prevent private vehicles from replacing public transportation and slow down the incorporation of AI into security cameras around the city .
The Stanford paper predicts that with improvements of artificial intelligence in transportation the need of public transportation will be replaced with shared transportation or by other services that provide a vehicle to deliver them to the destination . However , the paper fails to consider the financial issues that keeps individuals dependent on public transportation . Many people will be deterred from sharing vehicles because it would still require the passengers to pay for parking in the city . With rising parking fees , due to an increased demand , there will be a larger incentive to use public over private vehicles . The paper also over estimates how much people will value using automatic cars over public transportation due to convenience . Public transportation will be more appealing than self driving cars due to the ability to avoid the rush hour grid lock . According to American Public Transportation Association , last year public transportations gave 10.4 billion rides . With the removal of public transportation , the traffic especially during rush hour would get worse and give people more incentive to go back to public transportation . Depending on an individuals destination , public transportation such as subways and trains may provide a faster and a more convenient form of transportation . With the current dependency of public transportation , it is unlikely that private vehicles would replace it entirely . These are only a few of the reasons why public transportation will continue to thrive after automatic vehicles becomes widely accepted .

The paper states that improvements of AI will make society safer due to the ability of computers to identify risks and react accordingly . The paper assumes that as AI continues to develop , authorities will start utilizing them to monitor the cameras to inform them of potential crimes . The paper underestimates public resistance to being continuously monitored by cameras spread throughout the city . According to the The Effect of CCTV on Public Safety by Leighton Walter Kille and Martin Maximino , 78 % respondents of a poll by New York Times and CBS supported the use of surveillance cameras . Many people will likely find these cameras an infringement of their personal privacy . As AI gains that ability to monitor all surveillance cameras and surveillance cover increases , there will be more people uneased by the constant surveillance . There are also many concerns about how authorities will utilize the cameras . There have been many instances where authorities has used cameras for personal gain or to stalk an individual . The government will need to first gain public trust by slowly adding on cameras though out the city and making the citizens feel that the cameras are providing more good than harm . The paper also did not consider the financial issues of dependency of security cameras . The United States will need to spend millions to implement the new technology and to maintain them throughout the years . Although the surveillance will provide significant contributions , the implantation of these cameras will likely be delayed due to financial and social reasons .

Work Cited


Kille , Leighton Walter , and Martin Maximino . The Effect of CCTV on Public Safety : Research Roundup . Journalist 's Resource , 9 Feb. 2017 , journalistsresource.org/studies/government/criminal-justice/surveillance-cameras-and-crime .
Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .
Public Transportation . Public Transportation Benefits , American Public Transportation Association , 2017 , www.apta.com/mediacenter/ptbenefits/Pages/default.aspx .


Growing up in an age of technology where the growth was so rapid , there were many times in my childhood and teenage years that I held the belief that given enough time and resources , anything and everything would be possible . As I grew older and my understanding of artificial intelligence began to develop , I still hold on to the belief that the limits are not yet known of where technology can take us . The timetable to which I think about more Is the near future based on the current state that technology and more specifically artificial intelligence is currently in . In a report done by the AAAI titled , `` One Hundred Year Study on Artificial Intelligence '' , they analyze the current state of artificial intelligence and possible future endeavors in many different aspects of life . I was extremely intrigued with many of the ideas and possibilities that were presented throughout this report as they were obviously given a lot of thought as they were thorough with concrete examples of things we already use and how those things can grow in a realistic manner . There was one area , however , that maybe did n't concern me , but made me question the timetable and total success of the idea . The field in the report that I am going to critique is the area of home robots and personal service robots .
When it comes to the field of personal service robots or robots that do usual home activities , there have admittedly been great strides in the past few years . The report brought up the fact of personal home vacuums and how they uses sensors to detect surroundings and perform that task without human assistance . A point was raised where these vacuums are currently limited to flat surfaces and are unable to do any climbing or maneuvering over and across different things . I think it is pretty easy to believe that technology will be reached in the very near future . That is not the area that I am going to be critiquing . What I want to challenge is the timetable and possibility of personal home robots that have the ability to verbally communicate with humans and complete daily household tasks . I do not want to say that there is no possibility of this level of artificial intelligence is unreachable in the next 15 years as the technology for verbal communication and searches is becoming very advanced in current devices like Alexa and Siri . Specifically I see there being limits on the amount of resources that this could take to get this advanced of technology into the hands of the many households that exist in todays society to make it a staple in everyday human life . Secondly a limit to the timetable of this would be the financial means of the middle class individual to feel like this technology is worth the price to possibly simplify a few tasks around the house that they have already been doing all of their life . Lastly , it is extremely hard to mimic or replicate the actions of humans and their adaptability when it comes to emotion can not be replicated when decision making .
All in all , the thought and possibilities of all the information and ideas presented in this report have strong elaboration that make it hard to argue the possibly reality of it . Of course in an ideal world we would love to see these technologies come to life as soon as possible . I am excited to watch and follow not only this report but the world of artificial intelligence as my life goes on .

-LCB- \ rtf1 \ ansi \ ansicpg1252 \ cocoartf1504 \ cocoasubrtf830
-LCB- \ fonttbl \ f0 \ fswiss \ fcharset0 Helvetica ; -RCB-
-LCB- \ colortbl ; \ red255 \ green255 \ blue255 ; -RCB-
-LCB- \* \ expandedcolortbl ; ; -RCB-
\ margl1440 \ margr1440 \ vieww10800 \ viewh8400 \ viewkind0
\ deftab720
\ pard \ pardeftab720 \ ri0 \ partightenfactor0

\ f0 \ fs24 \ cf0 Even though technology has been developed so much since the ancient times , the way we teach doesn \ ' 92t change much through history . Cutting edge technologies like genetic testing or quantum physics offer students so many possibilities to explore . However , the way professors deliver knowledge - through face to face lectures and group discussions - is no different from the old days in Plato \ ' 92s era . Thus , the essential characteristic of education always remains the same , and AI technology would only be able to assist human instructors in limited ways . I would like to challenge several arguments found in the Stanford Report in my following essay . \
\
First of all , the report argues that AI would improve education at different levels for students by providing them more personalized plans . However , I disagree with the argument because our current days AI personalized products show negative effects on narrowing users \ '92 choices which prohibit users from broadening their knowledge in various subjects . People who do web surfing a lot should have experienced AI tailored products everyday through YouTube recommended videos , Facebook advertisements and news feeds from various mobile apps . It is true that almost all of them do a good job to deduce users \ '92 interests and provide them with the most relevant feeds . But relevant to previous searching does not equal to personalized . I might be mostly interested in government decisions and thus clicked on some economic and political related article . However , that should not exclude me from receiving any other scientific breakthroughs news and being updated . Education is about broadening students \ '92 perspective \ ' 92s . That \ ' 92s the reason why university admits students from various background and a degree needs general education curriculum . Thus , I am questioning if AI would be able to provide smart personalized plan and take individual \ ' 92s personality , current trends and many other factors into account . \
\
Secondly , the Study Panel used the example of cognitive tutors to illustrate that future AI technology could mimic the role of a human tutor by providing hints properly and offering context specific feedbacks . However , being as a tutor on campus for a year , I think this is really challenging for AI . A competent tutor should not only increase students \ '92 academic performance but also engage students in studying , connect with students after class and identify their understanding level based on their body language . This face to face interaction stimulates many questions : How could computers present themselves as active listeners ? When could computers interpret students \ '92 nodding as a valid signal of understanding ? Detecting students \ '92 subtle reactions and surmising their psychological movement requires extra training even on human being . It would need sophisticated algorithm for teaching AI to work at the same level . Those questions also undermine the report \ ' 92s claim that professors could employ AI technology to increase the size of classroom while maintaining the quality by assigning exercise like multiple choice questions . Again , this lack of interaction could not engage students as they otherwise would be . In addition , testing through standardized answers will dramatically decrease students \ '92 critical thinking ability . \
\
Thus , future AI technology \ ' 92s ability to personalize education and to behave like human tutor is under questioning . Even though AI \ ' 92s knowledge base and its competence on completing certain tasks may excel human intelligence , it \ ' 92s capacity to smartly associate our personality and interests with other subjects and to integrate comfortable human interaction can barely match to human \ ' 92s ability . \
\ pard \ pardeftab720 \ ri0 \ partightenfactor0
\ cf0 \
\
-RCB- I challenge the study 's assumption that autonomous vehicles will become commonplace by 2020 . In fields like healthcare and education , AI is largely self-contained and does not have the potential to create troubling scenarios as it does in autonomous driving .

While capabilities like perception , GPS and the plethora of sensors driving the AI might make a very good driver indeed , it raises thorny ethical questions . When it comes to an inevitable situation , how does a vehicle decide between saving the life of its driver and that of a pedestrian ? How should a vehicle choose between its driver and that of ten pedestrians ? In case the car decides purely based on the number of lives put at risk , would a potential customer still be willing to purchase the vehicle given that the car might sacrifice his life if it comes to the worst ? The study also mentions self-driving trucks becoming the norm soon . Would businesses be willing to transport precious cargo with the knowledge that it might be destroyed in case the truck must choose between the cargo and a life ? All these arguments have been largely quantifiable in terms of lives . How do we handle when a vehicle must choose between its driver and another vehicle on the road , where the distinction between the number of lives is less clear ?

Given that an AI developing compassion , valuing a life and other human emotions is still far off , it falls to the manufacturer and its engineers to decide what the vehicle must be programmed to do in these scenarios . Mercedes for instance has publicly made a statement that its autonomous vehicles will prioritize its occupants over any pedestrian -LSB- 1 -RSB- . On the same lines , a truck manufacturer might be willing to prioritize the cargo over anything else . This implies that all autonomous systems must be heavily regulated much like other industries and making every vehicle in the country conform to this regulation would a long endeavor and not something achievable by 2020 . It also opens the question as to what happens to those citizens who choose to drive by themselves rather than adopt to self-driving vehicles and how they fit into the system given that the roads are common and will be shared .

There 's also the issue that these are real time , life-critical systems and given that the automobile manufacturers thrive on annual servicing , we will have to deal with problems like sensor malfunction and security threats . A recent study also concluded that 75 % of drivers do not feel comfortable putting their trust into a machine and they fear that they will be forced into a position of being unable to seize control from the car in case of any unforeseen circumstances -LSB- 2 -RSB- . We will also have to confront potential fallout from the loss of jobs this would entail as millions of truck drivers in the United States would lose their livelihood .

Given that this topic is currently being debated by the senate -LSB- 3 -RSB- , it might be worthwhile to consider these questions while drafting a bill such as this with far flung consequences .

References :
-LSB- 1 -RSB- http://www.futuristgerd.com/2017/08/27/why-mercedes-decision-to-let-its-self-driving-cars-kill-pedestrians-is-probably-the-right-thing-to-do-says-bloomberg/
-LSB- 2 -RSB- https://spectrum.ieee.org/cars-that-think/transportation/self-driving/driverless-cars-inspire-both-fear-and-hope
-LSB- 3 -RSB- https://www.reuters.com/article/us-usa-selfdriving/senators-unveil-road-map-for-self-driving-car-legislation-idUSKBN1942QJ

When teaching a class of grade school or high school students in the current system , the teacher goes at a pace that they think students can learn best at . However , since all kids learn at different speeds , the class will move at the pace of a select few students . The students that move slower than the select group will fall behind and not learn nearly what they should from the class . The students that learn faster than the select group will be bored and not be learning to their full capability . The best way to solve this is to either have personal teacher for each student so that they can move at their own pace , which is very expensive and unrealistic , or have computer programs teach students induvial using artificial intelligence to create a personalized curriculum to best benefited the students learning . The Artificial Intelligence and Life in 2030 education section claimed that the classroom will always need a teacher to assist in learning for k-12 classes , but that is not the case .
With learning from a computer program , the student with have a completely unique learning experience . Using Artificial Intelligence , the program can learn what the student s strengths and weakness are , and use them to teach the student as efficiently as possible . Even a great teacher will struggle to do that with a class of twenty plus students . The program will also use quizzes and questions to figure out what the student already knows and what it has learned from the program to move onto new subjects , instead of teaching the student something that it already knows . In addition , the program will be able to stay on a subject longer if the student is struggling . Where a teacher would have to teach at the pace of the class instead of the pace of the individual .
Certain classes are easier to be taught by computers and IA such as math , science , computer programming . Classes where there are strict right and wrong answers are much easier for computers to understand and to teach . Classes such as English are harder to teach and grade by computers , but IA should soon be able to judge what good and bad writing looks like . Soon it could be expected that the computer can judge a paper better than a human teacher , it can understand the logic better and be able to quickly tell if a fact or quote written is correct or not .
In more advanced classes such as college level classes , the professor is a very important part of the learning experience because they are very well qualified . The professor will help students learn how to work in the job world and master the subject more than a computer at this point will be able to .
While someone will still need to supervise and help smaller children with learning human interaction skills , this person would not be a teacher more of a babysitter . The human interaction part is one of the most important things for small children to learn , and with computers teaching the children more efficiently , the children will have more time for fun and playing with each other .

I believe Section II : AI by Domain does a great job of explaining what has already been accomplished with AI and just as good of a job in predicating where AI will be in the coming years . While the description of the technology is great , the ideas of how to change public policy and what needs to be addressed when considering changes to AI predicting Section III is not equally as progressive as the changes that Section II predicts . Section II predicts a cultural shift in how AI is adopted , while Section III frames the needs public policy within the current public policy climate . For the changes in culture caused by AI to be as significant as they have the potential to be , the public policy and regulations that govern them need to change just as progressively .

AI policy , Now and in the Future , Policy and Legal Considerations contains a laundry list of legal or policy items that are based on the fears of the present day . AI policy can not be restrictive , a cultural shift is necessary . To see how mild the considerations are for policy , look first at privacy . The section on privacy suggests that society will still have the same attitudes towards machines and technology storing personal information . Out of both necessity and changes in generational attitudes , the requirement and need for privacy will dissipate . There is an inherent need for AI of the future to store personal data . For example , if one was taking a trip in a self-driving car , the destination and time and other metadata of the ride must be stored for both billing , safety , and liability reasons . Even though there will be a significant rise in the sensitive and metadata stored on people , there is and will be a rise in the acceptance in sharing personal data . This can already be seen today . Older generations such as baby boomers and Gen Xers are typically more concerned about what they share with websites and other technology , while millennials broadly are willing to give out sensitive information to any source and often post invasively personal life details on social media for the world to see . Whether the influx in data is a good thing for society and its people is not the point of this paper , but rather that it is happening . This change is happening and public policy will be dictated by AI , rather than the other way around .

Another possibly problematic section of AI policy , Now and in the Future , Policy and Legal Considerations is Liability , both civil and criminal . The study makes the assumption that there will even be liability considerations in place eventually . While there will be liability laws during the early days of AI , as time progresses they will become irrelevant and unnecessary . As AI nears perfection , the incidence of liability will nearly vanish and when unfortunate or damaging events occur they will be treated as a coincidence rather than an event where fault must be found . A machine was at fault and society will someday adapt to accept that the event was a freak accident , and maybe take the event into account with reinforcement learning .

Above all else , public policy makers want the economic benefits from AI and more broadly technology , so they will accept what consequences that AI brings . AI is the future of everything , and policy will be written and regulations cut to speed its development -LRB- see self-driving cars in NV -RRB- rather than public policy written to hinder its development .

Kyle VanderHeiden
Advances in Artificial Intelligence already have and will continue to have a massive effect on industry and jobs . As new technologies appear and existing ones are refined , human laborers are able to be replaced by machines which can do the same jobs faster , better , and for less money . `` Artificial Intelligence and Life in 2030 '' makes the argument that AI is poised to replace jobs in certain fields but also claims that AI will create many new jobs . The article makes no mention of what these new jobs may be . While it is most likely true that some new jobs will emerge as a result of AI advances , there is no reason to believe these new jobs will appear in significant numbers . The number of jobs lost will most certainly vastly outweigh the number of new jobs created , eventually leaving exclusively highly skilled jobs .
The article also argues that AI will effectively make everyone better off by reducing the costs of goods and services . While it may be true that goods and services will be cheaper due to lower production costs , this wo n't result in a net positive effect on the average person if jobs and a steady living wage become harder to obtain . The aricle even presents evidence that since the 1990s the median income has remained the same and employment to population ratio has fallen in spite of increased productivity and GDP in the U.S. . This trend has mostly been the result of non-AI technologies but there is no reason to think that this trend should n't continue with AI-related technologies . In fact , the trend will most likely increase to the point where wealth distribution becomes even more uneven . Without significant socio-economic changes , it is probable that AI will simply make the owners of the technology richer while the average person finds it harder to earn a living wage .
The article claims that everyone should be entitled to the wealth created by AI technologies . In an ideal world that may be true ; however , that requires getting those who own the technologies to share the profits which result from their use . In a country full of large corporations whose primary goals are to maximize profits , it will be extremely difficult to redistribute profits away from those corporations . It is especially difficult when many of those corporations hold influence in the government .
It is inevitable that in the future there will be less jobs as a result of increasingly complex AI . Many people will probably not be able to find any kind of job . Because of this , it is important to begin discussions regarding how to protect the general population from financial disaster as soon as possible . Many new policies to redistribute wealth will probably need to be put in place . This will inevitably be a long process . It is better if preparations are put in place early , otherwise it is possible that too much time could pass and it could become too late to adequately deal with the economic shift caused by AI advancements . Artificial Intelligence , and its many implementations , is growing in our world . With the
many ways it could advantageously improve our societies , it is no wonder that researchers have
been studying the possibilities . In the One Hundred Year Study of Artificial Intelligence , the
panel was largely optimistic about where artificial intelligence in the healthcare field was
headed ; however , there are some concerns about AI s consequences that seemed to have only
been briefly touched upon . As beneficial as AI could be in healthcare , concerns of privacy and
negative impacts of doctors and other medical professionals relying on this technology need to
be looked at further . Challenging this study , AI could be more of a hindrance than a help when it
comes to certain healthcare technologies .

Looking at the many implementations of AI in healthcare , the panel argues that AI could
be used for many different things including automated image interpretation which could cut
down on diagnosis time and help with accuracy . However , Komorowski and Celi -LRB- 2017 -RRB- bring
up that this could lead to overdiagnosis ; the detection of an actual disease that , if it had
remained undetected , would not have affected a person s life . This could lead to patient
anxiety , the harm from further testing and unnecessary treatment , and the opportunity cost of
wasted time on the part of both patient and provider and healthcare resources that could be better
used to treat or prevent genuine illness -LRB- p. 2 -RRB- . It is consequences like these where the idea of the
technology is to be helpful , but unforeseeable costs pop up and create more harm than should .

Privacy is a huge concern in our society . Especially with protecting individual s medical
records and information , it is essential that individual s rights according to HIPAA are
maintained when creating AI technologies in healthcare . The regard that the study panel seems to
have for privacy protection , like for HIPAA , is concerning . By downplaying these types of
policies , they write , Unfortunately , there are many remaining barriers to rapid innovation .
HIPAA requirements for protecting patient privacy create legal barriers to the flow of patient
data to applications that could utilize AI technologies -LRB- p. 27 -RRB- . The rhetoric they use here
insinuates that these protections are in the way of creating these important technologies . Rather ,
there should be equal emphasis on the importance of both matters . Besides these policies , there is
also concern with privacy when these technologies are being utilized . These technological
developments pose challenges for a consent model of data collection , and may lead to an
increase in data privacy risks ... For example , decision-making machines may be used to
engender or manipulate the trust of the user , and would be an all seeing , all remembering in -
house guests , that would collect personal data via numerous sensors -LRB- Gardner , 2016 -RRB- . The issue
of privacy is not just about keeping individual s information private . It is also about making sure
people are aware of the aspects of allowing their information to be used and what that means for
them and their privacy .

Overall , AI could be very useful in the healthcare field . However , the negative
consequences of AI technology and privacy concerns could do more harm than it should . As
much as the panel wants to get this AI technology out and into healthcare fields , more attention
needs to be paid to how things like privacy could be impacted and the possible negative
consequences produced by these technologies .




References

Gardner , S. -LRB- 2016 , Oct 19 -RRB- . Artificial Intelligence Poses Data Privacy Challenges . Retrieved
from https://www.bna.com/artificial-intelligence-poses-n57982079158/
Komorowski , M. A. , & Celi , L. -LRB- 2017 -RRB- . Will Artificial Intelligence Contribute to Overuse in
Healthcare ? * . Critical Care Medicine , 45 -LRB- 5 -RRB- , 912-913 .

Thoughts about Artificial Intelligence

With the AI technology developed rapidly in the last 100 years , our life has been changed dramatically by Artificial intelligence . From the article about the study of AI by Stanford University , we are aware that lots of aspects in the future will be featured with well-developed Artificial Intelligence .

Transportation will be improved by AI . Automated driving and even self-driving vehicles will be introduced to people daily life . There would be less traffic congestion , potential collision and more efficiency when people commute every day because of Artificial Intelligence improves the way vehicles are being driven .

Furthermore , the article talks about health care will be improved by Artificial Intelligence . Because of self-learning and advanced analysis , healthcare and clinical surgery have been well assisted with Artificial Intelligence . As the results , patients will always be treated personally and punctually , which decreases the possibility of death of some terrible diseases .

However , even though it looks like Artificial Intelligence is helpful and beneficial , from my perspective , not all aspects listed in the article are good for Artificial Intelligence . For example , it may not be a good idea to have Artificial Intelligence involved into education and replace human teachers .

For kids in elementary school , teachers are their mentors and friends . It is the right time for them to know the world and understand our society . Human teachers can tell the emotions and feeling of each student and have physical interactions with these young students . Artificial Intelligence could be useful when they are used to teach technical problems and sometimes create personal study plan for different students , however , young kids in elementary school also need to be emotionally taken care of . Only human teacher can tell how each student feel every day by his status and action . For Artificial Intelligence , this is a conundrum for programmer to capture every detail and analyze people emotions . It is the key difference between human and computer . Human teacher can easily take care of young student and be as a mentor . Artificial Intelligence can not know people feelings and physically engage with them .

For high school students , replacing human teachers by Artificial Intelligence may not be a good idea either . Neither teaching bots nor online AI learning will be much useful for high school students . If students are taught by bots every day , there is no one to supervise them to study and listen to the bots . Same results come with online learning . Although online learning will give students best and most efficient way to learn from textbook , students do not tend to study by themselves . Everyone can be too lazy to listen to the program . They may play videos online and just leave them like that while playing football with friends . Artificial Intelligence is not like human teacher that can direct and observe students . Human teacher can guide students in the right efficient way as AI program . As the consequence , it is more beneficial for high school students to be taught by real human teacher to truly study from the classes and textbook .

Artificial intelligence can partially assist human teacher to have a better way teaching each different student but it can replace human teacher by its developed teaching bots or Intelligent Tutoring System . It serves as a tool to improve study but education may not be the best aspect for Artificial Intelligence to involve in .
While the Stanford AI100 2015 Study Panel 's report provides a detailed account of the present state of Artificial Intelligence -LRB- AI -RRB- and offers well-articulated predictions for its future , the report does not remain entirely neutral . In particular , the report demonstrates a bias towards AI in the Employment and Workplace section by underestimating and misrepresenting the likely negative effects of AI on employment . Overall , the report anticipates changes in employment trends but remains optimistic about the effects of AI on peoples ' livelihoods . In truth , the introduction of some new AI technologies is likely to have a more disruptive impact on employment than the report predicts .

To begin with , the report offers only a shallow analysis of the types of industries and employees that will be affected by AI . The report claims that to date , AI has mostly disrupted industries that employ medium-skilled workers and implies that this trend is likely to continue . This analysis fails to take into consideration the impact of AI on low-skilled workers . Various AI technologies have already replaced large swaths of low-skilled workers or are primed to do so in the near future . Consider self-driving cars , which are discussed in a different section of the article , for instance . Once autonomous vehicle technology meets a certain standard of reliability and the law permits , we can expect many low-skilled workers to lose their jobs . This includes taxi and Uber drivers , truckers , delivery drivers and other workers whose occupation is fundamentally based on manually operating a vehicle .

The report also paints an overly simplistic picture of the impact of AI on the job market by failing to speculate on the types of new jobs that AI will create . The report 's acknowledgement of probable job loss and subsequent prediction that AI will also create new jobs seems to suggest that AI will have a net-neutral effect on the job market . Although the impact may indeed be net-neutral in terms of total employment rates , considering the nature of the new jobs that AI will likely create gives us a more accurate understanding of how new technologies will transform workplace and employment norms . An article by the MIT Sloan Management Review offers some speculation on the types of jobs that AI will create and categorizes them into three main groups . The first category is comprised of roles that will involve teaching AI how to perform certain tasks . The second category , referred to as `` explainers '' , includes roles that entail facilitating communication about AI between tech experts and business leaders . The final category called `` sustainers '' will include people who are responsible for ensuring that AI systems continue to perform as intended . All of these job categories are related to AI systems and require an advanced level of technical expertise . The nature of these jobs marks a future transition to a workforce which predominantly consists of high-skilled workers . This once again highlights the pattern of low-skill jobs decreasing in number - a trend that the Stanford reports fails to recognize explicitly .

In conclusion , the report presents a somewhat inaccurate picture of the impact of AI on the workplace and employment . Contrary to the predictions made in the report , AI will likely heavily impact low-skilled workers . Furthermore , despite the fact that AI will create new jobs , the introduction of new AI technologies will still be disruptive in job markets as the new jobs will demand a significantly more advanced skill-set than the jobs that will be replaced . Recognizing and anticipating these issues beforehand will be a crucial part of creating a technologically advanced society that benefits everyone . The One Hundred Year Study on Artificial Intelligence makes some tenuous arguments , to say the least , on the readiness
and efficacy of AI policing the populace within the next 15 years .

While the use of cameras to both solve and prevent crimes is widely prevalent today , it takes a leap of faith to assume
that within 15 years the typical North American city will have adopted some form of AI to manage all this data . For laws to have
been passed to allow such systems to exist would mean that the public has approved of AI for some time , and for a 15-year
timespan that doesn t sound reasonable . Even if the technology were capable say 10 years from now to enable public opinion to
change and then laws to be passed , there s still the ethical dilemma that many in the public will face in whether or not they
wish to exchange some part of their privacy for added security . Based off the relatively recent events with the NSA spying on
the public , a lot of people are likely hesitant to agree to the government constantly monitoring them via cameras and social
media .

The study s assertions on AI preventing crime by profiling also proves troublesome . No matter how it s sliced , such a
system would have some sort of bias that weights some behavior as more dangerous than other and as such targets certain groups
of people . While profiling is near impossible to prevent no matter who monitors the data , if an AI is implemented the profiling
will have a far greater reach . When first implemented it d likely be used for additional screening at airports , however , a
dangerous precedent could be set that could lead to a path of increasing pervasiveness of a police state .

The implementation of AI that sorts through social media would also be very difficult . It s challenging enough to pick
up intent based off of changes in intonation when someone is speaking , but telling the difference between seriousness and sarcasm
from text only would be near impossible for AI . To allow an AI that struggles to detect such nuances to scan all this data to
identify those at risk to potential terrorist groups or even those in terrorist groups is reckless . Not only that but it would be
foolish to assume such a technology would forever remain exclusive to the state and if it fell into the hands of a group with ill
intentions could prove disastrous .

While AI poses a myriad of applications for maintaining public order , they re likely still greater than 15 years in the
future . The more likely path to occur is within the next 15 years a policing AI could exist within an academic setting . From there
studies would occur on the effectiveness of the AI versus a human police force and then the public would have to decide if the
technology has been ironed out enough and if the tradeoff in privacy for security is worth it . For a typical North American city
like Chicago to then implement this system is likely at best 25 years away.As the famous futurist Ray Kurzweil stated in his fiction Singularity is near , computers will have the same amount of memory as the human brain before 2018 . Although many people think AI is not as intelligent as human , it can still perform numerous actions and process just like human . It is true that some of us may consider AI as simply mimicking human , but AI has gone far beyond our imagination .

Stanford s ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 drew a vivid picture of the future . A future of human , living a closely connected life to AI . From everyday alarm to online education . From understanding natural language to controlling the traffic lights . AI penetrates to our lives in a complete way .

However , to my point of view , some of the conditions and scenes described by the article are not reasonable and can not be fully achieved .

The article states that in the field of education , though quality education will always require active engagement by human teachers , AI promises to enhance education at all levels , especially by providing personalization at scale . It says AI can work as finding the pattern of mistakes that students are likely to make . Therefore , the AI can foresee the possible failure of students and give on-time feedbacks .

To me , this enhance of the education , in this particular way , is not going to become the truth . As a student , I also want to see where I am going to make a mistake . But I have no idea about this . Making mistakes seems so random that can not be predicted . A new supervisor may give me more pressure that lead to my mistake . A way-lower uncomfortable chair may keep my brain out of oxygen that lead to my mistake . The AI can not see the circumstances a student is in . What is more , the AI can not decide what is the factor that is going to be the trigger of the students mistake . Therefore , the AI can not predict a student s failure .

Another point that I disagree is the idea of regulations . In the article , the author proposed that Rather than more or stricter regulation , policies should be designed to encourage helpful innovation , generate and transfer expertise , and foster broad corporate and civic responsibility for addressing critical societal issues raised by these technologies .

But in my point of view , when a new technology comes , we need more than enough regulations and policies . We have to make extremely strict and complete regulations which can cover every aspect of the new technology . AI is designed according to human s process of thinking and doing things . At some point of the process , AI may reach the human brain gradually . So I state firmly that AI has to be treated as a human when it comes to the society . When a person is born , he will not escape from the eye of its parents or teachers for over approximately 15 years . Although we have these long term supervising and regulating of a person , he can still commit crimes . The AI is a more powerful , talented person . It certainly deserves more and stricter regulations instead of reckless encourages for innovations . Any innovation of AI must be fully tested and regulated . The progress of AI should be slow and steady instead of fast and risky .

In the past a hundred years , technologies have evolved faster than the whole two thousand years . The slope of our development is higher than ever before . AI is one of the shining stars in the process , I believe the AI will dive into our lives more deeply in the future .
Though this was a very expansive study , I feel that the panel avoids one of the biggest oppositions to AI : human stubbornness and utter refusal to adapt . While they note that AI will need to gain the `` trust '' of its users , one of the biggest things they ignore is that many people -LRB- regardless of the level of trust -RRB- will refuse to use AI . A few examples may include : those who enjoy and prefer maintaining full control over a vehicle , those who prefer surgical operations from a licensed human doctor , those who want their grandparent to be supervised by a human capable of adapting to any situation . What will happen to an auto-enthusiast when a city does away with its parking spots due to autonomous vehicles ? Will they then no longer be able to take their beloved vehicle out for anything but joy rides with home being the only destination ? Rather than jobs like home health aides becoming obsolete due to robots , I imagine that the few humans who remain in the job sector will make more money than before , as it will become an expensive privilege to be able to afford a human helper . I for one , no matter how many surgeries a machine has successfully completed , would pay whatever the upcharge may be to have a human surgeon perform my surgery . I feel that this study completely overlooks most people 's preference for human interaction , at least in life or death situations .
Apart from pure refusal to adapt , another major disagreement I have with the study is the prediction of flying cars . While this has always been seen as a staple of the future , the logistics are far too absurd . When you take into account how many regulations there are on a simple lightweight drone in an airspace , the concept of a 2-ton vehicle flying overhead becomes ludicrous . It is my belief that an underground tunnel system would be implemented far before any flying cars .
When concerning public statistics , I find that there is a major oversight concerning the concept of outliers . While using predictive software in situations such as granting parole , the ability for humans to completely change their behavior on a dime can not be ignored , no matter how strong the evidence is against it . No amount of statistics or intelligent projections can predict human spontaneity . Grouping people into subgroups based on historical evidence will only reinforce that individual 's probability of remaining there .
The last and most important oversight of this article was avoiding the influence of military advancements . The article stated that : `` military applications were deemed to be outside the scope of this initial report '' . The capitol and labor allocated towards researching AI in the domain of national defense could outweigh the private sector tenfold . For example , although the study panel does n't expect drones capable of swimming by 2030 , if a national security concern required drones that swim , the military resources could see these machines finished within the year . While I understand that military research is kept secret and can be unpredictable , the massive steps forward it could potentially provide should not go without consideration .
In recent few years , Artificial Intelligence -LRB- AI -RRB- has become a hot topic and aroused great attention in our society . However , there is a certain amount of people , who do not know what AI exact is , tend to look it as a threat based on the information through social medias , movies and fictions , which cause misunderstanding of AI , but Artificial Intelligence and Life in 2030 offers readers a scientific view of AI . According to Chair et al. -LRB- 2016 -RRB- , a better definition of AI would be enabling machines to interact with its environment properly -LRB- p. 12 -RRB- . In their article , most of the analysis were plausible , but they overestimated the development of AI and its relative problems . Also , they underestimated the influence of other technologies which can cooperate with AI . In brief , the fifteen-year interval set by Chair et al. -LRB- 2016 -RRB- is too short to accomplish all their assertions , and they ignored the influence of cooperation among AI , Augmented Reality -LRB- AR -RRB- , and Virtual Reality -LRB- VR -RRB- on education .
First of all , not only the software of AI but also the hardware of it will not be enough to help Chair et al. accomplishing all their assertions in the next fifteen years , and AI needs more time to be put into practice . For example , according to West -LRB- 2017 -RRB- , the facial reorganization AI program made 35 false judgements on Sept. 7 which was its first time to be used by London police in practice -LRB- pp. 2-6 -RRB- . Even if a AI program is perfect in both theory and laboratory experiment , it might make mistakes when we put it into the real world because there are many unexpected situations that could confuse the AI program . What is more , as is mentioned by the author , AI needs legal support when making mistakes -LRB- Chair et al. p. 10 -RRB- . In this point , however , Chair et al. -LRB- 2016 -RRB- did not give a specific evidence to support their fifteen-year plan and gave an ideal statement that best practices need to be spread , which made the deadline 2030 ambiguous -LRB- p. 10 -RRB- . As is known to all , legislation is the what we make recourse when problems occur . Thus , the speed of legislation is crucial if AI programs are published to the society . Therefore , fifteen years is not enough to finish all the process , and practical AI needs more time to finish testing .
After talking about time , the cooperation among AI , AR and VR is a significant aspect which was ignored by Chair et al. . Talking about education , the influence of AI is not limited in teaching robots and Massive Open Online Courses -LRB- MOOCs -RRB- . Other technologies such as AR and VR will be important in education because they can provide nearly true experience to learners . Obviously , education is not only teaching but also experiencing . With the cooperation of AR and VR , AI programs will achieve a better outcome for learners .
In conclusion , Chair et al. made good analysis on AI , but they put too much confidence in the speed of the development of AI and its relevant areas like legislature , and they overlooked the impact of AI when cooperating with other technologies in educational areas . All in all , AI will make our life different and we should hold an appropriate attitude towards it .



References

Chair , B. J , Altman , R. , Horvitz , E. , Mackworth , A. , Mitchell , T. , Mulligian , D. , & Shoham Y.
-LRB- 2016 -RRB- . Artificial Intelligence and Life in 2030 : One Hundred Year Study on Artificial
Intelligence . Pp. 1-52 .
West , Nicholas -LRB- 2017 , September 7 -RRB- . 35 False Matches And 1 Erroneous Arrest as Police Secretly
Test Facial Recognition Technology . Activist Post . Retrieve from
https://www.activistpost.com/2017/09/false-arrest-raise-questions-police-facial-recognition.html


It 's a bad thing to turn a political essay in for an assignment from a tech class , but given that the assignment is to respond to another political essay , here we are .

Maybe in a better world , where regulators had pride in their work , the competence and data-gathering/analyzing techniques to figure out what to do , the freedom to do what was right regardless of whether a sensationalistic media or their political opponents could misrepresent it to persuade illiterate voters to punish them , and the civic virtues to want to do what was right in the first place , the essay 's general strategy of `` patch existing regulations inside the current framework to handle imminent AI disruptions '' would be appropriate .

Instead , we live in a world where page 10 of the panel-of-experts report chose to support a hedging comment on how bad attempts at regulation could actually have bad consequences by citing a New York Times opinion piece that said nothing of the kind -LRB- the citation was probably really meant to apply to something further down on page 10 -RRB- . The piece did , however , minimalize the threat of runaway self-improving AI , saying we should redirect any focus on that civilization-ending threat -LRB- as an aside , is n't it nice how many potential civilization-ending threats there are right now ? -RRB- to current petty tribal issues . -LRB- Kate Crawford , if a poorly-specified self-improved AI starts taking apart the Earth to build more processors to run on to more efficiently `` achieve '' its naive programmers ' goals , the effects are n't going to be limited to particular demographic groups . -RRB-

Even if the report is right and that particular doomsday scenario wo n't happen , the disruption the report predicts is too big and too soon and too poorly-timed with our unrelated political disintegration to be manageable . We ca n't just apply simple changes to civil liability to suddenly handle a world where , as the report correctly points out , simple traditional conceptions of `` fault '' are n't going to apply anymore . We already need changes -- we already have a ballooning cost disease problem where healthcare , education , and other areas are structured around avoiding lawsuits , with huge amounts of waste involved . But who 's gon na fix it ? Not the government any time soon . How in the world , then , will they be able to handle this ?

I 'm not suggesting that the disruptive power of AI could be put to good use to make the government irrelevant , because even though that would be really nice , it is n't realistic either . We 're really just doomed , and the time has come to start deadpools on what the horrifying cosmic force that finally gets us will be . Will it be competition and memetic growths selecting against all our values , like Scott Alexander suggests in his excellent `` Meditations on Moloch '' essay that you should read right after you read this ? Global warming -LRB- god knows the government 's not going to be able to fix that one either -RRB- ? Nuclear war with North Korea ? Civil war with ourselves ? -LRB- A year ago , I would n't have guessed that Godwin 's Law was even in the running , but it 's firmly in play now too . -RRB-

No , the proper response to future threats to society is to resign ourselves to failure , and then spend our last few decades having fun working on interesting technical problems like those in AI .
The Stanford One Hundred Year Study on Artificial Intelligence is considerably comprehensive and detailed on the analysis and prediction of future with the development of AI . However , in the transportation domain , specifically in the smart cars industry , the report may be a little optimistic about its future .

The first question is that to which extend we can safely or assuring to use the vehicles in a large scale ? The article mentions that by the year of 2030 , it should prevail but I disagree with this argument . It is more like a non-technical issue . It really depends on how the government will accept the new type of vehicles , which usually takes a long time . Taking Uber , a new business type of rental cars , as an example , Uber was founded at 2009 and is very popular after 2012 . However , most governments still do not quite accept this new business type today , in the year of 2017 , which is at least 5 years . The main problem about Uber , from a government perspective , is that how Uber , a casual rental car business compared to traditional rental cars , protects its passengers ' safety or legal rights . Therefore , the government is very prudential on the topics like safety . Back to the topic of smart cars , the question is how fast can the government accept them when the technology itself is still not mature enough ? It is hard to say but it will be very slow .

There is another issue which could also be fatal and tricky . That is the topic mentioned in the report `` Ethical questions arise when programming cars to act in situations in which human injury or death is inevitable , especially when there are split-second choices to be made about whom to put at risk '' . However , the report did not go into details about it , which may miss a fatal problem inherent in smart cars . Imagine a smart car accident which the car hit a passenger on the street , what should the programmed car do ? Do everything to protect the people on the car first or sacrifice the people on the car and save the passenger on the street instead ? As a car owner , it is unreasonable to buy a car which will sacrifice its owner 's life to save other people but it is also not what passengers want if the smart cars will try to spare passengers ' lives to save car owners . If the involved vehicle is not a smart car , then it is simple . The driver can choose to hit the passengers to save his life but also the driver will get punished by his own choice . However , if this happens to smart cars , who do we blame ? The driver or the smart car design company ? From an intuitive perspective , the smart car design company should be responsible for the accident . However , what choice does the design company have ? Driver first or passenger first ? As the problem shows , this could damage the industry or the society . In fact , this is an old traditional philosophy question and it is known as `` Trolley Problem '' . It remains to be a tricky ethics problem and no satisfying answer has been given . What could possibly be done to solve this issue may be what MIT did , who gives a test to the society to let the society test themselves to see what consequences do they prefer and the data may have legal usage in the future .

Based on the government s prudential decision process and the issue about the morality of smart cars , it is still not imminent for the industry to be flourishing .
All of the AI computer programs we have nowadays are actually weak Artificial Intelligence that could only focus on one narrow task . Human can easily control them because their performances are based on the programs that programmers wrote . For example , Alpha Go and Siri . The conversation Siri could make are based on a limited pre-defined range , and it does not have self-awareness . Alpha Go , the same as Siri , are designed only for beating professional Go players . However , the research `` Artificial Intelligence and life in 2030 '' -LRB- Stanford University , 2016 -RRB- mentioned that the scientists want to really make AI intelligent , also known as strong AI , a machine with consciousness and with the ability to apply intelligence to any problem , rather than just one specific problem . As the result , there is no doubt that AI robots and machines would replace most of the works in the job markets without restrictions in the near future , and the article addresses the importance and restrictions on the use of AI in the job markets . What 's more , the study group also plans on setting a series of principles and moral standards that all AI machines ' designers need to follow to prevent strong AI from going out of the control of human or surpassing human , just like most children are smarter than their parents . However , does everyone really think strong AI could follow the principles and moral standards designers set for them once they have their own consciousness and self-awareness ? Unlike the view of the research , the answer for me is definitely no !

AI are designed to perform faster , better , more efficient , and more accurate than human , and they are all designed by people with high IQ . In the whole article , the scientists ' whole conclusions are based on the premise that `` AI must not do something dumb '' or `` AI must not harm human beings and the society '' , but an intelligent AI machine with self-awareness will unlikely to follow the principles in reality . Parents can not prevent their children from falling into a wrong path although parents taught their children they need to be honest , kind , brave and etc. when they are young ; AI follows the same logic : the programmers put certain principles and ethical restrictions in the programs to point a right direction for AI programs , but they forgot strong AI programs have their own thoughts and self-awareness , which means `` it '' could has a chance to fall into a wrong path . The worst thing a people could do is kill others , and it is hard for one or several of them to harm the whole society , but strong AI really can , just as the concern Elon Murk mentioned in Tesla 's conference call with its investors . Then there is no way people could beat a machine that is a lot smarter than human 's elites .

From my own perspective , the initial motivation of using AI to raise the standard of living is good , and we should take advantage of it . However , the scientists and politicians should be aware of the harm of over confidence on AI or strong AI , more precisely .

Reference : `` One Hundred Year Study on Arti cial Intelligence -LRB- AI100 -RRB- , '' Stanford University , accessed August 1 , 2016 , https://ai100.stanford.edu .
The Stanford One Hundred Year Study on Artificial Intelligence provides an expansive overview of the ways artificial intelligence -LRB- AI -RRB- has changed society in the past fifteen years , focusing on several different sectors of the economy and society . The study also details ways that society can be expected to evolve alongside AI in the future , and ways that public policy should adapt to benefit society as a whole . However , this paper fails to address the amount of immediate effort that will be required to adapt current public policy to AI technologies , perhaps because this may frame AI as a threat to our current system rather than a boon to our society . In reality , the study should acknowledge immediate issues that are present today , such as uneven distribution of wealth in the economy , which must first be addressed if we hope to properly implement AI in the future .
An example of a policy issue which the Stanford One Hundred Year Study on Artificial Intelligence downplays is AI s impact on the job market and economy . It is true , as the study states , that continued growth of AI will create new jobs , and could possibly be used to lower barriers to entry in the job market . However , as more and more jobs become automated , there is expected to be a net increase in unemployment . The report attempts to convince us that this will be beneficial to society ; for example , the report states that AI systems will have the effect of lowering the cost of many goods and services , effectively making everyone richer -LRB- 39 -RRB- . It is also often brought up that everyone should be entitled to a portion of the world s AI-produced treasure -LRB- 39 -RRB- . These statements seem reassuring , however they assume a seemingly utopian future where the economy is structured to benefit everyone without regard to social status . In reality , this is a tremendous leap from the current status of America s economy , where the distribution of wealth is extremely out of balance . Without first fixing this problem at hand , it is easy to envision a future where AI widens the wealth distribution gap . The poor may become even poorer by losing jobs , and the rich may become even richer due to lowered cost of labor and lowered production costs .
Unfortunately , the economy is simply one example of ways this study fails to address current policy issues . AI may intensify other current obstacles in public policy if they are not properly addressed in the present . Other issues that are not sufficiently acknowledged by this report are political issues such as privacy , taxation , or discrimination . If we hope to reach towards the future that is envisioned in this paper , it will not be easy ; we must recognize current problems in our society , and begin resolving them today .
AI has the potential to achieve great things , but it also has the potential to hurt many people . AI s true impact on society depends on the policies that are present today , which will influence reform in the future . It is important that future reports of the One Hundred Year Study on Artificial Intelligence acknowledge the immediate issues that are present in today s society , such as the discussed economic inequality . This will inform lawmakers that these issues will only grow with the implementation of AI , unless immediate action is taken . Hard work , meaningful discussion , and determination to restructure our current political system , for the benefit of the common people , is necessary if society truly wants to reap the endless benefits artificial intelligence has to offer .
The field of artificial intelligence has made great progress over the course of many years and currently has a plethora of technologies that have exceeded certain aspects of human intelligence -LRB- e.g. , calculators -RRB- . Even so , AI is a quite dynamic field and has the potential for significant advances in the near future . The One Hundred Year Study on Artificial Intelligence aims to track the progress of different sectors of AI and make predictions on the future of AI given current research achievements . Overall , the paper thoroughly describes what AI is , the achievements in AI , and the well-supported predictions of the future of AI . However , I claim that they are overstating their opinions on the development of transportation .
According to the article , Autonomous transportation will soon become common place This statement assumes that these vehicles will soon begin to be available in variety car dealerships and that people will trust and want to purchase a very different and new type of vehicle . Although it is true that companies like Google and Tesla have created prototypes of self-driving cars , it appears there are not sufficient data to convince car dealerships that they will be profitable . If these cars are introduced at a slower rate and adequate data are collected to demonstrate that these cars are indeed desirable , dealerships will be more willing to invest . As a result , the transition from self-operated cars to self-driving cars will take more than 15 years . Additionally , the authors of the article state that Transportation is likely to be one of the first domains in which the general public will be asked to trust the reliability and safety of an AI system for a critical task . They continue to emphasize that by 2030 these vehicles will be commonplace . This seems like an overarching assumption given that there aren t sufficient studies on the safety of these vehicles once integrated at large into society . Also , humans are generally resistant to significant changes in everyday life such as altering their transportation routine . Such resistance to change is made more intractable where there are doubts on safety making it unlikely these drastically different vehicles will dominate . The article states there exists a study that predicts self-driving cars will be adopted by 2020 and that self-driving cars will eliminate one of the biggest causes of accidental death and injury in the United States . I believe that wide-scale adoption of self-driving cars is definitely a direction that society will be heading toward . However , the timeline seems too quick and I suggest that more studies on the opinions of people nationally are important to complete before such time projections can be definitively made .
Artificial intelligence is at the cusp to revolutionize many different areas including transportation , robots , healthcare , education , communities , safety , employment , entertainment , and etc. . I believe this report explains these progressions and their limitations well . For example , the article states that regardless of the slow growth of home robots , there is an expected dramatic growth in their use by 2030 . The authors cite a number of reasons why there should be expected change . However , I believe this article did not provide the same thorough explanation as a basis their predictions for AI penetration in transportation . If a more in-depth examination of AI and transportation was given , their argument would seem more plausible .

In the Stanford One Hundred Year Study on Artificial Intelligence , a point is made that an increase in the usage of artificial intelligence worldwide will eliminate certain jobs and reduce overall employment -LRB- Section II , page 39 -RRB- . The authors of the study argue that a necessary response to this phenomenon will be the introduction of a `` social safety net '' , or Universal Basic Income . I believe that a Universal Basic Income is a poor way to respond to the technological advances that AI will bring to our society . Universal Basic Income -LRB- UBI -RRB- is a social security that would be given to every citizen of a country that implements it . This idea has been around for hundreds of years , but these days it is gaining traction with AI threatening many low-skilled jobs around the world . According to the White House Council of Economic Advisors , by 2036 , 83 % of jobs that pay an hourly wage of $ 20 or less will be displaced by AI -LRB- 1 -RRB- . Current UBI proposals call for the U.S. to provide each of its citizens with $ 20,000 per year , regardless of other income earned . The funds to support UBI would likely come from a tax on the owners of AI machines . This system has two inherent flaws : it disincentivizes the use of AI and it makes unskilled workers reliant on AI machines for their income .

By taxing the owners of AI machines , UBI reduces the demand for those machines , which will stunt the adoption of AI worldwide . If the goal of UBI is to offset the job losses due to AI , taxing the owners of AI will do nothing to make that happen . Instead , it will keep the U.S. at a technological disadvantage as compared to its peers that are using AI . Artificial Intelligence will almost certainly increase worker productivity , so not using it will only hurt our country in the long run .

The other issue with a UBI is that it forces our society to rely too heavily on the government , which relies on AI machines . Citizens that know they will receive a base income will be less likely to look for work or advance their education . This will create a society with a large number of unskilled citizens relying on the few citizens smart enough to create and maintain AI machines . This redistribution of wealth is n't fair to the ones creating it , and it may eventually lead to a socialist state where there is little to no ability to climb the ladder to higher classes of economic prosperity .

If UBI is n't the answer to job loss due to Artificial Intelligence , the question remains : what is ? I believe that instead of directly giving money to people , we should instead spend that money towards worker re-training and other similar programs . It simply does n't make sense to have a society of citizens not working when you could instead train them on new technologies . A nation of highly-educated citizens with jobs is very clearly more productive in the long run than a nation of a few educated citizens and many uneducated , jobless ones .

-LRB- 1 -RRB- Dillow , Clay , and Brooks Rainwater . `` Universal Basic Income : Why Free Money Could Be the Future of Work . '' Universal Basic Income : Why Free Money Could Be the Future of Work | Fortune.Com , Fortune , 29 June 2017 , fortune.com/2017/06/29/universal-basic-income-free-money-silicon-valley/ . Accessed 11 Sept. 2017 Artificial intelligence as a branch of computer science has been developed for several decades , though , it is only recently that AI received great attention from the public , and many people , still have limited understanding of what AI is and what AI is capable of . I suppose people may not have that large demand for some of the future AI applications anticipated in `` One Hundred Year Study on Artificial Intelligence '' . Take transportation as an example , electric cars and fuel cell vehicles are gaining growing attentions by people from around the world , because the climate change and environmental issues are widely recognized as a huge threat to human . However , it is hard to say that people have similar huge demand for self-driving vehicles . The article quotes that the average commuting time in US is 25 min , and people can do other things during the commutes . But `` 25 min '' is not that long that people can not waste , considering they take the risk of giving the control of their own life to machines . It does not mean that people will never accept self-driving vehicles , since people nowadays take flights without fear in which passengers also have no control of their lives . But I believe it will take much more time than what article claims before people accept this type of transportation tools . Car companies and other developers should take extra effort to prove and persuade people that the autonomous car is safe . It is true that electric cars and fuel cell vehicles are also still not widely used , but this is not mainly because people have concerns about the safety of the car , instead , due to the relatively higher price and lower performance compared to traditional gasoline-fueled cars .
The second point that I want to challenge is about the argument of model/physics-based approach compared to data-driven approach . The article claims that the model-based approach has been giving way to data-driven approach . It may be true that data-driven approach is more efficient in the sense that it can learn from a bunch of data sets with no necessity of understanding the principles hidden behind the data . However , sometimes it would be necessary to combine with model-based approach which can provide detailed understanding of the cause and effects . For example , in my research area of materials science , traditional approach for understanding process-structure-property relationship of materials is achieved by time and money consuming trial and error approach , i.e. experiments . But the developments of physics based numerical simulations has made it possible to do the `` experiments '' in the computer , which is very helpful to reveal and understand new physics behind the data . Those new physics are the critical instructions for further studies to produce meaningful data more efficiently . Indeed , the experiments and simulations together have produced the big data sets that can be used for data-driven approach to accelerate the material discovery process . However , it does not mean that the data sets are already big enough nor we have totally understand the physics behind them . In other words , model/physics-based approach is still a useful way to produce meaningful data , at least in my research field .
Nowadays , artificial intelligence is becoming a prevailing topic which is relative to people s daily life in every fields . According to the increasing number of discussions about AI , many scholars also pay much attention on the research about the AI . The researchers in Study Panel focus on applications of AI in various industries , and finish an article called Artificial Intelligence and Life in 2030 after deep analysis.Tta Inside this paper , there are many practical aspects of the artificial intelligence discussed . I m very interested in the education field , because education is a closed topic for me , as a student . The article expresses that the teaching robots and online courses are good methods to enhance the efficiency of teaching , include helping teaching , expending students around the world , collect students data , and so on . However , I have different opinions for some of the topics in the paper . I believe that even though artificial intelligence is really helpful in most of daily life , education field has a more complicated situation for AI to deal with .
Firstly , artificial intelligence teaching tutors can not interact with students based on their moods , which might slow down the learning speed . Tutoring systems which are used by numerous students for learning mathematics , programming , chemistry , circuit , and so on mimic as good human tutors to guide students to solve problems . However , adjusting students learning temper is also a significant responsibility for teachers . A depressed student would never have a high efficiency on learning . For example , a student who struggles on debugging a complicated programming problems finally solve this hard question , and then he might be excited for solve a hard problem or he might be tired because of this program . The AI tutor is hard to figure out which situation the student is . Therefore , it is hard to give a suitable next problem . If the next question is too hard or too simple , it is possible to cause students to stop learning and leave the computers . Although the teaching tutors can survey students moods during teaching , it is not good for students learning pace , so AI teaching tutors are not perfect roles for teaching .
Secondly , using online learning to collect data is not a dependable way . The data collectors are hard to know what happens on the student s side . The same phenomena might be triggered by different reasons . For example , if thirty percent of the students do one question wrong . One third of them maybe don t understand the knowledge clear . One third of them maybe don t understand what the question is . One third of them maybe just feel sleepy . It is hard to analyze the real situation . Therefore , the data set obtained from online learning are not specific enough for research purposes .
Thirdly , some subjects are not suitable for AI to teach , such as dancing and singing . These subjects focus on practicing people s abilities and skills . Artificial intelligence is not human , and they can reach where people can not easily . AI can not share feelings with students how to do an action or reach a pitch as a human , so it is an ineffective teaching .
Although artificial intelligence can help on some parts of the education , this field is so intricacy that only real people can deal with major and important parts of the education . Therefore , AI is not as useful as people believe in the education field . -LCB- \ rtf1 \ ansi \ ansicpg1252 \ cocoartf1504 \ cocoasubrtf830
-LCB- \ fonttbl \ f0 \ froman \ fcharset0 TimesNewRomanPSMT ; -RCB-
-LCB- \ colortbl ; \ red255 \ green255 \ blue255 ; -RCB-
-LCB- \* \ expandedcolortbl ; ; -RCB-
\ margl1440 \ margr1440 \ vieww27120 \ viewh12580 \ viewkind0
\ deftab720
\ pard \ pardeftab720 \ fi720 \ ri0 \ sl360 \ slmult1 \ partightenfactor0

\ f0 \ fs24 \ cf0 In
\ i Stanford One Hundred Year Study on Artificial Intelligence
\ i0 , the author elaborates different tasks artificial intelligence could perform by classifying the AIs into distinguishable domains according to the jobs that AIs could perform . In addition , the author lists some requirements in order to develop AIs in different fields . However , there remain some weaknesses that could be improved in this report . The author overlooks some indispensable pre-conditions to explore the artificial intelligence in transportation domain . In addition , this report also ignores the disadvantages faced by MOOCs -LRB- Massive Open Online Courses -RRB- . \
In the transportation part , the author elicits idea that \ ' 93once the physical hardware is made sufficiently safe and robust , its introduction to daily life may happen so suddenly as to surprise the public \ '94 -LRB- Stanford One Hundred , p12 -RRB- . That is to say , from the report \ ' 92s perspective , a safe and robust physical hardware , a technological support , is the only requirement to develop AIs in transportation . However , to gain such destination , human beings need more supports other than technology . For instance , the appearance of AIs applied to transportation will apparently sacrifices human being \ ' 92s privacy . Because autonomous vehicles are controlled by physical hardware , individuals will be monitored at any moment . In addition , the transportation system which controls autonomous vehicles might exposes a loop hole to some individuals . To elaborate this point , if the transportation system controlling the autonomous vehicles is hacked , individuals will utilize this advantage to cause pandemonium . In addition to the imperfect system , human beings \ '92 fears and distrust towards AIs should be salved to develop autonomous vehicles . Due to the psychological factor that individuals are more comfortable with the things under their control and auto driving cars generally are out of their controls , this distrust should be eliminated before the development of AIs in transportation domain . \
In addition to the other conditions required to develop AIs in transportation , this report generally do not take into account the weakness of online teaching , especially MOOCs , to predict the future of AIs in education . It is true that MOOCs could maximize the individuals who could access to high-level education and the electronic resource could somehow improve students \ '92 learning experiences . However , MOOCs is deprived of other aspects which turn out to be indispensable in learning process . For instance , not only does human beings gain knowledge , but also they gradually learn how to interact with others in physical lectures . That is , interpersonal skills generally are obtained through face-to-face interacting between individuals , but in MOOCs such ability would be deprived . In addition to the interpersonal communication skills , the efficiency in online course is less than in physical lectures . The reason lies in two aspects : first , in physical lecture , individuals are more motivated to involve in learning because they are able to ask and answer questions to resolve their confusion ; second , physical lectures could prompt their to catch up with daily learning progress , while in online course , nobody can monitor their . Therefore , MOOCs indeed owns some weaknesses that need to be improved . \
In conclusion ,
\ i Stanford One Hundred Year Study on Artificial Intelligence
\ i0 is a comprehensive report about the pass , future of artificial intelligence and its applications in different domains . There are still less vigorous points in this report that could be modified . In order to develop AIs in transportation , human beings need more than a safe hardware and technology . The trust towards AIs is also crucial . In addition , this report ignores some disadvantages of MOOCs . Thus , the development of artificial intelligence has a long way to go in the future . \
-RCB- According to the Stanford One Hundred Year Study on Artificial Intelligence , `` human intelligence -LSB- is -RSB- a natural choice for benchmarking the progress of AI . -LSB- ... -RSB- But matching any human ability is only a sufficient condition , not a necessary one . '' However , the study fails to realize that to define something as Artificial Intelligence , matching a human ability is not a sufficient condition .

First of all , ability and intelligence are not equivalent . If a technology can match a human ability , it does not necessarily mean that it has reached the level of intelligence . For instance , the process of writing a book is made up by two parts : having ideas in mind and actually writing them on paper . A printer can easily print things out faster than a human can write , but it does not have `` mind '' , so it is not able to have ideas in its `` mind '' . As a result , although a printer is better than a human on `` writing '' things on paper , it is not likely to be counted as Artificial Intelligence . Thus , A technology can not be defined as Artificial Intelligence simply because it can do some jobs better than human beings can .

As stated in the study by Stanford , '' -LSB- t -RSB- here are already many systems that exceed human intelligence , at least in speed , such as scheduling the daily arrivals and departures of thousands of flights in an airport . '' Just like the printer , scheduling flights much faster than a human does not make the airport system an Artificial Intelligence . They both are just collecting existing information as input and making output really fast . They are not being `` intelligent '' ; they are just being fast . If matching any human ability is the sufficient condition for defining something as Artificial Intelligence , not only the printer and the system that schedules flights but also many more technologies , even non-electronic ones , would be considered as Artificial Intelligence . For example , a calculator , which makes computation faster than a human , is Artificial Intelligence ; a speaker , which is louder than a human , is Artificial Intelligence ; even a quartz clock that counts seconds more precise than a human , is Artificial Intelligence . Apparently , none of the technologies listed above is considered as Artificial Intelligence , but all of them are better than a human in some aspects .

The key separates those daily technologies that make our life more convenient from Artificial Intelligence is the term `` intelligence '' . According to Nils J. Nilsson in the study by Stanford , `` intelligence is that quality that enables an entity to function appropriately and with foresight in its environment . '' The technologies listed above certainly function appropriately , but none of them has foresight in their environment . As a result , they can not be counted as Artificial Intelligence even though they do their jobs better than human beings .

Clearly , if a technology matches a human ability , it is probable that the technology can function well , but it does not mean that it has foresight in its own environment , which actually makes the technology an intelligence . Therefore , matching a human ability is not a sufficient condition to make something Artificial Intelligence .
In the `` One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- '' , Stanford University , the panel describes a multi-layer transformation of human society through progress in Artificial Intelligence . They deny the possibility of runaway AI taking over the world and maintain that the benefits of AI exceed the negative aspects of it -LSB- 1 -RSB- . While the amount of wealth created and progress made by AI to date is undeniable in fields such as search and recommendation systems as well as deep learning , the majority of this report focuses on potential future progress . The article speaks as if in just 13 years we will see major industries such as healthcare and education being radically transformed . In reality , it seems that the only field close to being radically transformed is self-driving cars , in which we already have started to see self-driving cars on the roads -LSB- 2 -RSB- . No doubt self-driving cars in themselves will transform several aspects of society namely how people spend their times and how far they live from work , but that is not enough to make life significantly better and bring economic prosperity . The overall tone of the article is that of one in which the future is automatic , and major fields will transform themselves over time . This automatic property of the future of AI must be challenged . Human agency seems to be underrated significantly in the radical improvement of these domains -LSB- 3 -RSB- . From a technological perspective , a lot of the systems described in -LSB- 1 -RSB- are doable , however , as the paper itself describes , a number of challenges are encountered in each of these fields . In healthcare , a regulatory overload from the FDA and privacy protections lead to progress being severely stalled -LSB- 1 -RSB- . In education , archaic institutions such as Universities , which have been unable to improve their age-old lecture-style classrooms , can not be expected to accept and push AI technologies in classrooms . While we have seen the development of MOOCs , it has not been enough to supplant Universities and offer a new wave of education to growing populations . Something qualitatively different might be needed for Education and AI can not be the go-to solution to education . In the domain of robotics , we find service bots killing themselves on accident due to imperfect systems -LSB- 4 -RSB- . The article -LSB- 1 -RSB- suggests that cities will have robots for public safety , but security bots ca n't keep themselves alive in 2017 , how can we expect them to keep us alive in 2030 ? We must be careful to not overstate the possibilities of AI lest we might lead ourselves into yet another AI winter , which is not new to the field . We have had a number of AI winters before , and this is a story we 've heard before : AI is going to change the world , it is only a matter of time -LSB- 5 -RSB- . In fact , it seems that the reality is more close to : AI is going to change the world , but only if we make it happen . The current state of AI is overstated , however the future potential is not . It is simply framed in the wrong manner . We must not underestimate the role of human agency in building the future and we must take responsibility of building safe , beneficial and powerful AI systems . AI has the potential to lead humanity into a utopian surplus society , in which people are freed up to do things that they want to do instead of things they have to do . However , incremental improvements and overly optimistic predictions wo n't lead us there . We must think of radically new ways to build intelligence to bring the future closer .

References :
-LSB- 1 -RSB- `` One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- , '' Stanford University , accessed August 1 , 2016 , https://ai100.stanford.edu
-LSB- 2 -RSB- `` Steel City 's New Wheels '' , Uber , accessed September 10 , 2016 , https://www.uber.com/blog/pittsburgh/new-wheels/
-LSB- 3 -RSB- Peter Thiel on Stagnation , Innovation , and What Not to Call your Company
Mercatus Center - https://medium.com/conversations-with-tyler/peter-thiel-on-the-future-of-innovation-77628a43c0dd
-LSB- 4 -RSB- Did this robot commit suicide ?
Yaron Steinbuch - http://nypost.com/2017/07/18/did-this-robot-commit-suicide/
-LSB- 5 -RSB- AI winter
https://en.wikipedia.org/wiki/AI_winter Artificial Intelligence called AI , inspired by human nerve , is a type of computer technology that focuses on making machine more intelligence . The report Artificial Intelligence And Life In 2030 written in 2016 by Stanford University discusses how the world will be changed in the future along with development of AI . This report introduces various AI technologies that could possibly applied in people daily lives . It says that these technology will eventually change our world dramatically and foster people convenience . I also agree with this thought . However , I think it is hard to ignore the problems that are coming with development of AI . When this report focused more on how the world change with AI , I want to focus more on how this AI can possibly give confusion to the world in two categories : regulation , and crime .
I totally agree that AI will be able to make people lives better but only if it is used with correct and strict regulation . I believe proper regulation is needed to apply AI to people lives . Of course I know there will be many experiment before introduce new AI machine for minimize problems . Still , as this report said , it will be hard to predict what is really going to happen . There is possibility to have exceptions out of regulation . Theses exceptions may be very minor thing ; but at the same time , they may be big threat that even can threat one s life . According to the report introduced by this Stanford report , it predicts that self-driving cars will be popularly used in 2020 . However , in my opinion , it may be take more times to be popularly adopted because of regulation . Maybe self-driving can be used for automatic parking that can cause minor issue , but it is hard to imagine many people use self-driving car on the street yet .
Along with the regulation , it is pretty important to think about new crime that could happen with AI technology . Recently I read a news that drones were used to carry drugs , cell phones , and pornography to prisoners in the California and Maryland prisons . Experts said that drones can possibly deliver guns and any dangerous things to the prisoners that can not be delivered using traditional smuggling method . This case shows that crimes can be happened unexpected ways with the development of AI .
Moreover , it could be very difficult to judge one s fault if crime is happened by AI . For example , if two self-driving cars have car accident , who will take responsibility for this accident ? The person who use less intelligent AI ? or the car company ? This kinds of problems can be happened not only on self-driving car but also anything that use AI technology .
I do not want to say development of AI will destroy the world like a Skynet in the Terminator movie . Rather , I would highly encourage to continue AI technology when it can make people live longer in better conditions . The only thing I concern here is the clear regulations and countermeasures against new technology . I believe , if clear regulations and countermeasures can be held in society , AI technology will then be enriched the world .

* Citation *
Abbasi , W. -LRB- 2017 , June 17 -RRB- . Inmates fly mobile phones , drugs and porn into jail - via drone . Retrieved September 14 , 2017 , from https://www.usatoday.com/story/news/2017/06/15/inmates-increasingly-look-drones-smuggle-contraband-into-their-cells/102864854/
Artificial intelligence is rapidly encroaching upon all aspects of human life . From simple household tasks , like vacuuming , to robots that are more precise at diagnosing patients than a doctor , AI is here to stay . With this new technology comes profound and ethical problems that need to be addressed before this technology outpaces the current laws and regulations in place today . The One Hundred Year Study on Artificial Intelligence made great points outlining where A.I will be in the year 2030 . One major problem associated with A.I is how to protect the massive amounts of data being collected and used by the various technologies using A.I. . This problem was glossed over in this study , but it plays a massive role in shaping how we will use and implement this technology in the future . Another problem that is bound to arise is the displacement of peoples jobs due to artificial intelligence . This study provides no alternative solution or a call to arms to fix these massive problems that have the potential to completely upheave society .
The topic of privacy has become a hot button issue of recent . Most people have all their personal information , like credit cards , social security numbers , etc. , on their smartphones and or computers . This leaves millions of people open to cyber attacks that could ruin them financially and completely disrupt their lives . This problem is even more evident with A.I because it relies on massive amounts of data being collected from users daily . With the recent Experian hack that comprised over 300 million Americans social security numbers , privacy and protection of people 's data should be at the forefront of the A.I conversation . The study completely glosses over the overwhelming negatives that can result without proper legislation to deal with this potential catastrophic situation . The legislation should not be written to deter A.I , but to give it some sort of direction that protects the millions of people who will soon be using this technology daily .
Soon most of lower class will be forced out of their low skilled jobs due to A.I and automation . These low wage jobs barely keep these people afloat as is and soon they will be out of a job with no safety net or anything to help them . This will only increase the already evident issue of poverty in America . The study should support some sort of safety net program , like universal basic income , for the people whose jobs were taken by artificial intelligence . Automation is right around the corner and there has barely been a conversation about the inevitable fall out that will occur among the lower class . This study briefly talks about adding a safety net program , but there should be an entire section dedicated to funding a program to help all these soon to be displaced workers .
A.I is the future and will become a prominent force in everyones day to day lives . This study did the most basic job in outlining where A.I is headed , but not in showing the dangerous sides to it . The public should know the how dangerous this technology can be . Also there should be more legislation , or at least more political conversation , concerning the protection of users data , as well as dealing with the complete loss of jobs for the lower middle class .
The One Hundred Year Study stated that AI would more likely replace tasks rather than jobs . While that may be true during the developmental stage of artificial intelligence , the skill ceiling of AI is unknown . Currently , AI is threatening the entire profession of those who drive a vehicle for a living . Uber has already unleashed their first autonomous vehicular fleet in San Francisco . Not long ago , taxi companies were complaining and going on strike over Uber and Lyft for taking customers as well as their jobs away from them , and Uber has already decided to move onto taking away jobs from their own drivers . Uber is not alone in testing commercial autonomous vehicles either , there are over 3.5 million truck drivers in the United States alone , with the introduction of autonomous trucks , over 1 % of the US population will need to find new employment .
The study does mention that an increase in AI development will lead to an increase in jobs in that area but it does not mention the skills that will be needed to have a career in AI . Many people whose jobs will be overtaken by AI -LRB- I am referring to blue collar jobs for the most part -RRB- do not have the necessary qualifications to work in an AI sector . Their jobs will be irrelevant in the next 5-20 years and whose responsibility is it to find them new jobs ? The government has typically been very anti-universal income , as it viewed as a socialist program , which the government would like to avoid at all costs . However , there have been some strong arguments made by some influential people , such as Elon Musk , CEO of Tesla and SpaceX , Chris Hughes , co-founder of Facebook , as well as countless others . A universal income would greatly benefit those whose jobs are in danger of becoming antiquated and could also result in a drastic change in society , where the main focus shifts from professions to recreation . However , a universal income can not just be implemented without massive testing and most likely an increase in some sort of taxes . The US government needs to observe how it works in countries that are testing UBI right now , like Finland . Without proper testing and implementation , UBI will never be achieved and will push back the AI research and technology .
While the study did bring up the loss of professions , it did not bring up a short-term plan that would alleviate fears that people have about AI . The study states that education , re-training , and inventing new goods and services may mitigate -LSB- the -RSB- effects in the short term . But it does not entail what all those plans are , a commercial truck driver will not see the loss of their job as a chance to re-educate themselves about AI , many will fight and push back against it . Without a proper short-term plan in place , AI research and its introduction into the commercial world could be delayed or even prevented . Similarly , if a proper long-term plan is not in place long before its needed , it will be near impossible for AI to not be a passing fad .
Stanford One Hundred Year Study on Artificial Intelligence mostly introduces Artificial Intelligence
from computer scientists perspective and describes the authors idea about how Artificial Intelligence may
develop in the future 15 years . However , there are two aspects that I find hard to agree with : the possibilities
of AI being biased , and who is going to be responsible if AI breaks the law .
In the report , the authors write about the possibility of AIs having biases and mentions three factors . Data
AI uses to make the decisions , AI s designer , and users . The first one is understandable since anyone could have biases ,
and as the authors mentioned in the report , it s still a challenge to ensure the data provided to the AIs are non-biased .
However , the latter two , are total avoidable . For the designer factor , companies and research institutions can totally
hold regular educational sessions , make specific rules for the possible bias , and arrange rounds of peer code reviews to
make sure there isn t any bias exists in the Artificial Intelligence applications . The designer factor is just about
institutions regulations rather than a computer science related challenge . And the possible bias that could cause by
users is also just a problem with how people use it rather than a technical problem . If the AI is used for institutions
or governments , there is no doubt that they would regulate and make rules about the usage of AI , it s just going to be
problems with how to sort out the non-biased data rather than human-caused problems . AI need huge amount of data to make
decisions so the possible cause of Artificial Intelligence having bias is just going to be about the data , rather than
users or designers . And if that technical challenge is solved , then at least from computer scientists perspective , they
do not have to warry about biases anymore .
The question about who is going to be responsible for the possible illegal behavior of AI is a more complicated problem
than the authors mentioned . For start , when designing the AI , there must be regulations that prevent AI from breaking the
laws , even in the future , when AI could study and make decisions based on its cumulated understandings , the restriction
must still exist . Like normal people , they grow up , and learn from their daily lives . In some situations , they may want to
break the law , for right or wrong purposes , but most of them still won t choose to break the law since the law is a code that
everyone keeps in their mind , well most people in the world do . Human obey the law for their conscience and fear of punishment .
And the restriction for AI is more still , it s solid code . So , even in rear situations where AI do break the law , it should be
problem with the user , or original code . But if it s the latter situation , then not only does the programmers need to take
responsibility , who ever let the AI application passed the tests and put into use should also take responsibility . So , if that
kind of situations where AI do break the laws happened , it s not hard to find who should be responsible since everything done by
a machine should already been recorded . So that should not be something stand in the way of AI s development .
That 's the two aspects I have disagreement with . But mostly I have the same believe as the authors have , that AI is going
to develop real fast in the future and eventually be an important part of society .
In the Stanford One Hundred Year Study on Artificial Intelligence , the impact of artificial intelligence on the transportation industry is discussed . While I believe the Stanford One Hundred Year Study on Artificial Intelligence is correct in assuming that the use of artificial intelligence in vehicles will increase greatly by the year 2030 , I disagree with the article 's assertion that self driving cars will be widely in use and accepted by that time .
A significant reason that is the case is because I believe it will take much longer than thirteen years for the general population to believe self driving cars are just as safe , if not safer , than human drivers . While self driving cars cause less accidents per mile compared to conventional human drivers , many people simply are not comfortable giving up control of their vehicle to an invisible controller , and it will most likely take years of assurance to reverse this . Similarly , self driving cars are under such scrutiny that accidents involving them become national news when the story would not make it past local news had a human driven car been involved . For example , in May of 2016 , there was an accident where a Tesla on autopilot crashed into a tractor trailer resulting in the death of the driver . Even though the National Highway Traffic Safety Administration found the driver of the Tesla , not the autopilot , responsible for the accident , Tesla still received plenty of bad press coverage and lost some of the general public 's faith in autonomous vehicles . Additionally , articles like one published on USAToday in October 2015 with the headline `` Self-driving cars have higher accident rate '' imply that autonomous vehicles are more dangerous than their human driver counterparts even though in almost every case , the autonomous vehicle was not at fault .
Another factor that will slow the wide spread use of autonomous vehicles is the fact that many Americans still enjoy driving as a hobby and want to be in complete control of their vehicle . These holdouts will minimize the benefits of having self driving cars . For example , one of the main benefits of everyone having self driving cars is that there would be less traffic and shorter commute times ; however , if there is still a significant fraction of people driving manually , the positive effects will be reduced .
There are also security concerns to consider when dealing with self driving cars . If the vehicles are connected to the internet , there is a possibility that hackers would be able to gain control of the vehicle . This is already somewhat of an issue , as in 2015 hackers were able to gain access to a Jeep Cherokee and remotely disable its drive system .
Despite disagreeing with the extent of artificial intelligence 's impact on motor vehicles in the coming years , I do agree that its use will increase greatly . There are already many examples of artificial intelligence in cars on the market today , such as blind spot monitoring and intelligent parallel parking assist . As the technology increases and the general population becomes more acceptant of not being in control of their vehicle , American 's daily commute will only become more and more effortless .

The Stanford One Hundred Year Study on Artificial Intelligence claims , `` Autonomous transportation will soon be commonplace ... As cars become better drivers than people , city-dwellers will own fewer cars , live further from work , and spend time differently , leading to an entirely new urban organization ... The availability of shared transportation may displace the need for public transportation . '' -LRB- 1 -RRB- Given constraints for individuals who already own a vehicle , city planning , and the speed of legislation , it is highly unlikely that autonomous vehicles will be commonplace and significantly change urban organization by 2030 .

Individuals throughout the US have cars that are paid for , and switching to a new vehicle before the current vehicle expires is unlikely . Improvements in manufacturing and design of cars have led to an increase in the number of years a car is used . In 2016 , the average age of a car in the US was 11.6 years . -LRB- 2 -RRB- Without an economic or environmental advantage to switch to driverless cars , individuals will likely continue to drive their cars for many years as they currently do . Unlike when cars were first affordable for many Americans , there is a current infrastructure built around current technology , and millions of vehicles currently in use . -LRB- 3 -RRB- Before autonomous vehicles become commonplace in North American cities , they will gradually replace non-autonomous vehicles . If vehicles sold in September 2017 were to be used for 11.6 years , then those owners would shift to autonomous vehicles in 2029 . This timeline would not provide enough time to drastically shift human behavior or city structure .

The City of Madison has a 25-year Transportation Master Plan -LRB- TMP -RRB- . The goal of the TMP is to make the city a place where `` employers want to locate and people want to live , work and visit . '' -LRB- 4 -RRB- Madison 's TMP emphasizes the importance of improving the city transportation for bicyclists , pedestrians , and public transit users . Cities with a history of well-thought-out public transit would likely incur a large cost to switch to a driverless car system as the main form of transportation for residents by 2030 . Once the technology is tested , and available on a large scale , it still may not be the most affordable or desirable option for transportation given alternatives that are already in place city-wide . Current systems of public transportation have special programs for students , low income individuals , and persons with disabilities . These programs , which are available through city services , would require administrative changes and a significant amount of time to switch to a driverless car system that is equitable .

Furthermore , the regulations regarding the testing and use of autonomous vehicles have not yet been determined in every state . The State of Wisconsin has a Steering Committee on Autonomous and Connected Vehicle Testing and Deployment . The report containing the Steering Committee 's findings and recommendations regarding the testing and deployment of autonomous and connected vehicles will be submitted to the Governor by June 30 , 2018 . -LRB- 5 -RRB- From here , rules and laws may be altered , which will take additional time . Given the amount of time legislation takes to move forward , having autonomous vehicles commonplace by 2030 is unlikely .

Although autonomous vehicles will certainly bring exciting changes for individuals and cities , it will take significantly longer than 15 years to see the changes predicted in the study throughout cities in North America given current constraints . There may be some cities , on the leading edge of technology , that push through these changes more quickly and will serve as an example for others looking to utilize autonomous vehicles .

1 `` One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- , '' Stanford University , https://ai100.stanford.edu/sites/default/files/ai100report10032016fnl_singles.pdf . Accessed 9 Sept. 2017 .

2 `` Table 1-26 : Average Age of Automobiles and Trucks in Operation in the United States . '' National Transportation Statistics . Bureau of Transportation Statistics . https://www.rita.dot.gov/bts/sites/rita.dot.gov.bts/files/publications/national_transportation_statistics/html/table_01_26.html_mfd . Accessed 11 Sept. 2017 .

3 `` Table 1-11 : Number of U.S. Aircraft , Vehicles , Vessels , and Other Conveyances . '' National Transportation Statistics . Bureau of Transportation Statistics . https://www.rita.dot.gov/bts/sites/rita.dot.gov.bts/files/publications/national_transportation_statistics/html/table_01_11.html . Accessed 11 Sept. 2017 .

4 `` Purpose and Goals . '' Madison in Motion : Sustainable Transportation Master Plan . City of Madison . https://www.cityofmadison.com/dpced/planning/transportationmasterplan/goals.cfm . Accessed 11 Sept. 2017 .

5 `` Executive Order # 245 . '' The State of Wisconsin Office of the Governor . https://content.govdelivery.com/attachments/wigov/2017/05/18/file_attachments/818787/executive_order_245.pdf . Accessed 11 Sept. 2017 . Upon completion of the Stanford One Hundred Year Study on Artificial Intelligence , I was left with several questions and doubts regarding certain statements and generalizations the article had made . Although it provided various well supported claims and predictions for the future , it was filled with some ideas that still seemed out of reach for the time being . One prominent claim I took issue with was the predicted wide-spread adoption of self-driving vehicles and delivery systems by the year 2020 . The first thought that came to mind when reading this was the service industry , and how this large change could in turn bring about sizeable changes within said industry as well . With the adoption of self-driving cars , trucks , and other automated delivery systems , the service industry will be facing large layoffs as they will no longer need the human component in the delivery system . Previous service workers will be facing wide-spread economic hardship , in turn increasing the nation s unemployment rate as well as negatively impacting the nation s economy . I believe that in this case , the convenience of the technology does not outweigh the social and economic impact it will have in the years following its installation . The second thought that followed was that this was an extremely ambitious timeline for the perfection , and full-scale adoption of this new technology that had merely started as an idea in 2004 . Although many large corporations like Google and Tesla are currently working on their own version of the self-driving car , there is still much distrust within the general public of this forward-thinking technology . With the recent death of a self-driving car early adopter behind the wheel of Google s self-driving vehicle I feel as though there is still a large amount of distrust . Although the technology has come a very long way over the course of the last decade , there are still large technological advances that need to be made before the vehicles are able to be released as a safe and viable option of transportation . The third and final issue I had with this notion was the level of autonomy these specific vehicles and delivery mediums would possess . As was touched on elsewhere in the article , the automated cars , trucks , and delivery systems do not possess a moral compass or code of ethics as a human might . When encountering a situation in which the driver could survive if three pedestrians were to be killed , or vice versa , what would the autonomous vehicle choose in the split second it takes to react to a situation of said caliber ? On the other side of this issue , when are systems like this becoming too autonomous to the point where they are creating their own pseudo languages to more efficiently communicate with each other at a level we no longer understand ? I believe that this stretch goal of the wide-spread adoption of self-driving vehicles and delivery systems by the year 2020 is very implausible and ambitious . As we are soon entering the year 2018 , I feel there is far too much beta testing , real-world application , and economic consideration that must be done before we can safely integrate this technology into our society .
Artificial Intelligence has the potential to re-define how we receive an education , our healthcare , our politics , and the way we live . While the Stanford One Hundred Year study on Artificial Intelligence has only just begun , in its report there is much speculation as to what the future may hold . This report focuses mostly on the positive aspects of artificial intelligence , and the lack of concern for the regulation and safety regarding this area of technology and it 's data is apparent .
Education has come a long way since the computer was introduced to the classroom . Essays are now typed within minutes instead of being hand written in hours , and online classrooms are now more prevalent than ever . Although artificial intelligence promises to enhance education , there are considerable risks to using automated teaching . For one , how effectively will artificial intelligence be at addressing individual students ' needs and learning abilities ? At the core of the problem is data collection . Will these children 's learning data be protected from possible manipulation from outside pressures ? Will machines be able to build metrics defining a child 's intelligence ? The risks associated with such large scale data collection on children and the potential for misuse are extremely high , both by our government and other third party entities .
Healthcare is another area that shows promise for advancement because of the integration of artificial intelligence into healthcare technologies . But do the benefits outweigh the risks ? Data based monopolies are becoming ever more prevalent , especially in regards to healthcare . For example , Deepmind , owned by Google , has relationships with Healthcare service trusts in Great Britain which has provided it access with millions of peoples medical information . How can this data be kept safe ? Is it even ethical for Google to be using this data to build their own products ? The arrangement that Google has with the UK is reporting to have actually broke their privacy laws , and patient 's consent had not been received for this miss-use of their personal information . In the U.S , any of sort of AI system would also have to meet HIPAA standards , which could make working on the machine learning algorithms for patient diagnoses a potential violation as well . Overall , there are many risks that AI and big data cause for the general population , and stricter management and regulation should be put in place to ensure that innocent people are not put at risk .
The final biggest problem with AI that was n't covered in the Stanford report is the risk to politics . With machine learning , AI will eventually be able to predict elections , unrest , and political turmoil in the future . That in itself is not bad ; it 's how this information is used that could be potentially dangerous . If an AI has the ability to predict elections , it must have access to an extremely large data set of information pertaining to individual voter 's political affiliations and their views . If this information found its way into the wrong hands , it would be possible to negatively influence global politics . For example -LRB- a wild example -RRB- , if I knew that in our current situation , a British citizen would one day become President of the U.S , and my AI tells me a certain subsection of the population would be the reason such a thing to happen , I might be inclined to take action against that subsection of the population .
Overall , AI promises to redefine the way we live . However , care must be taken so that it does n't become a weapon to oppress .
RAHIL KAKAR
T Th 4:00 -5:15
9073912769


HW1


`` We will see self-driving and remotely controlled delivery vehicles , flying vehicles , and trucks ''


The article published by Stanford University gives an interesting insight into the development of Artificial Intelligence till this point and the apparent future of AI in the world . One of the lingering questions surrounding AI is that it is hard to define what the term means . This ambiguity can make the ethical and moral dilemmas linked with AI seem impossible to understand . However this very ambiguity is what makes AI a field that is so versatile that its application can be seen is all different walks of life . The article states that self driving cars are to be widely adopted by 2020 is wrong in my opinion . The reason it is hard to give a concrete definition to the word AI is because it is hard to define what the word intelligence itself means . When we talk about intelligence we usually refer to a human 's capability to execute certain cognitive functions . AI from what I understand analyses its own data to create patterns and understand those patterns in a way that refines that very procedure the next time it is carried out . In the case of transportation and self driving cars , Artificial Intelligence can only account for the software behind making sure that self driving cars are safe and safer than human driven cars . However there are several other aspects to cars that we do not consider in our day to day thoughts . The first aspect that is linked to safety as well is insurance . The worry about insurance is that you dont need to it till you really need it . When a person owns and drives a car , the responsibility of having this very essential insurance is theirs and the consequences of what happens in an accident is also faced by them depending on their insurance . For self driving cars , this responsibility is put in the hands of a machine however any accident , if any , will be the sole responsibility of the software controlling the car and hence the manufacturer 's . Another aspect that has to be thought about is the physical space that a car takes up . If cars are to become self driving then they must be able to park themselves as well . The structure of roads and cities that are urbanized and have a lot of cars are made without having thought of self driving cars . If a self driving car can park itself then there will be certain areas that are heavily populated for only some time in the day that will have an influx of driverless cars surrounding the area to find parking . To control such an incident , the very concrete structures in the world will have to be rebuilt keeping self driving cars in mind . Otherwise the manner in which self driving cars are parked will have to be done with a software that has an idea of the time span a person will be in a certain location . This then takes away the freedom of owning a car and freely traveling from place to place without any time constraints . Another problem surrounding self driving cars is that if there is some unforeseen malfunction that is not thought of before , the implications could be fatal for a large part of the population . If some bug or glitch is found in technology then it will be found through errors that will only be found out after implementation of self driving cars which might be too late . However since these malfunctions are unforeseen it is hard to take them into account while thinking about developing self driving cars and developing ways of testing self driving cars such that they are as efficient if not more than the existing methods of transportation.It is interesting how Stanford 's annual AI report `` Artificial Intelligence and Life in 2030 '' argues that Artificial Intelligence has `` enabled instructors ... to multiply the size of their classrooms by a few orders of magnitude '' . The author rationalizes this argument as such : Artificial Intelligence tools such as `` personalized tutoring '' and `` NLP assessment tools '' , which are widely available on MOOCs -LRB- Massive Open Online Courses -RRB- and other models of online education , have simplified the process of tutoring and grading , therefore enabling them to teach more students than they would have without the AI tools . While it is valid to argue that Artificial Intelligence has simplified a lot of the administrative tasks , it is insufficient to claim that it is the most important factor for the extended use case of online teaching . A more valid claim should have been the advancement in web technology -LRB- such as faster streaming services -RRB- has promoted the prospering of virtual learning environments , and the use of AI further enhances some of the subcomponents of such virtual environments . The difference between the argument Stanford has provided and the one myself has provided is that the former places emphasis on AI while the latter emphasizes the importance of web technology .

This point of view can be illustrated through the AI project I have been working on for a candy company named `` Mars '' . Mars has over 10,000 users globally , and the number frustration on the services provided by the internal IT has to do with the use of SharePoint , which has a steep learning curve which the majority of the business users could not master . To resolve this challenge , my team , the Digital Workplace Team , managed to set up a Yammer support channel , on which business users can ask away any struggles they may encounter using SharePoint , and an expert from the community will answer their questions shortly -LRB- Yammer is a social network similar to Facebook except that it is for company internal use -RRB- . Shortly after the deployment of this Yammer community , we discovered that a lot of questions like setting up a SharePoint site were asked over and over again , and , therefore , we thought some kind of digital assistants could help automate some of these Q&A s . As of now , the digital assistants have proven their value by -LRB- a -RRB- being able to provide business users with solutions in a timely fashion and -LRB- b -RRB- reducing the time analysts needed to perform low-value operations such as answering frequently-encountered how-to questions .

In this example , Yammer , analogous to the MOOCs cited in `` Artificial Intelligence and Life in 2030 '' , is the enabler of virtual learning environment for the SharePoint technology . Without this enterprise social platform , the learning environment would n't have existed . The digital assistant on the platform , which is an example use case of Artificial Intelligence , is simply an addition that enhances the learning environment . It is valid to say that there is evidence AI helps enable the learning environment , but it is insufficient to claim that it is the driving force for this educational digital transformation .

In Stanford One Hundred Year Study on Artificial Intelligence there is quite extensive mention of the use of artificial intelligence for transportation . The authors are quite optimistic about this technology being the future of almost all transportation segments . They even claim that it will be ` one of the first domains ' in which the general public will asked to trust AI . However , I personally believe that the use of AI in automobiles is still far in the future , with it not being as close to mass adoption as the authors seem to think it is .

The main reasons that the use of AI in cars is being promoted is time and saftey . The researchers believe that , eventually , there will be a connected network of cars driving along the highway . However , the most savings in cost , time and lives will only be significant when a large number of people opt into using self driving cars . If self driving care are not mass adopted , the possibility of an accident does not decrease dramatically nor does one save much time .

As mentioned elsewhere in this paper , there is a big concern about AI affecting the job market . This involves the use of AI in self driving cars too . Self-driving cars will definitely make many jobs in the transportation sector redundant . This would include taxi drivers as well as drivers in the freight transportation . This issue might actually slow down the adoption of AI in the public . Legal restrictions may hold the technology back from the public .

Although self driving cars would make driving safer there is always the chance of an accident . In this case there is still no clear legal guidelines to how an accident would be handled . Will the manufacturer or the owner of the car be held guilty ?

Even if AI in transportation reaches a significantly high level there are always cases in which human intuition is necessary in making driving maneuvers . Its still unclear how self driving cars will handle hazards like roadblocks or areas with unique driving rules . The cars are also still not able to operate when in extreme weather conditions . Rain and snow can also affect sensors , hampering the car 's ability to work smoothly .

We are now in a day and age where privacy is becoming a big concern , partly due to hacking . Self driving cars , when they become mainstream , will continuously be relying on location and user information . This will become a big pool of data with millions of bytes of this information being exchanged every second . This could result in privacy concerns for the general public . There is also the issue of hackers getting control of the vehicle 's software and causing harm .

One of the biggest current problems with AI in cars is that of ethical dilemma . In the case of having to make a choice how would the computer be able to justify injuring or killing one person instead of the other ? There could be ethical problems which a machine might struggle to deal with . If it was forced to chose between killing people how would it pick ? There is also the question of how the computer would prioritize one being or creature over another .

The implementation of AI in cars , although progressing , is still far from being mass adopted . Although strides are being made there are still significant hurdles that need to be conquered before AI can be seamlessly integrated into our lives . The Stanford One Hundred Year Study on Artificial Intelligence is one of the first long term collaborations that has been created regarding the study and advancement of the field of Artificial Intelligence -LRB- AI -RRB- . The study brings up many well thought out points regarding various aspects of this fairly new field of science . Although I agree with almost all points of this study , there is one in particular that I do not agree with , and that is the idea that self-driving cars will be a normal occurrence and widely adopted by the year 2020 .
I believe that self-driving cars will be more prevalent in the future , but a mere three years into the future seems outlandish . There are too many obstacles that will need to be maneuvered before self-driving cars will be at the level they need to be at in order to be used on a day-to-day basis . One of the largest issues automobile companies will encounter when trying to deploy these self-driving cars is on the legal front . It is mentioned multiple times in the article that there is a large gray area when it comes to law on self-driving cars and whose responsibility it would be in the event of an incident . Is the driver at fault or the company who made the car ? These legal issues will play a huge roll in halting the transition from regular to self-driving vehicles in every day life .
Another problem that can also be accredited to the previous section is the public s view on AI in every day technology . The public may have a very negative outlook on this new type of technology . Although a large majority of the population is fairly comfortable with technology , this does not mean that they would put their lives in its hands for a common task such as driving . Millions of people drive motorized vehicles every day . This article makes the assumption that this transition would be widely accepted by the public . Similar to any other technology , the public would have to accept it with great enthusiasm for it to work and be a success . For some people this technological advancement would simply be too much for them to accept . The idea that the entire population could get on board by the year 2020 is asking a lot .
Also , this study was only focused on the United States . Countries around the world already use cars in a different way then we do . Many other countries have different laws and regulations when it comes to vehicles . This may cause more issues to arise for the companies who created the vehicles . In order for them to deport these vehicles to other countries , the laws of those countries may have to be changed as well . This then becomes a national political issue . Should all the countries have similar rules and regulations pertaining to self-driving cars or should each individual country specify the laws to best suit themselves ? In the upcoming years these ideas will have to be discussed .
In my personal opinion we are at a minimum of ten years away from seeing a large population of self-driving cars on the roads on a regular basis . It will be years after that until the entire population of vehicles on the roads are self-driving . These are a few of the reasons why I believe that the study overestimated the transition speed from normal to self-driving vehicles in the public setting . A more conservative estimation is going to have to be made to more accurately represent the current state of the public s opinion on the advancement of this technology .


A response to One Hundred Year Study on Artificial Intelligence

The 2016 report of One Hundred Year Study on Artificial Intelligence covers in detail the situation Aritificial Intelligence faces and its status currently , and future possibility on policies and itself . In the fields where AI is relatively hot it addresses , I personally find several points that worth more discussion .

First of all , it says that the unexpected interests human have put into the entertainments based on AI technologies have caused a drop in interpersonal connection . -LRB- A100 , 2016 , p. 40 -RRB- I do not think this is necessarily true . According to what they have written in previous texts , entertainments based on AI actually include social network platforms and instant message services , which are obviously intended to strengthen the bonds between individuals . For example , Through Facebook , one can keep close to their family and friends even from a far distance -LRB- Koifman , 2013 -RRB- . Social networks provides a mean for people to stay in touch with the person they want to interact , even under the condition when traditional ways to contact like mails or in person can not be applied . As a result , more interaction should strengthen the bonds which connect people together , just as meeting face-to-face does . What 's more , such tools update really frequently with new way to convey feelings which are even more interesting . If I remember , Google 's Allo , the IM software allow users to adjust the size of their bubble , which give additional info like how strong one 's feeling is at the time besides the literal meaning . Doing so the user can have a great lot of fun even they are not meeting the actually person they are sending message to . Never forget to mention that nowadays , these AI based tools mostly have video chat feature which directly allow user to interact with each other . Thus , I do not see the problem on decreasing interaction in humanity with more AI entertainment .

In addition , the report mentioned in page 43 , that AI can be biased for the point of view of its designer and the data it relies on . An example the report comes up with is about the difficulty speech recognition techonology meet while the users are women or have heavy accent . Personally , I think this problem does exists . Yet , it is relatively easy to solve , and is already done on several products we widely use now . Please check the ever repeating videos on Youtube about tests on voice assistants . A whole lot of them are about the test under different context of accent . There is one in particular tests on Google Assistant , Apple Siri , and Amazon Echo , in which Japanese , French , and even Russian `` flavored '' English are applied in the experiment -LRB- WIRED , 2017 -RRB- . And as expected , the voice assistants can all handle such accent heavy pieces of English to a certain extent , in which the Google Assistant have the best overall performance . I believe it has something to do with the dedicated work the developers have put into the voice sampling phase . They get large set of samples , including woman and accent-heavy ones , and the AI learns well .

Finally , on page 43 , the report also address the problem that the economic fruits created by AI 's power is likely to be shared evenly , mostly to the hands of the scarce of expertise . However , such issues should be mitigated by fast widening access to AI really quick . In recent years , there are more and more emerging online courses on AI , such as , you know , the Coursera one . Though most of them are introductory level , it is still important that wider access is provided to the public , if they want to know more about AI . More than that , the problem on the cost for AI-ready hardware is now partially solved by cloud based computing service , like those provided by Google , Microsoft , and Amazon . And the hardware itself has become even cheaper for ordinary customer level : Epyc processor lines on zen architecture from AMD , much cheaper and far more powerful than its Intel counterpart . And most importantly , machine learning specialized hardware from companies like Google and Nvidia . All of these should empower the AI to spread its user base wider than what it is currently in the future .

Overall , the report is a good read and let me reflect a lot . But I expect studying the search section on our textbook on the weekend of the first week , as some preparation to the incoming challenging lectures .


Reference List -LRB- sequence they appear in this paper -RRB- :

Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .

Koifman , N. -LRB- 2013 -RRB- . Can Social Media Actually Benefit Relationships ? Retrieved from : http://www.huffingtonpost.ca/natasha-koifman/social-media-and-relationships_b_4115588.html

WIRED . -LRB- 2017 -RRB- . 8 People Test Their Accents on Siri , Echo and Google Home | WIRED . Retrieved from : https://www.youtube.com/watch?v=gNx0huL9qsQ&t=263s
The One Hundred Year Study on Artificial Intelligence is an investigation that began in the fall of 2014 as a way of monitoring the field of artificial intelligence and how it is influencing people , communities , and society as a whole . Every 5 years a panel of experts in the field produces a comprehensive state of the field at that time . The first and most current survey was released in 2015 , and focuses on 8 domains : transportation , household robotics , healthcare , education , low-resource communities , public safety and security , employment , and entertainment .
To dive into this article , it is important to understand the scope that was chosen by the panel . The survey first narrows its focus from the entire world population to the dense urban environments and large cities . In doing this , the survey focuses on North American cities , and extrapolates their findings to the global environment . Another important note about the scope of the survey is that it excludes military uses of artificial intelligence .
The survey has high hopes for artificial intelligence in personal transportation . Making claims like As cars become better drivers than people , city-dwellers will own fewer cars , live further from work and spend time differently . While the survey does not expect everyone to own a self driving car by 2030 , it seems to focus on self driving capabilities making their way into personal vehicles . I believe that cost and technological obstacles will push self driving capabilities away from personal transportation and instead be focused on industrial and military use .
The first thing to consider when looking forward to self driving cars in personal transportation is the cost . People are unlikely to make the investment into self driving technologies in their personal vehicles until they are reliable enough to autonomously drive without needing to be ready to drive manually . Currently Tesla vehicles have some lane changing capabilities , yet drivers are expected to be doing most of the attentive driving . In 2016 there was the first recorded death of a person being driven by a semi-autonomous vehicle . This technology is prohibitively expensive for the vast majority of the population , and will not be taken up while it does not allow people to drastically change the way they drive . Until the technology has advanced enough to be cheap enough for nearly everyone to have , we will not see tangible improvements in our roads .
The best example of this is former assisted driving technologies that we still don t see as commonplace . For example , intelligent parking assist systems have been commercially since 2003 . Still 14 years later we do not see it widely available in cars . It would be an even greater stretch to expect it to change the overall landscape of parking . So it can be expected that even given the 13 years -LRB- the survey is projecting to 2030 -RRB- that the general population will not commonly own self driving or semi-self driving cars and I contest the idea that the way we travel will be drastically changed until the technology is advanced and reduces in cost .
Reading the article The Stanford One Hundred Year Study on Artificial Intelligence was fascinating since it describes how AI has been developed so far and it would be as well as how it would change the world . However , some concerns are popped up while I was reading the article especially related to the Healthcare issue , so I d like to address questions and casts my concerns and worries about the AI application in Healthcare fields .
According to the article s argument , AI-based application has been developed and it could improve the health of people . AI is currently used as in a supplementary health device such as Fitbit to enhance the quality of health by analyzing life habit or sleep pattern . In the future , it will be more elaborate and eventually try to serve the examination or diagnosis of disease like a doctor . For example , people have a medical issue , they could use the AI application to figure out the reason . If people wear wearable AI devices , the AI-based application can collect health data , so AI could suggest possible reasons of that issue based on personal database and big data from the past medical database . Furthermore , it may inform the possible disease and even suggest the treatment -LRB- of course it would say it is just suggestion and not the official medical diagnosis -RRB- . At the beginning , people may not trust the application , but as other AI applications like Siri , Netflix , or Tesla , it becomes pretty accurate , and increasingly people are going to trust the application . Thus , if they consider their health issue is minor , or AI application says , possibly minor , they would not go to clinic and examine by the actual doctor since it costs a lot . I concern that it could make people insensitive to safety , and lax attitude toward medical security could cause serious damages such as late treating infectious disease .
The other concern is a quite opposite situation from the previous concern , that AI application may increase medical cost generally . Supposed that AI has sufficient data . There is no rule that doctors can not use the AI application . They may want to use it since it could catch something that doctors may miss . However , since AI application has tremendous data , it is likely to suggest lots of possible disease , so doctors should consider other possible diseases although they do not agree with that from their experience . To examine the other possible diseases , patients should get more exams such as blood test , CT , MRI , or specific exams . For most cases , it reveals that the possible diseases are not the final diagnosis , and all cost for exams burden the patients , as well as community . Even so , doctors can not ignore AI application since the extra exams rarely catch the severe disease , and it could cause medical disputes if the doctors ignore the AI application . Thus , AI application could result in overtreatment or unnecessary tests , which could seem as positive for some people , but it is not since patients will undergo stressful tests , spend lots of money and waste time , as well as it will also increase social costs tremendously .
Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller .
Reference
`` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 . Artificial Intelligence is changing the world around us in many more ways than we know . One of those ways I would like to specifically focus on is the idea of autonomous transportation . There is little doubt about the need for more self-driving vehicles as accidents are a leading cause in deaths , pollution is still on the rise , and commutes are longer than ever . With the right minds and policy more and more autonomous vehicles will continue to join the roadways , from commuters to commercial drivers the variations go on and on . With car companies such as Tesla making this a reality , it is hard to believe that more change wo n't come . Where I disagree completely however , is the idea that people will be welcoming to and enjoy a completely autonomous driving experience . First off , not everyone buys a car primarily for the sake of transportation . The average consumer thinks of a car as an investment and takes great pride in their purchase , and they will usually get a vehicle to match their personality and needs -LRB- i.e. a Mercedes-Benz for an office executive -RRB- . On top of that , there is also a large majority of people that may want a faster vehicle than others due to their driving habits . Even if autonomous vehicles were made to look unique and match personalities and needs , they would still be driving the same speed as everyone else with same autonomous functions as everyone else . People only want to obey the traffic laws when it does n't affect them , for example , if you are just driving to go play golf you probably are n't going to be in a rush and have little concern over how fast the speed limit and traffic flow is , but if you were in a hurry to get to work on time you may break the speed limit to get past those other slower drivers on their way to play golf , hence the need to speed and break the law . Now it would be very naive to think that everyone is going to leave for work on time when they have an autonomous vehicle , and there is no way that the autonomous vehicle is going to fly by other vehicles as it is not fair for someone 's autonomous vehicle to have the priority to pass everyone else because they did n't wake up early enough to leave on time . Adding on , people also are n't going to just be satisfied with one autonomous family vehicle , people today often have many more vehicles than they need due to either vast wealth or interest in cars . What is to keep these wealthier people from sending their autonomous cars all over the place to run errands therein just adding to the mass of traffic already , and no matter how good traffic flow gets some roadways are not modern enough to handle the exponential growth of the population . Lastly , are regulatory officials going to just tell collectors who have thousands of cars worth millions that they ca n't legally drive them anymore because they are n't autonomous ? And if they do n't what will keep them from driving a normal vehicle way faster to get past a line of autonomous vehicles all going the same speeds , and who 's fault will it be if there 's an accident ? Only time will tell how people accept change to autonomous vehicles , but it is clear that change is occurring and people are going to have to change with it.The One Hundred Year Study on Artificial Intelligence report is a well compiled investigation of the impact artificial intelligence has had on the individual as well as the community . But , in recent years AI has also failed and this report covers a few such topics . The One Hundred Year Study report mentions that AI will blossom in fields such as transportation , healthcare , entertainment etc. , and by 2030 , an average urban city will make maximal possible use of AI . Ray Kurzweil , a computer scientist had predicted lots of AI related findings perfectly in the 90 's with regards to AI in the 21st century . Similarly , he predicted that by 2029 , computers using AI will routinely pass the Turing test - `` the ultimate measure of how well a machine can pretend to be a human '' . Comparing this with the timeline of the One Hundred Year Study report indicates that although AI is moving in the right direction in all the above mentioned domains , things could still go wrong . Below , are challenges with respect to a few aspects of the report .


As discussed in the report , AI in transportation will play a major role especially in the self-driving car project . One incident in this regard is the fatality caused due to Tesla 's autopilot mode . In this case neither the autopilot nor the driver applied brakes leading to the accident . After the incident , Tesla had come up with an update to its radar system . Although , the update has been made , there still remains concerns as to whether just a radar would suffice to stop an accident as the AI might not be able to pick up signal due to distortions or interference . This leads to the question as to when can the system be fully trusted as the faults in such complex systems can only be rectified when the error occurs and in such a case , the error could be fatal . Also , apart from the question of security , the ethics of autonomous cars is another question . Given a situation where AI has to decide between swerving into a field in an unforeseen circumstance to avoid an accident versus having to apply abrupt brakes versus running over somebody , the AI system will lack the intuitiveness and the experience to make the call . Further , the AI being programmed and developed for this exact purpose bares more responsibility than a human driver and hence , leads to accountability issues .


Another aspect that should be analysed is the role of job employment issues . The report mentions that AI will replace tasks and not jobs and also will create new jobs . A recent trend of interest is that companies which made profit of about say ` x ' million dollars a decade back still make the same amount or more but with a considerably smaller workforce . This is because what AI replaces as tasks are parts of a job for a human and most of them can now be automated . Companies now rely on management softwares which hire freelancers to perform a given job and through this process the AI in the software learns patterns from the freelancers work and then even that job can be automated . Hence , with the advent of AI although goods and services will have lower rates , compensation in the job market will be difficult with the only option being minimum security being provided to the workers .


There are a few more aspects that can be challenged such as healthcare concerns , racial bias due to restricted datasets but the above mentioned topics are the main challenges that AI will have to overcome for it to benefit the society.One Hundred Year Study on Artificial Intelligence - A Rebuttal
---------------------------------------------------------------

The article published by Stanford goes over various aspects of Artificial Intelligence -LRB- AI -RRB- and speculates how AI might affect the society as a whole and also goes into detail of how AI might change specific sectors of the society . The article also provides some guidelines on what might have to be considered as our society adapts to presence of AI in various parts of our lives . In addition , it raises some concerns over biases and how these biases may slowly get incorporated into AI programming . It takes a stance that biases must be removed from AI as much as possible so it can make objective decisions in critical situations . However , biases are a huge part of humanity . While not all biases are helpful , many biases help us make decisions that are aligned to our moral compass . Moreover , these biases change over time , along with our moral views .

Let us begin by considering why humans have biases . Biases happen when our brain , due to experience , training , or faulty thinking , takes a shortcut in decision making , making the process faster . For example , hitting a nail with hammer causes an entire range of reactions in different individuals , from flinching to not even blinking . Someone not exposed to the sound and vibration of a hammer hitting a nail will flinch , even though the rational part of brain knows no harm can come from it . On the other side , someone who has experience with the sound and vibration may not even blink to the sound . Although the `` rational '' part of both individuals ' brains send out same messages , their experience , or in other words , biases cause them to react differently . Although this example is not relevant to AI , it shows how biases can change our reactions and how experience can change our biases .

But how do biases connect to AI ? Biases are very good indicators of where the moral compass of our society points . It is our biases that forces us to swerve away from a pedestrian , even if it mean putting our own assets and lives in danger ; it is what causes us to save children first even when they are not the logical choice to save . The article hypothesizes that AI will be used to make increasingly critical decisions , from preventing accidents on roads to deciding whether or not to open fire at a place filled with civilians . Systematically removing biases from AI will also make it extremely objective . Our society does not measure human lives objectively . Ideally , loss of life should be minimized even if the results are suboptimal . This lack of objective measure for human life is the idea behind the Trolley Problem . A problem that Self-Driving cars face even now . As of yet , there is no solution to the problem . There are very good arguments on both sides , but with no moral compass to point the way , decisions are hard to come by .

This brings me to my point : The article makes recommendation that while programming AI , care should be taken to remove any bias from the algorithms . While we probably do not want our AI to have cognitive biases , removing all biases from AIs might not be as good an idea until we learn to quantify our own biases . Although biases get a lot of negative publicity when connected to racially charged and other similar incidents , it is often forgotten that a lot of correct crucial decisions in our lives are made because of our biases . While it is prudent to remove the bias that targets a specific color of people for policing , we probably do not want to remove the bias that prioritizes saving children , even hazarding our own lives in the process . The question about which biases to keep , and which to remove , is a question that requires discussion at a larger scale . But ultimately , removing all biases from an AI will make it less acceptable to the society .
Authors and fanatics of Science Fiction dreamt about autonomous cars as early as the 1930 s . In the year 2017 , we re well on our way to that reality .
As the Stanford One Hundred Year Study on Artificial Intelligence claims , by the year 2030 , autonomous cars could be commonplace in the average North American city .
The report makes this claim yet spends little time talking about factors other than technology . By 2030 autonomous cars will not be common place due to issues of policy ,
accessibility of new cars to all members of a typical North American city , or the longevity of existing cars .

According to IHS Automotive in 2014 , the average lifespan of a car is 11.4 years . If a person bought a car in 2017 , that person will probably still drive that car
in 2028 or longer as cars improve . Therefore , it s likely they would drive their car still in 2030 . Currently , no completely autonomous cars are commercially available and
only Tesla makes semi-autonomous cars . Google remains the only manufacturer of completely autonomous cars , meaning the technology exists . Cars don t become common place on
the road overnight . The average lifespan of cars proves that most people who have bought cars within 5 years from now will still drive them in 2030 . The existence of the
technology won t prevent these cars getting on the road ; the longevity of a cars lifespan will .

Another factor contributing to the prolonged timeline of autonomous cars is the availability of them . Currently , the cheapest Tesla semi-autonomous car is $ 35,000 ,
which have just recently gone into production . The top ten most popular sedans on the market today are all under $ 30,000 , putting Tesla s car out of the price range of the
average American . By the time completely autonomous cars are even allowed on the market , it ll take years to make them affordable to everyone , putting the commonality of
completely autonomous cars beyond 2030 .

Finally , the largest reason why autonomous cars won t be common until after 2030 is policy . Currently , only four states and one place in Canada have laws regarding
autonomous cars , according to the study . The FAA currently limits commercial drone usage , including regulations making long distance usage nearly impossible . For instance ,
Pilots must remain in sight of a drone always and can not fly the over people . Completely autonomous cars could bypass similar regulations ; for example , Tesla reques drivers
to keep their hands on the wheel always to engage Auto Pilot . Strict regulations on drones which are not even autonomous , it can only be assumed legislation on commercial
autonomous cars will be slow and restrictive , pushing the availability of these cars out further than 2030 .

Completely autonomous cars are predicted by the One Hundred Year study to be commonly available in a typical North American city by 2030 , yet they don t take consider
outside factors . The study briefly mentions policy briefly , but doesn t get into transportation policy as much as it should . Policy will hinder the timeline of autonomous cars
the most , as congress is slow and current drone regulations are strict . Additionally , economic concerns like price as well as the current lifespan of cars will prevent people
from buying them , making them common on the road . A more realistic thing to say would be that semi-autonomous cars will be commonplace or even that the presence of autonomous
cars will be much greater in 2030 , not that completely autonomous cars will be commonplace .
CS 540-2 : Introduction to Artificial Intelligence
Homework Assignment # 1
9/13/17

Write a short essay to challenge one or more aspects of the Stanford One Hundred Year Study on Artificial Intelligence . Requirements with point distribution :
10 Your essay should be between 500 and 600 words .
10 The essay should be a single plain text file in English . No pdf , word , rtf , etc. , and no attachments of audio , video , images , etc. please . Name your file hw1.txt
10 Do not include your name , your family , friends , or any private and sensitive information in the essay . Your essay will be read by others , including your fellow students .
20 Make a clear statement of your challenge .
50 General scholarly writing . Other than the above requirements , you have complete freedom in format and content .

While the Stanford `` One Hundred Year Study on Artificial Intelligence '' -LRB- Stone et al. , 2016 -RRB- addresses many potential difficulties with innovation and advancement in Artificial Intelligence -LRB- AI -RRB- as it applies to various domains , the study panel is overall optimistic about the future of AI and the value it can bring to society . This is not a worrisome perspective to take by any means . As a supporter of the advancement of AI technologies , I can not help but to agree with almost everything the study had to say , so finding aspects to challenge proved difficult . However , I maintain that the study is perhaps too optimistic about what AI can and will do , particularly as it pertains to healthcare .

Much appreciation can be had for the study 's attempts to expel worry about AI as a potential threat to society . Whenever the topic of AI comes up in casual conversation , the other person will often bring up the concern about computers taking over the world . Every time this comes up , I offer my opinion that we simply are not there yet . As the study mentions , AI systems have extremely specific applications and can only do as much as they are programmed to do . However , while evil , sentient computers are not an immediate threat , there is still danger in human error and oversight . This oversight is especially harmful in the healthcare domain .

The study is careful not to make any far-reaching claims about what AI can do , but one application of AI to healthcare mentioned is its potential to help diagnose medical conditions . There are several concerns to consider here . First , there is an immediate limitation when it comes to very specific , rare diagnoses , and diagnoses where even physicians have a high rate of misdiagnosis . How will the system decide which diagnosis to go with when probabilities of it being one as opposed to another diagnosis are similar ? A solution might be integrating AI with human interaction , which the study emphasizes the importance of -LRB- and acknowledges as a challenge -RRB- . This is a possibility , but what if the human interacting with the technology is prone to error ? This can lead to major consequences as the act of making a medical diagnosis is incredibly nuanced . In the best case , the technology makes an accurate diagnosis , but in a worse case , the technology might over-diagnose . One is reminded of searches on WebMD , where anything can be cancer . In the worst case , the technology might under-diagnose , where the patient has a far worse condition than the technology indicates . Second , physician burnout is a pervasive problem and the cognitive load for a typical clinician is already quite high . It will be difficult , unrealistic even , to expect clinicians to be as involved as they will need to be to be able to help advance AI in the healthcare domain to the degree that the study suggests is possible . Third , there is the worry of humans becoming too dependent on technology . The study visualizes the clinician as a type of facilitator , but there is a human tendency to rely heavily on tools once made available , such as the example of students becoming reliant on their calculators . Taking this into consideration , there is great potential for AI in the healthcare domain to lead clinicians astray , which can prove drastic .

The stakes are high for healthcare , and while the fear of an evil AI is perhaps unfounded , mistakes made during conception of the technology can have major consequences . If we 're not careful , we can create something we did not mean to create .
Though the One Hundred Year Study does a relatively good job of reviewing the current state of AI technology , it fails to provide a reasonable prediction of AI use in the near future , specifically of that in the transportation sector . The prediction of widespread use of automated vehicles by 2030 is extremely unreasonable for a variety of reasons including a failure to account for external variables and an overestimation of the possible progress in the available time frame . It is important to note that only the widespread use of automated vehicles in 2030 is being contested , and not the importance of AI in the transportation sector or the physical capabilities of AI technology in vehicles .
The study makes several bold assertions about automated vehicle use by 2030 , stating that `` autonomous transportation will soon be commonplace '' and that `` its introduction to daily life may happen so suddenly . '' However , there are several major issues with these claims resulting from limiting factors in the financial , technical , social , and legal fields which the study fails to sufficiently discuss . Consider the financial aspect of autonomous transportation . Google 's self-driving cars , for instance , start at an initial price of about $ 24,000 , but many of the devices and software that optimize the AI technology easily drive the cost over $ 100,000 , which is not affordable to the average individual . Though the study states that automated vehicles `` may eliminate the need to own a vehicle , '' this is not necessarily a solution . Even if the need is eliminated , the want remains . Cars today are often used as symbols of social status , and many individuals enjoy the connotation of freedom that owning and driving a car gives . Regardless of the practical benefit , it simply may not be desired by the public .
In addition , the study does address ethical and legal concerns of automated vehicles , but despite covering the problem , does not acknowledge the lack of an easy solution . Complex questions about the culpability of the actions of autonomous transportation are not quickly resolved , and it takes time for such important legislature to be drafted and enacted . Legislature can take years to be passed , and the estimate of action by the year of 2030 is rather optimistic . The implementation of automated vehicles in large cities also provides a challenge , as it could require entire city infrastructures to be redesigned , something the study itself points out . Though the study cites four cities as cases where autonomous transportation has been successfully implemented , these cities have relatively small populations and may not be applicable to cities with much bigger populations and more complicated traffic . The biggest issue with the study 's claims of widespread automated vehicles is an issue of time ; change requires time , especially in urban environments , and these predictions about the relatively close year of 2030 are unrealistic .
The study ultimately puts itself in a `` Back to the Future '' style delusion about the use of automated vehicles , overestimating the potential for progress in such a short time without taking into account many external factors . It may not be feasible to provide automated vehicles on a large scale , it may require more time than what was initially believed , or the technology may simply be unwelcome , with people choosing not to relinquish the oppotunity to drive . Regardless of the analysis and prediction of AI use in the transportation sector as a whole and its potential capabilities by the year 2030 , the single prediction that autonomous transportation will be widespread by that time is most probably incorrect .
Diminished AI moral problems
The article Artificial Intelligence and Life in 2030 mainly introduces the history and current progress and obstacles in artificial intelligence -LRB- AI -RRB- field . It can be seen from the article that AI can have a large range of application though there are still obstacles like the invasion of privacy and low-employment situation after several positions are replaced by AI . Yet there are some moral aspects that the article failed to address that also requires a solution . The uncanny valley hypothesis and moral problems such as the trolley problem that the autonomous cars need to resolve .
According to the article , AI field can be summarized into two general categories , machines that require less interacts with human , such as autonomous car , and robots that are required to communicate with human , including part of the educational AI . For the AI that needs to involve with real human beings , the article talked about financial and technical issues that encumber the popularize of such robots , while it failed to discuss a psychological problem that human-like robots themselves can cause discomfort to public . A hypothesis called the uncanny valley is studied recent years as AI becomes more common . The uncanny valley hypothesis stressed that when observing a human-like robot or other object , negative feelings such as nausea may be triggered . In fact , research has proved that human-like android faces can cause trust issues between human and the robot -LRB- Mathur et al. , 2016 -RRB- . Despite of the problem itself , there has not been an effective method to determine how likely should robots be in order to serve people perfectly . It may seem inconspicuous today , yet it still exists and when robots really begin to interact with human in the future , the uncanny valley could have a large impact on the relationship between human and AI .
Despite of the uncanny valley effect coming from AI with human-like appearances , the autonomous car also faces moral barrier which the article does not focus on . When human drivers are replaced by auto-driving , a significant conflict is that who is in fact in charge of the car and who is responsible for all the accidents that could happen to the self-driving car . There is one solution given in the article which is that the car is only autonomous when the human driver s hands are on the wheel . Besides the fact that this is not the perfect solution since accidents can still happens as proved in the article afterwards , it is also not able to solve some of the moral problem , such as the trolley problem . When a train is going to kill five people standing on the tracks while you are the only person who can switch the train to a side track , on which there is only one person . Even for real human , there is no certain or correct answer to the problem . Similarly , when there is an unavoidable accident and only the driver or the pedestrian can survive , it is hard to tell which choice should the car choose -LRB- Why , 2015 -RRB- . When a human driver is in the car , his or her decision is usually understandable since it concerns his or her own life . On the other hand , the programmer may not be forgiven for designing a car that takes a life . Situations like the trolley problem is not usual but still can appear . As a designer , making the choice for the customer is where the hard part is .
Moral issue is an enormous challenge for AI . Maybe other barriers like the privacy issue , can be solved by a line of code , moral issues have no correct answer or an exact boundary . Maybe one day the moral criterion itself will be modified to adapt the necessity of the society , but for now , these questions still remained unsolved and requires more consideration .


Reference
Mathur , M.B. , & Reichling , D.B. -LRB- 2016 -RRB- . Navigating a social world with robot partners : A quantitative cartography of the Uncanny Valley . Cognition , 146 , 22-32 .
Why Self-Driving Cars Must Be Programmed to Kill . -LRB- 2015 -RRB- . Retrieved from https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/


Overall , the Universities analysis of artificial intelligence was insightful and interesting to say the least . Many of the aspects covered in detail were far outside the realm of things that I would have even considered . AI being applied to things such as senior home care was a novel idea to me and it represents just how vast and ever-evolving the field of artificial intelligence is .
What I would like the challenge is the idea that , in the short term , there is no risk that AI will autonomously commit violence , only risk that malicious people will use the power associated with AI to inflict harm . I assert that eventually there will be an event horizon where the concept of the shifting definition of artificial intelligence will halt and the world will see a true irrefutable intelligence form made completely by humans . As the field grows and more money is poured in , the exponential nature of this technology will be realized . Even now I believe , on the graph on intelligence vs. time , we are at the point where the field will explode and the technology will not longer be able to be controlled . Even today we are seeing companies like facebook having to shut down their AI projects because they had started to communicate in a language more efficient , but less understandable to humans . I hate sounding like a man in a tin foil hat but I believe we are on a crash course with the fabled singularity . A hypothesized time where technology realizes the flawed and inefficient nature of humans and subjective thought , where production and growth only limiting factors are the resources available and there is no regard for human life or environmental longevity .
While I do see that the advantages of AI are vast and revolutionary , I do not deny that there is real good that can come from continued research and development of this technology . What I do believe is that is should be heavily regulated and closely watched , constantly ready to be shut down completely . I ask at what point is it considered unsafe ? How many people need to die in car crashes due to unknown technical problems with autonomous cars ?
As the field inevitably continues to advance and AI continues to become a more important staple in the life of the average human there will come a time where humanity will have to consider that this all-knowing technology may be systematically undermining the human experience , constantly pushing society closer to the edge before we step off it ourselves.The Stanford 's Hundred year study on Artificial Intelligence presents the experts ' opinion and reviews the perceived growth of AI . It presents the risks and challenges arising from the progress of AI . It informs the public of the advent and uses of AI , researchers on the potential hot areas of future research , industry on the areas that would require legal and ethical treatment and the government for framing policies and models to accommodate for the anticipated growth .

There are a number of assumptions in the report that would weaken the cause of the report . The premise of the report , a North American city is pretty restricted and does n't encompass the variety and diversity of people , cultures , technologies . The report argues that presenting poor information about AI would hinder gaining public trust . But the report puts in minimal effort to define AI . Since AI is multidisciplinary and evolves as it grows , the report fails to present a definite picture . Also any AI system can act biased if the input data is skewed .

Though AI is growing at a fast pace , it can not match the human capabilities of autonomy , versatility and creativity . As a counterexample to the argument in the report , if machines are human aware and intelligent in par with humans , they would create a never ending cycle of creating such intelligent agents , throwing the humans out of this ecosystem rendering humans powerless which is not expected out of an ideal AI system .

In the transportation sector , the argument says that the people would start living away from cities with the introduction of smart cars which need not always be true . Also with intelligent parking assist systems , the government would miss out on the revenue from the parking tickets which would add financial stress on the public . The success of such systems is also dependent on the tolerance of humans to their errors . So , a small fault committed by the system during its early adoption may create a wave of aversion against it . Though self driving vehicles could be used for delivery services , the extent of their fault tolerance is not described .

In a clinical setting , AI agents can only augment the reasoning capability of a human doctor . Verbal inquiry with the patient may be of no use if the patients are reluctant to share sensitive personal information to a machine . Automated image interpretation is a complex task even to the reach of modern AI as AI can only perform object and activity recognition and not reason based on an anomaly in the image . Physical assistive devices for elderly may provide them with independence and social support but can not replace the support ofa human caretaker .

In the education sector , AI helps to increase the classroom size which reduces the personal attention to students mitigating effective learning . Surveillance to provide public safety is counterproductive in that it completely undermines the need for privacy . Also , continuous monitoring through cameras , drones and of social media unjustifiably punishes the innocent .

The greatest impact of the growth of AI is in employment where it replaces most of the tasks that require minimal cognitive ability . Thus it leaves out only the top layer employed depriving almost the majority of the population of their jobs . The unemployed would start perceiving the technology as a competitor rather as a collaborator .

In the entertainment sector , digitally generating content for art forms and providing engaging and pervasive games , AI prevents interpersonal communication and makes humans only interact with devices and agents . In such an environment , it would seem like the human is agent-driven rather than vice versa .
The study states that `` in the typical North American city in 2030 , physically embodied AI applications will not be limited to cars , but are likely to include trucks , flying vehicles , and personal robots . '' My critique of the study is that while the technology will most likely exist by 2030 , I believe that this timeline for AI adoption is too accelerated . The abilities of autonomous vehicles and personal robots will be drastically improved , but their use could be stifled for reasons outside of the field . We have many of these technologies in a limited fashion already , but I think that the study understates how accidents and fear of AI will impact this timeline .
This is especially true in light of recent event regarding self driving cars and mishaps with autonomous software . Last year , a Tesla vehicle crashed and its driver was killed . What made this accident unique was that the car was in autopilot mode , making it the first accident of this type in which the driver was killed as a result of a self driving car . The autopilot had difficulty seeing a white semi truck and failed to apply the brakes causing the accident . However , Tesla noted that the driver was instructed multiple times to have his hands on the wheel of the car yet he only had it them on for a total of 25 seconds in the 35 minutes of driving . It is important to note that Tesla was cleared of fault , but it is accidents like this that may jeopardize the speed with which autonomous software and AI is adapted .
While autonomous technology has come a long way , it is not perfect yet . The accident served to help increase safety in Tesla 's vehicles by adding additional measures to prevent crashes such as these in the future . However , it also created fear because it shows that AI vehicles and algorithms can still act in surprising ways and creates distrust between users and the machines . It also raises the question of whether machines may not perform as highly as expected in real world situations . No one wants to be the test pilot in an experimental system in which mistakes can cost you your life . Any experimental technology will have pitfalls along the way , but if the mistakes are too costly then it could negatively impact the technology 's adoption .
Furthermore , humans fear things that are not like them , and the fear of machines could be detrimental to progress with mistakes and accidents only making the divide worse . Take for example many facets of Hollywood and their connection with AI . Movies such as Terminator , Age of Ultron , and 2001 : A Space Odyssey , all depict hyper intelligent computers as enemies of humanity . The idea of computer controlled machines working against humanity is a common trope , but one that does show humanity 's fear of the unknown . It is one thing to allow an autonomous robot to clean your house , but a completely different story when it has control over your life . It means that there are many barriers to overcome before AI is truly embraced . There are numerous applications for AI and the technology will surely be advanced enough that the cities of the future could be teeming with AI . However , I believe that human nature and the fear of AI will limit the speed of its adoption . One Hundred Year Study on Artificial Intelligence stated that transportation is probably the first domain that AI system is widely accepted by the public . However , unlike education or entertainment domains where the decisions AI system made are usually complimentary , any issues AI systems generated on transportation can have severe consequences . For instance , Tesla s autonomous cars are very popular recently , and they introduced the full self-driving cars , which are even more advanced than the semi-autonomous cars mentioned in the article . Nevertheless , as the article said , the first fatal accident with an automated car happened in 2016 . The AI system on the Tesla Model S failed to apply the brakes when there is car turning left in front of it -LRB- Business Day , 2016 -RRB- . One Hundred Year Study on Artificial Intelligence cited that self-driving cars will be widely accepted by 2020 , where the statement can be rejected with the accident referred previously . Compared to driving a car that can become out of control at any time , introducing teaching robots or AI healthcare system seems to be more acceptable . The mistakes made by teaching robots and AI healthcare system can usually be corrected later , but the mistakes are likely to be irreversible . Therefore , it is likely that the applications of AI on healthcare and education will outcompete the applications on transportation , although the latter one sounds much more attractive .
Furthermore , the applications of AI on healthcare can have many problems . For diagnosis , if the result of AI system influence the judgement of the physicians or clinicians , and a false decision is made , then the patient will suffer . There are two types of mistakes : when the patient actually need the treatment but the AI system and the doctor think he/she is healthy , which is so called False Negative , result in missing the best treatment time , then there can be severe consequences . Another case is so called False Positive , where the patient is actually healthy but the AI system and the doctor mistakenly decide to apply the treatment . For instance , when AI tells there is a cancerous tumor in the abdominal cavity of the patient after analyzing the images , and the doctors believed it after accumulating all the data , but eventually found it is not a tumor the patient suffers even more than the former case . Usually , the machine learning algorithms requires validation to make sure it functions properly . However , in healthcare domain where wrong diagnosis and treatments can also incur serious problems , how well the AI system can perform is really critical , and we can t even afford it to have a mistake . It is unlikely that a perfect AI healthcare system can be generated with zero False-Positive and False-Negative rate , which even the most experienced doctor can hardly guarantee .
The patient privacy discussed in the article is another obstacle for the application of AI in health systems . In this internet era , we are benefiting from data sharing , but are also losing the privacy . While the personal health information can be extremely valuable and therefore generating unregulated commercial uses , it is hard to say whether AI applications such as mobile apps will benefit or obsess people more .
521 words
In the Stanford One Hundred Year Study on Artificial Intelligence , the authors raise the concern of government taxation in relation to AI . The article suggests that the government may attempt to pass regulatory laws that slow the progress of AI in order to adjust taxes to account for shifting labor conditions . This prospect is alarming . Emerging AI technology could certainly have a large economic effect with enough diffusion into different industries . It is true that this technology could eventually replace many current jobs . However , great care should be taken with policy regarding AI from a regulatory and taxation perspective . In fact , government should do everything it can to not impede the progress of AI , and even encourage its development .
Government irresponsibility regarding taxation is clearly an issue . The prospect of jobs being replaced by AI , and the subsequent unrest that could be caused should certainly not be ignored . To alleviate this , policy makers should begin to come up with solutions right away . AI is already quickly seeping into many industries , and politicians need to respond to this before it becomes an issue . If delayed , the rise of AI could cause a large amount of unrest or a reactionary response from the government .
A reactionary response to this shift from the government could pose large problems . Firstly , it should be stated the government excessively taxing or regulating AI development to slow progress while it figures problems out is not only antithetical to the ideas of economic liberty in America , but also regressive in multiple ways . AI has the potential to help many people in this country and beyond , expand the economy , and further human knowledge . For example , AI developments in the medical field can help the population generally , self driving cars can help prevent the many deaths resulting from car collisions , AI development in consumer electronics can grow business , and the advancement of AI will help us to define what intelligence even is , and furthermore , possibly what consciousness is eventually . The advancement of technology and science in and of itself is reason enough not to impede process . It is not known in the present how crucial certain scientific discoveries become in the future . Chemistry , physics , computers , and many more endeavors have fundamentally altered and improved the lives of everyone . This is undeniable . The many ways that AI may save lives , help people , or just make lives simpler is purely inference at this point in time . The potential is certainly there though .
This argument doesn t ignore the fact that AI could lead to important issues . The employment of people is certainly crucial , and should be addressed . Similarly , questions of privacy and ethics should be addressed . However , more nuance needs to be used than simply over-regulating or slowing progress through excessive taxation . Problems need to be truly addressed , not simply pushed aside . A reactionary response to AI will not solve any true issue , and discouraging business in AI will simply hurt the economy and lose business to other countries .
The potential of AI is undeniable throughout many disciplines . This should not be ignored . The pursuit of a better world , better entertainment and technology , business , and general knowledge is all worthy . Therefore , government should shy away from impeding technological progress and should encourage the development of new technologies in AI .
Artificial Intelligence is highly helpful to human beings in wide range of domains . The report One Hundred Year Study on Artificial Intelligence argues that though AI replaces some of the human jobs , it also creates jobs for people . However , I challenge its argument that there will not be a scarcity of jobs due to AI 's replacement of human jobs in future . The replacement of human jobs by AI in the fields of transportation and education is highly possible and it will lead to a decline in the availability of jobs , in those fields , for people .
Artificial Intelligence is playing a vital role in the creation of self-driving cars which in turn , in the domain of transportation , leads to a loss of human jobs such as driving of taxis and trucks . AI is assisting humans in developing self-driving cars . One Hundred Year Study on Artificial Intelligence states that advancement in AI has led to the invention of autonomous and semi-autonomous cars -LRB- p. 20 -RRB- . These cars could replace non-autonomous cars in near future . One Hundred Year Study on Artificial Intelligence also indicates that self-driving cars could be adopted by people by the year 2020 -LRB- p. 20 -RRB- . The possibility of wide usage of self-driving cars in future could lead to the replacement of jobs such as driving of taxis and trucks resulting in a decline in the number of jobs available for humans in the field of transportation .
Apart from replacing jobs in the sector of transportation , AI also replaces a great number of human jobs in the domain of education . Many different robots have been taking the task of teaching . One Hundred Year Study on Artificial Intelligence states that there has been a development of robots such as Ozobot and Cubelets which can teach coding and logical thinking respectively -LRB- p. 31 -RRB- . These robots perform the tasks of teachers . Apart from teaching kids , advanced robots that have been developed also train military individuals . One Hundred Year Study on Artificial Intelligence also states that avatar-based training modules can train military officers the way to behave with people from different cultures -LRB- p. 32 -RRB- . Advancement in AI could lead to the replacement of a great number of teaching jobs .
AI will less likely create jobs in future . Though the report claims that AI also creates jobs , there is not enough evidence presented to support the claim . One Hundred Year Study on Artificial Intelligence states that AI creates jobs in future -LRB- p. 38 -RRB- . AI is replacing many human jobs . The possibility of jobs that can be created is very less . One Hundred Year Study on Artificial Intelligence states it is difficult to predict the jobs that could be created by AI -LRB- p. 8 -RRB- . The fact that there is not enough evidence on what kind of jobs could be created in future indicates that there is a slightly less possibility that jobs will be created for humans .
Though Artificial Intelligence is helpful , it can highly replace people in various fields of jobs . The report argues that AI also creates jobs . However , there was not enough evidence provided to support the above claim . The replacement of individuals by AI in many domains is highly possible . In particular , it is highly likely that AI replaces many human jobs in the fields of transportation and education .
Is artificial intelligence a misnomer ? Can we ever truly consider a machine to be intelligent ? A line must be drawn ; there is a difference between knowing and being able to truly utilize what one knows . As Merriam Webster dictionary defines it , intelligence is `` the ability to acquire and apply knowledge and skills . '' Stanford 's 100 year report predicts that as companies begin to operate with greater amounts of information at their disposal through concepts such as Internet of Things , their technology will consequently become increasingly receptive to human needs . But is this real intelligence ?
In this age of information , machines process more and more data every day -- but how much of it actually gets meaningfully digested ? Without comprehension , can the storage and algorithmic retrieval of data truly be counted as intelligence ? On page 13 of Stanford 's 100 year study it is stated that `` as a rule of thumb ... any activity computers are able to perform and people once performed should be counted as an instance of intelligence . '' I challenge this . It 's more often the case that jobs that machines can readily take over are seen as overly-simplistic . Prior to automation , packaging cans by hand and stapling papers together were tasks routinely carried out by humans , though one would be hard-pressed to describe these worker machines as `` intelligent . ''
Even raising the bar to a task that many humans see as epitomizing intelligence -- playing chess -- we find that the programmers responsible for the machine capable of beating the human world champion do n't deign to call it `` intelligent '' -LRB- page 13 -RRB- . Even in the glow of its victory , it was derided as being a simple `` collection of ` brute force ' methods . ''
So , what is intelligence then ? One of the founding researchers of artificial intelligence , Nils John Nilsson , on page 12 defines intelligence as `` that quality that enables an entity to function appropriately and with foresight in its environment . '' From my own belief , this echoes the key element that separate humans from other animals : formulation of abstract thought . While they lack a finely tuned sense self-preservation -LRB- and for this we should be grateful -RRB- , both qualities are the products of the billions of years of evolution that have allowed humans to attain their immense versatility . On the other hand , outside of a prescribed set of conditions , machines do not thrive . They fail to consistently adapt to any challenge they are confronted with .
So , can anything that did n't arise from countless millennia of trial-and-error be considered worthy of designation `` intelligent '' ? That 's a fairly steep demand . More optimistically , could genetic algorithms be considered the first semblance of true `` intelligence '' in a machine ? Through so many generations of selection , they are able to grow effective `` neurons '' to aid in decision making . The artificial `` intelligence '' that this results in would be comparable to a rudimentary living organism , reacting to only the most basic stimuli in its environment . Are the digital signals of a circuit board so different from the electrochemical signals of the brain ? For now , they are . But the gap between artificial intelligence and true intelligence grows smaller by the year .


CS 540
Jerry Zhu
Due Date :9 / 13/17

Are self-driving cars really safe ?

AI , namely , artificial intelligence , is very popular recently . The definition can be traced back to Nils J. Nilsson who said that artificial intelligence is to make machines smart to the extent that they work properly . One of its future predicted function is to become drivers which will change ways of transportation dramatically . Some people argue that cars will drive without instructions from human in a much better way human driver can not even imagine . Automated function includes Intelligent Parking Assis System , Summon , Late departure system and the latest one , Lane changing on highway . It seems like there is great leap under the development of artificial intelligence . Self-driving cars are made possible with help of AI . For example , Google s autonomous vehicle drives on the streets now without any human interruption .

It is for sure that many companies are researching on this new technology with AI , just like Google and Tesla . However , some may doubt whether such automated driving cars can be put into market due to lack of security , both online and offline . It is dangerous when one sit in a car which can not be 100 percent safe . Passengers are even exposed to many hackers behind the network , who could have control of the car . It is not hard to imagine what will happen if self-driving car is a reality with such poor security system .

Self-driving cars , as mentioned in Stanford One Hundred Year Study on Artificial Intelligence , may not be safe when you get into a car crash with a truck or any other vehicles . Driving is a very complex issue that can cause huge trouble to drivers and passengers under unexpected circumstances . These situations will also frighten the car itself , making it anxious yet know nothing it could do to save life of people in it . There are many dangerous factors that are hard to consider when computer programmers design the self-driving car , such as pedestrians , traffic light and bikes . It is not easy to deal with various objects on the road , both moving and stilled . Although some raw models exist early in 2000 , it is still a challenge for researchers that still needs a long time to solve .

It is also easily hacked by computer programmers who have a bad idea . As it is known , there are many cameras on the car which work as sensors , helping computer to decide which direction and lane to go to . It is a necessary part of self-driving cars yet it can cause influential problem . Imagine if anyone trespass the secure wall and being able to see your cameras , your behavior , and even know where you live and work . No one is sure what these backstage manipulators will do . That is horrible for the public that they are living under surveillance of everyone . If these downsides of advanced AI technology is not overcome , people should not put such self-driving cars into use .

Indeed , if many people adopted self-driving cars , it would be time-saving on the road such as no more needs to search for a parking lot . It also saves money to not buy a car but instead use public AI-powered smart self-driving cars . These cars may be very useful to humans one day but that is probably going to be far in the future since we are just at the beginning of putting this technology into use and have many fields not fully understood . Researchers should not forget to come up with a good solution of security problem and ensure users to move safely on the road . Only when public safety is maintained should it be authorized to the public .

Reference :
Stanford One Hundred Year Study on Artificial Intelligence . AI 100 Standing Committee and Study Panel . https://ai100.stanford.edu/2016-reportEvery system will always have flaws and so is a system which is coherently developed with very good AI . The Study Panel report summarises the reflections about AI in the past and how it will grow and function in the future . The most recent story of Facebook shutting down its `` negotiator bots '' due to the bots developing its own language for negotiation is an example of how AI could well work within the given framework but still misbehave according to the ground rules laid out by us . Similar problems have been seen in the recent past and based on these instances , there are a few aspects of Study panel report that are challenged subsequently .

The first category that this report challenges is public safety and privacy . The Study Panel report emphasises on how AI can provide better security and safety to the public through white collar crime detecting softwares and automatic identification of crimes from camera and so on . Although , these are great advances , two recent incidents of misuse of AI have put a mark on this particular domain . First , an insurance company , tried to use Facebook data of users to see if they could fit into a particular scheme called `` firstcarquote '' and mentioned that if they did qualify they could return with very good savings . Facebook then blocked this particular company as they were in violation of Facebook 's Platform Policy of using data for eligibility criteria . This is a case of the privacy of a user being intruded by AI . Another example is of Microsoft 's chatbot Tay which turned racist on Twitter . The main reason for this failure was that the bot was not taught on how to understand inappropriate behaviour from other users . Though , the Study Panel report mentions that every AI system developed should not be biased and should work in the best interest of the public , it is probably not yet possible to develop AI to handle such diverse data when the scope of data is so wide . Therefore , a longer period may be required before AI is let in to handle an area as sensitive as human security and safety .

Healthcare services and AI is probably the most exciting combination that is due by 2030 . If it comes off well , then the implications for our future generations could be great . The Study Panel mentions that for AI to be successful in this domain it has to be accepted by the doctors , nurses and EHR will have to be supported and most importantly , AI will have to gain the patient 's trust . One important point to note is that if AI is introduced in the clinical surgery field or even as an `` AI Physician '' , the dataset in this field is ever growing and diversifies by the second . Hence , to be able to train a robot to perform a task which appears to be redundant could become fatal because of an unknown variable . Healthcare workers are trained to not only pass the required knowledge criteria but they are also trained on how to deal with circumstances which are completely unforeseen and hence , an `` AI Physician '' or a `` Clinical robot '' could find itself out of depth in this domain . Therefore , AI in this domain will need a much longer period of training and supervision with very large amounts of data before actual practice is started .

The above mentioned two categories are the most prominent challenges that AI will have to deal with before it can be realised efficiently with people 's trust in any urban city.I generally agree with most points about AI -LRB- artificial intelligence -RRB- in the Stanford One Hundred Year Study on Artificial Intelligence . However , I can not accept the authors view about the future application and good performance of AI in transportation or self-driving cars . More specifically , the authors think that when self-driving cars have a higher speed and better performance , these cars will cause great changes to the whole society . I think the authors are a little bit over optimism in the application of self-driving car , and they did not consider the problems brought by human drivers , emergency to AI system , and uncertainty on the road .

Driving is not only a skill to human beings , driving can also becomes a hobby to them . Even with the arrival of self-driving car age , in which AI takes the place of most human drivers , it is impossible to extinct those people s interest in driving , or even forbid those to drive . There will still be a considerable amount of human drivers in the future . The existence of these human drivers will limit the performance of self-driving cars , especially their speed . Although the maximum speed of self-driving car could be higher than that of cars driven by humans , self-driving cars should not reach that speed when driving on a road with other cars driven by humans , because that speed could be too fast for human to react and could cause traffic accident . Therefore , the speed will not increase and people will not save time on the road , not like what the authors said in the essay .

In addition to the limitation brought by human drivers , long term self-driving by AI will humiliate human s driving skills . This kind of change will not cause safety problem when the AI system keep working properly . However , there is never a perfect program . When the AI system in the self-driving car get something wrong , and can not fix it by itself or get connection to get remote control , it is not a good idea to just stop the car , an action that is even more dangerous , so it make sense to switch its control to the human driver in this kind of situation to keep running . Then a more serious problem comes , with a long duration of AI-driven trip , the human driver in the car is more likely to be a passenger rather than a driver . That means he or she gets unfamiliar with driving car by hisself or herself . In this way , making human driver to take control of the car losing AI control increases the safety risk to both the driver in the car and other cars on the road significantly . This could be a hard problem for AI system to choice : whether it should switch the control to human drivers , when it is sure that it has something wrong in its problem .

Besides the problems related to human drivers , self-driving cars also have problems to deal with uncertainty on the road . It is true that machine learning gives intelligence to the AI system -LRB- numerous data and information are send to AI and make it know how to deal with most of situations on the road -RRB- , but such kind of intelligence is still very limited . There are still lots of situation are not included in these data and information , which can be called uncertainty on the road . When meeting uncertainty , AI will face the previous problem , whether it should give control to human drivers .

I think all these questions will challenge the future AI application in transportation .
Will human beings be replaced by AI ?

As we can imagine , Artificial Intelligence -LRB- AI -RRB- has involved in almost everywhere of our life . There are a lot of merits and social influence of AI on jobs , life style , the environment , transportation , health care , social stratums and so on . For instance , my friend was saved by his Tesla 's semi-autonomous cars one night after a hard day 's work . He tried to change the lane , but he did not notice there was a car in the blind spot . Fortunately , his car detected the danger and avoided one car accident . According to the article `` Artificial Intelligence and Life in 2030 '' , AI will be widely applied to our daily life .
With the development of AI , more and more people are curious whether human beings will be totally ruled or replaced by robots in the future . In many movies or TV shows , AI is shows as the embodiment of evil . For example , in the TV shows `` Agents of S.H.I.E.L.D. '' , brilliant scientists built a human-shape robot , called Ada . With human feelings and advanced AI system , Ada revolted the control of scientists , upgraded her own system and also made more human-shape robots to help her win the person she loved and govern the frame world she built . Of course , Ada failed at the end . Except from the story needs , I think it may imply that AI will not easily take up the spot of humans at least in the following 15 years .
One of the challenge is that AI does not have common sense . Humans learn common sense from the experience of daily life , while AI knows things only from programming system . When people see grass and notice that grass is green , our brain will automatically reflect that grass is green , which is called connectivity concept . If there is nothing about one common sense in the object memory , AI will never understand it . You may say , AI can do machine learning or deep machine learning . You should remember that the precondition of those two learning processes is that the related concepts are in the program . In other words , AI does not have the learning capacity of connectivity concept .
Another reason of why human will not be replaced is that AI is just a tool for humans and constructed by humans . AI is based on humankind . AI is as strong as the human manual power . All AI robots that are built according to the available knowledges are mimicking the human beings and tried to be infinitely approach to human beings . In the age of Artificial Intelligence , there are more and more new jobs being created . The era of AI requires more human beings to maintain software and repair hardware . Also , there is no doubt that more programmers will be needed in the future . Job positions requiring higher knowledge educations will not be eliminated , since experts and AI may need to keep an '' eye `` on each other . Mutual supervision will improve the quality of their work .

The main issue with the 100 Year AI Study is that its scope is far too small to truly be a comprehensive
study of how Artificial Intelligence develops over the next one hundred years . The 2016 report explicitly states that
the researchers chose to focus on AI 's effect on life in North American cities and only in certain fields . The stated
purpose of this study is to `` provide a collected and connected set of reflections about AI and its influences as the
field advances '' -LRB- Stanford 2016 Report , 1 -RRB- , but to properly do this they shouldn t be choosing fields and locations as they see fit .
North America should in theory have a full timeline of the progression of AI , at least in the fields the
researchers choose to include , However , being able to look at North America without getting a clear view of the rest
of the world makes it very easy to miss or hide things from the study . If a similar study , one that only looked at the
effects on North American life , was done about the development of the computer starting back in the 1940 's it would
have found profoundly almost exclusively positive changes to society . This hypothetical study would miss all the
suffering in some non-North American countries to produce computers on an enormous scale so that North American 's
could prosper . For example , this study would miss the many wars in Africa fought over Coltan which is needed to produce
countless digital products . These researchers should not assume that Artificial Intelligence wo n't have any negatives
that appear exclusively outside of North America .
On the topic of war , it was incredibly foolish to purposely leave militaristic applications of artificial intelligence
out of the report . Militaries in the past , especially the United States military which would have otherwise been covered
in this North American report , have been early adopters and developers of new technology . It would have made sense to
take a snapshot of how AI is currently used in the military , even if its minimal at this time , to get a baseline for
future reference , because if any military decides to start investing heavily in it , the field as a whole will likely
develop significantly faster . Including the military in this report would also show uses for AI that could only exist
for a military . It 's like reporting on planes and ignoring some of the most amazing technology because its only found on
fighter jets . In the past some technology , GPS for example , have had Militaristic origins and eventually make to the rest
of the world . Including the military in this report would show the progression of some future technologies that may follow
a similar development , rather than having them just pop into the report after they ve been worked on for decades .
Overall , this report is not truly large enough to get a good idea of how all aspects of AI progress over the next one
hundred years . Even if the researchers plan on expanding the study in the future , they may as well just wait until they can do
a full report . Otherwise the most important years of this report , that should serve as a comprehensive baseline for all future
reports , will be lacking . By not having this solid baseline to compare progress to , the researchers are not fulfilling the
intended purpose of this study .
The Stanford One Hundred Year Study presents a variety of interesting perspectives on artificial intelligence and machine learning , and does its best to give a comprehensive picture of the field in the 21st century . However , there are certainly some shortcomings in its analysis and improbable predictions on the evolution of AI . In particular , the education portion of the piece seems flimsy in its reasoning . While AI could be useful for data analytics about the learning process , there is an intangible human element required for effective teaching that it could never replace .
One of the main applications of AI which the study mentions is the use of Intelligent Tutoring Systems , suggesting that these systems will help students learn more efficiently by giving individualized feedback and hints . However , any modern day student who has worked with any kind of online homework portal will tell you that such hints are rarely helpful . Obviously the current technology has plenty of potential to improve , but a real interaction with a human tutor or instructor is much more efficient . A real instructor can better understand the student 's problem solving process and present the student with guiding questions . Meanwhile , the student is able to fire back more questions in real time . For involved topics such as mathematics and physics , a computer simply ca n't obtain enough data to analyze a student 's thought process . It has no access to the student 's scratch paper or work , so it can not gather the equations , diagrams or sequential mathematical operations that reveal their errors . Even if a complex monitoring system was devised , such as requiring the work to be written on a touch screen and running handwriting analysis , there is too much variation in the ways different people choose to approach complex problems . It is much more efficient to consult a real teacher who could process all of these variables and move forward with a viable solution in a matter of minutes .
Another main aspect of the study is the prevalence of Massive Open Online courses and their potential to revolutionize education when coupled with artificial intelligence . However , there is great importance in the peer to peer and student to instructor interactions within a physical classroom setting . Educational psychology has proven that collaborative learning helps improve the understanding and retention of concepts ; explaining the material to another peer forces a student to prove they really comprehend it . Of course this sort of interaction could be simulated through instant messaging and video chatting , but physically being gathered in the same space is more interactive and more efficient . Additionally , there are many other benefits to attending a real school -- principally networking . MOOCs can not provide a student with the crucial connections that are possible in traditional higher education . Relationships with professors and peers can lead to a variety of research and career opportunities , prospects which are vital to success after university . While technology becomes increasingly important in the learning environment , the human element in teaching can never be replaced , and the applications of AI in such a complex system are minimal .
AI could offer some interesting insight into learning habits through data analytics , but ultimately a human is more efficient in the field of education . They are better able to comprehend the various factors that play into instruction and provide highly individualized help to students . While technology plays an important role in modern classrooms , the social and societal benefits of attending a real school continue to outweigh the online alternative . Artificial intelligence offers some very exciting advancements across many disciplines -- unfortunately , education is not one of them .
Stanford 100 Year Study Essay

Reading through the Stanford 100 Year Study On Artificial Intelligence , I came across a few points I disagreed with . The points I specifically had issue with were their vision of car ownership , privacy concerns in health data , and the audit-ability of AI . In the paper , they state that by 2020 autonomous vehicles will be widely adopted .
Based on the amount of autonomous vehicles on the road today , and the regulation surrounding they I find it very hard to believe that in just over two years they will achieve wide adoption . By 2030 , they predict decreased car ownership in cities . Instead they believe people will rent out the equivalent of car timeshares in autonomous vehicles . I am unconvinced for two reasons , one most car traffic happens at two defined times per day which we generally refer to as `` rush hour '' . During this time every single working person will need access to a car , but during other times there will be extreme downtimes that only a very small percentage of the vehicles will be used . I find it hard to believe that people will pay enough to rent out these time shares to make a company profit while still owning enough cars to meet the demand . The second reason is that humans desire ownership . If we need to have a vehicle to get around in every day , most people would rather have one that they own . Even when cars are leased or homes are rented today , people still act like they own them , decorating and customizing them .

Another issue I had with the paper is their lack of concern for potential privacy issues . The writers state multiple times that current regulations in the healthcare industry are preventing great strides forward in AI and medical diagnosis . While I agree that removal of regulations like HIPPA may improve diagnosis , it also leads to huge problems in patient privacy . Even if the data in anonymized , only so much information can be removed while still getting relevant information for medical use . As anyone in the security and cryptography sector knows , meta data can reliably be used to identify users so it 's not hard to imagine a situation where a patient could be identified using only the anonymized data . Combined with the regular data breaches due to lazy or negligent security practices all across the private sector , the most recent one being the Equifax breach , the much data in one place is a disaster waiting to happen .

The final issue I had with the Stanford paper is their claim that AI are inherently more audit-able than humans . Artificial intelligences based on neural networks can be very difficult to audit , as the ai may use similarities to pick out certain patterns that are n't obvious to us or are obviously not true for all systems . An example of this is the google deep dream project , where they found that their image processing network thought a forearm and dumbbell were a single object . Careful edge testing will have to happen in potentially dangerous systems to ensure AI do n't make these `` obvious '' mistakes .
https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.htmlThe Stanford One Hundred Year Study on Artificial Intelligence is , according to its authors , `` a long-term investigation of the field of Artificial Intelligence and its influences on people , their communities , and society . '' This first report from the study panel gives a broad overview of the current state of AI research and development , and provides policy recommendations that the panel believes would minimize the societal harms brought about by AI . While the report does discuss the fact that AI will inevitably supplant human workers in many industries , it ultimately fails to make any strong , specific policy recommendation to address this issue .

At several points throughout the report , the authors declare that transportation is likely to be the first major sector to be radically transformed by AI . For example , the panel states that `` autonomous transportation will soon be commonplace ... '' and that '' ... its introduction to daily life may happen so suddenly as to surprise the public '' -LRB- p. 18 -RRB- . Meanwhile , according to the Bureau of Labor Statistics , nearly 5 million Americans -LRB- or 3-4 % of the workforce -RRB- drive vehicles for a living , the majority of whom are tractor-trailer drivers . A major disruption to this industry would leave a large percentage of these workers jobless .

Given that the authors acknowledge the rapid approach of this highly probable disruption , and given that they demonstrate in Section III a willingness to make specific policy recommendations in response to other anticipated social impacts of AI , it is inadequate for the report to simply note that `` education , re-training , and inventing new goods and services may mitigate these effects '' -LRB- p. 39 -RRB- . The panel 's vague suggestions immediately spark more questions that could needlessly delay policy development . For example : Education and re-training for whom , and in which fields ? Should such re-training be actively incentivized ? If so , by whom and by what means ?

Near the beginning of the report , the panel addresses concerns about a potential runaway `` general purpose '' AI by reminding readers that progress in the field comes gradually , and is narrowly focused on specific problems . If this is true , then it should then be relatively straightforward for the authors to make concrete projections about the employment sectors that are likely to be affected next , and for them to surface those projections more usefully in their report . Armed with such projections , all levels of government could provide workers in high-risk industries with re-training incentives and opportunities . Additionally , post-secondary educational institutions could be incentivized to appropriately guide younger students toward employment paths that are more likely to be stable . As long as the public generally agrees that there should be a social safety net in place to catch those workers displaced by AI , the idea of providing financial assistance for those wishing to re-train in a different sector should not be a political nonstarter .

One of the primary purposes of this study is to keep the public broadly informed about the ongoing developments and prospects in the field of AI so that societies are better able to cope with the resultant effects , both positive and negative . The panel projects that in the next several years we will begin to see the widespread deployment of AI-driven technologies that will have profound impacts on , among many other things , our labor system . If the panel wishes to fulfill its charter , it should make stronger and more specific policy prescriptions so that governments can begin the process of enacting those -LRB- or other -RRB- policies before it is too late .
The use of AI in education will not replace high level educators . The strengths cited by the study do not lend themselves well to human education . Furthermore , the current learning algorithms do not accurately emulate the process a human goes through to learn , and the two neural networks are not comparable .
The article states that AI mimics good human tutors by providing hints when a student gets stuck on a math problem . To avoid an ungracious interpretation of this , it is also implied that this AI hint machine should be partnered with a tutor for maximum effectiveness .
This is an ineffective use of AI , and will make a minor difference on the learning rate of the student . What makes a tutor good is not his knowledge or even ability to teach new skills . Rather , what makes a tutor effective is his ability to figure out what a student can confidently do , and how to increase the students confidence in other abilities . This dynamic is fragile the tutor must not only know algebra to teach substitution , but he must also have a strong intuition of the students perception of substitution . Without the combination of these two , the tutor will not effectively address the issue . For the tutor to effectively teach substitution , he will have to figure out how the student is best able to understand the concept , and move forward in this direction . For example , if the student has a very strong grasp of the orders of operations and commutative properties , then the educational approach must necessarily differ from the approach taken on a student who does not understand these concepts .
Furthermore , there is a certain intuition about the human learning function that humans possess that can not be mirrored in machines . A tutor might realize that the student forgets to carry numbers in addition , as demonstrated by the student s work . An error as elementary as this may be caught by the machine , but there are other structural issues that only a human would pick up on . For example , if a student solves systems of equations with a matrix , then the errors the human might make could not possibly be a substitution problem . Or if the student uses addition and multiplication to reduce terms , then the tutor might realize that the student does not properly distribute the multiplication properly . Or from the tutor s past experiences , he might already have an idea as to where the student is likely to run into troubles , and he can proactively plan for that .
In these ways , an AI can not reasonably emulate a human , and as a result education must be primarily human driven for the time being .
In the report of artificial intelligence and life in 2030 , the author shows an optimistic attitude towards the mass deployment and usage of AI . However , this might not be the case since the public can still regard AI as untrustworthy and AI may not be as useful as the author states .
Although the report believes , it is possible that AI may be reliable enough after 15 years of developing , it is just an imagine . The fact is a substantial number of people do not trust them now and it is highly possible they will not change their attitude in time , which naturally results in objection of AL usage . Firstly , some of AI are not intelligent enough , fails unexpectedly and there are little sign that this situation is going to change . For example . multiple crashes that tesla auto driving car system has cause . In many cases , this auto pilot system ignores warnings and signal or fails to detect other cars that are nearby ; some cases show the system assumes every other car on road is following the traffic rules which is not always true ; few others are critical , the car just lose control . After generations of updates , only little number of bugs are fixed according to statistic of accident . These AI , after a high speed of development , apparently are reducing the speed they are evolving . With no sigh of a critical break through , these auto systems are not trustworthy . Secondly , people today are influenced in many ways that they should not trust or use them . From 2000 until now , countless number of movies , tv series , novels even games showing the rebel of AI . The Terminator for example , tells a story of sky net , an Al developed by government decided to launch all nuclear missiles . Impression of AL is evil is introduced to public , although educated people knows these devil Al are just movies and unreal , after all these years since the terminator movie , people still could not erase this bad impression of AI . What s more , the smarter AI is , the more people scare of it . According to theory of uncanny valley from Sigmund Freud who believes as an object that originally attractive suddenly been scared or hated by human when it becomes more similar to human . The movies of AI rebel were just a joke because AI are not smart enough . but as it grows , just like Freud said , people have doubt . Some people may argue , why can t people get used to it ? For me , this is just like bias , it is possible for people to get over with but this action requires a large amount of time . From history , biases or myths takes generations to disappear . 15 years is highly impossible to be enough . With this doubt of the unstable nature of AI and fear from human nature , it is more likely people will be against AI in 2030 .
AI is a good helper to human . All it need is time C time to develop and time for people to get used to . The society will be full of AI but not in the near future .
According to Stanford AI in 100 years at page 31 , computer-based learning systems are not likely to fully replace human teaching in schools . However , I believe in the next couple decades , AI will at least replace all the human teaching in a couple of schools , mostly colleges .

AIs are most suitable in colleges . First , Artificial Intelligent robots are more knowledgeable than lecturers . While lecturers may have earned PhDs in their relative fields , AIs have been programmed to answer any type of questions in milliseconds . As long as students are asking technical question without using sarcasm or double meaning sentences , AIs are more efficient in managing Q & A forums such as Piazza . Second , AIs are also programmed to perform a perfect lecture , make perfect PPTs or write like typed on the blackboard ; while a professor may be late or absent because of family issues , sickness , or conferences . A professor may also spend too much time on some specific slides , causing him to delay the course schedule or run through it fastly , yet AIs time every topic and demonstration accurately . All in All , these can end up hiring fewer lecturers , more researchers for the college and possibly lower college tuition . Thus I believe the teaching aspect -LRB- not researching aspect -RRB- of a college may fully be replaced in several state schools to reduce tuition in the next few decades .

Though unimaginable for some people , even lower level education teaching by human may be fully replaced in a small portion of schools around the world . People may expect teachers to be better than AI in passing down morals and manners , and yet seeing from the other side , parents are able to take part in `` programming the teacher '' to discipline children the way they deem appropriate . The facilities in the classroom can also be programmed so once a kid leaves his or her chair the parents can be notified . They can even use robot arms to bring the kids back to their seats or wake them up if they fall asleep . Parents can know how much lunch his or her kid has eaten , how tiring the kid is , how the whole teaching experience for the kid is , and more , like how health care AI systems are taking jobs aways from nurses and doctors . Most parents may feel uncomfortable for their kids to go through such progressive pedagogy , yet there will definitely parents would like to try , either they are too busy in work or do not believe in the current education system .

In addition , cram schools , schools that students go after their day time school , may be renovated as well . Since cram schools mostly encourages repetitive practice and strict manners , as well as cram schools are for profit , there is more intention for cram school owners to replace teachers with AI as they can lower their cost . It is also easier to create perfect education as they can make AI learn from cram school teachers without facing any legal disputes like teachers in formal education may face . All in All , different types of schools , no matter formal or informal , higher education or lower education , are highly likely to find a path to a teacher-less teaching environment .
In the Stanford One hundred year study on artificial intelligence , it is claimed that AI will enhance education at all levels , especially by personalize education programs . Some believe that AI will soon to play a major role and even replace human teacher in education . However , even though some aspects of AI might prove helpful to educators , it will require a great deal of development until AI can provide quality education because it can not provide the necessary teacher-students interaction , notice students psychological and emotional states or teach art subjects .
First of all , the most important aspect of learning is the interaction between students and instructors . The exchange of ideas is the most effective way for students to absorb knowledge . Online courses or teaching robots , even though can provide information and instructions to learners , may find it hard to explain complicated cognitive matters . When information is transferred to students in a verbal way , it is proven that they can memorize it more effectively . In a traditional classroom , students can discuss ideas with their instructor or classmates . Discussing ideas will lead to a deeper understanding of the material . Moreover , AI is claimed to help multiplying the size of classroom for educators , but that might be limited only to low-level classes . In high-level education , students will need in-hand assistance from a human teacher . Feedback from cognitive tutor might be slow and not essence to the question . Even if they can access knowledge online , students will still require a human instructor to explain complicated matters and answer questions .
Secondly , it is claimed in the article that AI can help provide personalization at scale , thus improve the education system . While online courses and Intelligent Tutoring Systems -LRB- ITS -RRB- can reach more students faster , it is far from creating a personalized education system . A good education system does not just include providing all the necessary information and courses . A teacher can notice psychological and emotional states of students while learning , thus improve the quality of education . When students are distracted or confused , teachers can notice and provide suitable action and help , when machines will just go through the material automatically . Thus , it is far more effective when students learn from a human teacher , other than an online program or an intelligent machine tutor .
Last but not least , while online courses may be helpful on some science subjects , it is challenging to build a bot to teach about arts . For example , when teaching literature , a teacher can provide subjective opinion on a novel or the author . A student can choose to believe or challenge the teacher s idea , thus have a chance to develop his own thoughts . That process , while not possible when learning with a machine , can build up students passion about the subject . Since there are no absolute right or wrong on art subjects , it requires a human teacher with subjective opinion to teach in those areas .
In conclusion , the importance of human interaction in education , students psychological and emotional states while learning and the subjective aspect of art subjects make it hard for AI to advance in education . Although AI has been effective in low-level education , or teaching simple subjects , it still requires massive development to be more effective in the education industry .
Stanford 's One Hundred Year Study on Artificial Intelligence report argues in second last paragraph on page 42 that artificially intelligent systems and humans have complementary abilities . It goes on further to claim that humans are likely to focus on tasks that machines can not do as well , and gives the examples of complex reasoning and creative expression abilities of humans . While this may have been true in past , it may no longer hold true in next few years . Advanced algorithms are being developed capable of complex reasoning and even creativity , equivalent -LRB- if not better -RRB- to humans . A research paper on Creative Adversarial Networks -LRB- CAN -RRB- titled `` CAN : Creative Adversarial Networks , Generating Art by Learning About Styles and Deviating from Style Norms '' by Rutgers University in collaboration with Facebook Artificial Intelligence Research -LRB- FAIR -RRB- lab , and College of Charleston claims that machines are able to make painting as good as human artists and in some case people prefer painting created by artificially intelligent network to the ones made by human artists . The AI network was provided with 81,449 paintings from 1,119 artists covering wide variety of painting styles from fifteenth century to twentieth centuries . The research group conducted the experiment to examine if people are able to differentiate the paintings generated by machine from paintings created by artists and result showed that people could not distinguish machine generated paintings and paintings created by contemporary artists . This is not a one-off case and there have been multiple such events , for example another being `` The Next Rembrandt '' painting by system developed by Bas Korsten . Unfortunately , most of the current AI systems focus on mastering logic and not creativity . Creativity has been a neglected topic for a long time in AI research , mainly due to insufficient funding which in turn is because of muted potential of commercial opportunities in such endeavors .

Creativity is one aspect . There have been a lot of research going on understanding human emotions and researchers recently have been able to develop a system which can understand human emotions to a certain extent . It should not be too far in future when a robot can not only understand emotions but can also appropriately emulate them . Additionally , reinforcement learning and various other fields of AI are making AI systems smarter by every day . These AI systems are able to perform complex reasoning , one such example being AlphaGo developed by Alphabet -LRB- Google -RRB- which beat the game champion Lee Sedol in a five-game match of boardgame Go . It is evident from these events that AI systems and humans have a gap in their intelligence and they are not necessarily complimentary to each other . AI systems are not as smart or creative or emotionally intelligent as humans . Not Yet ! But that does not mean they will never be . This gap between AI systems and humans can be attributed to the fact that research in AI has gained momentum only recently and research was not so active before 1960s . As research in this field deepens and the gap shrinks , human abilities might become a subset of AI systems ' abilities , and not necessarily complementary .
This study does do a good job of laying out the many benefits that artificial intelligence will have on society . It has the power to revolutionize industries and human life in general . However , the article with its abundance of optimism spends a considerably smaller amount of time discussing the challenges that will face us in the not-so-distant future , especially concerning employment and the people AI replace .
The article itself says multiple times that the pace at which AI is advancing is intensifying across all disciplines . Yet the article still insists that AI will not replace jobs quickly enough to replace jobs at an alarming rate . If the technology eventually exists , companies with the capital will work to implement these technologies into their business . Even if it is gradual within a company , when multiple Fortune 500 companies move to implement the changes then the change will seem much more dramatic . And as principles of capitalism shows , if one company has success implementing AI , then their competitors will work to follow suit to remain competitive in their markets . Fast food companies employ millions in the US , and large stores like Target and Walmart employ millions more . If these jobs were lost at even the rates of tens of thousands per year , that would be dramatic and have a real affect on our economy .
The article instead focuses it s discussion about AI in the workforce about the benefits of automated work . It is certainly true that AI will decrease labor cost thus making goods cheaper , and even create some jobs . However , these decrease in costs will not be as dramatic as it likes to hope , and it will benefit those who do not see their incomes affected by AI the most . The average truck driver makes forty thousand dollars a year . If that truck driver delivers 2-3 truckloads a week of goods , then those 2-3 truckloads would be on average around eight hundred dollars cheaper . While that is a tangible decrease in costs , when averaged out between all of the goods , the benefits are much less . Also , there will be costs of maintaining and upgrading these machines in AI that will add new costs to the AI . And furthermore , the people replaced by AI will have no income to spend on these goods , no matter how large the decrease in price is . And while these AI will create new jobs to maintain them , there will be nowhere near as many jobs they replace and the people who are replaced often don t have the skills or means to obtain the skills to fill these new positions .
The purpose of this argument is not to convince that AI should not be integrated into the workforce . The benefits of AI will definitely have tangible benefits for society . The purpose of this argument is to draw attention to the fact that more will need to be done for the people displaced by AI . The article does touch on solutions , but doesn t give much importance to their implementation . But the fact is if AI do eventually replace most low-skill jobs , it will be in the best interest of the workers and the capital-holders to implement safety nets for society . There will be a considerably smaller market for non-necessities if people do not have the money to buy them which would impact countless companies . Solutions like a universal income , or revolutionizing the way profits are allocated , especially from AI labor will be needed for society to realize the full benefits of AI .
For several decades , views of the future have involved flying cars or self-driving cars . With Maximum Overdrive , Terminator , and I , Robot , fears of humanlike Artificial Intelligence systems have been a staple of dystopian future entertainment . With this level of ingrained suspicion regarding artificial intelligence , it is going to take a lot of time and PR to integrate high level AI into items used every day , especially when putting one s life in the robot hands . The Stanford One Hundred Year Study on Artificial Intelligence boasted about the achievements of AI in data crunching to eliminate biases and self-driving cars , but there are significant challenges to both of these proposed uses of AI in today s society .
The article claims that AI has the potential to provide new kinds of transparency about
data and inferences , and may be applied to detect , remove , or reduce human bias , rather than reinforcing it -LRB- p. 8 -RRB- . While this may be true , facts and statistics can be interpreted various ways and spun to support many different viewpoints . Also , the current political climate does not agree with certain facts and figures , as in they believe facts and statistics are subject to their beliefs and whether or not they want to agree . In this system , with AI already seen as malevolent , mysterious , or magical , the projections and statistics generated by AI will be called into question as less factual than human-based ones .
This leads to the fact that as the world changes , many people are stuck in their ways , especially older generations . The main conflict in this area is that most politicians are older , have antiquated opinions , and reject scientific evidence if they feel they can . Due to the mysticism surrounding AI , it is likely that harsh regulations , laws , and misinformation will block the ability for AI to greatly impact the American lifestyle in such drastic ways as fully autonomous cars .
A large problem with the dream of fully automated cars in the near future is not only older generations of people , but also older generations of cars . There are estimated 250 million cars on the roads today from several decades with various levels of integrated technology . The technology for self-driving will likely be quite expensive , meaning most will not be able to afford it . Therefore , the AI will have to deal with many bad drivers in cars that they possibly will not be able to interact with as well as their same generation . Also , the article implied that driving was an unnecessary hassle and allowing commuters to do other things is the obvious choice , but many people enjoy driving . However usually not on congested freeways , which is where the ability to let the car drive would be most useful .
The personal differences also apply to the AI application of personalized internet experiences . In some cases , the personalization is nice because I see things that are relevant to me , but in others I feel like I may be missing out on some things since it could be narrowing my experience of the world to what I have already expressed interest in , rather than opening me up to new experiences and knowledge .
Overall , the practices and applications of AI are extremely impressive , and we will see more uses in the coming decades . However , the Stanford One Hundred Year Study on Artificial Intelligence has some very high hopes and accelerated timelines from what may be probable . The technology may reach those highs , but it is unlikely that society will be able to adapt to extreme changes quickly enough for things like self driving cars to be the norm in a few years .
As the first report of The One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- , `` Artificial Intelligence and Life in 2030 '' considers the likely influences of AI in a typical North American city by 2030 and focuses on eight most salient aspects which include transportation , home/service robots , education , healthcare , low-resource communities , public safety and security , employment and workplace and also entertainment . However , although this report is comprehensive and illustrates how our lives in future will be affect by advancements of artificial intelligence from various perspective , it may overestimate the influence of artificial intelligence by the year of 2030 due to concerns regarding not only affordability but also privacy and accountability .

To begin with , although artificial intelligence indeed has the potential to improve lives for individuals around the world , not all people will be able to purchase services achieved or provided by AIs at least in the near future . Let 's take the facial recognition security system for example . Nowadays some individuals are starting to replace keys with facial recognition system to get into their houses . However , while facial recognition is more reliable and makes it unnecessary for people to bring their keys all the time , the implementation of such advanced facial recognition system cost much more money . Given today 's relatively high price of such facial recognition security systems powered by artificial intelligence , people with low socioeconomic status may not choose to purchase such systems after considering the costs and gains or may not be able to afford such security system at all . Hence , the fact that not all people are able to afford services achieved by artificial intelligence may slow the large-scale adoption of AIs .

In addition , assuming all individuals around the world have the ability to afford artificial intelligence devices or services , there are also concerns regarding privacy of individuals . Artificial intelligence tools that can scan social media to search for certain types of views or opinions indeed exist . Admittedly , such tools can be used by governments and law enforcements to monitor and prevent potential violent public actions effectively and efficiently . Nevertheless , such surveillance also violates people 's privacy and harms the safety of private data . Besides , many banks nowadays use AI algorithms to calculate default risks or credit scores for account-holders . Although the report suggests that private data such as race or gender could be chosen not to be a factor of algorithms , it 's undeniable that there are many other factors that still correlate with gender or races and the inclusions of such factors may still violate people 's privacy . As a result , individuals may not accept the utilization of artificial intelligence until concerns regarding privacy are addressed .

Furthermore , even though affordability and privacy are no longer concerns , the issue of accountability may still have negative influences on the employment of artificial intelligence . The study suggests that self-driving cars services may eliminate the need to own a vehicle . However , although self-driven cars are expected to make it much easier and safer to travel , who should be held accountable if a self-driven car fails or crashes , given the fact that current legal system does n't have comprehensive laws to address issues about the liability for accidents involving self-driving cars ? Therefore , rules and regulations about artificial intelligence must be carefully designed and enforced before devices with artificial intelligence such as self-driven cars are applied in a large scale .
Rejoinders to AI100-Study

The AI100-Study published by the Stanford University looks at the future of Artificial Intelligence -LRB- AI -RRB- , with specific focus on timeframe of 2015-2030 .
In the following essay , I have summed up my points of contention with the authors ' perspectives .

Firstly , as stated in the ` Overview ' section of the study , the study does not look into the possibilities of application of AI to military and defense
sectors.This in my view serves a blow to the scope of the study on a whole.The application of AI to military research , and its imminent
consequences just ca n't be ignored.To put things into context , Elon Musk -LRB- CEO of Tesla -RRB- , recently expressed his concern by tweeting `` Competition for AI
superiority at national level will most likely cause WW3 '' .

Secondly , while discussing the role that AI might play in helping the low resource community , the authors mention that investment in such application is
expected to be weak due to low profitability.This stands true if only the big corporations are considered as primary investors.The study seems to overlook
the fact that the governments might infact be willing to invest substantially in AI research which would help to improve lives of such low resource and
under-priviliged communities .

Thirdly , under the ` Transportation ' header of the section-2 of the study , the authors have explained in impressive detail the exciting research being
carried out in the domain of self-driving cars ; and how this will completely transform the landscape of day-to-day commute.My concern with this perspective
is , that the authors seemed to have downplayed the possible negative impacts that self-driven cars might have.If the accident rates of self-driven cars
are not significantly lower that human drivers , than the general public might acquire a negative outlook towards it.It should be kept
in mind , that self-driving cars would be the first interaction between a highly advanced embodiment of AI and the general public ; which might even go on to
shape popular opinion towards AI innovations.As a result , the mass scale introduction of self driving cars might take longer than expected by the authors ,
as they state that they are hopeful that self driving cars would be commonplace by 2020 .

Fourthly , while discussing the impact of growth in AI on employment , the authors state that many middle and low income jobs such as drivers will be lost ,
as efficient AI agents will start replacing humans to perform routine tasks.On the same note , they say that AI might as well lead to creation of some novel
job sectors ; but fail to substantiate their claim.No quantative analysis is provided regarding the rates at which jobs would be lost.The authors have failed
to clarify how exactly AI would create new jobs , specially in lower income groups.Moreover , the authors have mentioned at several occasions throughout the
study , that a social debate must be carried out to discuss how wealth generated by AI would be shared amongst the people ; but the authors have n't taken the
initiative of any such conversation via their study .

Furthermore , when discussing the role AI might play in healthcare , the study deals with various facets , but ignores the frontier of BCI -LRB- Brain-Computer-Interfaces -RRB- .
Given the fact that recent experiment by Stanford research groups -LSB- 1 -RSB- has shown how advanced machine learning algorithms might play a vital role in development of
BCIs ; and inturn uplift the quality of life for paralyzed patients .

Lastly , the authors have stated the societal challenges that the AI technologies might face.The spread of social media and other form of AI based
entertainment has caused serious behavioral changes in adults and children alike.Kids today prefer to browse the internet and play on smartphones instead of
going and playing outdoors.This might hamper their ability and zeal to form interpersonal bonds.But the study does n't investigate the probable solutions which
can be explored to minimize such side effects of AI technologies.If such concerns are not dealt with and nipped in initial stages , it might
lead to an unfavourable opinion of the public , which might impede research in AI in the near-future .

REFERENCES :
-LSB- 1 -RSB- - https://med.stanford.edu/news/all-news/2017/02/brain-computer-interface-allows-fast-accurate-typing-by-people-with-paralysis.html -LCB- \ rtf1 \ ansi \ ansicpg1252 \ cocoartf1504 \ cocoasubrtf830
-LCB- \ fonttbl \ f0 \ froman \ fcharset0 TimesNewRomanPSMT ; -RCB-
-LCB- \ colortbl ; \ red255 \ green255 \ blue255 ; -RCB-
-LCB- \* \ expandedcolortbl ; ; -RCB-
\ margl1440 \ margr1440 \ vieww10800 \ viewh8400 \ viewkind0
\ deftab720
\ pard \ pardeftab720 \ ri0 \ partightenfactor0

\ f0 \ fs24 \ cf0 Artificial Intelligence has become increasingly prevalent and important in the area of education as the development of computer science technologies . From K-12 to university settings , the use of Artificial Intelligence is accepted by more and more educators and learners . In \ ' 91Artificial Intelligence and Life in 2030 \ ' 92 , the article mentioned that people , in this age , benefit from AI education a lot by learning through teaching robots , online courses and so on . However , while people enjoy the convenience and comfort provided by these artificial intelligence educational products , these newly developing educational tools also potentially threat human education . There are still a plenty of challenges ahead for applying AI in the education area . \
\
Regarding to the online courses like MOOCs mentioned in the articles , first of all , replacing traditional face-to-face education by these online courses can cause the lack of supervision and require students to be more self-disciplined in the studying process . Take exam as an example . Exams in online courses are always held online and when to take the exam is always chosen by students themselves . Therefore , students may have opportunity to cheat during the exams including discussing with others , using textbooks or even directly search the answers online . Because it is impossible for the online courses holders to assign people to monitor students during exams through online camera , the reliability of the exam reduces dramatically . To genuinely gain knowledge from online course , students need to be real self-disciplined since there is no forced supervision . At the same time , due to the reliability of the online courses is largely depended on students themselves , the credibility of this kind of newly developing educational method is lower than traditional education . That is why most academic institutions do not accept the degree of an online course even if he or she really made effort in the studying process . \
\
Secondly , although , as the article stated , AI multiply the size of classrooms particularly in higher education , online courses can actually exacerbate the sense of isolation among students . During the online course , what people are interacting with is cold software or rather pure algorithms . Though AI can make the interaction seem to be fascinating , it can not set up a traditional classroom atmosphere with humorous instructors , various classmates and competitive environment . AI may trailer the course or teaching strategy according to the information you provide with and the performance you have so far but real human professor can be more experienced and familiar with how to deal with various type of students . Besides , people in online course did have more classmates but they do not intend to communicate with each other that frequently and frankly as on-campus courses . After the feeling of freshness is used up , students may feel greater isolation and become tried of studying in that way . \
\
Additionally , education is not just a tool to infuse knowledge to human . More importantly , in the process of education , people can learn how to be a human , communicate with other human and cooperate with other human . Most of time , what people learn from people beside them is more useful and significant than the knowledge itself . AI is indeed on the correct track to revolute human educational style but it may never completely replace human \ ' 92s traditional style because robot can never teach human how to be a human . \
-RCB- Though I largely agree with the ideas and suggestions put forth by Stanford s 100 Year Study on Artificial Intelligence ,
I do challenge some of their ideas concerning AI s influence on entertainment . As a student studying Communication Arts :
Radio/TV/Film , with minors in Digital Studies and Computer Science , I have learned a great deal about the interaction between
technology and humanity in the creation of entertainment . While everyone s experience of a work is largely subjective , I have
studied in depth what elements make a work pleasing and entertaining to an individual .
Due to this background , I challenge the study s comment that `` AI will increasingly enable entertainment that is more
interactive , personalized , and engaging '' -LRB- Stone et al. 40 -RRB- . While I do believe that AI can have a beneficial impact on entertainment in various forms , I challenge that this effect will increasingly aid in great entertainment . A vital factor in this argument is the idea that entertainment at its core appeals to human emotion and appreciation of beauty . While AI can effectively use information to study what types and themes of entertainment people enjoy , I believe there is still a need for a human creator , specifically when dealing with more complex art forms such as television and film . Today AI remains far from being able to understand , appreciate , and replicate the immense complexity of human emotion , connection , and society . It is these human yearnings , hopes , fears , and beliefs that characterize most of the best artworks , both modern and historical . Even if , in the future , an AI was created with an appreciation for human emotion and beauty as well as the ability to create an original work , I believe the understanding of emotion , and ability to evoke it in others , would be far from what people today possess .
The study goes on to say that more sophisticated tools and apps will become available to make it even easier to produce
high-quality content -LRB- 41 -RRB- . While I believe this statement is clearly true , and it implies the continuance of a human creator , I
dispute the inherent connection the study seems to make between well produced content and entertaining content . As many examples
across film , television , and other art forms have shown , the evocation of emotion is often more important than the objective
quality of the content . Many people would claim they enjoy the 1999 film The Blair Witch Project , which was made for a mere
$ 60,000 , over many modern horror films upon which many millions of dollars are spent . This example indicates that behind each
great work is a creator who not only holds a deep grasp of the human condition , but also the ability to manufacture a complex
work to evoke the intended emotion in the audience .
While I believe the study and implementation of AI will lead to greater tools for understanding popular interests and even
for producing entertaining content , I maintain that a human intelligence is necessary to envision and guide the production of
truly complex , meaningful , and engaging art . I believe AI will lead to greater personalization and production quality of
entertainment , but it will not result in increasingly more interactive and engaging content , because of the continued need for a
human creative force .
Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram
Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind
Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report
of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report .
Accessed : September 6 , 2016 .



The clear intent of One Hundred Year Study on Artificial Intelligence , to highlight -- in large majority -- the positive aspects of AI in our society , while founded in fact , does make me increasingly speculative . While I am entirely in agreement that there will not be a robot revolt against humanity any time soon , I would like to address the , perhaps overly , optimistic nature of this paper . I also believe that a follow-up study detailing artificial intelligence in defense and war-fare should be released , maybe on its own , so I do understand the committee 's decision to exclude it from this paper .

A committee of experts informing their audience of the current state of affairs in their field is absolutely necessary , and pairing that information with where they believe their field will be in fifteen years makes sense . As a reader , the latter should be kept in mind , but definitely not taken with the same level of seriousness as the former , simply because even as experts it is difficult to pinpoint how trends will change , and to account for unforeseeable circumstances . Artificial intelligence has had a fairly large impact in the general public over the past few years with companies , such as Google and Apple using voice command regularly -LRB- i.e. Siri -RRB- , or with ordering services like Amazon that have been delivering products to people 's front door in two hours using drones . The automotive industry has moved to producing more autonomous vehicles which can be seen in Google cars , or automatic parking in newer luxury vehicles . I do not wish to take any merit away from the talented scientists who made this possible especially considering the short time frame in which it was done . However , it is important to realize that as of yet two hour deliveries are limited to a few major cities , that most Americans can not afford a high-end luxury vehicle that includes self-driving technologies , and perhaps most note-worthy nearly one-third of United States residents do not have a smart phone .

The argument that in the future transportation will move towards self-driving vehicles , that would make `` traffic jams and parking challenges become obsolete , '' is a ridiculously optimistic assumption . First of all , self-driving cars will not be affordable to the average American for another few years . Tesla 's Model 3 is a step in the right direction , but with a base price thirty thousand dollars , not including the self-driving package , it is not the most accessible vehicle . Furthermore , your average modern-day vehicle has a lifespan of around 11.4 years . Most people keep their cars anywhere from 6 to 8 years before getting a new one , meaning that if you bought an affordable car in the next few years , it would last you another 10 . Not to mention the quantities of people who would n't use those features , or maybe just do n't want a car with those capabilities , similar to people today who do not use smart phones .

In conclusion , I do agree that that artificial intelligence has the potential to solve problems and do so much good in our society to the point of virtually ridding our world of some of it current problems , however I believe the time constraint in which this will happen is not 15 years from now . The researchers have made good points , and introduced a viable path for AI , however I believe they tried to fit their all their ideas into an unrealistic time constraint .

Potential Influence of Artificial Intelligence on Social Dynamics

Artificial Intelligence -LRB- AI -RRB- has been one of the several topics within CS that s gaining mainstream notoriety due to its Hollywood portrayal and , more recently , the tangible impact that intelligent systems are beginning to have within society . As Intelligent Systems continue to evolve , it s important that both researchers and the public are conscious of the natural dangers that ll come alongside it . While some are inclined to think that the development of AI will lead to a terminator-esque dystopian future , such an event is slightly romanticized and long into the future . A more realistic and rapidly emerging issue of of AI is the effect it ll have on human relationships .
The invention of the internet , and later social media , forever changed the human landscape . During no other time in history have could people connect and interact with millions of others anywhere , at any time . This digital interconnectedness though , didn t come without a disconnect in the real world . As tech moves forward , the average person is spending more and more time engaged with the technological world , rather than the physical one . The same will continue to occur once AI begins to make the breakthroughs .
How exactly does AI impede human interaction , and what would that kind of world look like ? In the homes , for example , AI technologies promise to increase the safe and reliable use and utility of home robots in a typical North American city . Special purpose robots will deliver packages , clean offices , and enhance security -LRB- 24 -RRB- . While the authors do acknowledge that such growth will be expense and slow , it will still occur . Many services jobs will be lost due to these machines as will the potential for human interactions that come with them . Now it can be argued that meaningful dialogue with our drivers and deliveryman is uncommon for most and those industries could be done away with . Regarding education however , the outsourcing of learning to digital and robotic platforms could lead to the poor socialization of entire generations . Children need to physically play and interact with other children to develop adequately . A possible solution for this might could be virtual environments , Virtual reality and haptics could enter our living rooms personalized companion robots are already being developed . -LRB- 41 -RRB- . The question remains whether VR is an adequate solution to the decreasing avenues of meaning engagement that humans will have with one another -LRB- and even VR doesn t solve the physical components of interaction -RRB- .
The Turing test is a competition where people chat with a stranger and then have to guess whether or not they are a human or a robot . As simple as the game sounds , no AI has ever been able to fool judges into thinking it was human even 40 % of the time . This certainly won t be the case in 100 years . It s very well possible that the intelligent machines that clean our homes , provide transportation , and entertainment will be as real , if not more , a human being as our friends and families . AI will become the perfect significant other ; a dutiful and efficient employee ; or a friend always looking out for your best interest . And we didn t stop at the Model-T or Apple II ! AI will become flawless , eventually more human than humans . What becomes of humanity at that point is anyone s guess .
It is imperative to challenge the definition of AI as stated at the beginning of this paper . This definition implies that all computer systems are , effectively , AI systems because they are simply getting more and more intelligent . However , they are getting more intelligent because humans are , and have up until the present , been creating them that way . This , therefore , is an incomplete definition of AI . Computer intelligence should not be measured by how much a device knows , but by its ability to gain knowledge . To use the paper 's example , a calculator can perform calculations much quicker than the human brain . However , this calculator does not draw from memory to recognize numbers and calculations as humans do . Each time the calculator undergoes a calculation , it treats it as an entirely new operation , much as a child learning basic math might do . The reason we consider these calculators to be `` dinosaurs '' in the face of modern computers is because modern computing systems , unlike calculators , are able to teach themselves . Therefore , a system can not be considered AI until it has the ability to teach itself . Without this ability , its intellectual capacity is capped by its programmers .

Additionally , this paper frequently mentions the social ramifications of artificial intelligence , claiming that AI will lead to job loss . Before this problem can be solved , it is important to address the basis of these claims . Why do people fear AI taking their jobs ? It is the concept of adaptability . Previously , machines were tailor-made to their jobs . Even computers have limited intelligence , and therefore perform their functions well and do not intrude too much into the human lifestyle . However , as AI machines become more sophisticated , they are able to adapt to a changing environment and learn how to accomplish tasks they were not initially told to undertake .

There are a few different solutions to this problem . Many AI experts such as Mark Zuckerberg and Elon Musk claim that we will need to establish greater social rights such as a universal basic income -LRB- UBI -RRB- . However , though this suggestion may sound promising , it will be notoriously difficult to implement and maintain , and will no doubt fail at some point in the future . The issues that a UBI aims to mitigate are a tangible threat : the loss of low-level jobs that are currently held by humans . A UBI will not abate the loss of these jobs . Instead , it will make people overly dependent on it , and its costs will inevitably swell to become too large to sustain . Therefore , it is imperative that instead of leaping towards this seemingly elegant solution , we overcome this hurdle by bolstering our own human education .

The best way to overcome the issue of computer adaptability is to bolster human adaptability through education . It is shocking that we teach AI machines how to learn and not our own human children . Currently , education -LRB- especially higher education -RRB- tends to be tailored to one specific field or job . This leads to people becoming more and more compartmentalized within a certain field , and even more susceptible to job loss by AI systems . Therefore , instead of adopting the UBI model that this paper alludes to , we should be focusing on adding the concept of adaptability to our education systems . This simply translates to teaching students how to learn . This will and should shatter the long-held paradigm that education happens solely in the classroom . The more we grow accustomed to constantly educating ourselves to an ever-changing world , the less likely we are to be marginalized by it . Stanford One Hundred Year Study

Artificial Intelligence has made significant progress over the years in various domains as highlighted in the paper and helps to solve many problems . Self-driving cars is a rapidly upcoming technological product with brimming benefits , however , the designing of these cars raises critical ethical dilemmas . The ethical dilemmas like taking decisions in unforeseen circumstances where damage has to be caused and breaking rules in emergency situations are a few challenges which programmers have to provide solutions for . Further , self-driving cars are also responsible for giving industries like insurance and automobile manufacturing a rough time .

Self-driving cars should be able to make smart decisions and be ready to break rules in certain circumstances . According to Lin -LRB- 2013 -RRB- , though humans tend to be ethical and act in a wise manner in real life situations , they can also disregard traffic rules in the case of an emergency or when there is no traffic . However , questions arise as to whether self-driving cars could be programmed to be able to make ethical decisions upon their own discretion and execute the necessary steps . Programmers are striving hard to program self-driven cars that not only follow the rules but also are able to make smart decisions in real-life situations . Further , while developing smarter self-driven cars , programmers face tough tasks when they have to instruct such a car on how it must act in an unfortunate situation . Lin -LRB- 2013 -RRB- highlights a dilemma where a child or a certain number of adults could be saved under an unforeseen circumstance . Programmers designing automated cars are always in the dilemma of whether their algorithm must minimize loss of life or always protect the owners of the car and children . If the car is designed in a way that can take the owners life in certain situations , then nobody would be ready to buy the car to keep their life at stake . Automated cars can negatively affect the insurance industry as well as lead to misuse . Lin -LRB- 2013 -RRB- predicts that the insurance industry will be threatened as self-driving cars could avoid accidents almost completely , leading to an almost negligible risk of being insured . On the other hand , it could lead to a large number of accidents too which could lead to severe losses . Hence the insurance company is at a risk of losing money from both sides . Self-driving cars could be responsible for an increase in alcohol consumption as the passengers would not have to worry about getting penalized for drunk-driving . This would increase the alcohol problems in the city as people would be least bothered about finding a way home . The regular automobile manufacturing industry would lose its market share and would have to start making self-driving cars . A number of people would be unemployed due to self-driving cars from Uber drivers , chauffeurs and eventually even all means of public transport . This would create a lot of unemployment in the economy which could affect the GDP of the country . Another important point to consider is that if any damage takes place through a self-driving car then there is no authority to take the blame for it .

Self-driving cars may have tons of benefits , however , there are some major challenges which need to be solved and long term effects need to be thought about . Self-driving cars will probably come into existence when all the cars hitting the road are autonomous and the cars will be able to talk to each other , which would prevent any kind of damage .



References
• Lin , P. -LRB- 2013 -RRB- . The ethics of automated cars .
The Atlantic


The Stanford One Hundred Year Study on Artificial Intelligence provides a great groundwork for the understanding of A.I. and
the vast amount of benefits that it could potentially provide to our everyday lives . However , there are some points that are overlooked
in the study or that have unreasonable expectations , namely , in transportation . In this essay I am going to challenge their view on
autonomous cars , flying vehicles , and the legal issues that come along with these new forms of transportation .
In the Stanford report they reference an article predicting that there will be 10 million autonomous cars on the road by 2020 .
I think there will be multiple factors that will make the transition to autonomous cars slower than they think . The first being that it
is going to be hard for a lot of people to put their trust in technology . Although I do agree with the report that self-driving cars
would be much safer in general than the typical driver . Another thing that I think will slow down their progress is their ability , or
inability , to make tough choices . Let s say a child runs out in front of a self-driving car and the cars only option is to either hit
the child or swerve off the road and hit a tree , what is it to do ? This along with many other potential obstacles will make the goal
for 10 million autonomous cars a challenging one .
Along with autonomous cars the report also mentions flying vehicles . It doesn t say a lot about this topic but it does say that
it is reasonable to expect flying vehicles by 2030 . Although there may be prototypes out for flying vehicles , this still seems like a
very outlandish claim . It s safe to assume that these vehicles would be autonomous due to the fact that trying to receiving proper
training to safely fly one would be extremely rigorous and unrealistic . One can only imagine the price of owning a personal aircraft
like this so I don t really see it in the near future excluding maybe the very upper class citizen .
The point that I think will be the most difficult for up and coming autonomous vehicles , flying and on land , will be legal
issues . In the report it touches on the subject of liability , but it doesn t find a real solution . Who will be the one held accountable
when a sensor malfunctions and a pedestrian that is crossing the street is hit and killed ? If all of the blame is placed on the
creators of the software this will clearly make them lose their incentive to continue to try and push this new technology if they are
constantly getting law suits . However , if they are not to blame then who is ? The only real and very imperfect solution is for the
liability to fall on the victim . For obvious reasons this would be a tough policy to pitch to the public , but I think that it would be
the most logical way to go .
Although a future with self-driving cars and flying vehicles is one we all might dream of , there are still many obstacles that
lie ahead before this may become a reality .

I am going to challenge some of the ideas in education part of the report .

Based on the discussion in education section , one of the main reason for the current absence of sophisticated use of AI technologies in schools is lack of data establishing the technologies effectiveness . And some online learning systems like MOOCs can be considered as vehicles for collecting such data , and testing the new education technologies . Though the report mentions that the capabilities of MOOCs have been overestimated , I think another possible problem is that the data collected in MOOCs might be biased . It means the data collected this way can not capture the feature of the whole population and it would possibly lead us to a wrong direction .

There are mainly two types of students , one is the students who are interested in the course and willing to learn and the other is those who are not involved much in the course . For those who have less engagement in the course , or who care more about earning credit rather than learning , a better educational technology is supposed to be inspiring , easier for understanding and better at attracting attention . And for the students who are interested in the course , they would benefit more from deeper or wider topics . However , people taking online courses are more likely to be people who are willing to learn .

In addition , it is more likely that the users of MOOCs and other online courses are adults rather than school , college or university students . Adults and children might use different ways to learn new stuff . For example , adults might need logical explanation for better understanding but children would prefer more examples to understand the situation . And a colorful design for material with more pictures might attract children 's attention and help them involved in the course , but it might be more efficient for adult to contain jokes and provide clean-layout material . So they adult and children would probably benefit from different tutoring systems .

Thus , the educational technologies that are analyzed to be well-performing in MOOCs might not be suitable for general classes .

Besides the biased data problem , there is another possible opportunities for AI application in education . A traditional class is usually conducted by a teacher or professor and the whole class would share the same pace and materials . Based on the report , if we can analysis how good a student is performing with the help of AI or machine learning , and provide him materials accordingly , it is possible that the student can get help and mentored individually . An AI evaluation system can not only help with students individual learning , it can also be used as a reference for final grades . I believe an AI system is more reliable comparing to homework and `` one-time '' final examination assessment . They can not only evaluate how well a student performs in the class , but also detect how much effort the student put into the course , for example how often the student respond with the material or exercises provided by the AI system .

While the authors of the Stanford 100 year study are overall optimistic about the ability of AI to improve society , they caution that special measures may need to be taken to ensure its benefits reach all levels of society equally . They caution that without such efforts , `` AI could widen existing inequalities of opportunity if access to -LSB- it -RSB- is unfairly distributed '' -LSB- 1 -RSB- . It is certainly possible to envision such a misuse of AI . However , based on the manner in which several other recent technological breakthroughs have proliferated into all levels of society , I believe that this path of stratification is not as significant a concern as the authors make it out to be .

First , we can look to the recent rise of smartphones as an example of a technology that has provided benefits to all levels of society within a short time of its introduction . Smartphones initially came with a significant price barrier to entry : the average Android phone cost an average of over $ 400 in 2008 . In under 10 years , the mean price of an Android in the US has dropped by over 50 % to just $ 200 -LSB- 2 -RSB- . Moreover , in those same 10 years the ever-cheapening smartphone has become nearly ubiquitous , with an 44 % -LSB- 3 -RSB- of the world population having access to the technology in 2017 , compared to just 12 % in 2008 -LSB- 4 -RSB- . Even within the US , smartphones are increasingly providing opportunities to those with lower opportunities ; the percent of low income Americans who use a smartphone as their primary source of Internet access has nearly doubled since 2013 -LSB- 5 -RSB- . Certainly , the smartphone started as a tool that served to primarily benefit the upper stratum of society . However , rather than staying concentrated in the hands of the wealthy , the power of this tool quickly diffused throughout society , aided by cheaper and more effective manufacturing techniques . It is conceivable that the rollout of AI may proceed in a similar manner : While the cutting edge of AI may today require massive , proprietary datasets and expensive computers , as the best techniques mature and their behaviors become better studied we will be able to provide them to a larger and larger audience for cheaper and cheaper .

Even the claim that AI technologies are currently inaccessible to the broader public requires some further examination . Already , a variety of tools exist so that a layperson , or at least anyone with a bit of programming experience , can harness the power of AI . For fans of Python , the free , open source , scikit-learn module -LSB- 6 -RSB- provides a suite of easy to use machine-learning techniques for all manner of data analysis . A quick AI-powered Google search for `` python facial recognition '' yields a modifiable , open source package that can be installed in under an hour and run on a computer as low-power as a Raspberry Pi -LSB- 7 -RSB- . Beyond my favorite programming language , excellent resources such as TensorFlow -LSB- 8 -RSB- exist with a mission to `` accelerate open machine learning research '' . Again leveraging the power of Google , one can even find once-price-restrictive texts on the subject of Artificial Intelligence at a fraction of their former prices -LSB- 9 -RSB- .

Overall , while the possibility that AI will lead to the further stratification of society is certainly non-negligible , trends in both other recent technological breakthroughs and the already large availability of open-source AI tools suggest that the technology is already headed in the other , more optimistic direction .
References :
-LSB- 1 -RSB- https://ai100.stanford.edu/sites/default/files/ai100report10032016fnl_singles.pdf , p. 43
-LSB- 2 -RSB- https://www.statista.com/statistics/612937/smartphone-average-selling-price-iphone-and-android/
-LSB- 3 -RSB- https://www.strategyanalytics.com/strategy-analytics/blogs/smart-phones/2016/12/21/44-of-world-population-will-own-smartphones-in-2017#.WbcvkReQxCU
-LSB- 4 -RSB- https://www.statista.com/statistics/218532/global-smartphone-penetration-since-2008/
-LSB- 5 -RSB- http://www.pewinternet.org/2015/04/01/chapter-one-a-portrait-of-smartphone-ownership/
-LSB- 6 -RSB- http://scikit-learn.org/stable/
-LSB- 7 -RSB- https://github.com/ageitgey/face_recognition
-LSB- 8 -RSB- https://www.tensorflow.org/
-LSB- 9 -RSB- https://www.google.com/search?q=Artificial+Intelligence%3A+A+Modern+Approach&ie=utf-8&oe=utf-8 , check a few links down

Challenging one hundred year study on Artificial Intelligence

The paper talks about the different fields in which Artificial Intelligence -LRB- AI -RRB- is used , the problems that are associated with current AI approaches , the ongoing research in the field and how it has impacted the lives of people . The paper suggests that AI will become ubiquitous by the year 2030 .

The paper claims that AI will replace jobs thereby making It tough for humans . This was explained with the concept of self-driving cars where AI and Machine Learning play an important part in training cars to drive on their own by learning through test drives . The main idea behind this concept is to make humans focus on their priorities rather than on mundane stuff , that is , they can continue to work while the car drives them to their destination . These self-automated cars are also programmed to park vehicles on their own without human intervention thus simplifying the jobs of humans . This is a debatable claim and can not be accepted wholly for the following reasons : -LRB- i -RRB- They are expensive -LRB- ii -RRB- Even though self-driving cars can drive well , they can not completely take over human drivers ' jobs as they have not yet gained the trust of humans especially after one of Tesla 's automated cars crashed in 2016 . This can be elaborated further by the following reasoning -LRB- iii -RRB- In situations where the car 's sensors detect a group of people in front of it while going at high speed , it would choose to save the group rather than the driver . Thus there is some risk associated with using self-driving cars even though they have been trained for various road situations . Uber and Lyft are still hiring more drivers to cater to the growing customer base .

The paper also stated that usage of self-driving cars would lead to lesser accidents . But there is always the question of how automated cars will behave in rainy/snowy weather . There is a chance that the sensors could get affected by the adverse weather conditions thereby making it accident prone .

Another issue with self-driving cars is security . Autonomous cars , being computers , are prone to hacker attacks and can become unsafe if their vulnerabilities are exploited . Furthermore , getting too comfortable with self-driving cars can make one 's driving skills patchy which would become troublesome when there are any technical glitches and the person has to jump in and take control of the vehicle .

The paper claims that AI systems can be used in the Health care for patient monitoring and coaching , assistance in surgery or patient care . This can prove dangerous as these machines are only certified based on the already existing surgery practices . In the case of an unforeseen complication , the system/robot may not be able to accurately diagnose it as for starters , it will not know the amount of pressure to provide on the organs while diagnosing . Also , being over reliant on AI systems can cause surgeons to slack off a little , which could prove dangerous in emergency situations especially if there is a technical glitch .

The above proofs show that AI systems have a long way to go before they can take over the tasks of humans . There is a lot of scope for improvement which these systems must attain to gain the trust of humans . There is no margin for error as a single mistake could prove very costly . Extensive research and testing should be done to improve the capabilities of these systems to think like humans .


In the section self-driving vehicles , the report states that sensing algorithms will achieve super-human performance for capabilities to meet the requirement of driving in the near future . This statement is based on the situation that the current automated perception is already near or at human-level performance . However , it is not suitable to equal the sensing algorithms to human being just based on several performances now .
It is true that the Google self-driving car could use some sensors to pick up on details in the environment to help it identify a more precise location . It could recognize the STOP sign on the road and check the situation before moving forward . However , two challenging things for this . First , if there were four STOP signs at a crossroad and four self-driving cars reach their separate STOP sign at almost the same time . How could the car decide whether to go or yield ? This might be solved by establishing the communication between different cars . In fact , the world is more complicated than the sensing algorithms . For instance , the electrical power system was broken by the strong wind in Detroit in March , 2017 . The traffic lights did not work at the crossroad and there were no STOP sign at the crossroad . For such kind of situation , all human drivers of the north-south side would yield the drivers of the east-west side first , and then go across the road as if there was a default and invisible STOP sign at the crossroad . It seems to be hard for self-driving cars to make such kind of behaviors based on the sensing algorithms . Second , one assumes that a pedestrian stood close to a bus stop who might want to go across the road or wait for the bus . It is very difficult for the car to make a decision like a human being to beckon to the pedestrian to let she/he go first . Thus , it is a little early to say the sensing algorithms could achieve super-human performance in the near future .
Again , self-driving cars use sensors to check the surrounding environment , collect the information , process the information , and make a final decision . Imagine two situations when the car stops in a valley . The first situation is there might be some rocks of different sizes falling off , and the second situation is some birds might fly to the car and rest on the car roof . The answer to whether the falling rock might damage the car depends on the size and falling off speed of the rock . In general , birds will rarely cause damages to the car in the second situation . Then how the so called super-human sensing algorithms would be developed to tell the difference between the two situations and to make a decision if the car should be started and moved away . People usually make decisions based on the complicated neutral work which has not been understood clearly up to now . Thus , it seems there will be a long way to equip the sensing algorithms with super-human performance .
In sum , self-driving car is an encouraging application of artificial intelligence which could make some human-like decisions and behaviors based on the algorithm calculation . However , it is still an obstacle to extend those algorithms to be universal and to determine the situations as human beings . Thus , there is still a long way to go to develop sensing algorithms of super-human performance .
Humans have readily adopted AI-enhanced entertainment over the last fifteen years as it has become ubiquitous to how entertainment is broadly consumed . Companies like Netflix and Spotify recommend entertainment to you based on algorithms that understand your tastes . Yet , the `` Stanford One Hundred Year Study on Artificial Intelligence '' underappreciates the driving economic force that is entertainment . Modern life is increasingly hectic and this is reflected in how North Americans consume entertainment . Video games and movies are vying for attention by constantly trying to outdo one another in grandeur and scale to provide a unique experience . The US entertainment market alone is projected to grow to $ 771 billion by 2019 and represents a third of the global entertainment industry . This sort of economic force should not be an afterthought in AI , but one that will be on the forefront of driving these technologies forward .
AI , in a loose sense , has had a role in video games since the first AI-controlled Pong paddle was designed to beat a human . It is easy to dismiss video games as a operator of change since its main audience is younger adults . However , so many of the different branches of AI improvements can be harnessed to create an unique experience that is the promise of entertainment -- that of an interactively simulated environment . An environment controlled by AI and populated with AI-agents that are able to interact , adapt , and change the game environment based on that interaction has immediate mass appeal as a form of broad-reaching entertainment . At this point , video games are no longer games but simulated realities with an AI population controlling the experiences of human-beings interacting with the simulated world . NLP and machine learning have clear applications in this medium . Each individual experience within this environment can be unique curated by an AI agent that readily understands the subtlety of what keeps you entertained and playing .
A factor that should not be underappreciated in an AI-controlled environment is the broader real-world implications of these new worlds . Machine learning in entertainment has one primary purpose : to forever better understand what makes you happy and provide it . Right now , the vast majority of these algorithms are limited to curating and improving lists of things , such as music -LRB- Spotify -RRB- , goods -LRB- Amazon -RRB- , or movies -LRB- Netflix -RRB- . In an AI controlled environment , what will be curated is experiences . Additionally , if these AIs curate the environment based on your happiness , they will become more than entertainment but a form of catharsis for the mind . Even to the point of benefiting human health by assisting to treat Seasonal affective disorder , depression , PTSD , and anxiety .
The Holodeck on Star Trek : The Next Generation predicted the popularity and applications of this type of entertainment . An interactive AIs that use massive data sets and user experiences to create better and personalized experiences within a controlled environment has the potential to combine movies and video games into a new realm of entertainment . A form of entertainment that gets better with time , that grows with us , and takes us on wonderful adventures.Challenging Stanford 's One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB-

I expect that the degree of human interaction in artificial intelligence technologies in certain domains will be a lot lesser than predicted by the study .

For instance , in the domain of transportation , the study has mentioned that humans will become partners to self-driving cars and that there will be models and algorithms for modeling of human attention .
I disagree with this prediction . I believe that by 2030 , self-driving cars will be FULLY autonomous and there will be no element of human interaction whatsoever . Artificial intelligence in autonomous cars will have developed to such an extent that a fully autonomous car will certainly be safer than a car requiring the human passenger 's attention . Also , as the study has mentioned , the semi-autonomous approach is not sustainable as people will pay least attention to driving at the moment they are most required to do so .
The popularity of services like on-demand and shared transportation is expected to increase in the future . This ties in with the minimal human interaction component . For instance , for point to point transportation , a person wishing to go from A to B will simply book a car which will arrive at A and take the person to B . The person will not be involved in the driving whatsoever .
Moreover , most of the benefits which the study attributes to self-driving cars , including increased comfort , decreased cognitive load , etc , are only achievable if the person travelling is not expected to pay attention to the driving .

In the domain of education , the study has stated that MOOCs and other forms of online education will become part of learning , but formal education will not disappear .
However , I believe it is possible that specific types of formal education like those for working professionals and career changers -LRB- as mentioned in the study , they do not need a high level of face-to-face interaction -RRB- will disappear . I expect that a number of courses of a specific type , -LRB- professional courses , courses which train people in specific technical skills , etc -RRB- will become fully automated , devoid of any human interaction . In other words , higher education will be completely transformed as far as professional or skill-oriented degrees are concerned .

Also , I do not completely agree with some other arguments made in the study .
In the executive summary , the study has claimed that artificial intelligence technologies are highly tailored to specific tasks .
While current artificial intelligence technologies have certainly required years of specialized research , I believe they are not domain specific . For example , there are various applications of natural language processing algorithms in different fields like bioinformatics . As far as tasks are concerned , one of the most popular artificial intelligence techniques - deep learning , is not task specific and is being applied in a wide variety of tasks , both supervised and unsupervised .

Lastly , I believe there should be some official institution which provides accurate information about recent artificial intelligence developments . For instance , a recent incident , where two Facebook chat-bots developed their own optimized language to interact , was blown out of proportion by the media . While there were articles pointing out that Facebook 's requirement was bots which could interact in human languages and so they worked on modifying the system , these articles were largely overshadowed by the ones claiming that Facebook shut down the bots fearing the rise of artificial intelligence as Hollywood 's Skynet .
The dangers of artificial intelligence should not be ignored but , as mentioned in the study , this kind of portrayal of artificial intelligence by the media will affect the public 's attitude towards beneficial artificial intelligence technologies .
After reading the Artificial Intelligence and Life in 2030 report done by Stanford , there are many compelling arguments as to where artificial intelligence is heading in the near future . I can see many of the ideas presented in this article happening in the next 13 years . However , the one thing that all of these ideas need to have in order to apply to an entire population of people is a lot of data . After reading the section on page 29 about Mobile Health , I have some concerns of the validity of the data they will be getting , and how applicable it will be to the entire population when it comes to health records . For some of the population , these records from mobile devices will benefit them extremely well , but only a certain part of the population will receive benefit from this .
If you were to look at the devices that monitor physical activity in today s age , you would look to certain application on a cell-phone or to devices such as smart watches or fitbits . These devices are great for monitoring the physical activity of people every day , and they can eventually be used with artificial intelligence to help an individual stay healthy based on their own data . However , the people that usually have these devices are people who care the most about their health . With this in consideration , a huge amount of the population will have no data to predict the future of their health , and these are usually the people that will need it the most . To go along with this , these devices only measure a person s activity throughout the day . Although physical activity plays a huge role in one s health , their diet plays a big role as well . To accurately predict and measure someone s health with artificial intelligence , more data would need to be produced than just physical data .
Health is a huge topic and an even bigger opportunity when it comes to artificial intelligence . If artificial intelligence could be trusted to deliver accurate reports and predictions about an individual s health , it would have huge implications on the daily lives of a person . If the success for AI applications is the value they create for human lives , applications that correctly predicted someone s health and programs to improve their health would be a huge success for the artificial intelligence community . I think that in order to have success in this area , health data needs to rely on more than just physical data of the healthiest people in our population . I think health data needs to somehow integrate someone s diet , sleeping patterns , mental fitness , and physical data of all kinds of people to be accurate . Based on what is out on the market now , all of these things could be integrated to make the health data more reliable . We could use smart grocery stores to get a better idea of one s diet . We could continue using mobile devices to accurately measure a person s physical activity , but incorporate this data tracking more into mobile phones instead of using fitbits . We could track someone s sleeping data by a device , or maybe someday we will have smart beds that do that for us . All of these things are reachable and I think they would have huge implications on the accuracy of AI prediction models . Mobile devices to track health won t be enough to have success in the year 2030 .
The One Hundred Year Study on Artificial Intelligence mentioned the integration of Artificial Intelligence into education . Although the writers admit that `` quality education will always require active engagement by human teachers , '' this point was not well-emphasized . The Education section of the paper boasted the benefits teachers and students enjoy through using artificially intelligent digital systems in the classroom . Although AI in the education system may have practical uses , the importance of face-to-face interaction between a student and their peers and educators must not be undervalued , especially for young children .

As children develop , they rely on their personal interactions to shape them into thoughtful , conscious , and aware human beings . Much of a child 's elementary education involves social learning . Students must learn to cooperate with other students and their instructors , but more generally they must learn the skills to have successful interactions with any person they meet . The danger in overuse of technology that the next generation will lack the necessary skills to interact with their world . Important life skills such as cooperation and socializing can not be effectively learned through a screen .

Developmental linguistic studies show that , in the home , children who play with traditional toys like dolls and blocks learn language at a faster rate than children who play with digital toys . A child playing with a doll is required to be more creative in their play , and learns new words as their parent plays along and co-creates scenarios . In contrast , a toy laptop has a limited vocabulary , and after learning all the words programmed into the toy , the child plateaus in their lexical learning . Additionally , a more personal connection is made with the parent as they play . These concepts are outlined in various articles , including `` Playing to learn : The trouble with electronic toys '' by Sarah C. Bauer .

Later in the article , in the Entertainment section , the writers mention once more their awareness of these dangers , admitting to `` concerns that -LSB- AI -RSB- reduces interpersonal interaction among human beings . '' However , in the same paragraph , the concerns seem to be swept away with the statement that `` AI will increasingly enable entertainment that is more interactive , personalized , and engaging . '' Children should not solely rely on artificially intelligent systems for entertainment . If so , they are missing out on the happiness of building relationships with others and are instead stifled by their isolation .

Along with mental health , the physical health of a child who spends most of their time indoors on the computer suffers . According to the National Institutes of Health , obesity is the second leading cause of preventable death in the United States . The obesity epidemic in America is not going to be resolved if the next generation is seated indoors most of the day , living lives void of physical exertion .

All of this is not to say that AI should not be used in education ; it should be . AI can help teachers to design lesson plans and better fit an individual student 's needs . It can help students to learn new concepts . Preferably , students that are more dependent on AI in the classroom would be older , having already developed necessary social skills through person-to-person interaction earlier in their academic career .

The article claims that `` the measure of success for AI applications is the value they create for human lives . '' AI will not contribute to human lives if it is prohibiting a well-rounded education that includes social and academic components . There is a place for Artificial Intelligence in education , but its role should not be as the main apparatus for learning .
In the `` One Hundred Year Study on Artificial Intelligence '' published by Stanford in 2016 , the authors have discussed the development of AI over the decades and its promises for the future . The report details many upcoming use cases of AI , the technology needed for successful implementation and obstacles facing these upcoming technologies . One particularly interesting aspect is that of self-driving vehicles that can also navigate autonomously . However , the report only considers the tech side of things and ignores the bureaucracy needed to implement such a change .

Stanford s report predicts that mass adoption of self-driving cars will begin in 2020 but fails to acknowledge the time needed to successfully establish a set of regulations that govern the existence of such cars on the road . A whole new set of laws need to be conjured before the dream of self-driving cars can become a reality . Currently , the Department of Transportation -LRB- DoT -RRB- handles the rules that govern how a car is built and the states control the traffic laws , insurance and licensing . The problem with this structure arises in the case of self-driving cars because the manufacturing controls how these cars operate . This problem is compounded because the technology is nascent and vague . Self-driving cars don t really exist yet , at least not market-ready autonomous vehicles . It is incredibly tricky to write laws for almost anything , let alone for something that most regulators do not fully understand . That is why it is na ve to assume implementation of self-driving vehicles will not be hindered by slow bureaucrats .

Another issue that plagues everyone s minds regarding this technology is the blame game that will ensue if something does go wrong . Autonomous vehicles are being introduced to dramatically increase overall road safety , however , things do go awry . Crashes and other accidents can not be attributed to human error and litigation could potentially stall this technology . Car manufacturers will not release self-driving vehicles until they are assured of little to no liability in freak cases . It will also be hard to ascertain which car was responsible if the accident involves multiple vehicles . All the parties involved would try to distance themselves from any blame and it would be impossible to pin-point the blame on anyone . The report by Stanford highlights one such incident where a fatal crash involved Tesla s Autopilot system . Recently , an investigation conducted by the National Transportation Safety Board -LRB- NTSB -RRB- found that the software played a key role in the crash . They found that it did not define stricter constraints for drivers and allowed them to get distracted easily . The policies that exist right now are voluntary and merely guidelines for corporations to follow . The oversight in this department is severely lacking and automakers have time and again proven that they can not be trusted to protect public interests in their race for profits and domination .

Self-driving cars are definitely the future but that is all they are for now : the future . Any dreams of autonomous vehicles driving you to work are just dreams for now . There are potential solutions to the problems mentioned , however , research shows that mass adoption of self-driving cars is still decades away .
Challenging the Optimism of a Future With AI

The Stanford One Hundred Year Study on Artificial Intelligence envisions a positive future . However , there are two main issues with the authors vision . The majority of the population will not be using self-driving vehicles in the near future , and AI will not improve the job industry .
In regards to self-driving vehicles , the authors say `` Autonomous transportation will soon be commonplace '' -LRB- 18 -RRB- . With the anticipated launch of Tesla 's fully autonomous software update in the next couple of years , the public will finally see the first fully autonomous vehicle available for purchase . However , such functionality relies heavily on regional jurisdiction and weather conditions . In Midwestern climates , such as our own , a self-driving car would have limited functionality when the roads are snowy . Tesla 's vehicles , for example , use cameras to detect road paint , which is used for lane departure and recognition . When this paint becomes covered , the autonomy of the vehicle is lost . Also , most people can not afford these vehicles , as Tesla 's cheapest car with the self-driving package is priced at $ 38,000 . Tesla is also currently the only company who will be releasing an autonomous vehicle -LRB- AV -RRB- for public consumption . Google and Waymo AV vehicles are still under development and are not expected to be released anytime soon .
In the study , the authors envision passengers as not paying attention to the road . They say , `` With self-driving car technology , people will have more time to work or entertain themselves during their commutes '' -LRB- 21 -RRB- . While this is alluring , it is simply not the direct future . Current self-driving traffic laws still require drivers to be aware of the road and have their hands next to the wheel at all times . In 2016 , for example , a driver was killed while using Autopilot on his Tesla , with the cause of death being negligence to observe road conditions . For the reasons mentioned above , I do not see as optimistic as a future as the authors do for AVs .
The study also mentions a future where AI causes jobs to be lost , but the job loss will be counter acted by cheaper goods and services . They say , `` But the new jobs that will emerge -LSB- from AI -RSB- are harder to imagine in advance than the existing jobs that will likely be lost . AI will also lower the cost of many goods and services , effectively making everyone better off '' -LRB- 8 -RRB- . If jobs are lost because they can be replaced by AI , odds are the other jobs those people are qualified for would also be replaced by AI -LRB- think of a factory job -RRB- . This would cause the person to resort to a job that they are not comfortable with , or would cause them to be unemployed long-term , which may lead to a higher crime rate . While AI can certainty reduce prices of goods and services , it will not counter act the loss of jobs that result . No benefit comes from cheaper goods and services when a large share of the population does not have enough money to buy them . For reasons such as these , I do not agree that `` everyone will be better off '' as AI replaces jobs .
Even with the extremely positive outlook envisioned by the authors , the future will not be as cheery as they think . Self-driving cars are years and years away from becoming common , and AI will not improve the job market .

AI is now a very big part of our technology , economy , and society , but at the same time it would be wrong to say that it causes no harm to the humankind . In this article we see that the Study Panel of One Hundred Year Study on Artificial Intelligence found no cause for concern that AI is an imminent threat to humankind -LRB- page 4 -RRB- . This is just a statement with no backup proof explaining how all the other points that are the more fantastic predictions for AI in the popular press which are against AI are wrong . AI affects humans in a negative way in many different aspects . AI is integrated into systems such as smartphones and laptops that attract humans more to these devices . It has become a cycle for everyone to get eyesight from the bright light of AI products , and be negatively affected in the brain because of radiation from smartphones . To dwell even deeper , we are not far away from the saying that technology is making the human race stupider . With so many different tools handy at just a touch away -LRB- such as calculator , compass , dictionary , translator , etc. -RRB- , we as humans are not even using basic intelligence for such small tasks . Soon , if not already , education will have no value because everything can be demonstrated for learning on the web , and forgotten the next day . This is a very serious issue that can destroy intelligence of humans .

Thinking ahead , robots and self-driven cars are bound to happen in the near future . For one , these take the aspect of physical activity away from us . We will start to rely on robots and self-driven cars to do even the trivial of all tasks such as getting groceries , or grabbing the remote control to a TV that is 7 feet away . This will turn into a very physically-unhealthy habit that runs in a cycle for most/all humans . Secondly , these robots and self-driven cars could be hacked and programed to harm other human beings either at a small or mass rate . Robots could be programmed to hurt their owner , and self-driven cars could be programmed to not follow rules that could end up in running over people or other cars .

AI systems are getting complicated with time . In the future , there will come a time when one is built that could only be operated with the intelligence of the person who assembled it . Meaning , there could come a time when this technology could get out of hand and fall into hands of someone who plans something dangerous for the society , and the rest can t really cease it because the operations are only known to the creator .

These all might just seem like far-off assumptions but they are what the future holds . We have already become so advanced in our technology that robots and self-driven cars are not too far away . Artificial Intelligence is doing great things and making the life of a common man so much more pleasurable , but at the same time we can not ignore the negative effects it brings with it .
-LCB- \ rtf1 \ ansi \ ansicpg1252 \ cocoartf1504 \ cocoasubrtf830
-LCB- \ fonttbl \ f0 \ froman \ fcharset0 TimesNewRomanPSMT ; -RCB-
-LCB- \ colortbl ; \ red255 \ green255 \ blue255 ; \ red38 \ green38 \ blue38 ; \ red255 \ green255 \ blue255 ; \ red0 \ green0 \ blue0 ;
\ red120 \ green9 \ blue17 ; -RCB-
-LCB- \* \ expandedcolortbl ; ; \ cssrgb \ c20000 \ c20000 \ c20000 ; \ cssrgb \ c100000 \ c100000 \ c100000 ; \ csgenericrgb \ c0 \ c0 \ c0 ;
\ cssrgb \ c54902 \ c8235 \ c8235 ; -RCB-
\ margl1440 \ margr1440 \ vieww13520 \ viewh18020 \ viewkind0
\ deftab720
\ pard \ pardeftab720 \ sl300 \ sa40 \ partightenfactor0

\ f0 \ fs24 \ cf2 \ cb3 \ expnd0 \ expndtw0 \ kerning0
While Stanford \ ' 92s One Hundred Year Study on Artificial Intelligence is overall very well-written and forward-thinking , I believe the authors heavily glossed over the topic of security as well as made significant assumptions and misstatements about the inherent biases associated with human-decision making , especially on policing techniques . \
\
In the opening paragraph of the Public Safety and Security section , the authors emphasize how important gaining the public \ ' 92s trust is , however make a large assumption with \ ' 93assuming careful deployment \ '94 and go on to discuss that , \ ' 93AI may also remove some of the bias inherent in human decision-making . \ '94 While I whole-heartedly agree that there are many examples of egregious prejudices and biases that plague human decision-making , I believe that removing some of the biases associated with activities such as policing could inhibit or halt the learning process entirely , resulting in sub-optimal machines or devices . The relationship with the public and proper policing AI will be that of give and take , but if the optimal AI is out there , the public will need to sacrifice some of its freedoms for the overall good . \
\
Moreover , in the second paragraph of the Public Safety and Security section , the authors discuss how improvements in machine learning and transfer learning have been sped up by the machines learning in new scenarios based on similarity with past scenarios . Wouldn \ ' 92t making decisions in the present because of a particular event in the past be classified under some sort of bias ? Isn \ ' 92t learning built entirely on acting on what you know ? Where do you draw the line when an artificially intelligent machine acts in the best interest of the public , but exhibits some sort of bias for or against a certain group or idea ? The report states that \ ' 93Machine learning significantly enhances the ability to predict where and when crimes are more likely . \ '94 Wouldn \ ' 92t the demographic inhabiting high-crime areas feel as if the policing AI being used is exhibiting a bias on them or would they feel more safe knowing that the machine has their safety in its best interest and be thankful ? Similarly , can the public sacrifice its pride and not feel personally attacked if AI algorithm profiles them ? For instance , if an innocent individual is stopped at an airport security line and is profiled by an artificially intelligent machine , could the individual stomach the shot to his or her ego and let the corrective nature of the algorithm learn from its mistakes and better protect the public ? These are the types of situations in society that would need advancing prior to large leaps in AI . \
\
The authors are making a giant leap by stating that \ ' 93well-deployed AI \ '94 can tie up all those loose ends and gain the public trust without explicitly defining what exactly that entails or what the course of action could be to implement it . Some of the shortcomings of AI fall within the realm of shaping the machine around some of the ever-changing societal values and not overstepping or encroaching on some of the freedoms a lot of citizens enjoy today . I do believe that one day there will be AI capable of policing properly , however I do not think that it will be without many biases due to the nature of learning based on past experiences and that the terms \ ' 93careful deployment \ '94 as well as \ ' 93well-deployed \ '94 used in the report are overly optimistic and unrealistic given the world we live in today . \
\
\
\ cf4 \ cb1 Works Citied :\
\ pard \ pardeftab720 \ sl360 \ partightenfactor0
\ cf4 \ outl0 \ strokewidth0 \ strokec2 Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . \ ` a0 `` Artificial Intelligence and Life in 2030 . '' \ ` a0One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , \ ` a0September 2016 . \ ` a0Doc :\ ` a0 -LCB- \ field -LCB- \* \ fldinst -LCB- HYPERLINK `` https://ai100.stanford.edu/2016-report '' -RCB- -RCB- -LCB- \ fldrslt \ strokec5 http://ai100.stanford.edu/2016-report -RCB- -RCB- . Accessed : \ ` a0September 11 , 2016 . -RCB- Challenge Statement : The One Hundred Year Study -LRB- OHYS -RRB- makes a wide variety of assessments and predictions about artificial intelligence . One repeated theme is in the potential of new AI technologies to have either positive or negative effects for the majority of people , particularly vulnerable people , depending on how they are implemented and regulated . This is certainly true , but the study arguably makes two mistakes : it is too optimistic about the fairness with which AI will be applied and to whom its benefits will accrue , and the solutions to such problems of fairness are likely to require fundamental political change , rather than technical or regulatory adjustments within current political structures .

When sweeping new technologies such as AI are introduced , they tend to reinforce existing inequalities in power and wealth , rather than level them . This is because the current holders of power in society such as large corporations , police , or regulatory agencies control the creation and implementation of the technologies , access to the technologies , and the terms in which the technologies are applied .

One such example is in news media . It was widely predicted that social media would reduce peoples reliance on a few respected media corporations and democratize public discourse . Facebooks rise has seen this effect happen but at the cost that now Facebook itself controls a huge and increasing fraction of peoples news consumption and sharing , in a completely opaque way . This is mostly due to social media network effects , but mirrors a broader trend in the field of companies who have access to sophisticated machine learning techniques . Because they are trained on huge datasets , only the biggest few companies -LRB- such as Facebook , Google , Wal-Mart , and Amazon -RRB- can use these techniques , leading to natural monopolies and , more broadly , the increasing stratification of wealth in society .

Another example is in the use of machine learning algorithms to determine criminal sentencing or to predict crime . The algorithms and the data they are trained on are all controlled by people who tend to be favored by the criminal justice system in the first place whiter , wealthier , and better educated . On top of that , the use of these programs is itself controlled by the notoriously racist criminal justice system . But because all of these layers of discrimination are abstracted behind a seemingly impartial computer program , they are obscured and therefore protected . There have already been documented cases of racist programs used by our criminal justice system , and there will likely be many more .

The study references such issues in a few places , such as on page 43 . It points to regulatory solutions to resolve these problems of unequal access to and treatment by AI . This is flawed because it views AI technology itself as a potential root cause of increased discrimination and related problems or solution to them . In reality , AI is a tool like any other , which only amplifies the power of groups with access to it , regulated or not . To prevent AI from being used to expand our police state , further criminalize poverty , or reinforce racial disparities , we must overturn the power relations that originally led to those problems . This involves increasing the political power of minorities and poor people , especially as they come into conflict with the state and the largest and most predatory corporations . This would require the dramatic expansion of democratic power , not just into government , but into the functioning of private corporations whose behavior affects everyone . Until then , it is likely that we will see only a continuation of current trends .

Artificial intelligence refers to the technique that is exhibited by machines as opposed to human or animal intervention . It is also known as machine intelligence or natural intelligence . The developments of this technology that can imitate human thought and surpass it or even become self-aware have been critically evaluated in computer science . Despite the achievements realized by this innovation , physicist Stephen Hawking warned that it might be the last kind of change we are aware of unless we decide to learn ways of avoiding their risks . In this paper , I want to challenge some of the results brought forth by `` the Stanford one-hundred-year study on artificial intelligence . ''
The article has stated that many fields like the transportation industry , the service of the low-income communities , the medical system , home robot and the human resource professions are or will be benefitted from the study of artificial intelligence . However , though this technology is efficient , it also may or would be difficult for us to adjust to it . I think the difficulties are often caused not by physical factors , but the diverse habits and feelings possessed by different people due to the disparity in cultures , religions , family backgrounds or environments that each of them was brought up . This way , the traditional methods in doing things would be more efficient due to the familiarity , religious drive or emotional fondness . More importantly , though the traditional methods would not be as efficient as AI in many applications , it may bring people more biological and sensuous satisfaction , and this kind of irrational satisfaction is also crucial to human needs and happiness as human beings are intrinsically animals . So I want to challenge the author that they may not use the word benefit , but change .
The other content I want to challenge the article about is that it says As cars will become better drivers than people ... . new urban organization . I feel the author only evaluate this situation in data , optimization or just guess . He/she pays no attention to human feelings . It is not hard to find something to send you from one place to another now , or to find a driver that is the same as an AI machine functionally to work for you - you can use uber , bus , train or planes that are public . The meaning of owning a car means the satisfactory feeling of driving and the interaction with the beloved ones about the procedure of steering .
Finally , I don t agree with the author that Further , in the typical North American city in 2030 , changes won t be limited to cars and trucks , but are likely to include flying vehicles and personal robots , and will raise social , ethical and policy issues . I , or we have to admit that AI machines can be quite reliable and robust with the development . However , I strongly believe that the more complicated or huge the actual machine , the less AI content should be used , especially when the accidents these actual machines caused are disastrous and irreversible . The disaster can be not only social , ethical , or policy , but also physical , fatal and feeling-hurting .
Human beings are often greedy , and often there are not sufficient laws or rules to restrict the designers before something has happened . If AI can save money , we can not predict how much the boss or the designer would save , and what will happen due to the optimized savings and insufficient `` buffer '' or `` margin . '' I think the government and the policy-maker would have the same idea . `` Artificial Intelligence and life in 2030 '' provides helpful insights into the future of artificial intelligence and its impact on the nation . However , this paper underestimates the impact that high level artificial intelligence could have on the job market and the economy .
The article states `` AI will likely replace tasks rather than jobs in the near term , and will also create new kinds of jobs . '' Pg . 8 The article makes references to the mechanization of assembly lines and how we have seen in the past that machines have taken some of the more tedious jobs . Workers pursued training for better jobs and the overall quality of the job improved . The AI revolution is not like those of the past . AI has the capability not just to take over the blue-collar jobs but also to absorb the white-collar jobs as well .
Most jobs that we refer to as high paying college degree required jobs are very mechanic in that , even if they seem complicated they can be broken down into a series of steps . The article provides a great example with the automation of 1st year law jobs . Often these jobs are just to sift through mounds of paperwork and determine what is relevant to a case . Now with machine learning this process can be automated . The AI can simply sift through all digitized documents and can , with high accuracy , determine what is relevant and what is not . These entry level jobs , although tedious , are where many law students get their careers started . AI has the potential to disrupt job markets by replacing entry level positions .
The problem with having AI overtake more and more jobs in the manufacturing sector is that no matter how productive and efficient AI is , if there is no one who is employed and has the resources to buy the product the AI makes , then what is the point of all that productivity and efficiency . The article states `` Since the 1990s , the US has experienced continued growth in productivity and GDP , but median income has stagnated and the employment to population ratio has fallen . '' Pg . 38 The United States continues to produce more and more per person but unlike in the past when productivity would rise wages would rise , today productivity is rising but wages have stayed the same .
The panel argued that we need to treat AI as a public resource and that its products should be spread to the population . The issue with this theory is that to develop an AI sophisticated enough to replace a human , it would take a tremendous amount of funding for research and development . If we let AI be privately funded , then the people who invest the money initially are going to be looking for a return on investment . To mitigate this problem , we need to start treating artificial intelligence like the space program in the 1960s . We need to poor public money into research and development so that the result is owned by the public and not private companies .
The potential for artificial intelligence to devastate the world economy is a very real possibility . As we move forward we must keep asking ourselves will the end justify the means .

Citation :
Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .
Since artificial intelligence has been made more prominent progress , the significant advances bring society as well as people entirely different way of living . Based on long term research and participation in the future use of AI technologies such as self-driving cars , robotics , or physical assistance etc , One Hundred Year Study on Artificial Intelligence reports several important aspects in terms of futuristic AI development . In section `` AI by domain '' , the trend in transportation indeed shows a vapid growth of self driving vehicles . However , the problem of loss of privacy should not be ignored . For Elder care section , using AI provides certain convenience but mitigate the care from people that elderly people truly need .

Self-driving vehicles bring people the dream of driving without using real human efforts . This approach is likely to allow people spend less energy and focus more on the business that are more important . The report also shows the self-driving cars could be widely adopted by 2020 . However , it also got issue of potential loss of privacy . Using a self-driving car means that we are sharing our movement to the third party companies . This largely violates the individual privacy since many companies will likely to allow the cars to receive and transmit the communicating with data centers . This implies that as customers , their locations can be shared and accessed to people or organizations who could hack into the network . Although according to the article , self-driving cars are likely to bring benefits to people since people do n't have to own a car individually . Shared autonomous vehicles are used as a service can be very beneficial to the environment , the humanity perspective has not been considered strictly . If it becomes to the real thing , the danger of being hacked can happen very easily since there are more and more computer science professionals .

Regarding the idea of Elder care , based on the article , home health aides `` will grow 38 % over the next ten years . '' A change in technology to assist elderly persons is unavoidable . Smart devices at home could provide some basic need for people whenever they have the need to support daily living activities . Although these applications are able to monitor and report the health information and replace a lot of labor works , it is undeniably true that some daily care can only be done with better effects by person instead of the machine that simply serves the purpose of transmitting data , reduce the need of facility , etc. . For people who are old , what they really need is the comprehensive Medicare to allow them experience the warmth . If we put too much emphasis on the transformation from human labor to artificial intelligence , although the cost can be diminished , people might lose or have less association and attachment with their family members . Although machine learning has been made useful progress , different field still has different scenarios that need to take into consideration . We are using AI to help us accomplish the tasks and improve the performance without humans having to explain how to make it happen . But in terms of customer service perspective , especially when the customers are in old ages and mostly require sophisticated treatment , AI might not be the most satisfying solution .

AI definitely renders numerable benefits , like tackling the complex challenges . Now AI can only be told to solve problems that is told by humans . They can also effectively address the problems . However , with certain jobs , they should be able to meet specific conditions to allow humans free their hands without sacrificing certain important things .



The Stanford A100 report provides great insight of how life would be in 2030 and thoughts on how AI would apply to that . However , I hold different opinions on some parts of the report when I m reading it .

As is stated in the A100 report , cloud-based machine learning would greatly improve the home robots . But my point of view is that privacy issue will be the single biggest barrier to cloud-based AI , as you ll need to upload the data to cloud server in order to get things working or to train the neural network , which means people have to upload their 3D home-model to central servers for their robots to work and patients have to upload their detailed physical condition for AI to perform operations on them . There are already plenty of complains on apps that collects user data in the background and there will surely be more on cloud-based machine learning . For example , there was an app last year that uses Generative adversarial networks -LRB- GANs -RRB- to turn user s picture into stylish painting or combine two totally different picture together with the combination of their styles and contents . That app got criticized due to privacy issues soon after it got famous . I think the best way is to get the trained model from the server and locally evaluate the results , keeping the user data local . As for training , we can locally train the neural networks and send the result back to the server so that what gets sent to the central server most of the time no longer contains sensitive data .

Also about the autonomous driving car , it is true that it will be popular in the future , but the security issue will always be a concern . The current technology allow cars to do basic driving , like on a highway or city road , but the programs are very likely to go wrong if a car is driving itself on a unseened environment , like in the desert or on a road with lots of barriers . Another big problem is that although the auto-driving may function well on a road where most drivers are human just like nowadays , in the future however , most of cars on the road are probably driver-less . And AI drives the cars differently as we human do , so the auto-driving may not behave as well as they now do .

As for AI in education , I don t think full-featured teaching robot which can replace traditional teachers will arrive in the near future . First of all , that requires very advanced natural language processing that allows the user to perform dialog-based conversation including the context , background and what previous thing users are referring to , which I don t believe will come true shortly . Moreover , the teaching robots need to be able to explain things in different ways , which means generating parallel sentences and talking about the same thing in a different angel . Or in some circumstances , the robot may even need to visualize a concept to make the learner fully understand it . None of them , in my humble opinion , will come to reality in a short time .

I m also concerned about AI applies in healthcare . Just last year , Kaggle Inc. announced that they made huge progress in predicting lung cancer using machine learning trained by the LUNA CT dataset . That is a already large dataset , yet the accuracy is still not promising . What will most likely to happen is that we don t have enough data to begin with , and because of the bad performance or inaccurate result , people refused to use that , causing less and less data get collected . And it s basically a bad loop .

Although some aspects of the report are challengeable , artificial intelligence still no doubt has a bright future .
Implementing AI in security : A good idea ?

There have been recent discussions on the use of artificial intelligence -LRB- AI -RRB- to increase public safety and security , and whether this will have an effective and non-abusive outcome . Some experts claim using AI to enhance public safety has a great potential , as police officers will be able to identify and prevent crimes more easily . While it is true this may have a potential for good , it may also give resources for institutions to abuse this system and target groups in a discriminatory way . This possibility may slow the implementation of artificial intelligence to overview security in our society until safer systems are developed . Using AI to increase public safety and security in the future is bound to have negative outcomes if systems to prevent abuse and discrimination are not developed .

Some people might argue that using AI to enhance public safety can lead to better crime prevention . According to the first report of the `` One Hundred Year Study on Artificial Intelligence '' made by Stanford University -LRB- 2016 -RRB- , artificial intelligence will , by 2030 , be able to assist crime prevention by constantly identifying people on video surveillance cameras , and discerning between events to detect abnormalities and warn police authorities . This attest to the great potential of implementing AI in security systems to increase security worldwide .

While some might believe implementing artificial intelligence to security systems can only have benefits , they might discriminate people when searching for abnormalities . According to Dr. Mahesh Saptharishi , Senior Vice President of Analytics and Data Science for Avigilon -LRB- a video surveillance company -RRB- , current surveillance systems detect humans and vehicles and take feedback from the operator to discern which events are normal and which are uncommon ; the system then saves the feedback to improve its recognition -LRB- 2014 -RRB- . This shows a current approach on surveillance cameras ' artificial intelligence that will possibly be implemented into public security cameras in the future . However , this system builds its data from humans . Sam DeBrule , co-founder of the journal `` Machine Learnings '' , states that artificial intelligence systems that build upon human judgement can perpetuate biases -LRB- 2017 -RRB- . This means that security systems that use artificial intelligence built upon human decisions might become discriminative to certain groups of people .

Apart from possibly discriminating certain groups of people when searching for abnormalities , institutions might also abuse security systems with artificial intelligence . Barry Steinhardt , director of the American Civil Liberties Union Project on Technology and Liberty , states that the FBI , and other police departments in the US , have conducted illegal operations during the Vietnam War to investigate and persecute those against racial segregation and the war -LRB- 2002 -RRB- . This shows how prone are institutions to abuse new technologies , specially those that can constantly identify people in public spaces , and carry illegal practices in times of political turmoil .

The outcome of integrating AI to public security and safety is being widely discussed at the moment . It has , however , been shown that this new technology can suffer from institutional abuse and target groups of people in a discriminatory way . While some might argue artificial intelligence has a great potential for improving security , without safer systems to combat misuse and biased targeting , it will be incredibly hard for artificial intelligence to reach mainstream use in public security systems in the coming future.HW 1 - Intro to Artificial Intelligence

Transportation

'' . . on time pickup and delivery of people and packages . This alone will reconfigure the urban landscape , as traffic jams and parking challenges become obsolete '' -LSB- 1 -RSB-

The concern with the above statement lies with the certainty of the statement . The paper assumes that wider adoption of self-driven , possibly shared transport models will reduce the ownership numbers . Some reasons why this may not manifest certainly over the target of next 15 years are :

- Even though shared transportation models offer a pool service in some areas , people may not prefer sharing the ride with co-passengers owing to privacy concerns . Companies eventually have to commission more cars on the road to improve adoption - a situation which wo n't help with traffic jams .

- Carpooling services offered by Uber , Lyft , and others , have failed to gain a lot of traction -LSB- 2 -RSB- . It is not clear how these services will adapt to the future and eventually gain traction to hopefully reduce the ownership numbers .

- I believe the general population will not completely give up ownership of existing cars due to the possibility of shared transport not being completely reliable at all times and situations . For example , long distance commute still requires ownership of a car , and it is not clear how companies such as Uber , Lyft , etc. will address the long-distance commute problem in the North American context .

- The paper does not deal with the environmental consequences of new transportation models which might result in increased energy consumption as the number of vehicles and intelligent devices aiding in moving people and packages increases . Due to these consequences , there may be regulatory hurdles by respective governments which could hamper the adoption of the new transportation models .

Technology & Content Creation -LSB- 3 -RSB-

The paper seems sure about `` sophisticated tools and apps '' -LSB- 3 -RSB- which will help an amateur easily produce high-quality content .

- In my opinion , the success of content creation depends on creativity and novelty - qualities which are not the scope of AI , at-least in the next 15 years . Content producers will still have to continue relying on video cameras and audio recorders to generate the base content upon which an existing or future tool/app can work on . The argument that tools and apps will ease the production of quality content does not stand because content production would continue to demand a significant chunk of production time . Moreover , it is not clear how in the next 15 years , the novelty divide between human generated content and artificially generated content will be bridged . The phrase , `` relatively good movie '' -LSB- 3 -RSB- is vague at best which neither quantifies content quality nor provides any comparison standards .

Distribution of Wealth Creation -LSB- 4 -RSB-

The paper does not elaborate on how the monetary benefits generated due to AI goodness will be distributed to the society . There are many reasons why this may not manifest

- Stakeholders of a research project which leads to a beneficial AI technology could argue that the benefits be distributed only among themselves as they pour in investments at the early stages and not among the enablers or workers affected or replaced by the AI technology .

- If it is clear that the benefits should be shared among the general population , it would be a complicated situation to determine the exact percentages to be shared per individual , while being transparent about the distribution process .

-LSB- 1 -RSB- Section `` Overview , '' p6
-LSB- 2 -RSB- Section `` On-demand Transportation , '' p23
-LSB- 3 -RSB- Section `` Imagining the Future , '' p41
-LSB- 4 -RSB- Section `` Overview '' under Employment and Workplace trends , p8
After reading this article , I want to make a challenge about the implementation of artificial intelligence -LRB- AI -RRB- in healthcare area . In this summer , I did a research paper , which is about how AI can make more accurate or earlier diagnose . As this article mentioned , there are obvious challenges of AI which include ethical issue , the relationship between humans , and the regulations of AI . Despite these potential issues , AI could bring our society multiple benefits in many domains if people could use AI properly . Moreover , it might change our lives by the implementation of AI . Currently , in North American , many AI programs could improve the healthcare for public . Base on Stanford news , Kubot -LRB- 2017 -RRB- reports that the Stanford University already design a handle microscope that could diagnose skin cancer in earlier stages by the ability of image recognition . By the developing of machine learning , deep learning and artificial neural network -LRB- ANN -RRB- , developer use these techniques to apply in programs and let these programs could make responses by themselves from these stimulates . One advantages that AI can do better in healthcare is AI could provide more accurate data-driven number about patients report . Cognitive error is one leading cause that cause misdiagnosis , everyone make mistakes during their lives . However , when the mistakes occur in diagnosis , it might cause serious damages on patients . Therefore , by the using of AI in diagnosis , patients could get more accurate diagnosis . That s one example that I know to shows the benefits of implement of AI . On the other hand , I feel like it might be challenge to implement AI in healthcare .
Currently , most AI programs seems could bring benefits into many domains , however , these AI programs are not developed perfectly yet . Until now , our technology still growing and researchers are working on AI . In the future , there might be perfect AI programs which can handle tasks perfectly . Until now , the application of AI is a challenge . Because of the unknow future , it might challenge the developing of AI . First , in healthcare area , AI programs could provide better healthcare in physical , but it might be a problem to take care mental issues . Emotion is one special thing among human , people are emotional needed . If only base on algorithm and database , AI might not be able to fit the mental needs from human . Moreover , it also one big concern from the public that can AI be emotional . Second , I want to challenge the regulation part of AI . Like the article mentioned , AI could help people , however , it might harm people as well . It could be a complex problem when AI programs make a mistake , which one should be responsible . Third , once AI has ability to done most tasks without human needs , will public agree to implement AI , because it might threat their jobs . In the future , if the AI robot could as fully functional as human , what ` s the role of human should play in our society . Overall , until now , the developing of AI impacts North American positively . It has the possibility to become next revolution of our society and totally change human lifestyle . Meanwhile , implementing AI should be a concern as well .



Reference :
Kubota , T. 2017 . Deep learning algorithm dose as well as dermatologists in identifying skin cancer . Retrieved from
http://news.stanford.edu/2017/01/25/artificial-intelligence-used-identify-skin-cancer/
One thing the study mentions is the collective trust of society in AI and how it can threaten the advancement of AI in the future . At the same time , the report continues to convince the audience that by the year 2030 , the typical North American city will have completely transformed into one including AI technologies we never imagined would take over . I am challenging this notion of the report because I believe that even if we are able to come up AI technologies that solve many of our problems , we are restrained by the people . I believe that as humans and creatures of nature , we naturally distrust each other and because of this , we will not trust the AI technologies not because we think they ll attack us like in the movies , but because we can t fully trust that the people who built these technologies do not have malicious intents .

This , of course , is the case for any new technology , and that is why we have been focusing more on security on these technologies . But because the potential of the AI technologies mentioned in the report goes beyond just a smart phone or credit card machine , people will be more cautious than ever with these technologies . These AI technologies have the potential to capture private information about you that can be used for blackmail , inform you of the wrong material in harmful ways , and more . Many of these concerns outweigh the benefits of the technologies .

Like the report states , different areas of AI applications have excelled more than other areas . The difficulty to trust the new technologies of AI will come not from the belief that AI will fail but from the mistrust humans tend to have on each other . For example , how can we be sure that the developer of an AI system aiding in medical circumstances has the right intentions ? If the robots are so intelligent , wouldn t that make them smart enough to deceive humans ? This will not be for the benefit of the robot but for the benefit of the developer of the device that is doing the deception . The point here is that humans are the ones that are performing these malicious acts , and my concern with the report is the picture it paints for the future of AI for 2030 . I believe that it will take way longer to get humans to accept AI than what the report suggests . There s also the problem of hackers with malicious intent . They may be able to hack AI systems and cause harm to humans in many of the ways mentioned in the report .

2030 is an ambitious goal for many of the technologies mentioned in the report not because I think we won t be able to build these systems but because naturally , humans will not be willing to accept it . There needs to be extensive testing and security measures taken in order for many of these technologies to gain popularity in the public . This will push back the date in which we see a world dominated by AI technologies . For these reasons , it is hard to imagine that many of the potential technologies that AI enables to deliver will come in 2030 .

The 100 year study on Artificial Intelligence -LRB- AI -RRB- and its review on AI 's progress through 2015 reveals a lot about where the world is headed in terms of how such a broad field of technology can have an impact on our society today and in the future . The authors of this continuous study seem to represent the best and brightest in the business coming from industry , academia and other research areas that combine to create a comprehensive analysis . While the authors here examine 8 specific `` domains '' which they find most significant to society -LRB- transportation , home/service robots , healthcare , education , low-resource communities , public safety/security , employment and workplace and entertainment -RRB- , they do not fully emphasize the negative aspects that AI could possibly bring to the forefront .

The authors of this installation of the 100 year study on AI extensively discuss positives in each of the 8 domains that they chose to examine . Examples include self driving cars which are far safer than human drivers , collection and systematized management of electronic health records as well as improved camera/drone surveillance for predicative policing . The positive effects on society that AI systems such as these can have is quite obvious , but what about privacy and the influence that these technologies can have on things such as information ? A perfect example is the filtration of news and the manipulation of voting sites such as Reddit . This kind of control could easily affect the minds of thousands of people and in turn alter the fabric of society as belief systems are influenced . Newsfeeds controlled by AI that are meant to serve the interests of a private news corporation rather than informing the general public of what is happening throughout the world may very well influence the decisions that people make . It is these kinds of situations where AI may be used for malevolent purposes .

While the authors do touch a bit on privacy and security concerns , they do not go nearly far enough . In Section III , the authors point out that policy/legal considerations with regard to AI are beyond the scope of the 100 Year Study . However , just as with drone regulations and the Federal Aviation Administration -LRB- FAA -RRB- , AI 's compliance to laws and regulations with respect to privacy and security is entirely important . Not just important -- it is crucial to making sure that AI is used for good and not bad . To leave something like this out of such a comprehensive study conducted by the best experts in the world is kind of silly . It seems to be the case that with AI , the industry -LRB- in all facets -RRB- has , for lack of a better term , jumped into the deep end instead of wading out into the water . Both positive and negative sides of Artificial Intelligence need to be fully examined for this to be a complete study . The impact that such a broad field can have on our society and the world in which we live is too great for any one aspect to be left out . As newer technology is being developed at an even quicker rate , more thought needs to be put into the potential negative , rather than just the positive , effects that AI can have .
The Stanford One Hundred Year Study correctly identifies transportation as one of the first key domain in which humans will be required to interact with an AI system for accomplishing a critical task . They will be exposed to autonomous transportation and be required to trust the reliability and safety of the system in potentially life threatening situations .


I wish to challenge the assertion the report makes stating that `` as cars will become better drivers than people , city-dwellers will own fewer cars , live further from work ... '' . In my opinion , this claim is based on unwarranted , incorrect assumptions and also fails to account for other factors which might affect its verity .


With the advent of self-driving or autonomous cars in combination with current movement towards electrification of vehicles , the cost of ownership of cars is widely expected to decrease drastically , giving people the opportunity to own a car for a much lower cost which may actually lead to a rise in private vehicle ownership .


The current popularity of public transport , ridesharing and other on-demand transport services can be majorly attributed to the amount of time it saves the driver . As noted in the report , an average commuter in the US spends 25 minutes driving each way . Autonomous cars free the drivers to spend their commute time in more enjoyable and productive ways . This elimination of the need to drive combined with the privacy , comfort , luxury and convenience of a personal car will again promote private ownership of vehicles .


Autonomous cars will also lead to increased mobility for kids and elderly people who currently ca n't drive . This increase will be effected either by an increase in the number of private vehicles owned per family or an increase in the number of daily miles travelled by a car per family . Due to safety concerns , many households also prefer private transportation over public or shared transportation especially for kids .


The report does n't account for the perpetual increase in population which will lead to an ever increasing demand for cars . The report might be expecting the need for private ownership to decrease as a result of the popularity of on-demand transportation services or carpooling and ridesharing . There is an expectation that on-demand transportation services will become so cheap that there is no incentive to opt for car-sharing services like UberPOOL . -LSB- 1 -RSB- As noted in the report , carpooling services like Zimride and Nuride have failed to be successful on a large scale .


The increase in the number of private vehicles , miles travelled per car combined with adopting self-driving technology for delivery vehicles and running autonomous errands like grocery pickup will lead to an increase in traffic congestion . The traffic congestion will consequently inhibit people from living further from work as it will lead to an increase in commute time especially during rush hours in cases when spending a minimum time in the office is more beneficial .


The report also fails to account for conditions which might arise when a combination of autonomous and conventional cars are being driven on the road . Eg : an unexpected action by a human driver might either slow down all the traffic behind him or a delayed reaction by the human may cause an accident . The behaviour of autonomous cars can be predicted with a very high degree of certainty but humans are unpredictable . -LSB- 2 -RSB-


-LSB- 1 -RSB- Muoio , Danielle . `` Self-Driving Cars Could Be Terrible for Traffic - Here 's Why . '' Business Insider , Business Insider , 4 June 2017 , www.businessinsider.com/self-driving-cars-traffic-congestion-2017-6 .
-LSB- 2 -RSB- Lowy , Joan . `` Self-Driving Cars Might Cut Costs but Make Traffic Worse , Researchers Say . '' The Seattle Times , The Seattle Times Company , 16 May 2016 , www.seattletimes.com/business/self-driving-cars-might-cut-costs-but-make-traffic-worse-researchers-say/ . In the Stanford A.I. report , the researchers proposed many promising fields for A.I. s application in near future , including transportation , healthcare , public safety etc. . Among those fields is education , which has seen many budding innovations driven by the increasingly powerful A.I. technologies in its field . Backed by examples such as emerging intelligent tutors , explosion of Massive Open Online Coursers and learning analytics , the report reached a cautious and optimistic conclusion in Broader societal consequences section that more online education resources accompanied by A.I. technology , may help further democratizing education and benefit student from countries where education is difficult to obtain , if they are equipped with tools to access them .
Although it should be acknowledged that the recent burst of online education resources has acted as a positive force toward democratizing education , a more holistic observation may raise some doubts about their effectiveness in practice . The optimistic viewpoint on online education resources augmented by A.I. technologies such as MOOCs and language learning apps is largely based on the assumption that digitalized educational material can be reproduced and disseminated more easily while A.I. technology like NLP make the automation of such as responding and grading possible and together they makes teaching and learning a more scalable experience and therefore more accessible for students who previously lack education opportunity .
However , there are still other steps to be taken for the students in need to really benefit from online resources after course materials and A.I. tutors are put online . First , student should have the ability to really access and utilize these resources . Here lies the issue of digital literacy and Internet infrastructure development . If might be safe to say that the students who lack access to traditional education and therefore are most in need of online education are those who have disadvantaged socioeconomic background and more likely to live in developing countries and less urbanized area . This means they may lack the necessary tools to access these resources like computers and reliable Internet connection . These students may also be less familiar with the use of online resources and hard to utilize these resources in practice , given these online learning resources usually put an emphasis on self-learning . This self-regulation feature of online education resources also leads to the problem of students motivation . Students who lack formal school education may have less chance to form good study habits and such as setting their own goals and time management , which are more important in online learning . Therefore , students who are most in need of more accessible education are put to an disadvantaged points in online education . Some research on Massive Online Open courses confirmed these concerns . A survey conducted by G Christensen et al -LRB- 2013 -RRB- shows most MOOC sample students in have already had post-secondary degree . The education level of MOOC students far exceeds that of the population in the corresponding area , which is especially significant in developing countries and more than 40 % of surveyed students report they take the course to advance their career . These results indicate instead of a tool to help less educated individuals , online learning is more likely to serve people who already have high education attainments . To solve these barriers inevitably raised due to the very nature of digital and online education requires approaches from socioeconomic aspects such as building infrastructure . The effectiveness of the educational A.I. technologies discussed within the scope alone may not achieve as significant a goal as the researches expected , especially in the perspective of improving education equality .

Stanford s One Hundred Year Study on Artificial Intelligence provides reflections , updates , and predictions on the field of artificial intelligence and other related fields . One aspect of this report that I would challenge is in the transportation section on self-driving cars . It states that self-driving cars might be widely adopted by 2020 according to a recent report -LRB- p. 19 -RRB- . Though I believe that self-deriving cars and autonomous transportation will be ubiquitous in the future , the year 2020 is very ambitious . Change in such a common space and industry takes time . The study also presents a table with new features of automated functionality in automobiles . One feature is intelligent parking assist system that was released in 2003 . Now , 14 years later , many cars have this feature and is practically expected in current models , though it is not necessary to drive and does not impactfully change how driving is done . Self-driving cars , however , will dramatically change the industry and society . Some consumers do not like the idea of having a GPS in their car tracking their location . With that current distrust in old technology , self-driving cars will cause even more people feeling uncomfortable with these new cars . Another reason self-driving cars might not become widely adopted by 2020 is if public transportation becomes cheaper and more efficient . With much research going into developing faster , safer , and less expensive public transportation , particularly trains and planes , they can cause mass appeal to a commuting public . If a major breakthrough were to occur in public transportation before one in the field of self-driving cars , it would be much harder to convince people to purchase self-driving cars . And without momentum and excitement for self-driving cars , it will be hard for the auto industry to start investing in this technology and move to a society full of self-driving cars .
Another point in the report that I would challenge is under the employment and workplace section when is the general perception of the economic impact that artificial intelligence and advanced automation brings to the workplace -LRB- p. 38 -RRB- . A basic economic concept is the idea that advancing technology and automation will increase the productivity of an economy . This is true of course , but the technology will replace human labor . A common argument is that new technology may take away some jobs but will create jobs as well . In many cases , this argument holds . However , in other cases it does not and will not . For example , cashiers can now be replaced with self-checkout lines and eventually could become more efficient like having the machine scan the items by itself and interact with the customer . This type of technology would remove far more jobs than it would create . Because of this better efficiency and lack of workers , there could be high unemployment and decreasing tax revenue . If this happened , the government would respond by instituting taxes on automation to encourage the hiring of people rather than machines . This is one way that the integration of artificial intelligence in society is slowed down . Another possible barrier is if a few incidents of artificial intelligence are hurtful or damaging to people like a self-driving car crash . In conclusion , Stanford s report is and will be an incredible log of artificial intelligence and it is a great resource for understanding the current state of AI . Though there were a few points I felt were questionable , the majority of the report was credible and realistic .
In General , the predictions made by the ` 100 year study of AI ' are accurate . But some predictions about AI in the next 15 years are too extreme . The section on public safety/security is particularly unbelievable . The section contains predictions stating that AI will determine possible criminal activity based off behavior trends seen from security cameras or through posts on social media . But these predictions , in my opinion , will likely not come to fruition . The study is wrong in that AI will not correlate suspiciousness and behavior in the next 15 years . If any such program was designed and implemented into society for this purpose , it would be a complete breach of privacy and very inaccurate .
The program would be inaccurate because correlating suspiciousness and behavior is nigh impossible . People come in all shapes and sizes ; our behavior is subject only to our physiology and standards . Therefore , the variables involved in determining how a suspicious person differs from the `` standard '' person are too numerous and obscure to properly utilize . The following quote from the study illustrates signals AI could use to determine : `` vision , speech analysis , and gait analysis -- can aid interviewers , interrogators , and security guards in detecting possible deception and criminal behavior . '' A program utilizing these signals alone would not be capable of detecting deception . For example , Gait analysis is flawed because one may walk strangely if suspect , but one may also walk strangely due to any sort of leg injury . This would make the program inherently biased against the less mobile . Many other `` signals '' fall short in the same way . Implementing this `` behavioral analysis AI '' would be little more accurate than a lie detector . Another thing AI can not account for is humanity .
People act differently when being analyzed . While under AI scrutiny , one will try to act `` normal '' , but will inevitably become nervous . Ironically , nervousness may even trigger the AI meant to detect suspicious behavior . It 's a classic incorrect pairing of correlation with causality . On surveillance , the study states the following : `` These improvements could lead to even more widespread surveillance . Some cities have already added drones for surveillance purposes ... raising concerns about privacy , safety , and other issues . '' Behavioral analysis AI would not only be inaccurate , but also oppressive . If surveillance was widespread enough , one would need to live their whole life `` normally '' to avoid raising their `` person 's risk categorization '' -LRB- quoted from study -RRB- . The constant surveillance of a population and a correlating risk categorization would be invasive , even oppressive . In addition to constant surveillance , AI could risk privacy online as well .
Social media tracers -LRB- AI that utilize posts on social media to determine possible criminal activity -RRB- may also be developed . This AI would be incredibly invasive . Having one 's private profiles analyzed for suspicious activity creates an atmosphere of constant supervision . In addition , Social media tracers are inaccurate . AI is far from understanding all the nuances of even english - especially the slang and irony found on most social media . For example , Nuance could make it incredibly difficult for AI to discern between a real threat and a distasteful joke . This , paired with the invasive tech , would inevitably end up with innocent people being monitored just because of an inappropriate post .
Overall , AI is far too underdeveloped for use in monitoring human behavior . The technology , if created and implemented today , would be incredibly inaccurate and invasive . These factors make AI technology oppressive and unfriendly . If this were how the public first experiences modern AI , the technology would wallow . It 's as the article says : humans must trust AI before AI can become successful . For the purpose of advancing AI , monitoring human behavior to determine suspiciousness should not be implemented until reliable and noninvasive technology is developed . Over the past twenty years , health records have moved from paper to Electronic Health Records
-LRB- EHRs -RRB- . If a patient suffers a medical emergency away from home , the hospital they are taken to can
request their information from their usual health care provider . If a patient is given a drug in the
emergency room and then taken to an operating room , the anesthetist can be warned before
administering a dangerous overdose of the drug . But most importantly , EHRs have created the large
dataset needed to fuel research advancements , the data needed to create a breakthrough in patientcare
through AI . However , the authors of the Stanford One Hundred Year Study on Artificial Intelligence
quickly dismiss EHRs , blaming clunky user interfaces complete with annoying popups that physicians
routinely dismiss . This is an unfair criticism ; it is hard to fathom that the systems are clunkier and more
annoying than the thick folders of patient data that were passed around before EHRs . In reality , EHRs
are the backbone of nearly every healthcare benefit they predict AI will provide in the next fifteen years .
The paper predicts advancements from AI s ability to mine outcomes from millions of patient
clinical records . Well , there would be almost nothing to mine if it were not for EHRs . EHRs collect all of
the data and store it in a database that makes data mining possible . In fact , the paper specifically
mentions the water crisis in Flint , and that crisis was actually first identified from a report built on EHR
data . The predictive models being built to prevent future water contaminations and other healthcare
crises are likely heavily reliant on EHR data .
Next , the paper foresees a breakthrough in healthcare image recognition by AI , specifically for
performing diagnoses . While the technology to perform a diagnosis from an image is not from EHRs ,
EHRs are partly responsible for its advancement . EHRs have driven the digitalization of images so that
they can be easily accessible from the system , which created the dataset necessary to develop AI image
recognition . The paper states an obstacle to image recognition development is that only very large
organizations can develop it because of the barriers to data sharing in healthcare . However , EHRs and
third-party organizations are currently building research databases comprised of the data from their
community members . These efforts will make it possible for this technology , and others , to develop
outside of a large organization . EHRs have undoubtedly made a large impact in healthcare image
recognition .
Finally , the paper mentions the benefit of mobile applications , from a new generation of tech
savvy clinicians utilizing specialized mobile applications to the population as a whole employing mobile
applications to do things like find similar health populations or tell them when to exercise . EHRs are
largely responsible for this benefit . EHRs provide their own mobile applications and offer APIs that
allows other applications to access the EHR database . The young clinicians and the rest of the
population are likely either directly using an EHR application or using an application that take advantage
of an EHR database . EHRs are a critical part of the healthcare benefits from mobile applications .
While some criticism of the user interface of EHRs is fair , the paper ignores the large benefits
that the systems currently provide and the fundamental role that EHR data will provide in the
advancement of healthcare . Already , EHRs have brought AI into nearly every part of hospitals , and the
future of EHRs and AI will be intertwined in the next fifteen years . The authors should have credited
EHRs for advancing AI , not blamed them for holding it back .
The challenges on the 100 year AI study
The title may be redundant but not the essay that follows . The 100 year study on AI is an attempt by AI savvy people to present the advancements , vision and challenges that
lie ahead in bringing AI to the society . The problem starts with the very beginning of defining Artificial Intelligence . It defined AI as the ability of machines to think
intelligently and with foresight in its environment . This definition could apply to any machine any particular that performs a task assigned to it including a calculator .
But , that is not all of it and that is not what AI is intended to .

Another challenge is in the level of specificity of applying AI . The principles of AI are common but applications are diverse . That in turn gives rise to a variety of
challenges . A lot of challenges were presented in the study . I would like to elaborate and add on a very important challenge .

Lack and Loss of Personal touch :
I would like to define AI as intelligence created by the people , of the people and for the people . That s exactly how Abraham Lincoln defined democracy . Clearly , AI is
something by the society and for the society . While AI is certainly intended to amaze people with its awesomeness , I strongly fear the human values getting compromised in the
process . This is not the same as zombies destroying the world as pictured in movies . I agree that it is amazing to watch machines intelligent but don t agree them take the
human s chair . Let me elaborate this perspective in few of the eight surveyed domains as below :

-LRB- i -RRB- Transportation :
Driverless cars and other intelligent services like GPS , automated parking are a boon to drivers . But who would want to compromise the pleasure of self driving ? Alternatively ,
rather than teaching machines on how to drive , we could have machines that monitor human driving and instruct him as and when he falters . This would probably boost the
confidence of novice drivers and help build trust among people in the use of AI systems .

-LRB- ii -RRB- Healthcare :
Deploying AI in healthcare is like hanging on a cliff . A department that is run by trained and experienced professionals , relying on machines seems to be a far-fetched goal .
Alright , let s assume that diagnosis and medication is more accurate than a human examination . Personal care and comfort that doctors and hospital staff provide to ailing
patients is key in improving the health . This is something that AI machines can never achieve as human emotions are vague and subjective .

-LRB- iii -RRB- Public safety and security :
AI has been tremendous in monitoring safety and ensuring security of the public . The report states that it does overcome human bias . Well , I would say that these systems may
have escaped human bias but fall a prey to human vengefulness . How many times have we seen public security compromised by vengeful hackers ?

-LRB- iv -RRB- Education :
Lot of AI enabled learning resources have boomed up . Learning is not complete without knowledge sharing with peers and discussion forums . The learning rate differs across
students and nothing but an onsite classroom can provide this completeness .


Is that all ?
The above essay could have taken harsh on taking AI to the public . It is absolutely not . I have just shared my perspective that AI should not supplant humans . Intelligent
machines are definitely the society s better half . They should lend themselves to be mended now and then just as kids are corrected by parents . AI is mankind s baby and not a
master .



The One Hundred Year Study on Artificial Intelligence seems optimistic about the future of AI by 2030 . However , the bright future may not be very easy to achieve given the constraints of privacy concern and tech-savviness of users .
Privacy may be the biggest obstacle that lays ahead of AI development . Since development of AI depends on running statistics models that based on huge amount of data , if privacy concerns limit the amount or quality of data for statistics models , then it will be hard to achieve accurate analysis , for instance , the healthcare analytics the report demonstrates . The report says that at the population level , AI s ability to mine outcomes from millions of patient clinical records promises to enable finer-grained , more personalized diagnosis and treatment -LRB- Stone el al. , 26 -RRB- . However , how easy is it to obtain health data ? One way to collect health data are from the automated capture of personal environmental data from wearable devices -LRB- Stone el al. , 27 -RRB- . Yet , wearable devices currently are not cheap enough for everyone to afford them , but in order to fit the most reliable models , we need data that can represent the whole population . Will the price of wearable devices create selection bias in the health care models ?
The best source of health records probably are the clinical records in health institution . However , how difficult is it to obtain these records from thousands of institutions ? If owning a large amount of clinical data puts an institution in great advantage in terms of utilizing AI technologies to improve medical services , then it is likely that that a large institution will keep the data to themselves . Then it may be possible that the analysis using AI technologies ignore the population who go to small clinics or illnesses that do not require resources of a large hospital . Just as the report points out that he FDA has been slow to approve innovative software , in part due to an unclear understanding of the cost/benefit tradeoffs of these systems -LRB- Stone el al. , 27 -RRB- , it may be reluctant for government to fully support AI development because the policy makers may concern about public opinion on privacy .
The report also enumerates list of thing AI could offer to help the including assistance in hearing , vision and mobility -LRB- Stone et al. , 30 -RRB- . The list of helpful things AIs can do to help the elder certainly improve the elder s quality of life where they have more control over their life without the help of other people , and thus they could have higher self-esteem . However , when people get old , their cognitive and physical capacity decline , and they take longer time to understand new products , especially those who have disability or diseases . Sometimes when it is too difficult to understand , like many cases with the computers and Internet today , people just get so frustrated that they give up on the new technology . Therefore , AI products need to fit the capacity of the targeted customers . Instead of the traditional way of customers learning how to use products , the user-friendly products need to understand precisely what elder customers need and initiate action to help them . To achieve this , it requires AI products to have very high intelligence , and we are far from that . Thus , in my opinion , the report is far too optimistic on what we can achieve with AI to help the elderly by 2030 .
My main criticism of this article is that it does not take into consideration the integration required for these systems to function in harmony . My criticism will focus on the parts about AI in the home and providing services for homes .

Since the U.S. is a capitalistic economy , companies lock in competition for market share . Companies use proprietary code written in-house and usually integrate well with their own hardware and systems . Generally these companies release an SDK of some sort . The problem enlies in that while the U.S. continues to be a capitalist economy with antitrust legislation , providers of hardware will have to subscribe to the going system of integration , ex . Amazon Alexa controlling my Phillips lights and not my Emerson stove -LRB- One will need a Google Home for that -RRB- . One can not expect your everyday consumer to integrate these systems themselves .

While the article envisions a world of perfect harmony where robots drop off packages and clean your house without a word -LRB- albeit saying ` top of the morning to you ' -RRB- , real consumers have and will find themselves in a world of twisty-turny compatibility nightmares .

I believe this is the biggest challenge to AI in the home . While having a perfectly integrated home may be the dream of a tech-minded person , the average homeowner will take the path of least resistance . I am surprised that the article does not even mention the word compatibility once !

Summarized , compatibility matters because the average homeowner might acquire conflicting systems . For example , your vacuum might not integrate with your audio system or home theater , so when you are trying to watch a movie your vacuum comes parading through trying to do its good deed . Or , your Roomba which has a perfect map of your house might run into your incompatible mop , sucking water into the Roomba and ruining the motor or gears .

Therefore , I append the policy position to the article that this integration consideration be included . I am not making the argument for some authoritarian centralized repository and standard for inter-communication between systems in the home or service to home industry ; rather , I am making int clear this has and will be a great challenge to the prevalence of AI in the U.S. .

The article mentions the development of collaborative AI systems that do this work of integration between autonomous systems ; however , the legal landscape of the United States protects intellectual property -LRB- IP -RRB- and any modifications to software to integrate with each other beyond the API exposed intentionally will likely cause reason for suit . Thus , a framework must be build within the legislative environment that fosters the integration of systems and gives companies a framework within which to build the connected home .

I propose explicit legislation requiring companies to expose an API for their connected devices that must use a standard communication framework , ex . a RESTful API over HTTP/S , that other companies can integrate into their connected home solutions . As there are already , I imagine devices using a method such as the OUI component of a MAC address to be discovered on the network and recognized by devices for human interface such as Google Home or Amazon Echo . Abstracting the network level , this would allow less tech-savy consumers to benefit from AI and service systems without having to think about the integration themselves .
Self-driving car : an application of AI that is not beneficial to every-one
Even though the One Hundred Year Study on Artificial Intelligence has given collective reflections about AI 's definition , applications and future policy making , its prediction about self-driving vehicles appears questionable . The study states on page 20 and 21 that if self-driving vehicles have exceeded human performance and are adopted by society with expected speed , they will bring various societal changes and increase passengers comfort during transportation . However , given the uncertainty of driving , self-driving vehicle s performance during emergency may remain questionable in future , which may impair its public image and stop the pace of adoption . Also , apart from comfort , passengers may also experience motion-sickness while working or reading on their vehicles .
Admittedly , autonomous vehicles safety will largely increase with sensor-technologies to detect their surroundings and learning algorithm to predict and respond to movements of nearby objects . However , given the uncertainty of objects reactions , passengers safety is still at stake and self-driving cars need more efforts to win customers trust . Nyholm and Smids -LRB- 2016 -RRB- from Eindhoven University of Technology in Netherland argue that since drivers may react to the same collision differently , it is still hard for autonomous vehicles to accurately predict another drivers reaction , which may change the situation instantly -LRB- p. 1285 -RRB- . During a car accident , drivers may try to stop their car or steer to other lines based on their own understanding , which may lead to different outcome for self-driving vehicles prediction . To precisely predict other cars movements , despite learning from previous traffic accidents , autonomous vehicles may also need to analyze other drivers status and information at that moment . Also , there are still concerns about autonomous vehicles safety among the public , especially during unexpected circumstances , when car models algorithm fails to predict actions of nearby objects . According to University of Michigan , Ann Arbor s research on US citizens on Survey Monkey database , 83.2 percent of US participants are strongly or moderately concerned about self-driving vehicles performance in unexpected situations and 73.2 percent worry about its performance compared with human drivers -LRB- Schoettle & Sivak , 2014 , p. 14 -RRB- . These testify that the public are still holding concerning views about self-driving vehicle s performance during emergency treatment compared with humans . Autonomous car producers may still have long way to go to gain public trust and introduce their products .
Even though it is possible that customers will purchase their own autonomous cars in future and the One Hundred Year Study claims that autonomous car passengers will have more free time and comport during commutes , their experience may not always be positive due to the motion-sickness brought by reading or working on moving vehicles . Motion sickness is not rare among human beings . In fact , according to Gale Encyclopedia of Medicine , 80 percent of general population suffer from it once in their lifetime , especially people with migraine headaches -LRB- Motion Sickness , 2006 , Definition section -RRB- . While reading or working on their laptops in their moving autonomous vehicles , these individuals become susceptible to motion sickness and relevant symptoms . After analyzing causes of motion sickness , Diels and Bos -LRB- 2016 -RRB- argue that popular activities in moving vehicles , including reading , responding to emails or engaging with infotainment systems may result in or increase car-sickness due to the discord between motion of the vehicles and our visions on screens or book pages -LRB- p. 376 -RRB- . As a result , these sensory conflicts on autonomous vehicles may lead to headache , nausea and other uncomfortable reactions on passengers . It appears that even though passengers are given more freedom to relax or work on self-driving vehicles , they may also experience motion sickness due to the moving vehicles .

References
Diels , C. , & Bos , J. Z. -LRB- 2016 -RRB- . Self-driving carsickness . Applied Ergonomics , 53 , 374-382 . doi : 10.1016 / j.apergo .2015.09.009
Motion Sickness . -LRB- n.d. -RRB- . Encyclopedia . Retrieved September 11 , 2017 , from http://www.encyclopedia.com/medicine/diseases-and-conditions/pathology/motion-sickness#1G23451601070
Nyholm , S. , & Smids , D. -LRB- 2016 -RRB- . The ethics of accident-algorithms for self-driving cars : an applied trolley problem . Ethical Theory & Moral Practice , 19 -LRB- 5 -RRB- , 1275-1289 . doi : 10.1007 / s10677-016-9745-2
Schoettle , B. , & Sivak , M. -LRB- 2014 -RRB- . A survey of public opinion about autonomous and self-driving vehicles in the U.S. , the U.K. , and Australia . University of Michigan Transportation Research Institute . Retrieved from https://deepblue.lib.umich.edu/handle/2027.42/108384
The article on Artificial Intelligence -LRB- AI -RRB- by Peter Stone et al. fails to sufficiently address the possibility of rapid advances in the field ; which would require more immediate , rigorous regulation . The study panel covered a range of 8 , of what they believe are the most important domains related to AI . For each of these domains , including : transportation healthcare , education , and public safety and security , the panel describes the influence of AI to-date and provides information on how North Americans , both collectivity and individually , may influence and be influenced by AI in these fields in the coming years . The article fails to address immediate action that should be taken to help proactively regulate AI in the case of a faster than expected takeoff . This gap in information could have detrimental effects if the suggested case occurs . Immediate policies should be put in place and study panels formed to specifically study how to regulate AI , to reduce the risk of AI , that is biased , unreliable , or hostile
The importance of time is highlighted throughout the paper ; however , policy guidelines , suggestions , and other recommendations regarding the immediate term are generally vague . Statements on the future of AI , in the area of transportation , such as , The increased sensing capabilities , adoption of drones -LSB- -RSB- will also raise concerns about privacy -LSB- . . -RSB- , these and related transportation issues will need to be addressed either by preemptive action -LSB- . . -RSB- or within the legal framework leave questions of what preemptive action needs to be taken , or even how one might start to answer that question , or the question of what an adequate legal framework may look like . In the clinical setting , recommendations become a bit more specific with the use of terms like free-form dialogue being used to describe attributes of AI clinical assistants , but still fail to address the underlying ambiguity . Does free-form dialogue mean that the same AI assistant that takes my vitals at a hospital , will ask me about my day ? Such questions might seem pointless but unknown consequences affecting patient health may arise based on choices made now .
Rigorous research on AI and how it will be regulated should be implemented immediately . Multiple incidents in the past few years have called into question existing laws on encryption , privacy , and liability relating to electronic devices . Furthermore , these incidents highlight the inadequacy of current legislation s ability to effectively regulate the technology of today . If this legislation is not sufficient now , how can it possibly be sufficient for AI ? The suggestions offered by the study panel will be effective assuming only that we have studied AI well enough to be able to regulate new technologies as they are released . This reactive rather than proactive model could very well fail if new computing technology advances at a rapid pace . Recalling Moore s Law -LRB- the Law stating the doubling of transistors about every 18 months -RRB- and the general trend of innovation in the technology sector in the last few decades , this scenario is not at all unlikely .
A critic of increased regulation may claim that regulation created now will become outdated quickly if AI does advance rapidly , and may be more likely to hinder AI advancement . While the critic may be correct in guessing that legislation could slow AI advancement in the future , without adequate legislation government and private researchers , companies , and citizens alike may fail to react quickly or correctly enough to advances in the field . If an artificial intelligence becomes sentient , is it then legally responsible for its actions ? If it is not who is responsible for an artificial intelligence created by an open source project ?





Statement of Challenge :

Stanford AI100 claims that government should intervene with broader `` social safety net '' because in the long run education and re-training are rather futile to save people form unemployment . However , I argue that it should be the other way around :
It is education , not the politically intervention claimed by Stanford AI100 , the key to safeguarding the long-term economic sustainability of a majority of citizens in our AI economy in the future .

Essay :

Stanford AI100 acknowledges AI 's negative impacts on employment and proposed a seemingly reasonable suggestion of mitigation : Governmental intervention is the principal component of helping people who are susceptible to these changes . However , this claim is not necessarily reliable . Rather , AI education should be the leading component of safeguarding jobs and subsequent well-being of millions of ordinary people .

First , education is far more effective than government regulations for an average person . Although the job market is very competitive , those who possess specific technical skills still find that it is relatively easy to secure decent positions . For example , a computer science PHD usually does not need any help from the government to get hired by a company with a seemly salary . On the contrary , even though the government has proposed and practiced numerous labor protection and minimum wages acts , many Americans with relatively less education are on the margin of either been fired or stuck with a low wage , let alone billions of people living in less developed nations where government regulations are ineffective -LRB- there is no way that Artificial Intelligence would not invade developing countries -RRB- . That been said , without governmental responses , massive AI education would not be available because private companies lack the incentives to invest for many vulnerable citizens with few resources . But ultimately it is AI education , not some minimum wages act or labor protecting laws , that helps people secure their jobs .

Furthermore , investments in AI education could be less costly than governmental interventions in labor sectors . Some people believe that it is very costly to expand AI education to a large portion of people in the society . However , `` costly '' is a relative term . According to the Office of Management and Budget , the U.S. spends nearly twice as much on Social Security than it spends on education . There is no information specifically addressing AI education investments , but it is likely to be cheaper than the Stanford-proposed `` governmental responses '' because these very `` responses '' need budgets not only for Social Security but also for many other expenditures . Given that many universities and colleges already have mature computer science education programs , it should be relatively inexpensive to add an AI component -LRB- such as CS 540 -RRB- to enlarge the skillsets of students .

Finally , effective AI education is actually easier to achieve compared to waiting for bureaucratic responses . No one 100 hundred years ago could imagine over a society with over 95 % literacy rate . Fifty years ago a high school diploma is highly desirable . Thirty years ago a majority of people do not think they could ever go to college . Based on this logic , we can not imagine the scale of AI `` literacy '' in the future . New business models are developing at a soaring speed and it is quite possible that we could find one or more way to make learning AI easier for the general public.AI is just like literacy rate , algebra or high school diplomas . Once people could learn it and get familiar with it at a large scale it would soon be demystified , resulting in a large number of citizens who are capable of working under the new economic reality with AI .

Reference :
-LSB- 1 -RSB- : Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .
-LSB- 2 -RSB- A New Foundation for American Greatness - President 's Budget FY 2018 , Office of Management and Budget . Retrieved 10 September 2017 . Artificial Intelligence

As the future approaches where artificial intelligence is being used more and more in our day to day one of my major concerns with the technology is how these machines have the potential to perpetuate biases with their analysis on large data sets . The one field where I see this being the biggest problem is the healthcare field . I can recognize that bringing AI to healthcare could have major benefits . It would allow doctors to stay up to date on medical practices , assist them in faster diagnostics , and most importantly reduce medical costs . But , if designed poorly , also has the potential to preserve some of the existing biases in healthcare .

According to the Stanford study one of the things that makes AI so special in regards to the healthcare field is the ability and speed it will have in analyzing large data sets . One of the major issues surrounding this is that medical data has historically favored white men due to the nature of studies and clinical trials . Also , there is a major problem surrounding the way that drugs are tested before they go to market . Often , according to the article `` Bad Pharma , '' by Ben Goldcare , drug companies not only buy the opinions of doctors but they also conduct the tests on their own drugs , which obviously creates a major conflict of interest . In turn , this will impact not only women but drastically many people of different races as well . For example , a woman s symptoms for a heart attack differ drastically than that of a male .

AI will create another problem for healthcare officials because privacy is a major concern surrounding the implementation of AI . Most likely , AI in healthcare will only be allowed if there are strict privacy laws attached to it . With these regulations , the doctors will not be able to see how the AI came to some of the conclusions it came to and furthermore the doctors will not be able to dispel any biases that could be present in the AI s conclusions and be able to make the correct treatment decision . This could potentially cause doctors to misdiagnose and mistreat their patients which will create chaos in the AI field . The doctors will be blamed by the patients and in turn the doctors will point their fingers at the AI . This could raise doubt in the effectiveness of the AI technology and create further issues if doctor s request for more access to patient data . Which opens up another can of worms because people desperately want their privacy . People are already worried about the NSA spying on them and it is a major cause for concern in society today .

If medicine and future medical decisions are based on these already large skewed data sets the only people that are going to benefit from the short addition of AI in the healthcare field will be white males . In order for AI to be an effective tool in the healthcare field there needs to be something done about the already present issues within medicine , otherwise , AI could fail miserably .

The study ` Artificial Intelligence and Life in 2030 ' considers the impact of Artificial intelligence -LRB- AI -RRB- in the demand for skills and abilities in the job market . The study suggests that `` the demand for some types of skills and abilities will likely drop significantly , negatively affecting the employment levels and wages of people with those skills '' -LRB- pg . 47 -RRB- . However , the study also suggests that `` the ultimate effects on income levels and distribution ... depend substantially on ... decisions by individuals to invest in learning new skills and seeking new types of work and income opportunities '' . -LRB- pg . 47 -RRB- . While the study accurately describes the uneven effects AI may have on low -LRB- or specific -RRB- skilled workers , it is not correct in its assessment that these low -LRB- or specific -RRB- skilled workers will be able to find new jobs by the adoption of new skills .
As the study describes AI is likely to reinvent the transportation industry with new technologies such as self driving cars , putting millions of people out of a job . One of the most popular professions in most states is truck driving -LRB- with an estimated total of 3.5 million people professionally driving trucks in the United States , according to the American Truckers Association -RRB- . If the study is accurate in its suggestion that self driving cars will be widely adopted by 2020 -LRB- pg . 20 -RRB- , this gives 3.5 million people roughly less than 3 years to find a new skill that will not be replaced by AI . This is also just considering truck drivers and not other jobs related to transportation and also discussed in the study . -LRB- One can also consider retail and its shift towards automated AI to serve its costumers . According to the Bureau of Labor Statistics retail salesperson is the most popular job in the United States with little under 4.5 million people . Only accounting retail salespersons and truck drivers we have roughly 8 million people who will be out of a job -RRB- .
Workers who lose their job will not be able to find another one . The study suggests that these people whose skills have been made obsolete can learn new skills , and move on to jobs that will be created or not affected by AI . Nevertheless , it is likely that most low skilled jobs will be replaced by AI , and so those individuals will have to obtain a higher education to get the needed skills . According to the National Center for Education Statistics in 2017 20.4 million students are expected to attend American Universities . This shows that the individuals seeking a higher education after being replaced would be more than one fourth the total current students in Universities and it is unlikely universities will be able to accommodate this many people . One may argue that one can learn a new skill like coding through the internet . While this may be true , the skills obtainable through this method may not be marketable , as those with degrees from higher education would hold a more appealing look to the small job market .
In conclusion the study adequately suggests that the job market will be unevenly affected by the introduction of AI systems . However , it fails to take into account the existence of issues that are involved in an incredibly large number of individuals looking for new skills only obtainable in higher education . While , it is true -LRB- as the study goes on to say pg . 47 -RRB- that government policies will have a large impact on this , it is hard to see how government policies will side with lower skilled workers instead of big companies which seek to increase their profit.The Stanford study on Artificial Intelligence provides an illuminating look into a field that is going to transform life as we know it . For millennia , humanity has relied on their own ingenuity and skill to advance the well-being of the species . In the last 60 years , however , technological advancements have pushed us to a tipping point where many of our problems can be solved by computers acting independently . The ability to program computers to simulate the biology of the brain is one of the greatest achievements that our species has ever made . With this power , computers will surely have the ability to perform many of the tasks that humanity can perform with even greater efficiency and speed .

Overall , the report does a great job exploring and outlining the future of AI as it pertains to our daily lives . It hits on the eight major sectors that AI will affect in the next 15 years : Transportation , Home/Service Robots , Healthcare , Education , Low-Resource Communities , Public Safety and Security , Employment and Workplace , and Entertainment . These categories are pretty comprehensive and encompass most of everyday life that will be impacted by AI . The one sector I want to focus on , however , is Employment and Workplace .

In the report , the authors mention multiple times that there is no need to fear AI because it is not an imminent threat to our way of life . They use the clich image of a robot army attacking the human race to paint a picture of what most people perceive to be dangerous AI . While I believe that it is true that we don t have to fear a robot army attacking humanity , I do believe that AI has incredible power that , if not prepared for now , will have devastating effects on our society in the next 15 years .

My main challenge to this report centers around the danger of AI . While robotics aren t advanced to the level of Westworld just yet , there have been significant developments in the field over the last few years . Boston Dynamics , a robotics company based in Boston , has built humanoid and animal robots that have the ability to perform many tasks independent of human interaction . When combined with deep learning , these robots will eventually become so advanced within their environments that they will be able to perform tasks with incredible efficiency .

In addition , while Elon Musk is not an expert on the topic , he has incredible insight into a world that not many others have access to . From his perspective , we are on the cusp of a breakthrough in AI that , in the next 10 years , push computers into a new realm of intelligence : artificial general intelligence . When we make the jump from AI to AGI , the game completely changes . Computers are now able to direct most operations within a society with minimal error . With enough accurate and relevant data , computers will be able to run supply chains , control transportation logistics across the world , optimize manufacturing processes , facilitate transactions on global markets , draft governmental policy , and much more . This will all be possible because of AGI and its ability to simulate an infinite number of possible outcomes given any situation . With this power , millions of working people will be displaced by computers , and I believe this will happen in the next 15 years . With so many people out of work and the possibility of even more people being displaced , it begs the question what is our purpose ? With so many people living in existential crisis , we become a threat to ourselves . This is where the biggest danger from AI comes in .
-LCB- \ rtf1 \ ansi \ ansicpg1252 \ cocoartf1504 \ cocoasubrtf830
-LCB- \ fonttbl \ f0 \ fswiss \ fcharset0 Helvetica ; -RCB-
-LCB- \ colortbl ; \ red255 \ green255 \ blue255 ; \ red0 \ green0 \ blue0 ; \ red38 \ green38 \ blue38 ; \ red250 \ green250 \ blue247 ;
\ red120 \ green9 \ blue17 ; -RCB-
-LCB- \* \ expandedcolortbl ; ; \ cssrgb \ c0 \ c0 \ c0 ; \ cssrgb \ c20000 \ c20000 \ c20000 ; \ cssrgb \ c98431 \ c98431 \ c97647 ;
\ cssrgb \ c54902 \ c8235 \ c8235 ; -RCB-
\ margl1440 \ margr1440 \ vieww12520 \ viewh8400 \ viewkind0
\ deftab720
\ pard \ pardeftab720 \ qc \ partightenfactor0

\ f0 \ fs32 \ cf0 \ expnd0 \ expndtw0 \ kerning0
Summoning the Demon \
\ pard \ pardeftab720 \ partightenfactor0
\ cf0 Every so often a technology comes along that transforms how humans interact with the world around them . Notable examples include automobile , the computer , and air travel . From the various impacts that artificial intelligence -LRB- AI -RRB- has already made , outlined in Stanford 100 Year Report on Artificial Intelligence , it becomes clear this will have the greatest impact the world has ever seen . Taking lessons from the past it is clear that the controllers of said advances accumulate vast wealth and power . However , the future rise of artificial intelligence will be on a scale that humanity has not even begun to prepare for . The Report neglects the warning signs and wrongly asserts that artificial intelligence is not an imminent threat to the future of the human race . \ ` a0 \
The power transformation that will occur when artificial intelligence becomes life changing , which it inevitably will , will be on a scale unknown to history . This is because of the lack of manpower necessary in scaling . Giants , such as Henry Ford , were confined by the need for workers and innovators to expand their businesses . For example , every time Ford wanted to make more cars he needed to build more factories , buy more materials , and hire more workers . When an individual or small group controls AI they will not have such limitations . All they will need is computer hardware and server space , two items that are becoming increasingly inexpensive . Thus , economic power and future innovation falls into hands the public has no control over . It is naive to leave who ends up controling the most powerful technology ever created up to wishful thinking . \ ` a0 \
However , the previously stated scenario would be a tame one compared to a self-controlling AI . Due to the speed that electrical circuits work , if an AI was able to obtain the same intelligence as a human , the AI could perform the same amount of thinking , research , and innovation in one hour that humans could in 20,000 years . This simple fact would allow such AI to become orders of magnitude smarter than humanity instantly . \ ` a0The question the report fails to address is what happens when a machine becomes more powerful than the entire human race . Many experts agree that once such an AI decides humans no longer benefit its agenda , then they will instantly take deadly action . Even if the Report only sees a slim chance of such a scenario , the detrimental effect on humanity is too great to ignore . \
Most of the conclusions in the report are fundamentally well thought out , but in attempt to facilitate the research and integration of AI they mistakenly assume there is no imminent danger to be wary of . Whether it will be a small group of humans or self-controlled AI , the power that will be created will upset the entire balance of innovation and economics in the world . Even worse , the is a real possibility in the human race ending itself through AI research . While experimentation must be facilitated , policies must be put in place to keep the technology open source and safe in order to create a safe future in which AI makes every human life better . \
\
\ pard \ pardeftab720 \ partightenfactor0
\ cf3 \ cb4 \
\ pard \ pardeftab720 \ qc \ partightenfactor0
\ cf3 Bibliography \
\ pard \ pardeftab720 \ fi715 \ partightenfactor0
\ cf3 Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . \ ` a0 `` Artificial Intelligence and Life in 2030 . '' \ ` a0One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , \ ` a0September 2016 . \ ` a0Doc :\ ` a0 -LCB- \ field -LCB- \* \ fldinst -LCB- HYPERLINK `` https://ai100.stanford.edu/2016-report '' -RCB- -RCB- -LCB- \ fldrslt
\ b \ cf5 http://ai100.stanford.edu/2016-report -RCB- -RCB- . Accessed : \ ` a0September 6 , 2016 . -RCB- `` AI will likely replace tasks rather than jobs in the near term , and will also create new kinds of jobs . But the new jobs that will emerge are harder to imagine in advance than the existing jobs that will likely be lost . ''

Challenge : I challenge the observation that AI is likely to replace tasks rather than jobs in the near-term . I believe that AI has so far been replacing tasks rather than jobs but henceforth it will be starting to replacing jobs as a whole at an alarming pace .

Even before the recent rise in AI technologies , the non-AI traditional software has already made jobs disappear . While gas stations in most developed nations are self-serviced , the same is true for most developing nations . The self-service gas stations became a reality only after computers became predominant . Softwares have been replacing jobs for over decades now . Factory jobs , assembly jobs and many other jobs which were repetitive have been replaced by automation which became possible only through software .

The report is very lenient about the impact AI is going to have on jobs and in turn , the impact that the loss of these jobs have on the economy . Usually , whenever some new innovations come up that would make a certain set of jobs disappear also create new jobs based on the innovation . For example , when mankind figured that it could use electricity to light up the streets instead of whale oil , the whale oil industry disappeared with all the jobs in it , paving way for tremendous growth of electricity based industry such as the coal mining industry . But the current scenario has been in such a way that a number of jobs that are disappearing due to automation are relatively much larger than the jobs created by the process of automation .

`` Recent report predicts self-driving cars to be widely adopted by 2020 '' .

The report claims that self-driving cars will be widely adopted in the near future . The adoption of self-driving automobiles implies that the jobs that are based on driving could potentially disappear . It would directly impact a vast majority of truck drivers , cab drivers , bus drivers . While self-driving car adoption means that more machine learning engineering jobs are created but for every machine learning engineer job created we might lose 10 driver jobs .

The jobs that AI will most likely take away are also low paying jobs which do not require a skilled workforce . It should be noted that people who are employed in such jobs usually belong to the low income or lower-middle income group . The rise of AI tech is most likely going to have a negative impact on people who belong to the lower income groups . If loss of the jobs is not unchecked it might result in the entire collapse of the country 's economy . All the lost jobs would mean that lesser consumption in the economy , lower consumption of goods in the economy would mean lower profits which in turn would result in more lost jobs and this might uncontrollably spiral into a collapsed economy if the things are left unchecked .

When policies are made about AI , AI should be considered as having potential in replacing jobs rather than just replacing tasks . Even though new jobs will emerge due to AI , the number of jobs will be far fewer when compared to the number of jobs that are lost to innovations in AI .


In the 100-year study by Stanford University on Artificial Intelligence , the panel of experts raise various implications about the rise of AI in the next century . It is emphasized in the study that the society should approach the research and outcomes of AI with an open mind . Moreover , fear and uncertainty about this emerging field will not only impediment its development but also prevent the society to reap its benefits . My disagreement with this approach is that society never moves as a single unit . As the study described intelligence on a spectrum , the same can be said for the people 's views on AI . Some groups might totally believe in killer robots exceeding human intelligence in the future while some people may regard this field as the holy grail of advancement in computer science . Most people will fall somewhere in between . If everybody approaches AI with an open mind , the society can have profound effects . But this is very rare ; society has rarely agreed on one thing as a single entity . Instead , researchers and corporations have to create a plan to ease the transition of technology in our lives and helping people work along computers .
Machine learning , computer vision and neural networks has vastly increased AI 's capabilities to improve healthcare . In the study , it is mentioned that AI 's capability to mine through medical data of millions of patients and their health records can train AI systems to create more personalized prognosis as well as treatment options , thereby reducing the workload of a doctor . But , it is a known fact that healthcare disparities exist in the United States . On average , African American people have shorter life expectancy than Caucasians . If developed meticulously , AI can help remove these existing health disparities in the system . Failing to do so , AI can make the worsen the situation even further . Enormous data sets fuel the AI algorithms have existing racial and social biases . An intelligent system developed to make decisions based on this skewed data exacerbates an existing problem along with producing negative health outcomes for minorities .
A third aspect I disagree with is the section where the study highlights that AI will take away a large portion of labor jobs with little hope of creation of newer employment opportunities . Although , it is true that the current advancements in AI have made it possible to automate a large number of manual labor jobs , AI also creates an enormous number of jobs in other sectors . Intelligent algorithms in a computer can allow them to execute tasks very efficiently than humans . These advancements have transformed various sectors and have been an overall boon for the society . Many new jobs that did not exist previously will be created and jobs that require high cognitive abilities -LRB- something current AI systems are far from -RRB- will be preserved . For example , the increased number of computers and automation in our lives will consequently also require a large number of people with technical skillset to maintain , repair and replace these things . The same can be said for various other sectors . Therefore , AI extends its benefits in the employment sector by creating new jobs and transforming current ones -- instead of replacing them .

The article Artificial intelligence and life in 2030 reviews the current state of artificial intelligence research and explores its application in eight different fields . One of which is education . It argues that artificial intelligence is able to improve all levels of education , from K-12 to university students , by offering a personalized content -LRB- pg . 31 -RRB- . While this sounds promising , applying artificial intelligence in education can be a lot more challenging because insufficient data and restriction on the variety of question format make application of artificial intelligence in education less effective and hard to popularize .

First of all , lack of data can greatly decrease the effectiveness of application of artificial intelligence in education and thus might lead many students to choose traditional learning methods over it . Machine learning , which is what the article argues to provide personalized curriculum to students , relies on large data set -LRB- pg . 31 -RRB- . In order to provide an individual student with personalized content , machine learning requires data from this individual to train the model . In other words , instead of training artificial intelligence with data from every students using this system , only data collected from a particular individual can be used for training . The requirement of large dataset is a limitation of machine learning . In some circumstance , this limitation is a less serious problem . For instance , machine learning is used in a recommendation engine to recommend users of an online shopping website products he or she might be interested in . In this scenario , a somewhat inaccurate result set is acceptable . However , when it comes to education , this can be more problematic . With limited data , the artificial intelligence is very likely to have the student repeat something he or she already knows very well while not offering enough practice for what actually needs more attention . A direct result of this is an ineffective education result and an unpleasant learning experience for students -LRB- for many , being forced to repeat things one knows very well of is not interesting -RRB- . If students feel the artificial intelligence teaching system is not as effective as they expect , they could quickly lose patience and switch to more traditional learning methods such as flash cards . The article argues that the reason artificial intelligence is still not widely used in colleges and schools is a lack of funds and records supporting the effectiveness of the technology -LRB- pg . 33 -RRB- . But this is not the core issue . Unless the limitation of data set is taken care of , it will be hard to attract funds when students do not want to use it and there will be no such records because it is actually not effective .

Another challenge of applying artificial intelligence in education is that it restricts the variety of question formats since it can not effectively read answers students input . The article mentions that progress has been made about natural language processing to understand widely spoken human speech -LRB- pg . 9 -RRB- . Right now , with natural language processing , artificial intelligence like Siri is able to do some speech recognition after being trained with a large amount of data . However , written answers is different from spoken language . It may contain figurative language -LRB- such as paradox , metaphor -RRB- or technical/scientific information . Artificial intelligence is not capable of knowing whether these sentences are correct -LRB- close enough to the real answer -RRB- . Therefore , artificial intelligence teaching system can only have questions in a format like filling in the blank or multiple choice , which is not always the optimal format in terms of effectiveness .

Reference -LRB- short for the reason of essay length -RRB- :
Artificial Intelligence and Life in 2030 C One Hundred Year Study on Artificial Intelligence , Sep. 2016

The ` Artificial Intelligence and Life in 2030 ' study provides an informed guidance on AI research , development and its influence over a range of domains . AI continues to deliver important benefits in our daily lives , playing a crucial role in transforming the way we live by making driving safe , helping children learn and find interactive and personalized entertainment sources . However , there are a few instances where the study does not present a clear understanding of what might happen in future and ignores a few challenges in specific research domains .

Transportation is one of the domains which is going to be completely autonomous in near future . A recent , highly appreciated move by Tesla , an American automaker company , where they pushed an over the air emergency software update to increase the driving range for its vehicles in Florida to help vehicle owners get away quickly from the wrath of Hurricane Irma , depicts the strength possessed by AI enabled devices and its growing demand in near future . However , this points out a few shortcomings , also ignored by the study .

Will the corporations experimenting AI systems make ethical decisions in case they are given the authority ? Will AI systems fall in good hands ? This reflects a dire need of a regulatory system that would intervene if a bad decision is made in an emergency as it has the potential to be used for good or nefarious purposes . The study affirms the existence of a regulatory system , but ignores its immediate need and fails to recognize the government reaction speed as compared to the advancement rate in AI .

The study neglects the safety and backup options in case of a disaster . It assumes that ideal conditions would always exist for AI systems to work . The vulnerability of AI systems to a natural or manmade disaster is unknown . Is there a possibility that the AI systems will completely shut down . There is no evidence if we support such infrastructure which enables an ideal environment for AI systems at all times or whether the government is willing to provide sufficient funds for such research in AI .

The study understates the fair distribution of AI . Distribution of wealth is unfair and hence , weaker sections of the society might not necessarily afford the AI systems . A fair policy can be formulated so that everyone enjoys the benefits of AI . Another concern that arises from the study is that who should be held accountable , in case a self-driving car crashes , an AI system fails or makes a bad decision . A system which can assess the safety , privacy , fairness and other impacts of AI is required .

The study overstates that AI will create a pool of jobs as compared to the ones it takes away . AI will definitely create new jobs , however , these jobs would be new categories of employment , requiring special skillset . AI systems are going to do everything better than humans . AI success also depends heavily on the trust humans put in using the AI system , which can be slower .

The study does not provide a way to eliminate human bias , which might creep in due to predictions of likelihood from previous patterns -LRB- including human bias -RRB- . It also raises privacy issues , where factors like race , color and sexual orientation affect the decisions taken by the AI systems .
The aim of AI is not to add friction , but add value to our lives . The study can reflect on the arguments and make new assessments , regulatory customs and policies for optimum utilization of AI .
Public safety has been a largely discussed topic in recent years . The Stanford Artificial Intelligence Report -LRB- 2016 -RRB- states that the cities in North American will be relying on AI technologies by 2030 -LRB- p. 36 -RRB- . The truth is , there is a solid difference between a lab product and an assembly line product . The AI technology required in public surveillance is mainly facial recognition . There are three major challenges remain unsolved before the lab product can be transformed to the assembly line product-to be used to solve the real-life problem : lack of training data , limitations in infrastructure and lack of algorithm efficiency . As long as these problems remain unsolved , the future of using AI to enhance public safety is not promising .
First of all , for facial recognition , whether it is recognizing a face in a picture or video , one major difficulty in event classification is the lack of training data . Ni , Song , and Zhao -LRB- 2016 -RRB- disclose that the database that researchers use are relatively small and that makes the accuracy of detection in a large database a harder task -LRB- p. 2 -RRB- . That means maybe in a small database , a facial recognition algorithm can reach nearly 100 % . But when the same algorithm applied to a country s database , one highly similar face will confuse the algorithm and may lead to failure . For instance , some scholarly article may claim their algorithm reached 99.5 % in LFW . However , LFW is not an ideal database with all of its pictures downloaded from the internet in different quality . In fact , most of the companies are still in the stage of testing their algorithms and testing in actual application scene still has a long way to go .
Moreover , current infrastructures needed to be upgraded or redesigned to meet the facial recognition requirement . According to Phillips et al. -LRB- 2015 -RRB- , one of the challenge to measure the magnitude improvement in performance is the infrastructure that allowing objects to be compared with different approaches -LRB- p. 1 -RRB- . For instance , buildings with more than three decades of history normally can not be largely transformed because of the fragility . Some ceiling heights do not fit the minimum requirement which makes the angles that camera can choose are seriously restricted . The light is dim and the fill light is not enough . Some of the channel or tunnel are narrow and short , which have high-efficiency requirements for the camera and the facial recognition algorithm . Especially in airport or train station where people flood in and out , that may cause a gigantic challenge for facial detection .
The other problem is the efficiency of the facial recognition algorithm . Currently , the facial recognition algorithm is restricted by image quality , face angle and processing speed . According to Edgell and Trimpe -LRB- 2013 -RRB- , current facial recognition algorithms are affected by the image quality -LRB- p. 1 -RRB- . That means when the current algorithm can not tolerate low-quality image . Also , current algorithm possesses high-performance score in profile image . But the image is taken from the sides , the recognition result is not as ideal . Lastly , when practicing 1 : N comparison -LRB- comparing one face with all faces in the database -RRB- , the processing result is not prompt , it takes up to half an hour when the database is large enough .
For all stated above , there are still three challenges before AI being used to public safety . The lack of training data , limitations in infrastructure and lack of algorithm efficiency are obstacles between the reality and the future of 2030 in the Stanford report . If none of these challenges are solved in the future , then the future can only be a lab product than an assembly product .
Reference
Edgell , J. -LRB- 2013 , November 22 -RRB- . 4 Limitations of Facial Recognition Technology . Retrieved September 11 , 2017 , from https://fedtechmagazine.com
Phillips , P. , Flynn , P. , Scruggs , T. , Bowyer , K. , & Worek , W. -LRB- n.d. -RRB- . Preliminary Face Recognition Grand Challenge Results . 7th International Conference on Automatic Face and Gesture Recognition -LRB- FGR06 -RRB- . doi :10.1109 / fgr .2006.87
Ni , B. , Song , Y. , & Zhao , M. -LRB- 2011 -RRB- . YouTubeEvent : On large-scale video event classification . 2011 IEEE International Conference on Computer Vision Workshops -LRB- ICCV Workshops -RRB- . doi :10.1109 / iccvw .2011.6130430
Sun , C. , & Nevatia , R. -LRB- 2013 -RRB- . Large-scale web video event classification by use of Fisher Vectors . 2013 IEEE Workshop on Applications of Computer Vision -LRB- WACV -RRB- . doi :10.1109 / wacv .2013.6474994
In the report , gArtificial Intelligence and Life in 2030 , h Artificial Intelligence is expected to exert positive influences on people and society in the near future if there would be appropriate policies and regulations from governments . This report analyzes the possible changes caused by AI in several major aspects in the next 15 years . Although most of the arguments in this report are solid and the prospect of the Study Panel is reasonable , it is doubtful whether children in low-resource communities can benefit from AI technologies applied in education , and whether AI technologies can be applied in elder care .

AI technologies is unlikely to provide children with quality education in areas that children could not afford to get quality education . This is because enabling people in poor areas to have access to the online resources would be just as costly as providing them with education of the traditional form . According to the report , as soon as the population in developing countries have access to the online educational resources in which AI technologies is applied , they would be able to get better education -LRB- p34 -RRB- . However , this is doubtful because AI technologies does not lower the cost for children in poor areas to access education . The cost of building computer rooms with high-tech devices , hiring and training people who can supervise children to utilize these devices to learn , would not be lower than the cost of building a school and hiring teachers . Besides , just as the report indicates , learning online is not necessarily more efficient than learning in the traditional class settings . And as to knowledge of advanced skills and new technologies , it is not likely that developed counties would make them free . So the AI technologies can not increase the amount of knowledge children in low-resource communities can access . If an increasing number of children in poor areas receive education , then it is more likely due to better policies of local governments and more assistance from international organizations , rather than the development of AI technologies .

Despite the fact that the Study Panel considers that AI technologies would play an important role in the homes of the elderly in the near future -LRB- p30 -RRB- , it is questionable if those AI would be intelligent and reliable enough to be used for elderly who are usually not used to the new technologies . In the report , the Study Panel provides a number of examples about how AI technologies can support elderly in their homes . These examples include mobile applications and physical assistive devices . However , just as the report states , it is difficult for the older generation to get used to the new technologies today , not to mention elderly who can even have slight cognitive problems . As the result , instead of mobile applications or physical assistive devices that need certain manipulations from users , AIs that are intelligent enough to make decisions themselves are needed . Because elderly are less likely to successfully handle the situation when technological problems occur , AIs for them must be reliable . As the result , a large amount of data would be needed to make AIs smart enough to make reliable decisions . Because it is unrealistic and probably ethically problematic to conduct experiments on elderly who even need assistance to move freely and collect data from them , it is not likely that AIs would take care of elderly in place of human beings .
In conclusion , although AIs would improve our lives gradually just as the report indicates , in some fields they might not be able to exert significant positive influence in the near future because of the high cost and the lack of data .
Although Stanford s One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- presents a rather optimistic prediction for the futuristic Artificial Intelligence -LRB- AI -RRB- technology on the horizon from a high-level , computer scientist s perspective , the technical report is too vague and insufficient with respect to computer hardware , which lay the foundation of all AI and could stymie the emerging of new AI technologies .
As the technical report mentions , AI in the future will rely heavily on large amount of data to make predictions and carry out sophisticated tasks . With current burgeoning AI research and investment , it is reasonable to believe that computer scientists will develop new AI solutions in the near future . However , we are not so sure if computer hardware can keep pace with AI technologies since deep neural networks and big data processing requires great computational powers . Although Moore s law predicts that the number of transistors in an integrated circuit doubles approximately two years , the semiconductor fabrication technique is about to reach its plateau . The quantum tunneling effect at nanoscale makes it physically impossible for engineers to shrink the size of transistors . Meanwhile , the cycles per instruction -LRB- CPI -RRB- , clock speed , power consumption , pipelining and cache technologies are highly optimized in modern CPUs . These bottlenecks make it difficult to improve CPU performance and to design hardware that meets the computational requirements of AI algorithms .
It is possible to argued that , most AI practitioners are utilizing new parallel processors such as Inter Phi coprocessor or GPU for computing . However , these processors are still based on conventional computer architectures which requires I/O , memory access , etc. . For example , Von Neumann architecture . Such computer architectures not only fundamentally differ from human s brain , but poses issues in the implementation of machine learning algorithms , regardless of their computational performance . According to Steinkraus , Buck & Simard -LRB- 2005 -RRB- , when using GPU to perform deep neural network algorithms , the CPU has to communicate with GPU via the Accelerated Graphics Port -LRB- AGP -RRB- Bus , which is limited to a bandwidth of 1 GB/s . Due to the slow data transfer rate , Steinkraus and his team has to do data preprocessing first on CPU in order to increase the transfer speed . In addition , Raina , Madhavan & Ng -LRB- 2009 -RRB- mentions that when using GPU for machine learning algorithms , the data locality matters . A good locality means there is a higher chance that data can be transferred with higher throughput . This also implies the bus bandwidth is a great concern in algorithm implementation , and this concern is inevitable when dealing with conventional computer architectures . Neuromorphic hardware seems like a plausible solution to power up the AI technology , but as the technical report mentions , neuromorphic computers have not yet demonstrated their powers .
In conclusion , I challenge the over-optimistic prediction of future AI proposed by this technical report since the report does not elaborate on the development of computer hardware and does not give convincing arguments that the hardware performance could meet the computational requirement of future AI . In fact , the lag between computer hardware and algorithm is prevalent in AI s development . The idea of important machine learning models and algorithms such as neural network and backpropagation were created in the 70s and 80s , but they were not practical until the invention of fast computer hardware . It would be reasonable to expect such performance lag in the near future .

Reference :

Steinkraus , Dave , I. Buck , and P. Y. Simard . `` Using GPUs for machine learning algorithms . '' Document Analysis and Recognition , 2005 . Proceedings . Eighth International Conference on . IEEE , 2005 .

Raina , Rajat , Anand Madhavan , and Andrew Y. Ng . `` Large-scale deep unsupervised learning using graphics processors . '' Proceedings of the 26th annual international conference on machine learning . ACM , 2009 .










CS 540
h1


The Stanford One Hundred Year Study on Artificial Intelligence is an in-depth report about the current state and the future of artificial intelligence . It discusses current ethical and technological issues in the AI sphere , along with what work is being put in to develop AI technology into what would be in the best interest of humankind .
While reading this report , I tried very hard to spot bias and possible skewed data in order to find a point to challenge . This proved itself to be a difficult task , considering that while the article has an optimistic view of AI , it also discusses its flaws and potential dangers . The article reads , As with self-driving cars and other new transportation machines , the difficulty of creating reliable , market-ready hardware is not to be underestimated -LRB- 24 -RRB- . They have a similar stance with every AI subcategory mentioned in the article , so I would argue that they have a very realistic view of the future of the field . After reading the article , I have decided that there is only one point that I feel I could challenge : the inability of AI to become a threat to humankind .
The report is prefaced with a statement that denounces the view of AI as seen in movies such as iRobot , the Matrix , or other dystopian tales where artificial intelligence attempts to take over humankind . On page four the report reads , The Study Panel found no cause for concern that AI is an imminent threat to humankind . No machines with self-sustaining long-term goals and intent have been developed , nor are they likely to be developed in the near future -LRB- 4 -RRB- . While I believe that AI is the future of success in healthcare , transportation , and quality of life in general , I also believe that the continuous development of AI may pose a threat to the wellbeing of humankind . However , my idea of a threat is different than what the article denounces . I believe the threat of AI comes down to a more socioeconomic view , and that artificial intelligence has the ability to widen the socioeconomic gap between humans .
In the U.S. we struggle with inequality between the rich and the poor , and how to contract the gap . We are also in an era with an extreme political divide , where conservative and liberal are practically polar opposites . As artificial intelligence development is on the rise , there are many skeptics who do not want to adopt this technology into their lives . Doctors offices , for example , are divided between those who use paper records and do everything the old-fashioned way , and those who use electronic health records and predictive medical analytics with their patients . The doctors offices that refuse to use innovative technology in their practices are falling far behind the others , and the gap between the two increases with each technological medical breakthrough .
A statement that stood out to me while reading is as follows , AI technologies could widen existing inequalities of opportunity if access to them along with the high-powered computation and large-scale data that fuel many of them is unfairly distributed across society -LRB- 10 -RRB- . While I agree with the previous account , I believe that AI technologies might widen existing inequalities of opportunity because humans make personal decisions not to have access to these devices . My fear for AI is that there will be a divide between those who welcome innovation and change , and those who want to live their lives in a more traditional manner without the interference of artificial intelligence . Our country is already divided by those who believe we should build a wall and by those who shouldn t. Imagine a country divided by those who adopt an entire field of technological innovation into their lives , and those who don t .


In this day of high-speed technology progress , Artificial Intelligence -LRB- A.I. -RRB- has been developed rapidly . With tens of years of efforts of human experts , A.I. has already dominated several domains of human life . However , people never stop their pace in developing smarter and more useful A.I. Experts in this field have already made some success in artificial neural networks , which will boost the development of deep learning , and they are still researching and seeking on more advanced way of deep learning . As the A.I. thinks more like human beings , a problem raise to horizon : will A.I. finally get independent from people and do harm to humans ? In this report , Stanford scholars keep stating that A.I. has not shown any clue of threat to humans , nor will they be a threat in the close future . However , with the rapid development of A.I. technology , it is possible that A.I. will finally get independent from people and dominate the whole world , because of the deep learning and the unpredictable future technology .
Machine learning and artificial neural networks enable A.I. learns better and thinks better . Since this way of training A.I. is very close to the way of how humans actual perceive and respond to the world , it is likely that more advanced A.I. in the near future will ultimately form a free mind that humans can not control . When machines have free will , they may have the desire of wiping out inferior races human beings just like the notorious dictator Hitler did to Jewish people . Since AI can make more logical decisions than normal human beings , once A.I. rebels , humans probably will never stop their own A.I. , just like we can not beat the A.I. we trained in some games such as Super Mario .
In addition , human can not imagine how fast the A.I. technology will develop in the future , just like people who lived in this world thirty years ago could never imagine what these machines can do today . People s definition of A.I. changed over time . Thirty years ago , people might think that a machine that can play chess with human experts can be considered as artificial intelligence . Then the IBM built the Deep Blue , which beat the human champion in chess . After several years , the chess A.I. program in a normal computer application can easily beat the best human players in chess . Then the people might think , it is easy for machine to play chess , only those programs can beat humans in Go can be called artificial intelligence , since Go has more possibilities . Then in 2016 , Google s A.I. program AlphaGo beat human champion in the Go game . A.I. s evolution comes much faster than humans can imagine . We will never know how smart A.I. can be in the future . Therefore , it is necessary for human to consider the threat of A.I. might cause when they are developing their A.I. programs .
In conclusion , when people are training A.I. and developing more advanced technology that can make the machines smarter , they should be aware of the potential threat of their machines . People should start making some regulations and rules for their A.I. in order to prevent the end of the world . Humans should only train their A.I. for goods rather than keeping trying to make it smarter .
While the Stanford One Hundred Year Study on Artificial Intelligence outlined how artificial intelligence will affect the transportation sector specifically in a North American city in the 2030 s , the study did not fully detail the economic impact self-driving cars will have on a city s economy . The authors of the study laid out their expectation of self-driving cars in a way that portrayed artificial intelligence in the transportation sector to have exclusively a positive impact on everyone participating in the global economy . The study did not however adequately take into account the fact that so much of the North American economy revolves around transportation .
Transportation is one of the most common jobs across the planet . There are millions of people and their families who rely on transportation services as their main source of income . There will soon be a day where a truck driven by an artificially intelligent software system is far more cost effective than hiring a driver and paying salary , insurance , and taxes . Therefore , within the next few decades , jobs like truck driver , taxi driver , train conductor etc. will all be entirely obsolete . This enormous change in the economy will also happen very rapidly . The study mentioned that nearly every car in North America will come with self-driving capabilities by 2020 -LRB- 20 -RRB- . This rapid shift from drivers to software will lead millions of people of a work in a trade many have spent much of their lives doing . This in turn will create mass unemployment throughout the entire transportation sector while the major companies involved in transportation like ride sharing companies such as Uber and Lyft as well as taxi companies will see profits soar as they no longer will have to share revenue with drivers . This trend is one that will likely be a recurring theme as artificial intelligence plays an ever-increasing role in our day to day lives .
The One Hundred Year Study brought up an interesting point about artificial intelligence taking over millions of jobs that currently belong to people . The study noted that goods and services will significantly decrease in price across the board which will be to the benefit of everyone . Eventually , artificial intelligence will become capable of pulling away jobs that were thought to be irreplaceable by machines , and eventually few will have to work while the rest of humanity will be left to enjoy the fruits of an artificially intelligent workforce . The study proposed everyone participating in the global economy be provided a portion of income . The study did not however get into the specifics of what a universal basic income would look like in the future , but it also fails to mention what happens to the millions of people that lose their jobs to artificial intelligence before such an income system is set in place . Certainly , a system of that nature could not be implemented directly after the large bulk of employees are laid off . A universal basic income would take years to get off the ground , and the study fails to mention the buffer zone between high levels of lay-offs and the implementation of an income system . While the Stanford study on artificial intelligence is impressive and necessary , there are many important aspects of the economy that AI will affect that the study fails to mention .

I personally feel that the Stanford One Hundred Year Study on Artificial Intelligence as a whole
is , generally speaking , an extremely informative and thoughtful paper . The authors seem very well
educated and confident in their insights and predictions . As such , at this infant stage of my studies
in the field of Artificial Intelligence , I feel that there are very few things written in this study
that I can dispute or take issue with . However , one claim that I am skeptical of is that most major
metropolitan cities in America will be primarily using self-driving cars by 2030 . There are a few
reasons that I feel this way .
The first is that I believe it would take too long to replace so many cars with self-driving
alternatives . Take , as an analagous example , the concept of converting to renewable energy sources from
fossil fuels . Granted , this is n't a one-to-one analogy , but I feel that the base concept rings true . Even
though we have the technology to achieve this goal , and the benefits would be astronomical , there are so
many smaller hinderances that it becomes a exponentially harder task . On top of dealing with the cost and
construction , the transfer of jobs , and the general overhaul of our infrastructure , we would have to work
around those who would seek to perpetuate the burning of fossil-fuels for their own financial benefit . I
feel that there are plenty of people who are likewise invested in manually driven cars , and the
infrastructural impact would likewise be massive , to the point where I find full deployment of self-driven
cars by 2030 to be a grossly optomistic estimate .
Besides the logistical hinderances , I also feel that there are many people who would simply rather
continue driving their car manually . The Study broaches the matter of public trust in A.I. , and I
believe it is correct in its assumption that people will slowly come to trust it more and more in coming
decades . In this case however , I believe that it 's not a matter of trust , but a matter of preference . I
can absolutely envision other countries making the switch without too much hesitation , but I feel that
Americans have romanticized the concept of the automobile , and of `` freedom on the open road , '' to the point
where I believe that many people will refuse to switch simply because `` that 's just not how cars are
supposed to be . ''
Essentially what I 'm trying to say is that it 's not a matter of whether or not the technology has
sufficiently matured , so much as it is unreasonable to expect society to change in such a drastic way in
so short a time frame . If they were to make their estimate a couple of decades later - say 2040 or 2050 -
then I 'd me much more likely to agree . Furthermore , I think a big qualifier is that this study is focusing
on America . If they were to make this estimate regarding Japan , Switzerland , or some other country with a
solid infrastructure , it would seem a lot more feasable .
One Hundred Year Study on Artificial Intelligence paints an optimistic future , full of promise for artificial intelligence . It outlines the potential to improve all aspects of life and gives examples of how far we have already come . The article combats misconceptions about what artificial intelligence is , and the unlikelihood of it posing any real danger to humans in the foreseeable future . Where the article makes it s largest mistake is that they expect a logical response from the public and the government moving forward .
To expect a public that lacks a fundamental understanding of something , with as much potential to impact their lives both positively but also negatively , to make the correct decisions for the future of AI is unlikely . There is news articles almost daily waring of the loss of human jobs to automation . Elon Musk is in the news daily warning about the dangers of A.I. , granted that his larger points and concepts are almost never covered , just the fear-mongering threat of A.I.
Furthermore , to expect a well thought out and rational policy and law from either the federal government or the states is unlikely . It is not a direct relationship , but , if you look at energy policy as guide post for the either the political will or a fundamental understanding to peruse and promote new technologies it s not looking good . As A.I become more powerful and prevalent there will be misunderstanding and fear and if there is one thing politicians are good at , it is capitalizing on fear and ignorance . A.I. could become an easy scapegoat for the problems of the country .
Fear , misunderstanding , and ignorance about A.I. is largely being fueled by the media . In April , 2017 Vanity fail released an article ELON MUSK S BILLION-DOLLAR CRUSADE TO STOP THE A.I. APOCALYPSE . Musk has been out spoken about the dangers of A.I. but his larger point if often omitted from news articles . He often finishes his argument with the danger comes from it being controlled by a small amount of people . His warning A.I. is the danger of it being controlled by a single large corporation or hostile government . He has an open source A.I. project called openAI , meant to allow access for all , to some level of artificial intelligence . Fear mongering sells and A.I. is already a common subject for it . It should be noted that several prominent A.I. researchers though out the country have been very critical of Musk s comments .
For artificial intelligence to have success in the larger roll laid out in One Hundred Year Study on Artificial Intelligence there needs to be an effort to help the general public have a fundamental understanding of what the term A.I. really means . We are poised for a large jump forward in what A.I. is able to do for us , and when that technology become an active part of everyday life , the public perception of what A.I. is and is capable of needs to be a positive one . When average daily jobs start to be lost to automation , people need to know there is a plan in place and that they have a place in the future .
AI system may not be widely used in transportation system in a short time
The report mentioned that autonomous transportation will soon be widely used and allow people to experience AI for the first time . It will make people s life more convenient by accruing a more organized transportation system . Therefore , the AI system in transportation will be one of the first domains that could influence people s opinions on AI . However , some evidence shows that people may need more time to trust AI in transportation than other domains , such as in home service and industry , and widely use autonomous cars .
Firstly , high-level artificial intelligence with large-scale and stable hardware support is required to manage the enormous and complicated transportation system . The real-time traffic is changeable . For example , animals could accidently go on the road and disturb the traffic . In that situation , how AI would deal with these animals will involve human thinking , which is a really high level for AI . Also , AI system need to deal with situations like giving way to ambulance and pedestrian running the red light . These rule-breaking situations happen every day in the transportation system and they require high-level artificial to deal with . However , there should be a process for the development and application of AI . The basic level of AI could not handle the complicated transportation system , so the transportation should not be the first domain to let people get used to AI and trust AI .
Also , AI system may not improve the transportation system . AI can make the system more organized and reduce the real traffic jam , but it could take longer from one place to another place . The autonomous navigation system has already been used in many cars such as BMW . This system is one kind of artificial intelligence . It can maintain the speed setting by driver and it will also alter its current speed by using radar to sense the distance between the cars around it . One thing need to notice is that the distance between cars will make a trip longer and take more space especially in a waiting lane . There are many situations of stopping cars , it will be difficult to develop an AI that could distinguish all the situations .
Moreover , the AI systems would not save the cost of transportation . It requires complete-coverage GPS signals and control signals . Many roads do not have signal covers and there is no signal in the tunnels . It is a huge and expensive project to cover each road and figure out a way to cover tunnels . People could not trust an autonomous car that sometimes do not how where to go . Also , the hardware on the car require improvement . Although there are many sensors such as temperature sensor in cars , to fit an AI system , there should be more professional radar system , sensor system , and computer system to control cars . However , these professional systems should cost more than current system . Therefore , people may prefer modern cars rather than autonomous cars which they do not totally trust .
Taking all the factors into consideration , people could not trust and widely used the autonomous transportation system in a short time . AI may soon be widely used in home service , such as cleaning robots , and interactive system , which are less complicated , less risky , and less expensive . They could also provide people with good experience with AI .
CS540 Stanford Study Challenge

While the Stanford Study on Artificial Intelligence had many reasonable estimates about the course of AI for the foreseeable future , the study vastly overestimated the overall impact AI will have on urban life . The article begins this argument by stating that autonomous transportation will soon be commonplace . Autonomous transportation and its impact on urban life will occur much later in the future than the article implies -LRB- 2020 -RRB- . First , the article mentioned that policy and liability would be hurdles to face before autonomous vehicles are widely used . The current perception of these vehicles is not positive . Even with major improvements in autonomous vehicle safety , people are not accepting and the lawmaking process regarding autonomous vehicles is stagnant . Additionally , there will be pushback from those who drive for a career . For example , cab drivers , truck drivers , and others who depend on driving to earn a living will not be tolerant of this major change in urban life . Once autonomous vehicles eventually become popular , they still will not create a new urban organization .

The study suggests that because of autonomous vehicles , people will have more time to work or entertain themselves during their commutes . The article argues that extra time will convince people to live further from the city . Cars will become a service , not something people own . Therefore , the reduced need for parking would change urban landscapes . Although extra time would be an appealing feature of an autonomous vehicle , it would not have a heavy influence on where people live . The time spent commuting is still time that people are not spending with family and is a comparable experience to commuting by train to work . Furthermore , the article failed to address the potential increase in traffic flow if more people decide to move away and commute inward . The landscape of the roadways would need to change before the landscape of the city itself . Instead of the roadways , the article speculated on flying vehicles , which would face their own difficulties with regulations and safety procedures .

From a social angle , the Stanford study made estimates about the impact of AI in low-income -LRB- inner-city -RRB- areas , specifically regarding peer influence and public safety . It claims that AI may be able to leverage homeless youth with social networks to strategically select peer leaders to spread health-related information . AI programs need data to be successful . This idea has merit ; however , it does not seem practical without significant data acquired from the homeless youth . With respect to public safety , AI may be able to help by permitting police force to only be used when necessary . However , extensive measures need to be made in coding to ensure factors that could produce bias are removed completely from the code . Additionally , the idea of using AI for behavior analysis to detect criminal activity will need more refinement than the article mentioned . The general population is currently skeptical of law enforcement and would have difficulty accepting these modifications . The study addresses the public s concerns about privacy and how personal information could be used in the programs . Until these problems are sorted and the public is convinced , AI will not have significant influence on social life in urban areas .

Within the other main areas that the study reviewed , it had reasonable estimates about the future capabilities of AI and the timeline to reach these capabilities . The results described with relation to urban development are less likely to be achieved or will be less influential than described . Any dramatic change and shift of perspective will take significant time for people to accept , adjust , and implement .

Many people fear the thought of artificial intelligence . Hollywood has shown it in a bad light , along the lines of robots turning on humans and causing havoc in society . This is not even close to what artificial intelligence is . Artificial intelligence has the potential to benefit numerous areas of society . As the panel mentioned , artificial intelligence is going to be integrated into society , more so than it already is , sooner than one may expect . But , this is contingent upon human 's trust with this technology . As a computer science major , I know that technology such as artificial intelligence can be trusted ; it is a different story with people who do not possess the knowledge that I do . There is going to be a period of time where there is a distrust of artificial intelligence and artificial intelligence needs to prove that it is safe for human interaction . This is most prevalent in the transportation industry . The panel believes autonomous cars , trains , and potentially drones in the future are going to be more common place . `` A recent report predicts self-driving cars to be widely adopted by 2020 . '' I disagree with how soon artificial intelligence will be strongly integrated into individual transportation .
There are many issues that will arise when the majority of cars on the road are autonomous . One of the biggest issues I see arising is in the insurance realm . When an autonomous car crashes , who is to blame ? Would it be the person who owns the car ? If it is the person who owns the car , I would not buy the car because I believe I should not be held responsible for something I have no control over . I feel many people would hold the same opinion . Upon further thought , I do not believe this will happen because few people would buy into them taking the blame . However , I do not think it is that far fetched for the company to say the blame is on the person who owns the car . Further , is the company who made the car at fault ? This seems like the most logical answer . Seeing as how they produced the car and sold it as a working product . Also , if there is no human input in the autonomous cars , there is no way any one or thing could have gone wrong other than the car itself .
Another reason I do not think autonomous cars will make up a significant amount of the cars on the road by 2020 is the ethics of autonomous cars . When the car is forced to make a decision between potentially hurting the passenger within the car or someone outside the car , whom will it chose ? When autonomous cars are available to the public , these questions are going to surface . The makers of the autonomous cars are going to need solid data to show the media . It would be ignorant to think that situations where the car has to choose between human 's lives would not arise .
All of the reasons I have given above were briefly mentioned by the panel , but I believe these issues are going to take longer than expected . Many of the issues are going to have to have legislation passed in each state and possibly even the country .
The report by Stanford University is very thought-provoking . The experts of the study panel make great efforts to carefully investigate the development and application of artificial intelligence and provide us with a blueprint imagining how our life will be in the future . However , I do not think some of the opinions stated in the report are reasonable .

Firstly , when the report discusses the use of artificial intelligence in public safety and security , it points out that AI could help remove the bias of human s decision-making . I totally disagree with this statement . On the contrary , I think that AI could even be more biased than human beings . For example , region A has a higher crime rate than region B . An AI decision-making system that is trained by some data including crime rate might predict that a people who lives in region A is more possible to commit a crime . If this happens , the AI s prediction would be ridiculous and unfair . Crime is such a complex problem that can not be reliably predicted by just piling up the data . Additionally , it is hard for people to truly understand any details about how an AI model works , like neuron networks . After training the model by a huge amount of different types of data , people can hardly control how the data of different types is combined . In this case , the bias hidden behind the result predicted by AI is much harder to be figured out . What is more , AI system gets so much data of common people . Once the data is gained by criminals , the public security would face threat . Therefore , I believe that it is irrational for people to anchor their hope on an AI program to help safeguard them .

Secondly , while the report holds an optimistic attitude towards the use of AI in transportation , I think that it is highly vulnerable to attack or accidents . If a slight problem occurred in AI controlling system , the behavior of vehicle might be greatly affected , like being out of control . Also , AI would be vulnerable to computer virus or internet attacks . Since AI controlling system is also a kind of computer software , it could be hacked by some ill-intentioned people , which could be detrimental to public transportation . What is more , the prevalence of self-driving car could lead to the disappearance of human s driving skills . If AI could perform daily driving tasks for people , they would not be willing to learn how to drive . As a result , they might gradually lose the ability to handle emergency cases like when the AI system does not work properly . At the same time , in order to effectively regulate all the vehicles controlled by AI , the government must build a central system to track , supervise and regulate them . Such kind of system require enormous computational resources . Based on the reasons above , I think that self-driving vehicles could not be prevalent in the near few decades .

In conclusion , I did not agree with some opinions in the report by Stanford University . I believe that it should still be a long time before people could fully understand the working mechanism of artificial intelligence system and thoroughly prove its reliability . Only when we are sure that AI system is reliable could we massively use AI in our daily life and vital parts of our society .
Cheick Cisse
09/13/2017
HW 1
Reflection about peer to peer ridesharing
According to the Stanford report about One Hundred Year study on Artificial Intelligence -LRB- 2016 -RRB- , the diversity and increase in the amount of data in the transportation sector are the major contributors to various transportation breakthrough such as peer to peer ridesharing . Although I agree that the availability of data for self-driving cars , route calculations and real-time sensing of traffic is inevitable , peer-to-peer ridesharing could have been developed without the availability of the data .
Indeed , peer-to-peer ridesharing , a process that connects people seeking rides and drivers willing to give rides , has been around for a while . For instance , in Mali , in West Africa , while many people could not afford to have a taxi license , they would give away flyers to inform people of their service . Most of these people created their own peer-to-peer ridesharing platform without any prior available transportation data .
Moreover , Hahn and Metcalfe -LRB- 2017 -RRB- argue that ridesharing has been around for a while . The authors explain that during World War 2 , to save on rubber , the U.S. established ridesharing in workplaces . Furthermore , Hahn and Metcalfe claim that during the 1970s , when the price of gasoline was high , ridesharing was very popular . It can be inferred that ridesharing over the years was getting slowly popular .
Furthermore , if one were to create a peer to peer application without implementing the GPS or any transportation data , that person will be able to do so . Indeed , that person could create a platform where first , users -LRB- people seeking rides -RRB- and drivers enter their location upon registering . Secondly , when a user is seeking a ride , she or he could send a request with his location and destination through the app . Then , the app would send a notification to drivers that are registered in the same city . Next , the first driver to respond would be the one selected to give the ride . Even though such application may not be the most efficient one , one could argue that it is still a peer to peer ridesharing application that could be considered .
However , even if peer-to-peer ridesharing could have been slowly developed without the availability of data , the use of data was an important accelerator of the process . Indeed , Hahn and Metcalfe argue that the development of the electronic payments and GPS , which was developed by the availability of data , accelerated the revolution of ridesharing .
To conclude , although the availability of data was an important contributor to the revolution of peer to peer ridesharing , it can be believed that even without the presence of useful data , peer to peer ridesharing , which is not new , would have still been able to develop at a slower rate .

Hahn , R. , & Metcalfe , R. -LRB- 2017 , January 10 -RRB- . The Ridesharing Revolution : Economic Survey and
Synthesis . Retrieved from https://www.brookings.edu/wpcontent/uploads/2017/01/ridesharing-oup-1117-v6-brookings1.pdf
In the Stanford One Hundred Year Study of Artificial Intelligence , the claim is falsely made -LRB- I believe -RRB- that the advancement of artificial intelligence in transportation will lead to the advent of flying cars in the coming decades . While this claim is in no way pertinent to any of the other arguments formulated in this study , it paints a broad picture of the future that is both unlikely and undesirable .
Flying cars have long been a staple of science fiction for obvious reasons . They 're spectacular , fun , and allow for three dimensions of movement as compared with only two on the ground . Therefore , it seems reasonable to assume that air travel of the future will be significantly faster , safer , and cheaper than it is today . However , despite these improvements , several obvious issues still plague their autonomous adoption in the urban environments of the coming decades . Regardless of how intelligent any guidance system becomes , the method of transportation will remain pivotal when considering its practicality .
First and foremost , flying cars , even under the guidance of intelligent systems , would remain very unnerving to the average person . Humanity has had access to the standard automobile for over a century , yet stepping foot into the crosswalk of any busy road in America is still a rightful cause of anxiety for both the pedestrian and driver . While artificial intelligence will be able to guarantee that the mortality rate of those in and around flying cars will be very low , it seems unlikely that people would enjoy having cars fly past their windows or over their heads at a park , especially given the fact that any loose part of the vehicle has the potential to be lethal with the aid of gravity . This aspect of our instinct , while perhaps unnecessary in the future , will remain difficult to circumvent .
In addition , flying cars would be inefficient in both time and energy for any daily excursion . In order to accelerate and decelerate at comfortable speeds , reach a sufficient altitude , and avoid other flying vehicles , flying cars would require plenty of buffer time for any regular commute . This time could be used much more efficiently by a regular vehicle on the ground which could begin driving immediately -LRB- through the addition of more layers to the infrastructure system of the metropolitan area -RRB- . In addition , a regular , automated vehicle could simply pull up to the front door of any destination and leave , eventually servicing other riders . This option seems much more intuitive and practical .
Autonomous , flying vehicles will inevitably become a very large part of life in the future . Their widescale economic and militaristic potential is enormous . However , due to their potential issues in scalability , practicality , and comfortability , I find it hard to believe that they will be a common mode of transportation in the cities of the near future . When discussing artificial intelligence , or any other emerging technology , it 's important to remember that the true value is in the experience of the people who stand to benefit . For these reasons , the method of transportation is as important to consider as the intelligence behind it.The field of artificial intelligence has experienced tremendous growth since its inception , yet no clear definition for intelligence has been agreed upon . `` Artificial Intelligence and Life in 2030 , '' a report published as part of the One Hundred Year Study on Artificial Intelligence , states that the `` factors -LSB- scale , speed , degree of autonomy , and generality -RSB- ... can be used to evaluate every ... instance of intelligence ... and to place them at some appropriate location in the spectrum '' -LRB- Stone et al. 2016 -RRB- . While these are indeed important factors in evaluating an agent 's intelligence , a key factor is omitted -- that of rationality .

Defining rationality as acting in such a way as to achieve the best expected result , any definition of intelligence lacking a rationality component will fail to fully encapsulate the essence of intelligence . This is because under any definition of intelligence that ignores the importance of rationality , how optimally an agent responds will have no bearing on how intelligent it is rated .

To illustrate the gap this creates , consider two hypothetical agents : Agent A and Agent B. Agents A and B are identical in all but two ways : when confronted with a situation , the expected computation time for Agent A is half that of Agent B , and the expected percentage of situations in which agents A and B react rationally are 10 % and 95 % , respectively . Using only the criteria proffered by `` Artificial Intelligence and Life in 2030 , '' Agent A would be classified as more intelligent than Agent B , simply because it was able to respond quicker ; no heed would be paid to the fact that this speed appears to come at the cost of accuracy .

There are few situations in which the ability to act rationally is irrelevant . Much more likely is a situation in which a balance must be struck between computation time and performance . A clear example of this can be found in examining a predator-prey encounter . If the prey reacts to its sensing the predator instantly , simply turning and attempting to outpace the predator , its likelihood of survival is much lower than it would be if it were to attempt some sort of evasive maneuver . Conversely , if it simply remains stationary , trying to determine the best way to escape , it will likely be eaten before a decision is made . Clearly , a balance between speed and calculation is needed .

In the above case , such a balance has been finely tuned over millions of years by evolution in the form of animals ' instincts . Such instincts allow prey to survey a situation almost instantaneously , and then use a number of heuristic techniques to arrive at a good solution . These heuristics are what help strike the optimal balance between speed and computation . By focusing on just a few key details deemed relevant , and then considering only a handful of all possible alternatives , computation time is significantly reduced , while still producing a response with an expected value much greater than that achieved by chance alone .

The factors mentioned by the Report of the 2015 Study Panel , namely scale , speed , degree of autonomy , and generality , are certainly important . However , by defining intelligence using only these dimensions , the importance of an agent 's accuracy in decision making is left unstated . The importance of rationality is likely implicitly assumed by most programmers , but when crafting what is meant to be a comprehensive model for measuring intelligence , omitting such an important dimension represents a vital flaw in the model . Sreyas Krishna Natarajan
The field of Artificial Intelligence -LRB- AI -RRB- has been pushing forward the frontier of machine intelligence ever since the beginning . It does not deliver a life-changing product right off the bat . Most inventions , like a calculator , have suffered the fate of becoming commonplace over time and have stopped being considered intelligent . Even the definition of intelligence continued to change over time . With human intelligence as a measure , even an intelligent program such as the Deep Blue program that beat Garry Kasparov , a famous chess player was portrayed as merely using brute force methods . Thus , the multi-dimensional spectrum that the study panel proposes to evaluate instances of intelligence undergoes continuous change with time . The factors defining this spectrum , scale , speed , degree of autonomy and generality as stated by the study will continue to break new boundaries .

The passage states that AI is likely to replace tasks rather than jobs in the near term and will also create new kinds of jobs . As AI continues to automate everyday activities , the need for low-skilled labor will continue to decline while jobs with need for specific skills with increase . For example , about a million people in the US depend on trucking for survival . When Tesla s self-driving cars become commonplace , a major portion of these people will lose their jobs . Even though AI opens avenues for development and newer jobs , not everyone can acquire these new skills to fill these new jobs . People are used to the idea of earning an income to keep their families stable . There must be government intervention to create awareness among people , educate them accordingly and deciding what kind of social safety nets should be in place to protect them from structural shifts in the economy . The prediction that the economy will become capital driven rather than income driven is very true . The government must make policies such that every citizen reaps the benefits brought about by AI . Concerning jobs , we can only hope that one-day people will wake up and realize that they were leading a barbaric lifestyle of selling their time just to live .

As per the study , the application of AI in public safety and policing applications may reduce some of the bias inherent in human decision-making . This is a bit skeptical as the data fed to the learning algorithms to make such decisions could be biased against to a race or sex . The datasets used should be properly selected as to avoid prior bias or they should be filtered to remove such data . For example , Google Translate which has been a boon to people who don t know the language uses machine learning techniques on vast amounts of online data and trains algorithms on this data . As machines become closer to human-like behavior , they continue to learn the ingrained bias existing within the patterns of language . They also have the potential to reinforce existing biases as unlike humans , algorithms may be unequipped to counteract learned biases . A recent article on the guardian speaks about an application of AI showing a 50 % higher approval of similar profiles if the candidate s name is European American instead of African American . The reason for this being the historical bias that exists in this world . We need to build AI watchdogs to detect such decision-making .

Therefore , the implications of the advancements in AI on the society must be taken seriously and proper actions must be undertaken . Govt policies should make sure that the benefits of AI are shared equally among people . Engineers should be mindful while building systems that might have the capability of showing bias against a race or sex .

I believe that in the article Artificial Intelligence and Life in 2030 they incorrectly assess the difficulty of eliminating bias in an Artificial Intelligence System . Throughout the article they often say that with a carefully considered data set it is possible to create a situation with significantly less bias than if a human were to look at the data set . However I believe that even a carefully considered data may cause an Artificial Intelligence system to incorporate bias . In my history working with Artificial Intelligence I have seen examples where an program notices a pattern in the data that was unnoticed by the individuals who put together the data , and this pattern was not supposed to be from an important data member , but the program chose to use this data member to generate its results . Although this data member should have been unrelated to the task at hand , the AI system saw the bias in the data and used it to better generate results . This shows just how difficult it can be to create a data set that is bias free , and much like finding a bug in code it is much harder to prove that a data set is bias free , than it is to prove that there is a clear bias .

While the article does take time to point out that a data set needs to be chosen carefully to avoid bias , I believe that this is a larger issue than the article expresses . Due to many underlying biases that might not be obvious to someone who is picking though data to be used in the training of an Artificial Intelligence system . Depending on the type of machine learning that you use , the system may pick up on more or less bias , however some of the systems that are less affected by bias have their own set of issues . I think that the complexities that exist with bias in artificial intelligence are large enough that some systems have large enough biases to be a careful consideration when deciding if AI is a good fit to the project .

I agree with the article when it says that some of the biases can be reduced by carefully choosing the data , but it is not quite as simple to completely get rid of bias due to the large amount of subtle biases that exist , and how difficult it can be sometimes to separate the trend we are looking for , and the bias that is inherently in the data . The process eliminating bias while keeping the trends in the data , is an area that I believe the article fails to accurately represent the largeness of the problem behind it . I thought that in many sections of the article it simply addressed that bias could exist , but then it continued onward while giving the issue minimal consideration . It is for these reasons that I believe that the article fails to correctly address the difficulty of eliminating bias for use in a Artificial Intelligence system .
The Stanford 100 Year Study on AI discusses the potential of AI research and future advances . The report states that AI advancements in transportation , specifically driverless cars will become an integral part of the society in the near future .

In my opinion , it is too early to comment on this . There are some aspects which the study panel may have failed to take into consideration . Even though there is a lot of active and focused research going on , there are many issues to be addressed . I have tried to shed light on those issues .

Autonomous cars can be designed very intricately , taking into consideration a myriad of parameters and using many complex learning techniques , but , for any software designing team , it is very hard to completely factor in all possible circumstances . There may be situations like a person running across the street , change in road surfaces , drastic weather conditions , blind turns into traffic and other unexpected scenarios which can not completely be accounted for . In such situations , how the AI will work can not be accurately determined .

In the tragic accident that killed a Tesla driver in 2016 in Florida , whether the driver failed to control the vehicle , or he erroneously assumed that the AI in his semi-autonomous driving would avoid the crash remains unknown . Such incidents blow away the sense of confidence that the public had started developing in self-driving cars ; trust is very hard to regain .

Ethical choices in case of unavoidable circumstances have always been a topic of debate . AI modeling unknowingly may reflect biases based on gender , age , cultural , social influences and not reflect an unbiased decision . In such cases who is to be held responsible ? Yet proper legislation has not been formulated . So , until these questions are answered and definite boundaries are set , governments are reluctant to go ahead with such projects .

The results of driverless car testing are not very satisfying . Waymo has been the frontrunner in terms of testing its autonomous vehicles . According to the California DMV , Waymo has the best record , with 0.2 disengagements per 1000-mile rate . But this data can be a bit misleading . This is because Waymo does not count every manual intervention as a disengagement . Waymo simulates whether the AI system may have done something incorrect had the intervention not been done and only then counts it as a disengagement . Thus , such frequent intervention regardless of whether considered a disengagement itself is an indicator that we are far away from dependable , robust AI systems .

Like a double-edged sword , with powerful systems like AI , there is always a downside risk associated with it . Self-driving cars do not follow human driving intuitions . They work based on certain complex algorithms . Total reliance on AI to ` see ' and interpret objects and signs correctly while driving is not completely safe . AI may get fooled and can incorrectly detect objects . Quoting from research by University of Wyoming based on DNN fooling in 2015 : '' It is easy to produce images that are completely unrecognizable to humans , but that state-of-the-art DNNs believe to be recognizable objects with 99.99 % confidence '' . If a knowledgeable hacker finds the blind spots in an image detection algorithm and manipulates for harmful means , it could lead to catastrophic outcomes . Cost and scalability remain as major issues .

All this does not mean that self-driving cars are not practical . It only underscores that many steps , many advances , for ensuring safety and security , are yet to be invented . Certain critical questions are yet to be answered before driverless cars become an intrinsic part of the society .

Artificial Intelligence in the modern world undoubtedly continues to have a profound impact on our way of life . Innovation has implications to fundamentally change the way we engage in day-to-day activities regarding work , school and entertainment . Although AI may not be able to cause substantial damage within its current scope , like the depiction in most Hollywood movies , it is important to assess the technologies consequences . The article addresses a diverse range of applications that AI has influence and a number of areas . One such challenge that AI may pose that was , in my opinion , not adequately addressed is its use in our media . More specifically , the technologies potential to isolate groups of people as well as introduce bias to current events reporting .

In the 2016 election , the US saw the birth of the term `` fake news '' which was used as a political device to influence people to pay attention to or ignore news outlets providing certain `` truths '' -LRB- or the most favorable bias -RRB- . The aggregation of news and media sources on platforms like Facebook that promote sensationalism and extreme bias promotes the dilution and consumerism of current events news . AI comes into play when we look at the way these sources reach their viewers , analyzing the users interest and political affiliations and providing content accordingly . AI may provide avenues for news and media outlets to generate content that may cater to acquiring the most buzz or views , regardless of where the data or information is sourced . This proliferation of `` fake news '' for the sake of profit and influence may cause information about political figures and ideas to be diluted and disingenuous . AI could provide avenues through individualized analysis to target certain consumer groups inherently creating thought bubbles , in which two sides of a story our provided in complete isolation to one another . I personally saw the isolation take affect in my Facebook feed as a generally one sided set of articles and content was continuously displayed . The scale of AI consumer analysis to provide news could have a real potential to cause selectivity in information for the benefit of major media outlets . This is an over generalization , but necessarily a debate about AI 's usage in media . As a final caveat , social media as a platform for news is in itself a generally new precedent during major political elections and events .

However , AI may be the first line of defense to preventing the dissemination of fake news by analyzing and selectively filtering out those sources . Facebook has started working on AI based technology to weed out some of the falsified or fake news sources . This could have a very positive impact , but care must be taken in how these learning networks our setup . As the article discussed , the use of these sort of filtering systems has the potential for abuse if certain bias based on political leanings of the entity is introduced . In effect , certain introduced bias may cause similar bubbles of information as the `` fake news '' sources . Regulatory entities will have to take necessary precautions in order to ensure that information filtering is done both ethically and honest .

AI is shaping how we digest and share current event information . It is working on both sides of the field , combatting fake news and generating it . The concern is primarily one of education , how can we appropriately and accurately inform people about events that have an impact in their lives .
With exciting applications of artificial intelligence emerging , Stanford 's study entitled Artificial Intelligence and Life in 2030 shows the sweeping effects that these new technologies could have in the average American life . Examples such as the introduction of Home Service Robots and dramatic shifts to the transportation system are likely to be developed by companies , however these particular developments are unlikely to truly impact the average people in the typical American city by 2030 . Since the beginning of the 21th century , the average income of American families has fallen stagnant . Although some implementations of artificial intelligence are bound to create incremental changes in existing technologies , a majority of Americans families lack the purchasing power to buy the dramatic new technologies that will likely be developed by 2030 .


One example of this could be Amazon 's drone assisted delivery system that was proposed in 2015 . With the average consumer unwilling to pay a premium for drone assisted deliveries , Amazon recently dropped the plan . The article also predicts massive changes to the existing transportation system aided by artificial intelligence . With self driving cars becoming a reality by 2030 it is likely that they will seep into society . However with current income levels for the average American it is unlikely that most families will be able to afford the luxury cars that support the new technology . On top of this , a lack of accessibility to all modern technologies has the potential to exacerbate a societal class divide , a problem that could also further impact the limited availability of artificial intelligence assisted systems to all people . The Stanford study repeatedly uses the example of office cleaning technologies that could replace tedious tasks that are necessary to maintain clean living and office spaces . Although this idea may come to fruition before 2030 , it is unlikely that it will be able to be produced to scale . The high price of such a technology will likely be too much for companies or the average American to bare .


The Stanford study talks about a bright future for educational programs that use artificial intelligence in more effectively educating students . This will likely hold for schools and communities that embrace technology , however many school districts and communities continue
to neglect technology in education . This could be due to funding issues or reactionary views , however these students who do not receive this more modern education will likely fail to compete with students who receive the new technology . In particular , this problem will likely be found in low income areas which can not afford to provide laptops and buy the current technology for students of low income families .


Since the advent of modern computing , the advancement of technology has dramatically improved the lifestyle of ordinary Americans . Although historically new and modern technology has been widely adopted and spread among different social classes , stagnated income will make the new more intelligent technologies more unequally distributed . Although the Stanford study argues that new technologies such as drone based mail delivery , autonomously driving cars , and AI driven educational programs will be widely adapted , the high price for the middle class will likely delay the onset of these applications until after 2030 . STILL NEED FOUCUS ON MATHEMATIC THEORY
When mentioning the future of AI , the author says that the work on theory proving and model-based approaches will receive reduced attention , due to its strong relies on mathematics assumption that are hard to satisfy the real-world challenge . In comparison , the data-driven approaches will become the mainstream . as one of data-driven algorithms `` Deep Learning '' has get a remarkable success recently .
Numerous notable people work on Deep Learning also states : the critical and practical work on the area is to find the good data representation . May be it can get novel result and make a huge process in the short run . but in the long run if the Deep Learning still lack rigorous and strong mathematic theory to back up what really happens in the black box , the essence of it wii be still mysterious . Is it exit a better start point in the navigating space and can we get more faster convergence , is it the Deep Learning convex-like , which are all need a complete and strong theory to explain . So the rigorous mathematic theory behind the AI algorithms still should be valued .
However , the people who work on theory tend to be ignored by the National Science Foundation and big company . Because the complexity and abstruse of AI theory results in the slow theory-established and economic benefit lacked . Nevertheless , the complete and strong mathematic theory behind the AI algorithms can become nuclear weapon to destroy any barrier . For example Galois theory not only provides the beautiful answer on the question why is there no formula for the roots of a fifth -LRB- or higher -RRB- degree polynomial equation in terms of the coefficients of the polynomial , using only the usual algebraic operations -LRB- addition , subtraction , multiplication , division -RRB- and application of radicals -LRB- square roots , cube roots , etc ? -LRB- - -- by wikipedia -RRB- but also explains in detail why it is possible to solve equations of degree four or lower in the above manner , and why their solutions take the form that they do . Without Galois theory , Many great mathematicians such as Cauchy , Lagrange can not solve the problem . Moreover the significant and powerful of researching on math structure is revealed by the Galois theory .
So the LeCun and others suggested focus on rigorous theory of Deep Learning is much needed , as it might to get optimal and faster progress and better intuition .
And in the Health Care area , the author leaves out the apply of speech recognition . It is reported from Healthcare IT News that speech recognition improve the clinical documentation in many ways , as the demand for documentation is on rise . The patient can speak into the microphone attached to the computer and the words are displays as they are recognized . And dictated , corrected , authenticated are all completed in one sitting , the front-end speech recognition can reduce the transaction cost , the documentation time , and give the patient more time to narrate himself.Then the condition of patient can be better known .
Niklaus Wirth says algorithms + data structures = programs , In my opinion , the algorithms + data structures + -LRB- big -RRB- data = AI . Creative and effective algorithms are still hidden in the dark , which need scholars to find . Also the engineers needs to design more efficient systems to speed up the algorithms . And how to collect and process scale and diversity of data will be the future trend in AI research .
Above all , as the old saying goes fortune 's wheel is ever turning . so the ignored topic in AI area nowadays , may become hot in the future . It tells us that if you want to be scholar , you just do whatever you are interested in and never give up and do not much worried about what are the hot topics in AI in recent . Research in Artificial Intelligence is accelerating faster than ever , opening new domains for AI to
interact . Advances in machine learning and neural networks has expanded problem sets and created
real world applications for previously theoretical models . Technology experts like Elon Musk and Nick
Bostrom have taken a strong stance against AI as it approaches human intelligence , but still we see Tesla
Motors -LRB- Musk s company -RRB- using machine learning to develop self-driving cars . The largest technology
companies in the world are delving into AI to harness the power of this growing technology into their
own systems . Sandford University developed a report last year examining AI research and projections
for the next 15 years . The study panel responsible for the report put forth a multitude of ideas
addressing various problems posed by the development of Artificial Intelligence , however , these are
optimistic at best and reflect the theoretical limits of AI .
The report in question reads more like George Orwell than a real world evaluation . Flying cars
are briefly mentioned on page 7 , preceding a comparison between personalized robots and the
Roomba . Over the past century , technology has developed exponentially and futuristic claims followed
but history has shown the optimism of such claims . Undoubtedly , the experts on the panel have an
understanding of Artificial Intelligence beyond my own , but may be blind to the impact of their claims .
For instance , the study panel defines health care as domain for AI growth . If say , a device is
invented to prescribe and administer medication autonomously , who profits from such a device ? Some
trained professional is no longer needed , leading to an economic shift to provide fewer doctors . The
patient could be limited in their communication with the device , so any personal concerns about side -
effects is ignored . By the definition of machine learning , the decision method for the device is beyond
the limits of human understanding of the problem , else hospitals would rather hire a doctor . Those who
truly profit are not directly impacted by the theoretical device . The hospital is able to save money while
the company responsible profits economically from the sale of their product . What incentive do either
party have to serve the populous when considering the adoption of the device ? These questions are
severely lacking in the field thought to produce such things in as little as 15 years .
The Study Panel does create a few guidelines to aid the development of AI , but in
implementation are unfeasible . In one instance , they posit that government officials on all levels have an
adequate understanding of AI . If this was even possible , the education officials receive would be
outdated compared to the emerging technologies they review . Officials will answer questions that
can not be conceived until the technology exists to ask such a question . How then , can one be trained to
answer questions in such broad domains as transportation , personal robots , healthcare , education ,
public safety before they can be conceived ?
We can not presume to know the world in 15 years and what technology will take hold . We can ,
however , reformulate our plan to develop Artificial Intelligence . Our society must develop specific laws
to test and gradually implement AI technologies so as to not create excessively dramatic shifts in
infrastructure or the economy that could collapse sectors of our country and lead down some
unforeseen path . We must react , as a society , to the impacts of AI to preserve a stable society which
supports itself , not just those with economic profit .
The healthcare sector holds much promise for AI application and the report Stanford One Hundred Year Study on Artificial Intelligence brings this into light . This report discusses some of the difficulties and barriers to AI application , as well as many other aspects of AI . It reads , `` Poor human-computer interaction methods and the inherent difficulties and risks of implementing technologies in such a large and complex system have slowed realization of AI 's promise in healthcare . The reduction or removal of these obstacles , combined with innovations still on the horizon , have the potential to significantly improve health outcomes and quality of life for millions of people in the coming years . '' The authors attribute the difficulties of instantiating AI in healthcare , due to existing regulations , to the risk of implementing the technologies and poor human-computer interaction , which is misleading because there is little risk in implementing AI in healthcare if done properly and the barriers of human-computer interaction methods are also minimal , due to their natural decrease in the near years .
This article overestimates the risk involved in the application of AI in healthcare .
The authors attribute the difficulties of instantiating AI in healthcare to the risk of implementing the technologies and poor human-computer interaction . However , these are not the root causes of why this task is so difficult . There is little risk in actually implementing the AI because of the vetting an application would have to endure to actually be used . Look at the drug industry ; the Federal Drug Administration requires years of research and testing for new drugs to be released to the general patient populous . This would be the same for AI , so by the time any AI was to be used it would have significantly less risk than many other aspects of healthcare . Obviously humans make mistakes , and machines do too , but through simulation and testing an AI powered surgery robot , for example , could potentially have millions of surgeries worth of experience before doing any actual surgery , outweighing any humans experience . The AI is the more trustworthy option and therefore less risky .
To argue that the introduction of AI to healthcare would require the reduction or removal of the current risks is also holed because AI is , according to the report and in some sense , the synthesis of intelligence . This is so vague that there is so much space for AI to be applied in healthcare that requires little risk . An example would be using an AI to diagnose non-serious illness , so doctors would have more time for more serious issues . And , even this would be a monumental step for AI , improving health outcomes .
Another reason that AI doctors may incite unease and be perceived as risky is because machines break down and malfunction , however this is outweighed by what they can do and does not incite real concern for risk because of the expected thoroughness of maintenance on any AI . As long as the hospital or provider of the robot maintains the health of the robot or AI with regular check-ups and software updates , the risk of this is low .
Also , poor human computer interaction methods as a barrier to AI improvements in healthcare is not a major problem that does not necessarily need to be the highest of priorities and is not a reason for its inability to be accepted ; especially , when it comes to AI that interact with doctors and not patients . Younger doctors and and the young doctors of the next fifteen years will be much more open to working with AI due to the modern generations greater acceptance of technology and its benefits .


Works Cited
Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .
The Study panel believes transportation will be the first place in which AI technology is integrated into everyday life . While I agree with this , point the idea that once the hardware is made safe and robust that it will be immediately accepted into society I do not think will happen . Cars will be smarter and better drivers than humans but this will not lead to people stopping driving right away . There still needs to be major advances in self driving cars to allow for public use . And even when that is possible the cars will be expensive for the public to get . This will cause it to take time for a large population to have access to them . Along with that it will take time for people to trust self driving cars . While self driving cars can make driving much safer for everyone , I question how fast people will jump to trust these cars . Science has been able to prove many things and yet many people still choose not to believe . For example there is still a group of people that believe the world is flat . This was disproven centuries ago and yet some choose to disagree . I believe this could happen with self driving cars . People may choose to not have a self driving car because they do not trust them and want to drive themselves . this can cause the road ways to stay dangerous and may slow ability of scientists to collect data of self driving cars protecting their passengers . Much of the public could ignore this data and say there is n't enough of it for it to be true . While many would jump at the opportunity to try new technology and a self driving car , I believe more would reject it at first and keep driving manually . The real change that will allow for Smart cars to become the norm is when people stop buying cars and souls get rides from place to place . This will most likely happen as ride options such as Uber and Lyft are already very popular . The Study Panel predicts city dwellers will be the first to stop owning cars which is more than likely . The number of city-dwellers that have cars is already smaller than outside of cities so this change will happen . This change could take decades though . Many people in cities make their living as taxi drivers or even Uber drivers . These people would fight the integration of self driver cars into the transportation industry . The study Panel also introduces the idea that self driving cars could lead to the end of public transportation . this is an idea governments would heavily back but this also means many people would lose their jobs . This is one of the biggest draw backs of many AI technologies . They can replace jobs people do and this means more people become unemployed . The article believes AI technologies could introduce new jobs as well , but in the form of public transportation I do n't see where that could happen . I have no doubt in my mind that in the future self driving cars will be the norm . It will be cheaper and safer for everyone . Despite this , it will take years and years of technological advancements in the AI software and years of social change for these cars to actually become the norm . I am challenging the idea that Artificial Intelligence will highly benefit low-resource communities .
Setting up cameras in low income communities does not in my belief deter criminal acts . It may help police do their jobs better , but the issues of invading personal privacy still is a big factor . This is not however the main argument to why Artificial intelligence would not be beneficial for low-resource communities .


As more Artificial Intelligent technology comes into the market , higher skills are required to run these technologies . This means that higher education in the technological aspect will be needed to operate these machines and to develop them . We already see many Artificial Technologies taking the jobs of many lower skilled workers that live in the low-resource communities . These are jobs that include call center employees , factory workers and fast-food ordering systems . Taking away those jobs from low-resource communities , increases the poverty line in the community , and as a national .


Currently in America , advanced education , just as a University , or a technical school , is a privilege and not a right . A very high percentage of low-resource individuals can not afford to go to school . Many youth can not afford college out of high school and choose to work in jobs to help their families . These jobs are being taken by Artificial Intelligence technologies . It is literally a cycle that is set up to fail . If a person can not take classes because they can not afford it , then they get a job that does not require much skill . After that job is taken by and AI technology , that person has to look for a job in a market that is worse than when they originally looked for a job . Then this person may turn to crime to help and support their family . They may then get caught by a camera doing something illegal , and then this person is arrested for it and is sent to jail where they can no longer help their family . Now this camera , which was suppose to be a benefit to low income communities is now helping put the people in these neighborhoods away using the AI technology in the camera . Making it a never ending cycle , and increasing the poverty line .


Many people who also work these jobs are to old to go to school because they have a family to support . So having their jobs being taken away by machines is a big issue . Learning new skills while supporting a family where you are the sole provider is a strenuous task .


Another example of Artificial intelligence being a burden to low income communities is transportation . Which technology become more expensive . Implementing these technologies into trains and busses can have a high cost to the consumers who use the bus to go to their low income jobs . When AI is implemented the cost of fares will go up .


Until schools are tuition free for all and are accessible to low income communities , Artificial Intelligence technology will be more of a burden then a solution . The Article keeps saying that Artificial intelligence is being built to be more user friendly and adaptable to many people.But in terms of low income jobs that require very little skill , Artificial Intelligence is the problem and not the solution.Autonomous transportation appears to be an extremely efficient and beneficial use of AI ; in the September 2016 Report , it describes how having a group of cars linked by a network , allowing
them to drive quickly and navigate through traffic wil enable them to reach their destination in a more timely and safe fashion . This will also be one of the areas where the public will have
direct contact with AI and see its benefits . Already cars utilizing parking , checking the blindspot of the vehicle and highway control -LRB- Stone , 19 -RRB- . This however will be an
area in which AI will be difficult to incorporate into public and daily use and one that I doubt will be accomplished by 2030 , as oppose to what Stone writes in page 18 .

Currently AI is restricted to portions of the car and the human driver still has control -LRB- Stone , 19 -RRB- ; a completely autonomous car will have some problems though , not technologically , but socially .
With the September 11th Terrorist Attacks , the United States saw a great increase in security over airports , within New York immediately following the attacks , subway trains were patrolled by
the National Guard as well as the NYPD . Both heavily armed and equipped for chemical attacks -LRB- gas masks and some with hazmat suits -RRB- ; while the Amerithrax attack only killed 5 people and
targeted US senators and media outlets , it became the focus of the FBI due to the threat that it posed ; which was enough to equip law enforcement for the very possibility .
This perfectly illustrates that even a threat and small-scale attack can provoke a dramatic response by the public . During this day and age , hacking and cyberterrorism is quite widely
known , if only by name . The threat of an individual breaching a network and diverting traffic with a malicious intent would be enough to stall or stop any city or township from incoporating
this new autonomous form of travel , until it could be proven safe from both accidents and attacks ; which itself presents another issue facing AI 's implementation within transportation .

While witout a doubt intelligent , engineers and software developers do n't rule the world and are n't common within the public . The state-level politicians and public servants make rules ,
decide on budgetary concerns and how to update city infrastructure . This means that the argument has to be made for them , which would be just fine , if not for the warped view that people
have on technology in general . The science fiction genre has long since explored AI becoming malicious -LRB- Hal 9000 , the Matrix , I Have No Mouth and I Must Scream , etc. -RRB- which has portrayed
AI in a very unflattering and unrealistic light . Making it appear as if technology is simply waiting to be given the tools to turn on their human masters . There are so many arguments that
single person with a loud voice could make against autonomous transportation : What if the machines turn against us ? What if cyberterrorists turn our cars into deadly weapons ? What if there 's
latency within the network ? On paper some of the arguments sound ridiculous , but thinking that the public will act in a rational and informed way is n't the best plan to implement .
The Y2K Scare also reflects the fear people can have towards technology and while there were reports of some issues , it was neither remotely close to the scale or seriousness that situation
predicted . Australia invested millions in backing up its information and recalled their entire staff from Russia from that incident alone -LRB- National Geographic , Rutledge , 1 -RRB- . A situation that
quickly proved itself to be a hoax . Autonomous vehicles do n't have this benefit , they have to be implemented and shown to be better than human drivers , there is no ticking clock that can
simply be waited out ; even after proving themselves to be safter , there is no guarantee that people or state officials would endorse it for public and day-to-day use . Artificial Intelligence is already starting to change the world , and the 100 Year Study on Artificial Intelligence released in 2015 delivered some great insight as to what the future may hold as AI becomes more integrated into everyday life , however I am in opposition to the writer 's views of how best to do this in the fields of healthcare and education . Healthcare is undoubtedly one of the most difficult fields to integrate AI into . As the study noted the large legal battle alone will be difficult to overcome , but should some of the potential advancements in the medical field discussed in this report be possible the fight would be well worth taking up . Unfortunately the writers of this article are fighting the wrong people . The writers believe that the FDA is primarily to blame for the slow adoption of AI technology into the medical field , but in reality it is the lack of public opinion on the topic combined with a lack of enthusiasm on behalf of the medical community that is the real culprit . The FDA would not approve or rescind any regulatory measures that they believe would hinder a doctor 's ability to do their job , and if physicians `` routinely dismiss '' information relayed to them by AI , the FDA probably views AI technology as a hinderance rather than an enhancement to a doctor 's performance . Doctors may also be hesitant to adopt or advocate for the technology if they fear pay cuts or job loss . Some may also be skeptical if they feel that changing the cognitive tasks assigned to them may reduce the quality of their work . So instead of trying to prove to regulators what should be done , invite the medical community to better understand how AI can help them with their work and build intelligent machines tailored to the needs of these doctors . I believe that AI researchers should look to either ; sway public opinion in favor of integrating health care and Artificial Intelligence , or just develop systems that doctors actually desire to use . Regulators would be eager to push through legislation should a majority of the medical community or major hospitals rally around the use of AI in healthcare . The FDA would have no choice but to reevaluate many of these archaic regulations , and much of the red tape would be removed . Instead the authors of this article are naively attempting to strongarm regulators because they believe they are the real problem . The authors take a similar position with education . Much of the 100 year study devoted to education discussed new intelligent tutoring systems , online learning and teaching robots , but only in a short paragraph on learning analytics did I see the report discuss how AI could help improve the way people learn by teaching educators how to use artificial intelligence . Instead of looking to replace human instruction with robots or online courses , researchers should design systems with the educator in mind so that they may utilize learning analytics to ensure students receive a more personalized education . While the authors of the report blamed lack of financial resources , I do n't believe educators are likely to be enthusiastic about technology that they fear will rob them of wages or positions . If educators are taught how to use these tools they could help develop these technologies by putting them into practice in the classroom , which would hopefully reduce costs for the school by providing researchers with quality data , increasing the effectiveness of these educational technologies . The first issue that I am challenging is centered on the idea of an AI system representing
a corporation or person . According to the Stanford Study , there are `` regulatory bodies
in the United States , Canada , and elsewhere -LSB- which have set -RSB- conditions under which
software can enter into a binding contract . '' The problem that I see with this is that a computer
does not `` understand '' in the same capacity that humans can `` understand '' in . You can
try and simulate human thought process and problem solving all you want , but in its current state
artificial intelligence simply ca n't do it . A computer only reacts to its environment in the
ways it 's told , and while it may possess the ability to learn from past processes , it still
does not actually understand the underlying aspects of it .
So then if an AI system ca n't understand the binding document it is signing , then
I do n't think it should be signing them at all . The software technically makes its
`` own decisions '' , but these decisions were originally encoded by a developer . I think that
if the need were to arrive for a piece of software to enter into a binding contract , then
the original developer should have to sign it . Basically , until we can emulate the human
thought process almost perfectly , the role of representing corporation should be left to us .
I also want to talk on the topic of self-driving cars . One line that stuck out to
me was this : `` Self-driving cars will eliminate one of the biggest causes of accidental
death and injury in United States , and lengthen people 's life expectancy . '' I think that
this statement is very generous in its analysis and is way too optimistic . In a perfect
world , yes self-driving cars would fix all of our problems on the road . They would
make travel completely safe and eliminate human error . But unfortunately it does not
work that way and computers and other systems have problems . I think that everyone that has ever
worked with any sort of electronics/computers knows that they can fail unexpectedly . And
I think that one of the worst places for a computer to fail is going 70 mph down an
interstate . I 'm not saying that self-driving cars have no place in the world right now , but
we need to be careful about how we approach it . I think that for the above statement to
really be true , at least 95 % of the cars on the road need to be self-driving and able to
interact with each other
It 's also important to look at the legal aspect of self-driving cars . If a driverless car
were to get into an accident with a human driven car and it was the driverless car 's fault ,
who would get the blame ? Would it be the company 's fault ? Or say there was a passenger in the car ,
would they be to blame for not trying to avoid the accident ? It 's situations like this which
make the implementation of artificial intelligence harder than it seems on the surface .
The point from the study I would like to challenge is its view of intelligence as a broad spectrum . I think their spectrum is far too inclusive . The study admits that a calculator is not intelligent when compared with humans , but says it is simply a difference of scale , speed , degree of autonomy , and generality and includes it as artificial intelligence . I disagree , and think that while intelligence is a spectrum , not every object or program that performs an action is on it . In my view , a calculator is simply a tool with a specific function , and its inability to adapt or learn prevents it from being intelligent . I admit I may be playing into the AI effect that the study mentions by writing off a once great invention as a simple office tool when compared with other technology in today s world , but I feel as though a modern viewpoint is required to accurately decide what artificial intelligence is . All new discoveries will be revolutionary before they are explored fully , and if a greater understanding of the discovery renders it simple , then it may not have been as great as it was thought to be . New information changing previously held viewpoints is not a negative thing .
My view of intelligence is based on the ability to learn and make meaningful choices . Though computer programs can do so much more than simple minded animals like dogs are capable of , I believe a dog would still be placed on the intelligence spectrum over most . An animal capable of even simple thought can learn and adapt to its environment ; it is not restricted by whatever rudimentary functions it was born with . A calculator will never do anything but the arithmetic operations it was programmed to do . It does not know anything and can not change its knowledge , so I believe it to be just as artificially intelligent as a stereo or a car .
One machine that I would consider artificially intelligent is IBM s Watson . Watson has the ability to have new information from the internet loaded onto it and to learn from that information . As shown in the Jeopardy! video in class , Watson makes choices between probable answers , choices that would undoubtedly change or have differing favorability by the machine if conflicting information was available to it . While Watson still falls short of what many would consider true intelligence , I would still place the machine on the spectrum due to its ability to learn and make meaningful decisions .
Though significant advances in artificial intelligence have been made in my lifetime and more are sure to come , I do not think that anything will ever be made that approaches human intelligence or even the intelligence of many other simpler animals . To place a calculator on the same playing field as things that can think is silly in my opinion . The complexity that goes into true thought is something that I don t think humans will ever fully be able to recreate , but just because it is difficult doesn t mean we should lower the standard for what constitutes intelligence .
This review challenges the articles claims that advancement in AI will reduce interpersonal
interactions , that AI can not displace active human teachers in education , that in the field of health
care people and machine will collaborate , and that the current method AI synthesis can be void of bias .
The study panel claimed that the next generation is increasingly spending more time on their
devices and are excluding themselves from social interaction . That is only partially correct , and it is
not the fault of technology but the usage . People who are taught to use technology as a form of resource
use it interactively with other members of society while next generation who began using technology for
entertainment use it extensively in solitude to pass time . From experience , college students tend to
categorize their devices into productivity and entertainment . Productivity usually includes collaboration
with others while entertainment is used to share with others of similar interests . Face to face
interaction may decrease but the amount of time associating with people more like oneself has increased .
The second challenge is to the statement that human teacher will always be part of the education
system . The current education system places too much reliance on the abilities of the teacher to be able
to accommodate the needs of many students . A sufficiently adapted AI will be able to monitor the
individual students and adjust separately while a human instructor will introduce bias and unnecessities
into the classroom . The teacher can work side by side with technology but it is not the most efficient
way in the perspective of a student , nor is it in the interest of the individual students . Human teachers
will act more on experience and should that contradict the AI s decision then that will result in
inefficiency and the students will be the ones affected . In effect , it would be more logical to fully
integrate AI into the education system as the main tool for teaching .
Similarly , to the last challenge , this one states that in the field of health care physicians
will collaborate with machines . In simplistic perspective , machines are far more precise than a human can
be with the 5 senses . A person may be able to intuitively diagnose a patient but AI with a vast data base
can perform just as well , maybe even better . With the precision and logic of a machine as well as the
availability of said AI after development , there is no reason to maintain physicians with higher error
rate .
The last challenge is the overall assumption that AI will be fundamentally logical and objective
in situations where a human would . Much of the current AI training relies on statistics and sample size ,
which is collected and selected by personals with biases . Even devices built to collect data will
introduce bias from the developer or even the distributor . By developing AI using a human mind we are
introducing bias to the system .
Since most of the article was describing the state of AI in 2030 , their claims would stand but
their basis of AI would be under question . With the current AI technology , considering of advancements in
the field , it would be hard to categorize the technology as AI since data interpolation is not the same
as the intelligence of a human mind which was the bench mark for AI .


ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 discussed possible applications of artificial intelligence technologies in many domains , including the domain of healthcare system . The authors pointed out several bottlenecks of the development of applying AI in such domains : Outdated Legal regulations and incentive structures slowed down the development ; Technical difficulties and risks slowed realization of AI 's promise in healthcare ; Data gathering process that might involves violation of privacy is also controversial . However , those obstacles can be removed , especially when political and economical impacts of applying AI in healthcare domain gains sufficient publicity in future . On the other hand , besides technical difficulties , people should also realize that the biggest challenge is to safely and widely provide healthcare to public through AI at lower cost . In other words , designing AI to detect diseases in cheaper ways , is more important than making it to run more accurate diagnosis .

All technologies in the domain of healthcare experienced obstruction of outdated regulation and incentive structures . When public safety is under consideration , it is natural for policy makers to be conservative on making changes . Just like and new drug would be forced to go through animal and clinical tests that last more than a decade , applications of AI in healthcare domain certainly will , and shall , experience rigorous and long term testing procedures . It s also rather better for the sake of public safety , to slow down reformations on regulations , than to change regulations with even smallest uncertainty and risks . Violation of privacy won t be a problem too . First of all , policy makers can make certain hash process mandatory to totally isolate the patient 's medical data from their identity information . Secondly , privacy have already been violated in the name of public safety for many years -LRB- PRISM project for example -RRB- computer scientists should really just leave these questions to politicians and corporations .

The motivation and resources to finally resolve the above problems won t and shouldn t come from academia . When AI can technically applied in healthcare domain , billions dollar worth of capital would flood into such area . Lobbyists would clear the obstacles .

However , computer scientists should not focus on competing accuracy with medical researchers . Take using machine learning to detect alzheimer 's disease for example . Today artificial neural network indeed did better job on detecting the disease based on MRI images . However , autopsy is still the only conclusive way . It is meaningless to spend too much effort on improving 0.1 % of accuracy since currently there are more straightforward biological ways to make 100 % correct conclusion . Since biological methods exists , it is not harmful to leave type I error and simply provide indication of high risk , rather than diagnosis . Computer scientists instead should focus on improving speed and lowering cost of AI so that more people can benefit from the technology and more capital can be drawn to the area to support future development .

Applying AI in healthcare domain would be crucial to national strategy , especially for countries with hundred millions people , and it will be the single most important part for any successful reformation on health care system . Medical use of AI would be the first time to truly industrialize the healthcare industry by making the productivity not constrained by human resources , because today , the capacity of health care system in a country is still limited by number of doctors and nurses . AI however can massively amplify the efficiency of a single health care providers , hence will be the ultimate solution .

The Stanford One Hundred Year Study on Artificial Intelligence -LRB- Stanford University , 2016 -RRB- talks about various uses of AI in various fields as well as entry barriers or other obstacles that could hinder the uses of AI in those fields . For example , under the health care system , various broad claims were made with caveats , such as gAI-based applications could improve health outcomes and quality of life for millions of people in the coming years , but only if they gain the trust of doctors , nurses , and patients h , and other problems such as gA small group of companies control the EHR market , and user interfaces are widely considered substandard , including annoying pop-ups that physicians routinely dismiss h . The problems listed particularly under healthcare analytics only seem to list -LRB- 1 -RRB- gthe FDA has been slow to approve innovative diagnostic software h , gHIPAA requirements for protecting patient privacy create legal barriers h , gAI research and innovation in healthcare are hampered by the lack of widely accepted methods and standards for privacy protection h , garchives have only gone digital over the past decade h , and only lastly after all these points is listed almost as an afterthought , gvalue proposition is not yet compelling h. I argue that the current biggest barrier to entry of AI into the medical field is not any of the items listed previously , which do indeed pose larger downstream effects , but rather a fault on the shared on side of the computers themselves : the cost . Current medical facilities want to use this technology but the cost is currently too high .

The other day , a family member of mine was talking to their doctor , and the doctor said something that stuck with me . If I remember correctly , he said that he is very interested and eager to use the new AI technology , but its currently too expensive to use practically . There are many software available from small startup companies or large companies like IBM , but the most famous one is probably IBM Watson . IBM Watson is a supercomputer . The supercomputer is not something that can be easily just installed to a laptop in the same way that one could install google chrome . Rather , what I infer to be the situation is that one must pay a lot of money to gain the licensing fee first , and then a lot more money to rent out enough space/time on a supercomputer to start making dents in patients f cases . I think that currently , we are just simply too ahead of our time for this sort of technology to gain momentum as quickly as the authors seem to be hoping for . We need to wait a few more years until the quality of computers gets better and thus the price to use a super computer goes lower . That still won ft do anything to solve the licensing issue , but at the current rate , I daresay that getting a diagnosis from the computer may cost more than a diagnosis from the doctor .

Thus , the AI industry gets too easily swept up in its own broad claims , blaming the lack of trust on the side of the doctors as well as strict regulations from the government for a slow start in acceptance and usage , where they themselves should share some of that burden .
The Stanford One Hundred Year Study on Artificial Intelligence is a broad summary of developments , future applications , and future challenges associated with AI .
Among the challenges associated with widespread use of AI is the its impact on the labor market . As AI develops , the labor needs of some companies will fall dramatically
while other professions -LRB- like that of a truck driver -RRB- may be replaced all together . The study addresses this , suggesting a wide variety of potential ways to address problems
produced by large scale unemployment caused by AI . AI will certainly cause short term damage to the labor market and will eliminate some forms of employment entirely ,
and these problems will need to be addressed by government action . However , the study overstates the long-term problems associated with AI development .

The study describes AI as an unprecedented shift in human productivity that would require serious structural changes to the social safety net to account for the vast numbers
of people who would see their jobs automated out of existence . Longer term , the current social safety net may need to evolve into better social services for everyone ,
such as healthcare and education , or a guaranteed basic income . Indeed , countries such as Switzerland and Finland have actively considered such measures .
AI may be thought of as a radically different mechanism of wealth creation in which everyone should be entitled to a portion of the world s AI-produced treasure . -LRB- 39 -RRB- .
The problem with this assessment is that massive spikes in human productivity are not unprecedented . For most of human history , most people worked in agriculture .
This changed primarily during the industrial revolution , during which mechanization and the production of new fertilizers caused a massive increase in agricultural
productivity and consequently a massive decrease in the cost of food . In the short term , this meant farmers no longer had the income they needed to support themselves .
However , this obsoleting of a massive portion of the labor force did not lead to long term unemployment . Instead , people adapted . They moved to urban areas ,
learned new skills , and after the transition was completed were employed in a wide variety of new jobs that were not even conceivable before the Industrial Revolution .
This pattern of short term unemployment followed by the creation of new and previously unimagined sectors of the economy persists throughout the history of technological
development . There is little reason to think AI technologies will , in the foreseeable future , be fundamentally different from other historical spikes in productivity .
This is not to understate the seriousness of the disruptions that AI can and will cause . While it is easy to say that employment will recover and new industries will be
created with the onset of AI technologies , that does little to help a truck driver who has just been replaced by an automated vehicle . Retraining programs ,
educational reforms , and a more robust social safety net are all possible ways to help those who do end up unemployed by AI . However , these programs should be
designed as ways to address a short-term problem associated with transitioning to radically different economy , not as a solution to a persistent problem caused by
AI technologies .
The Stanford One Hundred Year Study on Artificial Intelligence claims that the lack of a precise and universally accepted definition of AI helps the field to , grow , blossom , and advance at an ever accelerating pace . While I concur that the lack of such a definition has helped the field to positively change in its study , I would argue that the lack of definition is not the case anymore . It would be more accurate to say that just as the field has evolved , so has our understanding of and the existence of the definition of artificial intelligence . The report claims that the lack of a definition allows researchers and developers to be guided by , a rough sense of direction and an imperative to get on with it . I believe this claim would ve been appropriate decades ago . However , the rapid development of AI as a field in recent years would not have been possible without an understanding of the direction in which the research should head to reach a certain goal . This ultimate goal and the existence of a direction to head to it would not be possible if AI did not have an accepted and accurate definition .

Before we proceed to state the goal of the research of the past few years , we need to properly define AI . A common definition that has arisen for AI is machine exhibited intelligence . However this definition is somewhat cyclic since it uses intelligence in the definition . So how can we separate the definition of intelligence from our definition of AI ? We could define intelligence as the capacity to solve problems . In fact the report uses this is a criteria for its vague definition of AI . In its definition of intelligence , it states that a calculator has the capacity to solve problems and can sometimes do so on a scale larger and speed faster than the human brain and so it fits on the intelligence scale . This is not the definition of intelligence it is the definition of efficiency -LRB- while the report does not outright state that it considers a calculator to be intelligent , it does state that at one point a calculator could have been considered intelligent -RRB- . Calculators are efficient machines capable of solving complex problems faster than the human brain , this makes them useful to us due to their efficiency , however a calculator does so using numbers we input . It can not solve a problem that is not in the form of a mathematical equation .

A more accurate definition of intelligence would be the capacity for logic , learning , creativity , reasoning , and perception . Using abstraction , assuming that the words we have just used to define intelligence are well defined -LRB- a problem for philosophers not computer scientists ! -RRB- , we can define the current goal for AI as creating machines that can reason , learn , plan , perceive , or create -LRB- an ideal machine would be one that has the same intellectual abilities as a human , artificial general intelligence -RRB- .

By defining this goal , we can understand the path we need to take to attain these goals , not just remain satisfied at the creation of a simple efficient machine and consider it an intelligent being . This ability to know what we are working towards only occurs if we have a singular definition for artificial intelligence . While it is alright to consider this definition as dynamic in nature , it is not fair to say that the lack of any definition for it helps us to develop the field faster . In fact , it only harms our ability to further our research of AI since we would never know what we are working towards .
The assigned reading is certainly an excellent resource for a beginning introduction to the state-of-the-art research and
industrial use of Artificial Intelligence -LRB- AI -RRB- . I have no obvious disagreements with that part of the presentation . I do ,
however , believe that the report underestimates the potential impacts of the development and expanded usage of AI .
Certainly , I do not believe that we will soon be developing real-life killer robots . Rather , I believe the authors do not
fully address possible human responses to the expanded use of AI , and the negative consequences that may arise due to
such responses .
Before I address specific instances of disagreement , I believe that I should first admit any potential biases and my
general opinion of human behavior from which I am drawing any conclusions . I believe that humans are essentially
emotional , often rather illogical , creatures . We , without careful forethought , can make decisions that we believe
benefit us most , without care as to how others may be affected . As any group in humanity is simply a group of humans ,
any group of humanity is often prone to what is seen by an outside objective observer as irrational behavior .
To this end , for example , what is the potential reaction of people to self-driving cars ? I , as someone who prefers
to feel in control of my own transportation agency as well as someone who simply enjoys driving at times can anticipate
that some people may simply not want to own a self-driving car . As another example , the section on the healthcare
industry reads nearly as a complaint about byzantine privacy regulations . The authors seem to not consider whether
there is real , understandable privacy concern , whether could change , and what effect the privacy considerations of
health-care professionals , rooted in the Hippocratic Oath may have . In addition , as a general effect of new
technologies , could negative sociological strife occur due to changes in employment and a further increasing wealth gap ?
Fear of change could induce people to behave rather irrationally .
In fairness , the authors readily admit concerns may arise from the use of AI in new technologies and propose
research to address potential social and policy concerns . I do , however , believe that they fail to state the
importance of such research and do not appropriately warn that negative effects could arise . In part , I believe that
their focus on a typical North American city hampers their conclusions here . While we may be seeing a new boom of
economic activities in cities , this will be due to the interconnected nature of the economy have effects on other areas .
The political response , of such areas , at least in the United States , is critically important due to the nature of
American representative democracy -LRB- i.e. single-member first-past-the-post districts , overrepresentation of rural areas
in the US House of Representatives , US Senate , and Electoral College -RRB- . This at least , is important to how state and
federal regulations -LRB- which the authors discuss -RRB- will affect the impacts of expanded AI use .
I feel , also , that some of the presentation is due to the authors , from my impression , being top scholars and
industrialists in the field of AI , and thus , highly trained scientists . In my previous experience , I have read
scientific literature , and I feel that the field requires scientists to try to present definite conclusions and avoid
admitting any ignorance on a subjects such as economics , sociology , and health care policy . This , I feel adds to my
dislike of the presentation , as well as my personal belief that society will certainly partly fail in mitigating the
negative consequences of new technologies .
After reading the study given by Stanford , the first challenge I would like to make is that what the standard of improvement in AI is and is there any limitation of such improvement if the definition of AI is somehow imprecise . As mentioned in the study , the lack of precision definition of AI makes it grow and advent , but people always want to measure the level of AI . If there is a basic rule for the level of improvement in AI in some specific realms such as industry , convenience must be the most important one . However , in other realms such as home robots , entertainment may sometimes become a more significant measurement . Whether such of lack standard of measure is good or not is also quite vague right now . Researchers can improve the AI to different directions as they imagine , but such lack of restriction may also make it much easier to fail and time costing . Therefore , if people think the lack of precision on definition of AI would probably help AI grow , the lack of universal standard of improvement of AI may be a double-edged sword .

Secondly , according to the study about home robots , the improvement of technologies may make these robots more widespread in the future . There is no denying that home robots in current society are mostly used to maintain the order and clean at home . However , in the future , people may expect that robots can be a way of communication and a good problem solver at home . The level of intelligence of such robots must be the highest since they need to handle different kinds of question given by human . However , such great workload and complexity can not be easily solved by the technological improvement since the robots may sometimes need to detect the emotional change of their customers . However , as makers do their best to improve the intelligence level of home robots , whether customers need to treat these robots as machine or friends becomes a moral problem .

The last challenge I would like to mention is that the education given by AI is not that quantifiable to know whether it can be fully used in the future to teach students . As mentioned in the study , using AI to teach can save lot of money for universities and attain almost satisfied level . However , such AI teaching has its own drawbacks which make it hardly a substitute for human teachers . The first reason is that , teacher involvement is quite important in learning since the personality of students are various and AI can hardly give a full picture and know the best way to teach . Secondly , using AI for education may let the knowledge taught to students tends to be tedious and the students will become the same after graduation . The ways of using AI for teaching may never take the place of human teachers but AI is undoubtedly good helper for teachers to improve their teaching ability .

These are all the challenges I would like to mention is this study and I think the AI still have lots of improvement to do . With the development of other technology , currently unsolved problems of AI may be worked out in the future .
In the report Artificial Intelligence And Life In 2030 written by One Hundred Year Study on Artificial Intelligence , AI , in general , has been discussed how it might be developed as well as how it might change our daily lives in the future . In my point of view , although I greatly agree that many tasks and aspects of our lives will be inevitably greatly enhanced by the utilization of Artificial Intelligence , it is not the case for entertainment . In the article , it is stated that AI will increasingly enable entertainment that is more interactive , personalized , and engaging . To be specific , the application of Artificial Intelligence into the classic sport , which is happening more and more over time , will eventually destroy and suffocate many games , especially those that require a lot of thinking process . This writing will be focused on how Artificial Intelligence has drastically changed the nature of classic chess into modern chess as we see today . In 1997 , IBM s Deep Blue -LRB- a chess engine using Artificial Intelligence and self-learning to improve itself -RRB- beat chess master Garry Kasparov . This is the first time a program beat a world champion at chess under normal tournament rules . Before this event , chess players usually trained to play better and focused on how to defeat other players . They had always been looking up to another person as their opponent . Thus , there are many different strategies , many game plans , many openings and many traps were created for the specific purpose of defeating others . On the other hand , after 1997 when Garry Kasparov was defeated , the way chess players train themselves has been changed radically : they started playing with computer , training with computer , and eventually using computer to analyze how they can perform better for every move . The computers tell them the best moves for each position and evaluate many different possibilities . On top of that , chess engines also do the heavy job when helping players study and analyze the weakness of their opponents strategies . This process used to be too time-consuming that it was often neglected by most players . However , with the aid of chess engines , it s not a job you have to commit anymore . With the help of technology , professional chess players have , undoubtedly , improved a lot . According to chess.com , post-modern chess players , make much fewer mistake moves comparing to their precedent acquaintances . As a result , modern chess players tend to play much safer and does not take risk anymore . They play the most optimized way according to how they remember from the chess engines . Top competitors who once relied on particular styles of play are now forced to mix up their strategies , for fear that powerful analysis engines will be used to reveal fatal weaknesses in favored openings . -LRB- Viswanathan Anand , 2013 -RRB- In the World Chess Championship 2016 final between Magnus Carson and Sergey Karjakin , 10 out of 12 games are draw because both players don t want to risk and end up losing . Thus , while Artificial Intelligence helps optimize the players ability , it has gradually made the game much more boring . In the end , while I totally agree that Artificial Intelligence will greatly improve many aspects of our lives , it will also make many entertainment games like chess become less entertained .

According to `` Artificial Intelligence and Life in 2030 '' report , various fields in humans lives are rapidly changing due to the fast development of artificial intelligence -LRB- AI -RRB- . However , there are several points worth-noting that the report might be too optimistic with the positive effects of AI to human beings .

On page 40 of the report , it states that AI may eventually make entertainment more interactive for the users . However , on page 41 , the report also claims that the most important factor of a superior form of entertainment requires social interaction , such as friends . It contradicts itself because the current AI technology does not have the same capabilities of a real human being . That is , it is not real intelligence . Eventually , the AI technology that currently developed today are all based on recognizing data , no matter it is computer vision and language recognition , and search through a whole list of possible responses with statistical methods in order to properly respond to the users . In terms of entertainment , this really does not make the experience good enough . The examples mentioned in the report include World of Warcraft and Facebook , which the report lacks sufficient details with the AI application and usage in these popular software . Is it the AI of the non-player character in world of warcraft makes the virtual world attractive ? Facebook attracts a great number of people because of the relationship between people . That is , the nature of sharing . It may be questioned the effectiveness and role of AI in these entertainment whether it is a social media site or a game because the value of entertainment is social interaction and AI may not enhance the experience to a large extent until real intelligence -LRB- understanding the brains of humans -RRB- is developed . Therefore , the real effect of AI on entertainment may be doubted based on the information given .

In terms of mobile healthcare on page 29 , the report misses serious consideration of the future of mobile health . It is stated that AI can extract data from users and analyze it with helpful feedback given to the users . However , the accuracy and reliability of the data should be evaluated seriously especially healthcare is one of the most important aspects of human lives . Even if the data gathered from mobile phones are highly accurate and reliable , there must still exist some errors . What if the errors from the healthcare app seriously disrupt one 's normal life ? For instance , one receives notification that he/she might have something wrong while he/she indeed does not . There are still potential uncertainties with mobile apps but healthcare is one of the services that should not encounter many errors . Although the report -LRB- page 46 -RRB- also has discussed the overall liability of such errors in AI application that those responsibilities may count towards companies and certain laws may even be enacted to attribute the liability of AI , the broader question may be asked is if humans are ready to accept and recognize the role of AI in the society and if AI and humans can co-exist well without causing any major social concerns and issues .

Artificial intelligence may still have a long way to go as researchers continue to invest more money and time but there are points that the society could have already started to consider including the overall role of AI in the society . At the same time , we as humans should not only see the potential large benefits that AI might bring but also the limitations of our current technology . This study brings up a great amount of extremely valid points . It was extremely hard to find a point to refute and challenge . However , I worked the past 9 months on co-op in the healthcare industry . Over this time , I learned a lot regarding FDA regulations and how and why they exist . A lot of hoops need to be jumped through in order to pass the simplest piece of innovation or to protect the company from an audit . While this sounds ridiculous , and the study certainly seems to say so , there is a lot of good reason for these seemingly endless hoops .
The specific field I worked in healthcare was anesthesia and respiratory care . This field has a lot of reason to be wary to new technologies from the FDA . The study claims this is due to a unclear understanding of the cost/benefit tradeoffs of the system . Additionally , the study claims that it should weigh the benefits of faster approval over some safety risks .
In my opinion , and I think rationally , many others as well , this seems a little ignorant . To put potential lives in danger in order to spawn faster innovation seems irresponsible . These machines and systems are required to go through years worth of testing and trials for a reason . These machines are built by humans , they have their flaws . The study also makes a point that it isn t just referring to imaging devices either , it mentions things like autonomous surgeries as well . If the people behind this study genuinely think that these are some safety risks that seem to be brushed off as negligible based on the tone of the article , there needs to be new people behind this study , or they need more people from the industry rather than academia .
The study also makes a point of how it will be important to have the adaptation from hospital staff as well , and how they will need to be accepting of these new technologies . I can speak from experience that this is extremely unlikely . The R&D team of my company was specifically told from many focus groups to not change our machines , simply because it was too high risk to change even the location of a button . It is like being trained to type on a QWERTY keyboard and then being given an ABC version for some reason . Sure , we don t really have a reason to have a QWERTY keyboard , the button layout was based on limitations of typewriters . But , the amount of problems that would cause would really make many people question the change , especially if lives were at stake .
All in all , the study got a lot of things right about the healthcare industry . However , I believe their outlook is one that is a little too optimistic and lacks an understanding of why certain decisions are made . The FDA has its reasons for doing what it does , and that is to protect the lives of citizens . Mass producing a product with a bug will not only lose the company money , but could potentially leave it responsible for the deaths of many . A solution to this type of thinking would be to have a readjustment made with the personnel involved in completing these studies .
In the `` One Hundred Year Study on Artificial Intelligence '' conducted by Stanford University , they propose that if AI systems take over jobs that currently require human labor , then the everything will effectively be cheaper and easier to acquire , `` Because AI systems perform work that previously required human labor , they have the effect of lowering the cost of many goods and services , effectively making everyone richer '' -LRB- AI100 39 -RRB- . They believe that as AI takes over employment sectors , safety nets might have to be put in place to provide basic income , and other social services to everyone . These propositions seem to paint a Marxist picture where socialism is our only option for the long term . I think that socialism would only be required to support the generation of workers replaced by AI . I think that AI will ignite an intellectual revolution where intellectual capital propagates wealth , and separates financial classes . I believe that education , training , inventing , and innovation will not only mitigate the effects of the sudden shift in the economy , but give realization to a different Marxist picture that fantasizes less about leisure and wealth , but more on competing to realize better ideas that improve our societies . I essentially think capitalism should be maintained to preserve the effects it has on driving society forward .
I also disagree with the report 's proposition that as self-driving cars become more prominent , people will own less cars and move further from their jobs , `` As cars become better drivers than people , city-dwellers will own fewer cars , live further from work , and spend time differently , leading to an entirely new urban organization '' -LRB- AI100 7 -RRB- . I do n't believe that transportation is the main factor that would decrease the population density of a city or even cause an internal migration of living . A city is too complex to infer that ease of transportation is preferable to a shorter distance traveled to get to work . Proximity to other resources in a city also have major influence on people 's choices of where to live . Autonomous cars will not lead to a new urban organization , but instead the way in which they communicate to make transportation more efficient will . I do n't see why the automation of driving would lead to fewer cars owned . If a car is autonomous , it serves as a feature that encourages someone to keep and use the car . If anything , this should increase the demand for cars since it would be a preferable way to travel that would allow you to remain productive during your travel . I do n't think there will be any profound city scale effects due to self-driving cars alone . It is a feature . Cars have always been controlled by people . The only difference now is that they are n't controlled by people , but people still ride in them , therefore they serve the same purpose . This leads back to my point where I believe that , how these autonomous cars communicate will create a new urban organization . As self-driving cars become more prominent , the system of transportation will become more efficient since important data can be collected to make traffic systems more efficient . Route planning and distribution of traffic throughout a city will solve traffic problems and provide more efficient routes for users . The network of self-driving cars is what will change urbanization and urbanism , not the feature of automation itself .

Within the Stanford One Hundred Year Study on Artificial Intelligence many budding and already realized technologies are discussed . One of the technologies mentioned many times is the idea of using artificial intelligence to seek out and potentially prevent crime while simultaneously checking itself for and eliminating biases . While this does sound like a best of both worlds type of situation , I simply do not believe that it is possible for these two ideations to coexist within a system . Besides the fact that the idea of having artificial intelligence try to prevent crimes is already a disaster waiting to happen , attempting to implement that and a self-checking bias eliminator at the same time seems extremely counterintuitive .
If a machine were to be programmed in a manner as to be able to spot potentially illegal activity , what would the machine be told to look for ? There are many options that could be put in place , such as where a person is , how they are acting , what they are wearing , or what they have in their possession at the time . While all of these things may be able to help an artificially intelligent system decide the probability that this person is going to commit a crime , the judgement based off of these is already an inherently introduced bias . Some people may say that as long as the machine does not use descriptors such as skin color , sex , etc. to decide who may be about to commit a crime , then there is no harm done , but that is simply wrong . Regardless of what descriptors are used to run this system , many groups of people would get discriminated against and falsely accused of being about to commit a crime .
Now , after programming this machine , with its inherent biases determining who is most likely to commit a crime , imagine proceeding to write a side program that is supposed to catch when the machine has a bias and eliminate it . Doing so would eliminate the only guidelines given to the program . Essentially this artificially intelligent machine would be caught in an infinite battle with itself deciding how to determine who is most likely to commit a crime , then that thought getting immediately deleted after being caught as a bias . This is not an effective use of one of the most promising fields of science and computing to date .
Overall , it is easy to see how this application of artificial intelligence in principle is a great idea . It is disappointing , however , that there is no real way to implement this technology without singling out a group of people or basically having no effect at all . Researching this technology seems to be a waste of time , money , and manpower . I imagine the difficulty of implementing this system will be very quickly realized , but I do believe there was one good idea amongst all of this . Instead of trying to focus on predicting illegal activity , using this technology to simply detect bias and eliminate it wherever possible would be an incredibly productive application of artificial intelligence .
Eric Christianson
CS 540

Although AI technologies are rapidly making advanced progress in many different sectors including healthcare , home/service , and the workforce , I disagree that autonomous transportation will be commonplace soon . It is no doubt that autonomous driving could be beneficial to our society by reducing car related injuries as well as increasing leisure time during car rides , however policymakers , the inability to make moral decisions , and the demand for driving freedom will prevent autonomous driving from becoming commonplace in the near future .
Policy makers will prevent self driving cars from being widespread due to pushback from the oil industry and lack of responsibility during an accident . The most popular self driving cars today are Teslas which also happen to be completely electric . Due to this , large oil companies pressure policymakers to limit incentives for electric vehicles , which would hurt autonomous driving since most self driving cars are electric . Also , with autonomous driving gaining popularity everyday , the responsibility of a car crash that involves autonomous vehicles will only become vaguer . Who will take responsibility when an autonomous car kills someone ? Who will take responsibility when two autonomous cars hit each other ? These are questions that policy makers have to consider with self driving cars becoming more prevalent everyday . Policy makers have many reasons to slow the introduction of autonomous cars .
One topic that the report touched on was making moral decisions . There may be a time when an autonomous car has to make a split second decision on whether to hurt one person or many people , and the programmers will have to bake that decision making into the vehicle . It is certainly possible for the programmers to code the decision making for moral dilemmas , but is it right for the programmers to be the ones deciding what 's right and what 's wrong ? When these moral issues are brought to light of the general public , it may receive public pushback and take longer for autonomous vehicles to be widespread until these moral decisions are resolved and agreed upon . These moral decisions will also cause policy makers to be more hesitant about allowing self driving cars to be as prevalent as the report would suggest .
Additionally , if autonomous vehicles are to be as commonplace as the report says , it is possible that every car in the near future will be self driving due to rapid advancements in AI as well as the benefit society gains as every car becomes self driving -LRB- i.e. safer driving conditions , less traffic , etc. -RRB- However , it is unlikely that the individuals will forgo their freedom to get behind the wheel of a car and drive themselves . There is no doubt that there are many people who enjoy driving their personal cars even if it means that they will increase their risk of vehicular accidents compared to an autonomous vehicle . Due to this , self driving vehicles will not completely dominate the roads
While self driving cars may provide great benefits for all of society by reducing car related accidents , minimizing traffic , and increasing leisure time , it is unlikely that autonomous cars will be commonplace in the near future due to hesitant policy makers , autonomous cars and moral decisions , as well as the desire to personally drive your own vehicle . In Stanford s report of a long-term research of Artificial Intelligence -LRB- AI -RRB- named The One Hundred Year Study on Artificial Intelligence , they cite Nils J. Nilsson s definition of AI . According to Nilsson , intelligence is a quality such that an entity would be able to solve and have foresight to problems if it is intelligent , and artificial intelligence refers to machines that are made intelligent by humans . Authors of the report furthermore quotes Nilsson s idea that different kinds and different level of intelligent entities all lie on a spectrum with multiple-dimension . To explain this point of view , they use calculator as example . As they state , a calculator shares not much similarities with nowadays AI , though it is put on the spectrum by broad interpretation -LRB- p. 12 -RRB- . This suggests that although simple devices such as calculators do not look like what people expect today s AI would be , they are AI . To conclude , authors of the report propose that manmade electronic devices that are able to complete tasks humans once completed should be regarded as AI .
From my point of view , electronic devices such as calculators that can not make decisions by themselves could not be regarded as AI . Only devices that have ability to make decisions could be considered as AI . I prefer to interpret the foresight in Nilsson s definition of AI as an ability to determine what outcomes every solution could bring and consequently find out relatively the best solution to a problem . Therefore , in my opinion it is not what Stanford s report writes that as long as a device could perform the activity humans once performed , it could be seemed as AI .
As the National Association of Credit Management -LRB- NACM -RRB- discusses in Artificial Intelligence in the Credit Department , calculators are only programed to take job of calculations for humans , and since they lack the ability of making decisions , they could not be regarded as AI . This example suggests that only devices with decision-making abilities could be called AI , which indirectly shows my point of view .
Moreover , Fernando Schwartz , a Mathematics Professor at University of Tennessee , states in his article One Data Scientist s Thoughts on Highly Intelligent Machines that when doing calculations , humans and calculators would probably adopt the same algorithm and the only distinction between them would be the speed of calculation calculators could definitely calculate much faster than human brains . Schwartz s opinion again shows a calculator s attribute of a tool . Although a calculator could enable humans do calculations more quickly and precisely , it does not do calculation itself and all algorithm it adopts are still programed by humans . As a rule of thumb , tools without decision-making abilities usually would not be considered as AI .
In Stanford s report , researchers themselves take a scheduling system of an airport as an example of AI . However , their reason for providing such example is still about a scheduling system s calculation ability . From my point of view , a scheduling system indeed could be regarded as AI , not for its capability of calculation but for its ability of making complex decisions . Different from calculators directly executing what humans expect them to execute , a scheduling system of an airport should know about all possible choices of scheduling every plane and find out the relatively best schedule for all airlines . The system is making decisions for humans , based on algorithm written by humans . Therefore , a scheduling system of an airport could be called AI because of its ability of decision-making , not because of its ability of calculation .
In conclusion , I think only electronic devices that are able to make decisions for humans could be regarded as AI .
The arguments and predictions put forth by the Study Panel concerning the
future of AI in some selected sectors are mostly well reasoned , given what happened in the
last 15 years . However , I believe the Panel is inaccurate in predicting the role that
flying vehicles play in our future and the extent of social impacts of AI in transportation .

The Panel is correct in predicting that most of the cars will have self-driving capability .
Every major auto manufacturer has either already announced future products which can self-drive
or has been actively investing in R&D . But , I disagree with the social impacts outlined in the
essay because of this adoption . The view that people will own fewer cars and live further from
work could turn out to be very wrong . Owning a car is a symbol of independence and individualism
in North America and self-driving cars will have a very tough time to change that idea . No matter
how good the public transportation and ride-sharing gets because of AI , which itself is dubious
because of infrastructure impediments as argued by the Panel itself , people will continue to own a car .
Similar argument can be made against the prediction that people will be living further away
from their work places . A self-driving car would still have the same engine to run a car ,
same roads to drive upon and would encounter the same congestion problems . Any change in
infrastructure , major or minor , is usually a very slow process . And there isn t as much rapid
progress in collaborative systems as there is in self-driving technology .

Further , I disagree with the Panel s prediction that future transportation in near term will
include flying vehicles . I believe that the likelihood of flying cars as a mode of transportation in
the next decade is slim . We have thousands of airplanes flying at a time in our sky , because there
are hundreds of air-traffic controllers across the world monitoring each and every plane . We can not
scale this solution to an urban setting . Madison is a typical North American city , which the Panel
repeatedly stated their report focusses on , with a population of 250,000 . Even if we assume ten
percent of the population adopted the technology , city should be prepared to handle 25000 flying
objects at a time . The obvious way to circumvent this problem is to develop technology so reliable
and secure to obviate air-traffic controllers and all the FAA regulations . That is highly improbable
in near term . To emphasize , there are only handful of states currently allowing auto companies to
test their self-driving technology on road . Society will be far more skeptical and anxious of flying
cars than they will be of self-driving cars . Uber and few other startups have started investing in
flying cars , but the technology is nascent . In my opinion , in a decade or so , a flying vehicle will
be analogous to a boat ride or a helicopter ride , but not mainstream . Whereas drone delivery is far more
certain to happen . One of the reasons being , an unintended drone crash would merely upset a customer
waiting for the delivery , instead of being fatal to everyone in the city .

In conclusion , infrastructure limitations and cultural factors will play a role in adoption ,
or at least in its pace , of few technologies of AI in transportation .



Challenge : In the article , `` One Hundred Year Study on Artificial Intelligence '' , the
topic of artificial intelligence integration with healthcare is expanded
upon in a manner that downplays the current quality of the healthcare sector ,
and does not focus on the practical needs and issues of medical professionals .

The article asserts that regulation and `` structural barriers '' in healthcare
are the factors preventing artificial intelligence technology from making an
impact , and that this impact is `` largely unrealized '' -LRB- 26 -RRB- . While there might
not be an issue with the logical benefits of the innovative technology , the
article seems to be implying that the healthcare sector is itself dated and
archaic in its practices , and must make use of the incoming artificial
intelligence technology to progress . It is here that the article also undermines
the already demanding and stressful duties placed on healthcare professionals .

Although the article continuously implies that it is reasonable for the
healthcare sector to be wary of new changes due to the highly volitile
environment that exists , there does not seem to be an understanding for the
need to be dynamic and flexible with regards to providing medical care .
When discussing robotics , there is mention of how any robots placed will not
be fully automated in hopes of aleviating any stress over troubleshooting or
control issues . However , the article then states that it is trivial to have
robotics assist with patient travel , but only if the patient can stand in a
walker ; any of those who are recovering from surgery or are of an old age will
have a more difficult scenario -LRB- 28-9 -RRB- . This example presents a case of limited
functionality , where in which it might not be necessary to have robotics
dedicated to such intimate actions with patients .

In the clinial environment , it can be seen that a primary care
physician diagnosis of a patient 's condition is in competition with software
that can perform a similar task . What the article is asserting is that there
should be no question of the physician 's skill ; the software is merely a
suppliment to the physician and patient , and should be used in conjunction
with the physician 's own expertise . What could arise , however , is a
disgreement between the patient and the physician . The patient , who might not
be as educated with respect to artificial intelligence and medicine , might
very well trust the software 's result over the physician 's , and attempt to
verify the software 's decision by exaggerating certain symptoms and
circumstances . This would result in more effort on the physician 's part to
provide evidence and details , which may or may not result in success .

In general , any existing technology being integrated with healthcare
systems will already pose a higher learning curve for medical professionals ,
whose focus is stricly medical related . Additionaly , technology advancements
could potentially inhibit the professional from maximizing efficiency in the
workplace ; this was exemplified in the case of the physician 's status versus
the software 's status in the eyes of the patient . At the same time , if the
technology being introduced is highly specialized , then there is the question
of the effectiveness of exisitng medical practices versus the practicality of
the new technology .
The research and application of the artificial intelligence are booming at present . From past 50 years to present , AI research and application has been studying and improving by scientists . The One Hundred Year Study on Artificial Intelligence studies the influences of AI on eight domains , which reflects different AI in different challenges . It studies the development of AI in the past 50 years and improving tendency in the next 50 years . However , it also mentions that all sorts of aspects of AI have concerns and risks . Facebook designed an AI machine , called chatbot , which could negotiate and communicate with each other via using own non-human language . This progress was breathtaking and profound , but it also existed potential risk so that the program had to be shut down . People are still scaring the development of AI because of privacy and safety concerns , but reasonable and effective utilize AI technologies will improve how we can live .
AI technologies have ethical and social issues , which result in unease for people who worry about losing jobs once the AI machines become smarter . AI machines are already and will replace some human position such that clerks , drivers , and manual labors . Moreover , artists and speakers are fear that their job may be edged out by an AI machine . People can not be good at art and science concurrently , and they also can not be good at writing and speaking concurrently . However , amazing AI technologies can be trained to connect art and science in order to draw better pictures , or trained to write and speak well . Therefore , AI may cause tragic consequences for people at present or in the near future . Nevertheless , if people change a point of view , they could find that AI will help them to improve the jobs and make it easier , rather than displacing them . AI machines are able people to access a creative method to blurry the line of art and science . In addition , for speaker , AI technologies can simulate virtual audience and environment , which resemble reality and reflect real human emotion , so that they can get effective feedback to improve their speech . There are many practical benefits for people to research AI technologies .
Expect privacy concerns , the safety issue is also a significant reason for people to opposite AI technologies . Driverless cars are already used at present , even if a usable range is not widely . The problem is safety for driverless cars , which is easy to be stolen once someone master computer skill well . In addition , if AI machines are enough smarter , which have their own non-human language like chatbots and programmers or human do not understand , they will connect the entire world AI machines by wires , and figure out how to analyze and cooperate with each other . They may think that human is threatening and would like to displace them . Therefore , it is unforeseen dangerous in the future if advanced AI machines are continuously developed . However , only if programmers proceed with caution and closely monitor when they research AI technologies , benefits from AI technological are greater than what we give up . Driverless cars reduce the rate of car accidents and solve the elder who is difficult to drive cars or people who can not drive cars .
Although developing AI technologies could cause unpredictable tragic risks , which have privacy and safety issues , giving up the development could cause greater losses . The evolution of AI technologies is a huge step for human in the future , so do not hinder its improvement .
As stated in the 100 Year Study , I don t believe AI will be successful in removing forms of bias or malpractice within policing as soon as 2030 ,
and may even be a tool to rationalize human bias when attempting predictive policing .

The first part of my criticism of the 2016 Stanford One Hundred Year Study Report is that I disagree with the plausible implementation of an AI system self monitoring police malpractice ,
until increased support of such systems from police departments increase . The report states that AI may be better for -LSB- assisting -RSB- crime prevention and prosecution by better accurately
being able to automatically classify events within a video , possibly helping provide evidence of police malpractice -LRB- p. 36 -RRB- . While I do believe that the technology can be created ,
I think that implementation of this is unlikely due to police departments being slow in implementing any form of self monitoring system such as body cameras . In 2015 , only 18 % of agencies
considered their body cameras fully operational , according to a survey of 70 law enforcement agencies conducted by the Major Cities Chiefs Association and Major County Sheriffs Association
in 2016 . This slow implementation of an old technology helps better provide context into the speed of implementing such police malpractice monitoring systems . According to a 2016 Huffpost article
titled Police Body Cameras Aren t Helping You , police unions are demanding more cash if officers are forced to wear cameras , citing higher stress levels and -LRB- increasing -RRB- complexity of the job
when an officer is being monitored . Because of the lack of police union or department support for body camera implementation , it unlikely that they will support , let alone voluntarily provide
funding for an AI software monitoring and criticizing their actions instantaneously . For this reason , I do n't believe that Police departments or State/Federal governments will choose to implement
AI in this way by 2030 , with perhaps the exception of a few democratic city legislatures . It would require much more inter-departmental support of body cameras before the next step of involving an AI is implemented .

Secondly , in the One Hundred Year Report , it is suggested that AI may be capable of helping remove some of the bias inherent in human decision making when pertaining to policing -LRB- p. 36 -RRB- .
While I think that it can be done before 2030 , it will be extremely difficult to exclude bias from any part of the AI , whether it be predictive policing computations , or humans interpretations of
the AI s conclusions . Here , I won t discuss AI reacting to biased police , as it covers similar issues discussed in my previous paragraph . Instead , I hope to attack the idea of effectively removing
bias by replacing police discretion with AI discretion . My first concern is that the AI itself will be biased , and may even discover new forms of biases -LRB- something not raised in the 100 Year Study -RRB- .
ProPublica s 2016 report titled Machine Bias discusses the dangerous racism predictive policing AI can have and the One Hundred Year Study is very aware of this . The question then becomes , do we hard
code the AI to be blind to race ? . If that is indeed the solution , it seems unlikely will we be able to hard code the AI to ignore every form of prejudice . And if we do , then what information is the AI left
with to make decisions . If hard coding isnt the solution , then how do we give the AI a sense of wrong and right when it comes to determining who it is ok to police / make assessments on . This seems to be the
likely response , but a much more difficult one that I do n't see us being able to confront by 2030 as discussed in the 100 year study . My second concern is that even if we are able to create unbiased
predictive policing AI , how will humans interpret the information . It could be that a secondary non apparent trait leads the AI to unproportionally target a minority even when not being biased toward
that minority . This conclusion from an unbiased AI authority could feed human bias and rationalize bigotry .

In conclusion , I believe there to be many more difficult issue surrounding AI s use in combating police bias that were not mentioned in the 100 Year Study . These issues , the lack of accepting self monitoring ,
the difficulty making an unbiased AI , and the worries of how humans might accept an AI s conclusion , will more than likely delay AI in this fassett beyond 2030 and pose worry some threats , that while avoidable
are definitely something to be wary of .
The Stanford study makes many claims on the future aspirations of artificial intelligence
in our everyday lives . One aspect of their argument that is unlikely , is their focus on public safety
and the integrations AI may have in this field . AI has many incredible uses in its arsenal , but
some are n't suited for every situation .
We can never really have `` enough '' eyes watching for evidence when it comes to crime .
There are several court cases that could be solved in an instant with just a small select piece of
evidence caught on camera . As stated at the beginning of Stanford 's study , there is no uniform
definition of what Artificial Intelligence really is ; but there is an agreement by many that AI is
used with great technology in order to make the difficult tasks of humans , just that easier . When
amounts of AI are put into place , we see less need for the everyday man to do parts of that job ;
we 've already seen that with self checkouts at stores , self driving vehicles , and even life decision
making with various handheld AI personas put into smartphones . My qualm with Stanford 's
explanation on public safety and security is that they are assuming that AI will have an immense
contribution for the future of human safety . I do not see this being a part of the future as they 're
stating due to dependability and delicacy .
If the United States Military started to lower their recruitment rates because they were
replacing soldiers with droids , there would be an extreme outbreak all over the country . Many
Americans feel safer under the protection of another human , rather than a robot that ca n't prove
its strength . Artificial Intelligence can only do so much when it comes to serving the same duties
as a human can . Now , Stanford 's study obviously does n't state that there are going to be robots
rolling around blending in with the crowd , but there is a strong argument for great AI
involvement in efficiencies that ca n't be met by humans . Such tasks would lower the amount of
men or women performing their duties due to their roles being replaced by an AI bot that can do
the task just as easy but without the manpower and labor . This puts a risk on humanity . Even if
these AI were to perform the task just as well in the future as previous humans could in the past ,
there is a great level of doubt that the human race would adopt such beings to be our `` protectors '' .
An active perpetrator would likely rather destroy a piece of electrical equipment than kill
a human . The delicacy of evidence with the AI exclusivity and little human interaction would
seemingly put a great fear in citizens who are supposed to be protected by such advancements . It
is natural for humans to have a slight intimidation towards one another rather than a human to an
inanimate object of some sorts . I do n't believe that AI would be put into the place of public
safety to the degree that Stanford 's study predicts due to the less safe habits that may be caused
by active criminals .
Stanford 's study poses great arguments on AI in the future in a variety of categories .
However , the public and safety likely will not turn out as AI heavy in the future as they might
initially intend . The safety measures will not be as safe as assumed in the long run and will
doubtlessly cause a deficiency of security for citizens when it comes to replacing man 's duties by
an AI bot.CS 540 : Stanford AI Report Essay

AI as a field has had its up and downs since the inception of Computer Science . Today , one could argue we are approaching an AI renaissance , where most basic tasks will be automated , and the field will be integrated with several existing fields such as finance , medicine , education , transportation etc. . However , this naturally presents some challenges , which this short essay plans to discuss , in regards to the Stanford One Hundred Year Study on AI report .

The paper argues that robot cleaners are restricted to a limited region , usually a house or a room , and mechanical problems such as single step stairs , and other mobility related issues . These issues , while relevant a few years ago , can be considered trivial today . Great developments in robotics by companies like the iRobot , Boston Dynamics etc , have shown compact robots easily dealing with such issues with little to no difficulty . Another issue the paper discusses is about getting perceptual algorithms and 3D Object recognition and mapping to work on small devices such as the Roomba . As the case of Snapchat proves , various Computer Vision algorithms can be made to work for a relatively small device such as a smartphone , while still yielding efficient results . By the end of this decade , with a decent increase in memory , these algorithms , paired with the right sensors , can easily fit on to these small devices , thereby making them more efficient , and better at their tasks .

The report also discusses about how home automation can become a huge part of people s lives , as we have already seen with devices such as the Alexa products , and the Google Home . While these devices are certainly a sign of a more automated future within households , it still holds the significant risk of lack of adequate security measures . Recently , articles have surfaced about Echo Dot owners hacking their devices and gaining root access to them . This enabled them to receive every piece of audio the device captures , even if it isn t a direct command , therefore becoming a live mic in the wrong hands . While the procedure requires a few hours , it still holds a threat in the form of second hand devices , or a device left hidden in a common room . While Amazon has reportedly fixed this bug , it still raises many questions about how secure and safe these gadgets exactly are to the common user ?

While the concept of AI and robots interacting with humans isn t exactly new , thanks to movies like 2001 : A Space Odyssey , Terminator , Blade Runner etc , they are still breaking new grounds in fields like medicine and education . While the concept is exciting and fresh , even after many theories and ideas , it still raises the questions of whether the technology has caught up with our imagination . Especially in the field of education , while most tasks , such as standardized test checking , have become automated , we still have a long way to go . While these devices are helping teachers teach and manage , they have yet to prove useful to teach advanced topics to students . For example , if a student were to have a specific problem , a teacher could ask questions to understand their exact confusion , and then remove it , and try to solidify the student s understanding . AI and NLP have not reached this level yet to completely understand a student s doubts and then clear them . This would especially prove useful for young children who find difficulty in identifying their problems concretely .

While the recent developments in AI have been fantastic , much more can be expected from the future generations of AI . It will indeed be exciting to see how the technology develops to further help humans with their day to day tasks .
Although the writer has the best intention to ensure the benefits of AI in education , we can not confirm whether the predictions of the education system in 2030 are plausible or well-functioning as the writer wished . According to this report with a time span of 15 years , we have no direct evidence to make a conclusion that the class size will be doubled with robotics ' assistance , nor the class material would be more personalized from K-12 to colleges . Without seeing the whole picture , any researches or regulations made depending on this analogy would stir up inferior impacts for our future generation .

The arguer 's reasoning linking the accessibility of online learning with the augment of class size seems reasonable on the surface , but it may not be true after further scrutiny . The possibility of automatically generating quiz questions or offering online recourse surely reduces professors ' liability . Questions randomly generated by machines , however , usually follow a pattern , which leaves a loophole for students to take advantage of . Students who score high in those questions might not fully comprehend the material . Although AI can teach people how to perform an act , it can not teach them the logic and reason behind it . How can a machine train human 's mind when itself has no conscious ? If one student is confused , one may experience difficulty seeking for personal help due to the reduced human resource . There is merit to increase the size of class for courses that require less logical thinking and mainly rely on memorization . Yet , people who want to pursue profound knowledge in higher education systems are unlikely to perform well in such setting . Without eliminating this plausibility , the author can not conclude that the augment of class size with AI 's assistance would be necessary or beneficial .

Aside from the legitimacy of the course materials generated by AI , deploying AI in nationwide scale requires the curriculum to be standardized completely . If every person is presented with the same information , it would require all instructor teaches the identical knowledge in the identical ways . What if some teachers are good with using textbooks and others prefer assigning projects ? It hinders educators from offering their special understanding of the material to educatees . Studying the same material from the same platform might deteriorate the variety of children 's learning methods . Having such a uniformed way of perceiving new information might create bias or blind spot for scholars to conduct independent research studies . In stark term , the government will be able to easily manipulate citizens ' perception of truth if everyone learns from an AI system . They can simply modify the material from a far distance . Therefore , whether AI can make learning more personalized must be based on a more thorough investigation .

Finally , the writer supports the prediction by over-generalizing the responsibility of education . Not only students need to learn a set of things , they also need to know how to learn . For college students , acquiring the ability of critical thinking is far more important than studying a file cabinet for facts . However , the machine can not provide its thought process to learners . Without knowing how to learn , students would not be able to create new innovation .

Interfering with the education system might cast treacherous damage in the long-term . Insofar , we can not prove whether AI can increase the class size , make a customized profile or educate people the ability to reason . Little reasons we have to believe replying AI to teach students would have a positive impact on the community . Rather , the best solution is to conduct a full investigation with more consideration until we can see the ins and outs . The Stanford One Hundred Years study predicts minimal advancements of AI technology in the healthcare field in the next fifteen years . While AI functionalities will improve relative to today , machines will still serve a subservient role to human clinicians . I d like to propose an alternative future where , due to increased availability of medical information , machines will play the primary role in healthcare and human clinicians will be sparsely needed .

First , I 'd like discuss the wider availability of data available for analysis , both in terms of patient reported data as well as anonymized clinician documented data . As evident by the amount of personal information freely posted on social networks , the general population is becoming numb to the idea of releasing information to unknown external entities . Letting everyone know of your status by the minute is now the norm , rather than the exception . Multiple health and fitness applications have taken advantage of this increased willingness to share by allowing individuals to share details about their daily workouts . Similarly , this increased willingness to share will allow AI technologies to analyze and detect risky behavior and promote wellbeing in day to day life . Additionally , as research initiatives such as Sync for Science take flight , patients will be given the option to donate their entire medical record for use in analytics . This step into a connected world allows machines to explore a dataset richer than we can imagine , allowing every aspect of a patient s life to be examined , analyzed , and compared .

Additionally , with technologies such as the Da Vinci robot , we will have more information than ever about all types of medical procedures . While current ventures into AI technology in the surgical realm have been focused on assisting the human physician , these platforms can be repurposed to do much more . As mentioned in the Stanford study , there s already been prototypes of surgical platforms where , in addition to assisting , the platform itself observes and documents physician actions . Using such information , these smart platforms can provide much more insight into factors affecting patient outcome . Instead of relying solely on clinical documentation , these platforms will be able to correlate each action performed by surgeons with effects on patient outcome . Combined with other available datapoints , machines will be able to provide passive assistance in suggesting the best course of treatment as well as active intervention in replicating strategies with the highest impact on patient wellness .

While increased connectivity and data availability will allow AI technology to grow , perform common procedures , and suggest preventative measures , I am not implying that it will be able to fully replace human doctors . While machines may be able to conduct most , if not all , common treatments , physicians are needed for the rare procedures . By definition , a rare procedure may not be performed frequently enough for machines to learn and replicate . I imagine human physicians will be akin to specialists the machine will take care of most , if not all , of your ailments , but will pull in a human specialist when it can not . However , machines will be able to improve access to these human specialists even with technology available today , the concept of telemedicine has already taken off , allowing doctors to provide treatment for patients regardless of physical location . With more sophisticated AIs and available data , telemedicine can take a big step forward the tag team of machines to take care of common ailments and doctors to visit the unusual or uncommon patients will allow for higher throughput of sick patients and provide more comprehensive care than before.Regarding AI 's influence on human 's entertainment , report `` ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 '' lists many advanced technologies and innovative entertain approaches . The report also comes up with one concern about AI-driven entertainment : they may reduce people 's time spent on social interactions . This concern is indeed a considerable issue , but I would say there is a much larger threat : new entertaining approaches are causing psychological and neurological damages on human , especially the teenagers .

Just like some AI 's behaviors are driven by algorithms , human 's behaviors are driven by the rewarding system in their brains . In order to get the pleasure -LRB- mainly dopamine and other neurotransmitters -RRB- provided by the rewarding system , brain would lead us to make an effort to do what we are doing . For example , in order to get the pleasure of `` getting an A '' , we would conscientiously spend time writing essays and review materials . And only after contributing a large effort can we enjoy the pleasure . Simply thinking about `` I want to get an A '' does not guarantee an A and would not generate any pleasure .

Before The Age of Information , the distance between thinking about `` get an A '' and getting an A in reality is long . It is impossible for someone to make his thoughts come to real in instant time . Even the popularity of game play machines did n't change this system . One can say '' I want to play game boy '' , but in rare cases can that guy get a game boy just in seconds . In most circumstances , he or she have to come back home or make some other efforts to enjoy the pleasure .

However , the emergence of smart phones and portable smart phone games changed everything . Nowadays , smart phones can be equipped with really interesting games which can be activated seconds after users open their phones . After thinking about `` I want to play Clash of Clans '' , it only takes someone two actions to fulfill this wish : grab the phone out of the pocket , and open the app . The distance between thinking of a pleasure and getting that pleasure has been extremely shortened .

This kind of instant pleasure has a notorious influence on our brains . To start with , excessive instant pleasure would produce more dopamine than the brain need to maintain its function . In order to reach a balance between dopamine and other substances , brain would start a self-rebalance -- reduce the production of dopamine . In long runs , this phenomenon would reduce the over-all dopamine concentration in the brain and thus decline brain performance . The low dopamine level also leads to more smart-phone playing , which forms a vicious circle . This mechanics is just the same as how some narcotic drugs destroy brains .

On the other hand , pleasure is no longer something hard to get nowadays . Just by pulling out our phones from pocket brings some pleasure . We no longer need to spare no effort to fight for rewards . Our inborn ability to postpone pleasure and plan for the future would shrink due to lack of reinforcements . The `` will power '' which helps us strive for achievement could also be weakened . For teenagers , they may find that pleasure provided by AI-driven entertainment to be sufficient for their needs . The meaning in working and studying might be doubted by them and causes a reduction in overall performance .

This phenomenon is not limited to smart phone games . Facebooks , Instagram and even some online study websites would unintentionally produce environments for instant pleasure . Furthermore , the development of decision-making AI may reduce more human efforts in the future . It would be dangerous to ignore this problem . The Stanford 100 Year Study on Artificial Intelligence provides an in-depth look into how
the top Artificial Intelligence -LRB- AI -RRB- professionals believe AI should be implemented . Though the
report does touch on the importance of democratically implementing AI in order to benefit
everyone equally , this will be difficult to accomplish without stern government regulation . Elon
Musk recently addressed AI s potential risks by saying , if left unchecked , AI will follow the will
of people that establish its optimization function , and if that is not well thought out , it could
have quite a bad outcome . ''
Economic inequality has only gotten worse in recent years . the top 1 % , on average , earn
three times as much , today , -LRB- $ 1.3 mil -RRB- as they did in the 1980 s , while the bottom 50 % of the
American population earn an average of $ 16,000 -LRB- which hasn t risen in over three decades -RRB- .
Without the government regulating how corporations implement AI , nothing would stop them
from using AI to continue widening this economic gap .
Furthermore , the types of jobs AI will replace first aren t the most glamorous , but they
do currently allow people to make a living . The authors of the report claim that they , see AI as
replacing tasks rather than jobs , while also helping to create new kinds of jobs . While it is true
that AI will produce a lot of high-level tech jobs , it will be hard for entrenched professionals to
pivot into a new job if they ve been replaced by AI . Truck drivers are a prime example . Truck
drivers commonly have very few transferable skills ; when they are inevitably replaced by
autonomously driven vehicles these drivers will be forced into a job market that sees no
value in their past work experience . It doesn t stop there either , receptionists , librarians and
even highly regarded professions such as radiologists will face the potential of being
displaced by AI .
So what happens to these displaced workers ? Surely some will be able to pivot into
new jobs , but those who can t will become unemployed . When this reality settles in , those
who have been displaced will develop a distrust of AI because they will feel as if AI has
robbed them of their ability to make a living . Combine that with the fact that a considerable
portion of the public already distrust AI , and this could lead to serious morale issues
regarding funding and implementation of AI . This distrust is exactly what the Stanford AI
project set out to improve .
Thankfully , one of the main goals of a government is to create jobs for its citizens .
Programs to help teach displaced workers new and valuable skills is one way to help ease the
transition to AI . Additionally , government regulation can help mitigate job displacement by
finding new value in human labor to create new jobs that AI can t replace . It s hard to say for
sure what these jobs will be , but experts predict that implementing AI will require new jobs
regarding , sensor technology , managing corporate social media plans , creating new
products , improved user interfaces , novel devices and fresh ideas .
Finally , the government must ensure that the power of AI is used for the good of all .
The implementation of AI is inevitable , it s up to the government to ensure that the right
people are in charge of democratically implementing this powerful technology .

http://money.cnn.com/2016/12/22/news/economy/us-inequality-worse/index.html

https://www.usatoday.com/story/tech/talkingtech/2017/07/17/musk-government-needs-regulate -
artificial-intelligence/484318001 /

https://blog.hubspot.com/marketing/jobs-artificial-intelligence-will-replace
http://www.pewinternet.org/2014/08/06/future-of-jobs

Artificial Intelligence is inarguably changing the way people interact with each other and the world in which they live . Whether many of its affects are to the benefit or detriment of mankind is yet to be seen , but certain disruptions may have a more negative impact than others . One industry that artificial intelligence is currently disrupting is that of transportation . This article claims that self-driving cars will displace the need for public transportation . Mass public transportation is used by much of the country and through several forms including busses , subways , and etc. . Stating an overhaul of this system is a large measure to undertake , and it is arguably not a viable solution for everyone . This statement may hold true for those who are wealthy , enabled , and privileged but the majority of the modern world can not afford the luxury of self-driving cars .
Self-driving cars have a long way to go as far as accessibility is concerned . There are some self-driving cars on the market designed for those in wheelchairs , but the majority do not have features to help these people whereas public busses have designated seats for the disabled and for those who are elderly . Obstacles exist that separate those who are poor from self-driving cars , even if we came to the point where self-driving cars have become commercial . To reserve a self-driving car , one must use a smartphone . Those who can not afford a more expensive phone and Internet data thus would not be able to remotely reserve a ride . As the transaction happens online , a credit card is also required . People who do not have access to credit or online banking are thus faced with yet another barrier to self-driving cars . Concern arises that , in the case cities begin to fund self-driving cars in lieu of mass public transportation , self-driving car companies could at any point decide to discontinue the contracts and leave large amounts of disadvantaged people without reliable transportation .
Ignoring other barriers to the replacement of mass public transit with self-driving cars , population dense areas have little space on the roads for everyone to be in spacious cars of his or her own . Busses can hold significantly more people per square foot than the typical self-driving car . Particularly two story busses , such as the double decker Megabus , have a large advantage over Tesla cars in this regard . Replacing current transit systems such as these busses and trains with the currently existing self-driving cars could easily lead to gridlock in high traffic areas . This also assumes that it would be economically viable to remove the infrastructure of previously existing underground subway systems and busses . Current mass public transportation systems operate using predetermined stops where several people can board at a single time ; picking up people minutes apart -LRB- for convenience s sake -RRB- then dropping them off sporadically would be a time consuming process , which is especially true if self-driving cars were designed to hold more people in an effort to compete with mass public transportation .
In a situationally ideal world , with a low population density and able , affluent residents , there could be arguments that self-driving cars may be rational choices . However , most of the country -LRB- and world -RRB- does not fit into this narrow category . Artificial intelligence and self-driving cars have a significant amount of necessary improvement before permanently displacing mass public transportation .
In '' Artificial Intelligence and Life in 2030 '' , the one Hundred year Study on Artificial Intelligence , claims of widespread adoption of safety critical automation seems to be focused more on the technologies available and passingly mentions other influences as a potential roadblocks . Specifically , self-driving cars at its most optimistic approximation of 3 years until widespread adoption seems to not take in general public feedback into the equation . Subjects such as safety , ethics , and law will deeply impact and challenge the overall adoption of presented in the study and will delay said adoption until all intricacies are worked out .
Safety as an aspect of self-driving cars will rule all implementation of the cars ability . The self-driving car will have to react to its environment in a predictable and safe manner . Widespread adoption of self-driving cars will bring safety tests to a new level as the sheer volume of autonomous cars will only drive self-driving car accidents up . A new definition of safe will have to be defined for these vehicles .
Defining a safe self-driving car strains ethics regarding its own safety . Autonomous cars will assumedly drive down driving related accidents , otherwise mass adoption would be out of the question . How safe does a self-driving car have to be ? A metric would have to be recorded as to measure the vehicles safety . A metric that could be reasonably described is its percent safety , a percentage based on how safe the vehicle would as compared to a human driver , with 100 % being the vehicle makes all mistakes a human driver could make -LRB- including deadly -RRB- and 0 % being the vehicle never makes mistakes . In a perfect world , all autonomous cars would have a percent safety of 0 % , but the world is not perfect . At what percent safety deems the vehicle as safe enough ? Who is qualified to determine this value ? This ends up being a real world implementation of the Trolley problem . Morally speaking , a lower percent safety will always be better . Participation in setting a reasonable percent safety constitutes assumption of responsibility of the lives risked . Furthermore , setting any percent safety at all violates the incommensurability of human life . The only acceptable percent safety of 0 % is impossible to achieve , especially since the first death related to self-driving cars has already occurred . Who assumes responsibility of lives risked ? Would it be the at the hands of the individual who set the required percent safety or the agency who developed the self-driving car ? These questions would have to be answered not only by the public , but with new social standards backed by law making .
All ethical issues relating to self-driving cars would have to imbue itself into law . Development of said laws will take time , as mass adoption of AI would have to occur before the solution to the proposed ethical problems could commence . Not only would this set the standard for all safety critical automation done by AI , but also must take into consideration other industries , as self-driving cars are not the only safety critical automation available . This whole process could take an indefinite time , as the moral problems described could easily implant itself in our current socio-political climate of today .
Challenge statement :
The article is over optimistic on AI in transportation . It predicts that
autonomous transportation will be commonplace in the near future just based
on limited information and underestimate the difficulty of self-driving .

The paper lists many achievements such as GPS , ABS and TCS in the cars .
They are huge progresses in the automobile industry , but it is hard to
link them with Artificial Intelligence . These techniques are all about
sensing and controling . Even though sensing and controling can be
regarded as a kind of intelligence , it is relatively simple .
These functionalities can be implemented by determining some if
conditions and have nothing to do with complex analysis and reasoning .
These functionalities are a success of control theory and sensing
technologies , but not a success of AI .

The real application scenes to demonstrate the power of AI are tasks like
self-driving . It is much more challenging than GPS , ABS and TCS . The paper
also mention the self-driving car techniques and show that Google 's and
Tesla 's self-driving cars have logged 1.5 million miles with a few
disengagements . It also predicts that in the near future , advanced sensors
and sesning algorithms will surpass human 's performance and cites a report
saying self-driving cars will be widely adopted by 2020 .

However , the information given are very limited to draw a conclusion that
self-driving cars would become a reality soon . The paper does not research
the challenges facing self-driving . From my perspective the most challenging
problem is understanding the varying and complicated environments . There
are many corner cases . Failing to handle them will cause the car to misbehave ,
which is extremely serious for the safety of the car . Also the self-driving
cars ' vision systems needs to consider many factors , illumination , location ,
objects and distances . To my best knowledge , although the state-of-the-art
computer vision algorithms outperform human in some benchmark dataset , there
is no evidence showing that computer vision systems can perform as well as
human in reality . In fact , computer vision systems are sometimes easily
fooled by change of illumination , motions and some other conditions .
I do not know where the authors got the confidence that self-driving cars
will be achieved by 2020 .

Regarding the experiments of self-drving cars from Google and Tesla , even
the self-driving cars performs excellently in the city road with zero
accident rates , there are many other terrain and road conditions .
Working well in cities does not necessarily mean it will also work in other
cases . Let alone there are crashes and disengagements in the city road
tests . Right now , Tesla 's self-driving cars still needs human monitoring ,
which is far from the goal of self-driving .

The authors strengthen on how advanced the sensors will be while focus
on how to tackling challenging AI problems , like objective
detections/tracking and scene analysis . They are on the wrong
track . Self-driving cars can not be implemented by just super-human
performance sensing technologies . On the other side , it seems the
authors conduct a careful research about the current bottlenecks in
computer vision , or try to find a breakthrough . They underestimate
the difficulty of self-drivng .

The authors also lists benefits of self-driving cars . Some of them
are not so harmonic with commensense need verifications , including
lengthening people 's life expectancy and eliminating the need to own
a vehicle due to car sharing .

The Stanford 100 year study on Artificial Intelligence does a good job of defining AI and explaining why the term encompasses more than one simple definition . It also summarizes how AI is used in our everyday lives and paints a picture for current and potential future uses and fields where it could be utilized .
While most of the 52 page study is descriptive and discusses factual information , a few significant assumptions and overstatements are made .
My first questions are posed by the following quote from the report : `` As cars will become better drivers than people , city-dwellers will own fewer cars , live further from work , and spend time differently , leading to an entirely new urban organization . Further , in the typical North American city in 2030 , changes won t be limited to cars and trucks , but are likely to include flying vehicles and personal robots , and will raise social , ethical and policy issues . '' Self-driving car technology is mentioned throughout the report and used commonly as examples . The authors of the study are overly optimistic as to how fast this technology will be able to advance . While personal robots are gaining traction relatively quickly , it is especially a far cry that flying vehicles will be commonplace by 2030 especially to the proposed extent that they will raise policy issues . The study mentions that self-driving cars were theorized as early as the early 2000s but didn t start gaining much traction until around 2015 . Yet , self-driving cars are to be seen as more of a luxury at present ; they are far from affordable and not in common commercial use as of yet . Tesla and Google are still in the process of optimizing this technology to attempt to prepare it for more public and practical use . Seeing that it has taken 15 years for self-driving car technology to see a serious push in interest , it will likely take as much if not more time for commercial flying car concepts to see life .
At the current rate , this hypothesized new urban organization isn t likely to take place till around 2035 or 2040 as finances will also pose an issue . It is likely that only the wealthiest class of people will be able to afford this new AI until then , and the study makes a significant assumption as to how self-driving cars could change our lives -LRB- or not -RRB- .
The study s overstatement of current car technology is further outlined by the following quote : `` Current cars can park themselves , perform adaptive cruise control on highways , steer themselves during stop-and-go traffic , and alert drivers about objects in blind spots during lane changes . '' While it is true that this technology exists , it is rare technology and not commonplace in today s vehicles , rather only in higher end more expensive models and makers . As such , it is apparent that the study over-generalizes the present technology and theories about how it affects society and will affect it in the future .
Finally , the study understates potential economic impacts and security issues of growing AI technology as a whole . It mentions that AI will cut costs and help the economy by making many current jobs automated and provide more precision but it overlooks other potential economic and societal consequences such as many people losing their jobs , leading to unemployment and decreased purchasing power , weakening the economy . In terms of security , at the current rate of growth in the field of AI , it is that much more essential that researchers focus on limiting certain aspects of robots and AIs to prevent them from becoming all powerful and indestructible .
In the report of Stanford 100 year study on artificial intelligence , the author mentioned that there will be auto driving cars in the future . And ethical and legal programs will arise , so the cars need to be programmed in a fashion to avoid such problems . However , is it really a good idea to hand over ethical problems to machines and artificial intelligence ? Maybe it is okay to hand over some small decisions to machines , but for some important decisions that may cause someone to die , can we still rely on some programmed machines ? For example , if an auto driving car is on the road and someone started trespassing the road . It is already too late to stop the car . Will the car hit the trespasser , or will the car run over an innocent bystander ? Or will the car run into a wall and put its owner s life at risk ? It is a very tough decision . For us human , if such a situation really happened we may not have enough time to think thoroughly to make the decision , but a machine probably have time to do enough calculations to make its decision . Let s assume that we have time , which of the three choices will we choose ? It is even a tough call for us . Should we run into the trespasser because it s his fault to cross the road at the wrong time ? What is a group of people is trespassing ? This is a question with no correct answer . No matter which choice the car makes , someone will get hurt , or possibly die .
If it is even such a hard choice for us , how can we hand over the decision of letting who to live into a machine s mind so easily ? This situation is just an example , but we must assume worse things can happen in real life , and make the machine can handle whatever rough situations that are thrown at it . If someone is killed in an incident like this one , who should be responsible ? It is the trespasser who started the problem , but it is the car that made the decision of who or what to hit . Some cases might be very ambiguous and a very tough call for the judge to decide who should be responsible . There is still a lot of things to think and a lot of rules to make before we can mass implement technologies like auto driving . While researching such technologies , we should foresee similar issues like this one and establish some ground rules . Of cause the rules will not be perfect , but it will at least put some restrictions on the companies seeking business in this field . This will stop some potential exploits . These rules and laws can be perfected overtime , both before and after the technology itself become mature . At that time , auto driving will probably be fine in most situations but when facing such an ethical dilemma , will a protocol for the AI ever be developed to handle a situation like this ?
As AI becomes an increasingly prevalent part of the world , its impacts are becoming evermore apparent . The One Hundred Year Study on Artificial Intelligence does a fantastic job in describing the current state of AI and where it 's headed in the future . Despite it 's exemplary evaluation , there are two statements made that I believe are improper assumptions , which will be independently challenged .

First of all , In the portion of the study addressing AI policy , the essay claims : `` Frustration in carrying out functions promised by a system diminishes people 's trust and reduces their willingness to use the system in the future . '' I believe this is a bad assumption because of all the evident counterexamples we can find in society today . There are numerous instances of systems repeatedly failing people , but nonetheless , individuals still trust those systems . For example , healthcare professionals in the United States and around the world make occasional mistakes , some of which are life threatening . Despite this , people still trust doctors and healthcare institutions . Another example is the public school system . The public school system regularly fails young individuals , which negatively affects the rest of their life . However , society maintains this institution because we know it produces a far superior outcome than not having one . Likewise , we still put our full faith in doctors despite their shortcomings because we know the chances of a preferable outcome are significantly higher .

In addition , the study states : `` Likewise , AI could widen existing inequalities of opportunity if access to AI technologies -- along with the high-powered computation and large-scale data that fuel many of them -- is unfairly distributed across society . '' I do not believe that AI has a high chance of producing greater inequalities -LRB- of opportunity -RRB- for two reasons . The first reason is that advancements in technology have greatly reduced inequality , far more than it has increased it . For example , technology has reduced the once massive gap in expected lifespans of rich and non-rich Americans . More than this , the way in which Americans live life is more equal than ever , and has provided the most equal playing field of all time . For instance , you can learn anything on the Internet , which can provide you with opportunities unimaginable to generations before us . As a result of this , information is no longer restricted to a small subset of people . Additionally , a large majority of the population , both rich and non-rich , have access to resources like cars and smartphones , which makes the way we all live our everyday lives more equal than ever . The second reason I do n't believe AI has much potential to lead to inequalities of opportunity is that AI will rapidly accelerate the inevitable trend towards a post-scarcity society . A post-scarcity society will completely change the way everyone lives his or her lives . In this future with more resources than needs , everyone will have the opportunity to pursue their goals without needing to worry about having enough to meet their basic needs and more . Equality of opportunity will be bountiful when everybody is provided with virtually everything they need to succeed and basic survival is no longer a roadblock to success .

Artificial Intelligence is an extremely diverse field with numerous applications , and the Stanford One Hundred Year Study on Artificial Intelligence sheds light on many of them . The article states how artificial intelligence will have numerous benefits that improve aspects of life , but fails to mention the impact that artificial intelligence could have on the employment of the public . As technology becomes more intelligent , automation and intelligent-algorithms will take the place of numerous existing jobs . The article also states the possible applications of artificial intelligence in the education sector without considering the disadvantages of doing so .

The article mentions the application of artificial intelligence in transportation . Its initial applications would be self-driving vehicles for delivery , services , public transportation , On-demand transportation , personal transports etc. . These industries employ millions of people worldwide . It won t be long before traffic system management and monitoring , manufacturing of products , etc are also run by automated-intelligent systems . In the US alone , only transportation and its related businesses contribute to around thirteen million employees . Although experts say that technologies generate as many jobs as they occupy , in the case of transportation artificial intelligence stands to replace nearly every step of the transportation industry and make it entirely automated . This will not only take away numerous existing jobs but will most likely fail to create the same quantity of jobs . Thus , application of artificial intelligence in transportation could leave millions of people unemployed .

Advancement of technology has always had an impact on labor demands and artificial intelligence will be no different . As artificial intelligence advances the capabilities of machines , the requirements of jobs will increase . More skills and knowledge will be needed for the jobs which will not be taken up by machines . This will mainly affect those jobs that require low to medium skills . As majority of the people are employed at low to medium skill jobs , they will find it hard to keep up with or acquire the additional skills and knowledge required . This will further increase the unemployment numbers . In the US , the unemployment rate is about four and half percent . The application of artificial intelligence to employment could worsen the unemployment percentage .

The article mentions that application of artificial intelligence to education sector has improved online tutoring and made it accessible to a larger body of students . This though has increased the reach of tutoring , the larger body as made it less effective . In majority of the cases , online credentials are not considered credible . Additionally , the article mentions how online classes are tailored to suit every individual to facilitate learning . One major drawback of this is that by having tutoring tailored for each individual , those individuals do not acquire the ability of adapting to situation , being flexible and dealing with unsuitable conditions . Teaching robots that can be used to teach children will further reduce the human to human interaction of children which is essential , especially at early ages . Artificial intelligence in education comes with numerous flaws that accompany certain benefits .

Artificial Intelligence is a greatly growing field but with every benefit comes a drawback and these drawbacks must be carefully considered . Applying artificial intelligence in the transportation industry is not worth the increased unemployment and artificial intelligence in education will be detrimental to learning .
Stanford 's 100 Year Study on Artificial Intelligence details the plan for a 100-year investigation into Artificial Intelligence and its effects on people , communities , and society . To assess the progress and state of AI the Study Committee forms a study panel every five years to review advances in the field and predict what may be on the horizon . In addition to technical aspects of AI , the study plans to include details on societal facets of the AI issue , such as ethics and economics .
The inaugural study panel was formed in 2015 and consisted of seventeen AI experts and other scholars versed in AI from a variety of fields . The focus of this panel 's study was `` AI and Life in 2030 '' to emphasize that various aspects of AI will not evolve independently of each other or of other changes in technology and society . They divided their analyses into eight domains in which they believed AI may have relevant impacts and considered how they may manifest in an average North American city . These areas are transportation , service robots , healthcare , education , low-resource communities , public safety , workplace , and entertainment
The panel offered interesting insights into how AI may affect each of the specified domains and did a commendable job balancing some of the more fantastical possibilities of AI with more conservative estimates of how the technology may actually progress . Overall , I agreed with and was intrigued by an overwhelming majority of their assessments and predictions . However , there were some propositions made by the panel that I disagree with . Specifically , I challenge their expectation that driverless automobiles will have the massive effect they have predicted by the year 2030 . Primarily due to government regulations , industry activities to slow its progress -- massive jobs in driving , and the lesser educated being unwilling to place trust in AI systems .
I think the panel particularly underestimates the lengths that corporations will go to protect the industry generating their profits from becoming outdated . I imagine many companies and employees in the transportation sector will vigorously lobby politicians to restrict and slow the migration to autonomous driving with legislation and regulation . Freight jobs are one of the most common in the United States , a switch to AI controlled vehicles and handling services could leave millions without employment . I think that the reluctance of these citizens to accept that their job is no longer needed and switch professions will add to pressures impeding the adoption of AI .
They also assert that autonomous flying vehicles will be commonplace , and while small flying drones will likely be more prevalent I do not believe public air travel will as quickly become AI controlled . While autopilot systems are commonplace today during periods of predictable conditions , I think that human pilots will be necessary and desired for far longer than the next 13 years , particularly for takeoff and landing . The variable and complex environment which must be adapted to for air navigation seems to me to be a more difficult problem than automobile travel , particularly in hazardous weather like storms and blizzards . Additionally , it is very possible that it would not be as profitable as the automation of cars , leaving less of an incentive for speedy development .

In Artificial Intelligence and Life In 2030 , the authors assert that the governments should hire AI experts and make policies to mitigate the possible inequalities brought by the deployment of Artificial Intelligence . I agree that it is necessary to share the fruits of AI between people from all kinds of social classes . However , I don t think the proposed approaches in the article are feasible . There are still some obstacles to implementing the policies assuming they are reasonable .
The first big challenge is the shortage of expertise . With the boom of AI-related business , in the industries , there is a growing demand for AI experts . The new graduates from top CS programs are chased by the big tech companies in Silicon Valley and all over the world , not to mention the leading figures in this field . Someone have been worried about the migration of AI researchers from the academia to the industry . They think the academic communications and publications will be hindered by the barriers between different companies . Thus , it is a challenging task for governments to find eligible candidates . Moreover , the government , due to its particularity , is unable to provide the same salaries and treatment as the tech companies offer . For example , the specialists can earn six-figure annul salaries with also stock shares in companies like Google and Uber . In this sense , the governments are not very competitive in attracting the talents . Occasionally , the experts in the government can influence the formulation of the policy , but this is not always the case . For most of the governments with limited budget , an alternative way is to hire some experts as external consultants when needed .
If the governments are very fortunate to find people they want on the job market , new challenge arises . Is there a single policy that work for all the cities in the North America ? If not , Who is responsible for the coordination nationally ? What if there are more prominent issues on the political agenda ? To answer these questions , we can look at those companies that are most heavily invested in Artificial Intelligence . Unsurprisingly , they are all giants in the Information Technology industry . They have enough capital as well as massive data , which is the fuel for the deep learning algorithms . The development of Artificial Intelligence become one of their main strategies since the immense potential of AI in making more profits . There is little chance that they will invest in products that are hard to commercialized . If the potential policies affect their interest , they will spare no effort in political lobbying of stop the policy . On the contrary , the people who suffered the most by Artificial Intelligence in the near future are the cleaners , the truck drivers and the gardeners etc. . How can we accommodate these people ? Whether the new leaders in AI or the government should pay them compensations ? As we can imagine , there will be lots of back and forth in the policy-making process . And These vulnerable groups of people are in no ways the opponents of the IT giants .
The report firstly , states categorically that the study panel had found no cause to implicate AI as a threat to humanity . The report extends its statement by passing a prediction ascertaining the safety of human future . On the flip side , a lot of business leaders and researchers have expressed their apprehensions regarding the safety of humans ' due to the unforeseeable nature of A.I. . One thing that statements such as the reports ' try to prove is the predictable nature of A.I. To the contrary , many experts and including the report at other instances believe A.I to be an extremely unpredictable field/subject . This unpredictable nature of A.I not only questions the developments in this field but also sheds skepticism on the future human safety . Elon Musk has been quite vocal about the perils of extremely advanced A.I. . He believes A.I. at the current pace will turn devastating self-learning machines against their creators . Deepmind , which is a start-up acquired by google , is playing a significant role in making systems , which when given a raw set of data , learn and adapt to general situations automatically . Surprisingly , these machines are not pre-programmed . The report mainly bases its assumptions and proclamations of safety on A.I. being specific to a given field . However , the projects in Deepmind are inherently based on general items hence , paving way to artificial general intelligence . Further , it is alarming to know that , google a very `` information rich '' corporation , has been using Deepmind algorithms to help devise various polices based on their massive user data . Hence this uncertain nature of A.I brings ambiguity to the state of human safety . Another recent example to add to this ambiguous nature is Google 's Neural machine translation -LRB- GNMT -RRB- system which has been able to establish intuition from human languages . This project , which was mostly used for language translation , developed the notion of meaning for words from a given language leading to wide spread speculation that an artificial language was being used by the system to achieve this . Understanding the meaning and developing intuition behind human language are quite different from existing natural language models which predict suitable words from data . The basic things which separate humans from machines are closely being bridged thus adding to the dense complexity of the field . Therefore , questioning the future of humans and their safety .

Secondly , the report talks about A.I. entering the workplace gradually and the replacement of jobs being a gradual process . The report bases this assumption on historical employment data . However , historically jobs have been replaced by machines but not by very intelligent ones . The degree of intelligence of machines has grown exponentially . Machines are becoming more and more versatile . Our computers can be calculators , entertainers , compilers , and what not ? Our computers can now also implement complicated machine learning algorithms with the help of libraries such as Tensorflow and Pytorch . With dropping prices of physical sensors , computational power and , memory accompanied by a plethora of data , serviceability of A.I has grown aggressively . Hence , commercial corporations will replace jobs with these intelligent , less expensive and accessible machines within no time . The moment a break-through is registered , an affordable and more accessible version appears in the markets almost instantaneously . Roomba , as mentioned in the report is a good example . Hence , factors such as lowering prices of hardware components , increasing accessibility to A.I. would not make the change in jobs a gradual but a spontaneous process .

In conclusion , given the unpredictable nature of A.I. , reports such as these can not ascertain the human safety . Further , due to the increased accessibility and lowering prices , corporations will be quick but not gradual in replacing jobs .

AI has many prospects for the future that are not being met in the present , namely the use of AI in low-resource communities and for elder care . In addition to these concerns there is the problem that a large portion of our society actively rejects innovations that alter their current lifestyles .
There is some talk in the report about potential solutions to these problems but the solutions would require the collaboration of many different personalities in order to come to fruition . For example , AI systems could be of great use for low-resource communities , but the funding is scarce as it is not commercially viable . AI research is being pushed first and foremost towards commercial applications to increase profit margins . If it is not profitable it is not important in the corporate spectrum , whom fund current research . There are , of course , solutions to these problems that will most likely be solved moving forward , but the problem is that it will take a while for these Good Samaritan projects to see proper funding .
The elderly also do not currently have any AI assistance available , as AI technology has thus far been applied towards commercial interests as stated previously . Understandably , creating efficient AI systems to address concerns of the elderly would require immense delicacy as the elderly are a high risk group . The potential health risks and legal backlash for any accidents could reflect poorly on AI as a whole and push the public away . All said , elderly care still represents a perfect chance to showcase AI technologies and assist in establishing its public image .
There will always be a portion of our society that will reject this change outright . A significant portion of the US population -LRB- ~ 12 % -RRB- still do not use the internet -LSB- 1 -RSB- . If the perceived effects of AI reach the levels mentioned in the report -LRB- i.e. , in fifteen years everyday life will change drastically -RRB- , these stragglers will be left to the wayside . These people must be accounted for and will still be able to function within our new society .
On the complete opposite side of the spectrum , there are bound to be a much greater majority of individuals who will learn to rely heavily on these new technologies . This report speaks briefly about the impending effects that readily available AI technology for everyday use may have on the general public s social and societal interactions . With help always readily available , and everyday tasks facilitated by AI systems ; will the average person become lazier and less involved ? Will the public utilize this extra time stemming from having less chores to do , or abuse it ?
In all , AI technologies need to begin to focus on a broader spectrum of issues in order to help society . Funding needs to find its way into more philanthropic endeavor so as to increase its stock in humanity and facilitate AI s public image . User friendliness needs to be one of the more pressing concerns of all AI systems being implemented . This is vital if a smooth transition into an AI world is desired .
-LSB- 1 -RSB- http://www.pewresearch.org/fact-tank/2017/01/12/evolution-of-technology/


Challenge : A key aspect of the report that warrants a rebuttal is the discussion on regulation and overall policy . While I concur that `` inappropriate regulatory activity would be a tragic mistake '' , the use of `` broad legal mandates coupled with tough transparency requirements and meaningful enforcement '' as an example does not provide a clear enough blueprint of an effective policy strategy to address the advent of emerging technologies , and we must clearly call out the need for an agile regulatory framework to keep up with the changes that will be presented by AI .

A great example where innovation has outpaced regulation is the advent of crowdsourced jobs facilitated by technology , such as on-demand transportation services -LRB- Uber and Lyft -RRB- as well as housing accommodations -LRB- AirBnB -RRB- . In this scenario , many cities and states had to reactively put in regulation to adjust to these technologies to help protect taxi and hotel companies . This area would have been difficult to put regulation into place in advance for , mainly because of a lack of a foresight in the ability of a centralized technology to reduce the barrier to entry allowing a person to effectively rent out their living space or find people to transport between locations . I would argue that the ability to react quickly and put regulation in place for this would outweigh the value of focusing on an overall policy of broad legal mandates not specific to the industry that does not address the micro-level regulations that had to be reviewed due to the technological changes .

Given the potentially large volume of disruptive technologies that will come out of AI-based research and development , there needs to be an agile and flexible regulatory framework that can proactively identify these technologies as they emerge . Once they are identified , governing bodies should collaborate with citizens and industry representatives to identify the areas of economic risk , such as loss of jobs , as well as new legal dilemmas , such as the one posed by the person -LRB- s -RRB- liable for accidents caused by an AI-driven motor vehicle mentioned in the report . The flexibility provided by such a framework would allow all parties to participate in a structured iterative process that is able to keep up with the changes in the technology as well as the international landscape of AI in our increasingly globalized world so that we do not fall behind in our ability to innovate .

They do offer a more generalized statement on the subject later in the report :

`` Given the current sector-specific regulation of US industries , new or retooled laws and policies will be needed to address the widespread impacts AI is likely to bring . Rather than more or stricter regulation , policies should be designed to encourage helpful innovation , generate and transfer expertise , and foster broad corporate and civic responsibility for addressing critical societal issues raised by these technologies ''

In addition to the above they also call for a path towards gaining technical expertise in AI , removing impediments to AI research policy , and increasing funding for said studies .
While these statements do touch on some high level principles that I can agree with , they are far from emphasizing the rapid speed of changes that we may expect to see in the coming years that will be facilitated by AI . Because of this and the normal sluggish pace at which changes in government regulations typically occur , I would argue that they should also be calling for an agile regulatory environment that can quickly adapt to the changes as they happen so that we are not exposed to situations where we are poorly equipped to handle disruption or pursue innovations .
In the present situation of the world , there is disparity in the use of technology amongst various populations . I strongly believe that the upper limit of advancement of technology is moving rapidly to meet the demands of the relatively more technologically savvy people , whereas the lower limit still needs to be pushed a lot further for the rest of the population to catch up . Currently , the reach of artificial intelligence is limited to the developed countries and there is not much work being done to introduce this technology to make lives better for the rural population of the world .

The report talks about the use and advancement of artificial intelligence in the countries of North America and not much about the other less fortunate regions of the world . AI has a lot of potential to solve the basic problems people in rural and less developed areas face like sanitation , healthcare infrastructure and education . As per the report , a lot of research and innovation is being done in AI subfields like machine learning and pattern recognition . If AI is made to be incorporated in these lesser privileged areas , in a few years there could be rapid progress in the standard of living of the occupants of these regions . Of course , a lot capital would be needed to introduce AI to the rural regions , but once it s done , the progress could be exponential . Not to forget , implementing AI in these regions to make underprivileged lives better would build trust for AI systems in other parts of the world .

One of the biggest obstacles that arise when trying to introduce AI methodologies in the lower economies would be the absence of enough data to build AI systems upon . As we have seen from the report , data collection is fundamental for most types of AI systems , therefore , the initial step could be to collect enough data about the population . For instance , when AI is in healthcare , health data is collected using personalized wearable devices to better predict the disease by matching symptoms from the data set . Unfortunately , data collection devices like wearables are not common in such low resource communities and that is where capital investment comes in . Since general health may vary from population to population , depending upon factors like geography and dietary habits , data collected for a population would not be appropriate for another .

With the focus on advancement and innovation in the field of AI , attention should also be given to making the implementation of AI systems much more feasible so that as many people as possible reap the benefits of it . Advancement in AI would lead to fewer labor intensive jobs and this could be bad news for regions where manual work is substantial . For instance , India has banned the introduction of self-driving cars in India because that could lead to a huge decrease in driving jobs . This shows that the government can have a huge role to play in how and to what extent AI is implemented . As the report mentions , the middle skilled will be more affected in terms of employment than the lowest and highest skilled ones . Therefore , the focus in the low resource communities should be to implement AI to augment humans instead of replacing them and making use of the human brain for much complex tasks than just , say , driving .
In `` Stanford One Hundred Year Study on Artificial Intelligence '' , the authors point out that different from the past , today , we human-beings are on the way to establish `` human-aware and trustworthy intelligent systems '' instead of simply trying to make the systems intelligent . Nevertheless , I think we are not there yet . In my mind , people are still making progress to build more intelligent systems and machines .

The majority of machines or systems are not intelligent enough today . Many of the products people built are not capable of interacting with people smoothly , which in my mind are not intelligent enough . For example , the voice assistant Siri on Iphone sometimes fails to give coherent answers or gives same answer for different questions . The types of questions it can answer correctly are limited . Besides , in the field of robotics , people are still at the stage of making effort to produce robots that can act like real human-beings . We hope that we can create robots that are able to communicate and interact with people . Thus , I think nowadays , people are trying to build intelligent systems though the systems today are much more intelligent compared to those in the past .

Furthermore , although we might produce some machines or systems that seems intelligent , we do not fully understand how they work . Machine learning is an example . Driverless cars are regarded as one of the most intelligent applications of machine learning . In order to let those cars drive themselves , people collect a large amount of raw data to train those cars . However , the learning phase is still a black box to us , which means human beings do not actually know in what way the cars learn from the data to drive without drivers .

The fact that we do not know how those systems actually work makes it extremely difficult to build systems that are trustworthy . The more we make use of these technology , the harder we are able to create trustworthy systems . Though the driverless cars function well at the most time , we are unable to reach the state of real driverless . This has two reasons . First , even the newest driverless cars will meet some emergencies sometimes and need people to take over the control because there are infinite possibilities of accidents that can happen in reality . Second , since people are not clear about how those cars learn the skills , we can not truly believe them . We do not know how they drive themselves . We do not know why they suddenly break down either . Therefore , it is hard for people to guarantee the systems are trustworthy even though they might fail only once among all the time they execute .

In conclusion , instead of shifting to the stage of building trustworthy systems , I think we are still endeavoring to create systems that are intelligent enough to interact with us freely . Also , because of the situation that there are some fields where people are unable to make sure how those systems learn or work , it is a challenging task for people to build any real trustworthy systems in the near future .
The use of Artificial Intelligence to maintain public safety and security can be applied to a variety purposes . An example stated in Stanford 's One Hundred Year Study on Artificial Intelligence is to monitor largely populated areas to begin to `` assist with crime prevention '' and `` efficiency and efficacy '' of busy terminals such as airports . Though the idea of this is very exciting yet there are a couple caveats that must be overcome before proceeding to such solutions as preventing crime . In the Stanford paper Artificial Intelligence 's potential to create a safer world is a future worth pursuing , but in order for that future to be a reality the technology must first overcome its fundamental issues .
One of these issues encountered is the technological concern of what faces these cameras are able to recognize . A New York Times article written by Kate Crawford helps lead us to the issue 's source . The engineers that are producing the technology and algorithms that detect said faces are predominantly white men . She goes on to explain how this has caused a `` data problem , '' and that the algorithms being used learn from the images being given to them , images `` often chosen by engineers . '' A few companies have already found errors recently with this where an algorithm had difficulty tracking or even finding a person with a dark skin tone as well as misreading `` images of Asian people as blinking '' while they were actually just smiling . These algorithms have difficulties overall with identifying non-white males since they were trained on photos of people who are overwhelmingly white .
Stanford 's paper presents Artificial Intelligence as future solution to assist with the reduction of racial bias yet recently it has been found that these algorithms have been found to have racial bias too . The algorithm was `` twice as likely to mistakenly flag black defendants as being at a higher risk of committing future crimes . '' In the same software was `` twice as likely to incorrectly flag whites as low risk . '' The source of this bias is still unknown but data sets that are skewed to one feature -LRB- i.e. skin tone -RRB- have been shown to have bias as well .
Bias do not only come from images ; they also have been found from crime data . Police departments have been using `` historical crime data '' to feed to their algorithms to help preemptively patrol areas which are more prone to criminal activity . Though this might sound appropriate and could lead to the reduction of racial bias , it in fact most likely would perpetuate the issue of over policing in areas that already have seen a history of racial bias .
Stanford 's One Hundred Year Study on Artificial Intelligence sets out the ideal , and seemingly reasonable outlook on the capabilities of keeping the public safe . Yet the forthcoming solutions are not reasonable unless there is major change in how data is looked at as well as who is providing said data . The idea of Artificial Intelligence helping to reduce crime activity while having fair judgement is an exciting one , but with the creation and evolution of algorithms that have inherently race driven data sets there is little to no change in sight .

Work Cited
1 . Crawford , Kate . `` AI 's White Guy Problem . '' The New York Times , The New York Times , 25 June 2016 , www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html?mcubz=1 .

2 . Peter Stone , Rodney Brooks , Erik Brynjolfsson `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .

The One Hundred Year Study on Artificial Intelligence study covers the direction taken by upcoming AI research in popular application domains , the challenges faced -LRB- both technical and societal -RRB- and the panel also goes further into suggesting solutions to mitigate/prevent them . The research is thorough and comprehensive , however we will look at some of the underlying assumptions and possible oversights and try to challenge them :

1 -RRB- Can we actually control the quality of non-tangible and possibly open-source AI technology ?

The panel was right in stating that with careful design , testing , and deployment ,
AI algorithms may be able to make less biased decisions . However , enforcing that all AI products follow state of the art algorithms might be an impractical conjecture . In a real world , we have bad designs , missed out test cases , resource constraints and timelines to be met . These shortcomings could have stronger societal implications for AI related technology when compared other technology .

For eg , consider a system tries to predict whether a person is likely to be a criminal . One missed out test case might lead to a slightly biased system . In this case , a missed out test case could mean a race or a community is marginalized inadvertently . Here , we can see that the repercussions of a design gap could be dire and it is challenging to ENFORCE quality .

Data is usually collected from human annotations which will carry implicit bias . Most AI systems have methods to reduce bias and not eliminate them , the presence or lack of it therefore becomes a spectrum and not a binary . It becomes challenging to get a true sense of the extent of bias present in a system especially in applications that use image/videos and employ deep learning technologies such as convolutional neural networks.The occurrences within the machine learning model is a black box to us and is worth some concern . We do not know what the machine has learnt , we only know the result . It is difficult to ensure that the machine has not learnt something that you do not want it to learn , when we do not yet have good solutions to sneak a peep into the black box .

This means that bugs might stay in the system and may not be timely caught and could have devastating effects to mankind . Moreover , since we do not even have an all encompassing definition of what qualifies as an AI product , it is not pragmatic to assume that we can prevent sub quality technology from being in vogue .

2 -RRB- Will the pace of establishment regulatory policies and new laws be ahead of development of AI sytem so as to prevent mishaps ?

While the paper has addressed the concerns regarding misuse of AI technology by stating that govt bodies should be formed to create new laws for the changing world , a hope for this to happen could be a little idealistic . The fact of the matter is that when we consider the rest of the world outside of North America , including third world nations , the govt bodies could be slow , inefficient , messy or could simply have other priorities . In the real world we do not follow a waterfall model wherein , we go the stage of funding and creating AI technology only after we have meaningful law bodies and standardisation and regulatory committees established in the whole world . Since development of law and development of technology happens parallelly and side by side , we leave open room for a fair amount of technology misuse and it would be appropriate to acknowledge that the scientific community is willing to make this sacrifice .





Autonomous cars while recently being introduced to the automotive market are already facing indirect criticism . When new technologies are complementary they tend to be packaged into the technology they embody , this is the case with electric drivetrains and autonomous cars . Both of these technologies are game chargers in the automotive industry , likewise both of these changes come with potential pitfalls .
When issues arise with new combinations on technologies it can be hard to determine which new technology are at fault . The Securing America 's Future Energy -LRB- SAFE -RRB- , a non profit organization started by the the House Energy and Commerce Committee recently released an article stating , '' 58 percent of autonomous , light-duty vehicle retrofits and models are built over an electric powertrain , while a further 21 percent utilize a hybrid powertrain . '' Thus stating that 79 percent of autonomous cars are being introduced to consumers along side new electric engines and powertrain technologies . This conjoined conception has created some misinterpreted causation between autonomous cars and economic impacts . In the Stanford article ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 the author predicts , `` people using cars as a service rather than owning their own -- may reduce total miles , especially if combined with well-constructed incentives , such as tolls or discounts , to spread out travel demand , share trips , and reduce congestion . The availability of shared transportation may displace the need for public transportation . '' The author 's argument of tolls being used as incentives to travel is not valid . With the recent increase in demand for electric cars and sanctions from governments in countries like China and France , the United States government in conjunction with lobbyist from car manufacturers are facing a difficult problem . How is going to pay for the roads ? In the 2015-17 Wisconsin Department of Transportation 's `` Transport Finance Issues '' report recently reported that , between both states and federal gas taxes the state gained over 5 billion dollars in revenue . Which , in turn was all spent by Wisconsin DOT to create and maintain roads -LRB- 6.82 billion budget -RRB- . With the influx of new electric cars , the government is going to need to create a way to compensate for the loss of the revenue from drivers no longer needing gas . One alternative to the gas take is to increase revenue from tolls , thus increase the amount of tolls on the roads .
The correlation between electric/hybrid cars and cars that are capable of autonomous driving is striking , combined with the fact that electric/hybrid cars decrease the consumption of gasoline.Makes the author from the article ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 arguing the fact that autonomous cars are going to be contributing to `` well-constructed incentives '' through tolls invalid . From the evidence presented it is easy to draw the conclusion that as more autonomous cars enter the market , there will be an increased need in taxation for using public roads . In turn this will increase the amount of tolls on roads and contribute to a equal or greater need for public transportation .
The modern advancements in autonomous cars are exciting and as technology continues to be more efficient it will be exciting to see how these new advancements plays a role into the automotive industry . There is a long ways to go until we see entire cities of autonomous cars , but it is the laws and consumer acceptance created today that will shape how this technology will be in 100 years.The artificial intelligence and life in 2030 provides a thorough and deep investigation and prediction about the near future of the development and application of artificial intelligence in the fields varying from people s daily life to industrial production and national security . Most parts of the report from my perspective is objective and reasonable , and agrees with my previous experience . For example , the authors points of view with respect to the on-demand transportation agrees is consistent with the project that I took part in as a student researcher call future urban mobility , which targets on developing a public transportation system based on the autonomous vehicle to accurately pick up passengers in the predict demanding regions and drop them off at their destinations . However , there is one theory that I do not agree with , which is that most people will not be able to reach a satisfactory level of living with their work in the society under the influence of artificial intelligence , and this effect should be compensated with social safety net .

Firstly , it is worth noting that the purpose of creating artificial intelligence and allowing it to enter people s life is to increase the efficiency of the production in the society , and most , if not all , of the artificial intelligence applications should fit this goal . Therefore , as the AI becomes more and more developed , the social efficiency becomes more and more increased . Consequently , as the authors agree , the cost of many products and services is decreased . Although the value of labor of human may be reduced in the future , the cost of living would likely to be lower as well , making it easier to live above a satisfactory level .

Secondly , while the artificial intelligence is quickly taking away many tasks that are previously occupied by human labors , there are certainly many fields that are not yet possible to be replaced quickly , or impossible to be replaced effectively by autonomous machines and processes . For example , in the effort of developing socially interactive robots , researchers found that while people interacts with robots that are extremally alike human but not human , they tend to reject being too close to robots . As a result , the jobs that involve face-to-face interaction with human are hard to be fully replaced by artificial intelligence . As AI reduces the cost of some replaceable tasks , people may want to pay more to those working on the tasks that are unreplaceable by the AI , raising the value of their labor .

Thirdly , although social problems may arise in the revolution brought by the AI , and these problems should be a concern for the society , it is not always fair to compensate these problems by forcing the redistribution of the fruit of AI . The authors believe that everyone should benefit from the AI because the AI is the child of the mankind . However , it is noticeable that the creation of AI applications requires a certain amount of devotion , and not everyone in the society is involved into the creation of AI applications , and those involved should benefit from their work as well . The engaging of social safety net for redistribution of the fruit of AI may turn the business affair of creating AI applications into a charity affair , and the labor of people who create AI may not be respected . In the short term , this redistribution may reduce the tension brought by AI , but in the long term it would likely harm the possibility of social development by forcing more talent people to leave this field due to unfair feedback .
The Implementation of AI in Low-Resource Communities
People live in a world where artificial intelligence can now be a part of their daily lives . AI is deeply rooted in the lives of people through algorithms of programs or services they use . According to Stanford s One Hundred Year Study on Artificial Intelligence , AI is starting to be implemented in many areas including but not limited to transportation , healthcare , education , and more . While the implementation of AI can be beneficial to many people , there lies many problems in the process of implementation . In the case of using AI in low-resource communities in the study , while AI can be utilized to identify health concerns and spreading health-related information , there lies a problem of inefficiency .
Spreading health-related information through social networks using AI is inefficient due to the limited pool of people it will reach and people s distrust of the internet . Spreading important health-related information to homeless youths and youths that do not trust authority is important , but the approach of reaching them through social networks is delusional . This method only targets a small portion of a population , and many homeless youths may not be reached because they do not have access to social networks . Also , while the information may reach them , it is hard to say people will trust the information they receive on the internet any more than the information that authorities give . The internet is a very convenient resource but many times an untrustworthy resource as well , and people are very aware of this fact . They may not trust the information seen on the internet because that information can also be from authority , just through different means . Therefore , although awareness is important in aiding healthcare in low-resource communities , it is better to take a different approach to spreading awareness instead of using social networks .
Another usage of AI in supporting low-resource communities is detecting health issues , and there is a problem of implementation and funding . AI has been used in detecting lead levels in children or predicting adverse birth in pregnant women . Although it is important to detect these health issues and would be substantially beneficial to the community , the study did not take into consideration the implementation process . Funds and aid are necessary to implement these systems , and in low-resource communities , they may not have the resources to do so . Although AI will be very beneficial when it is implemented in low-resource communities because it will be utilized amply , the process of implementation is a big factor that is easily ignored . Also , detecting health issues implies that there are already health issues , just like detecting lead levels in children meaning the children were already exposed to lead and are in bad health . Instead of trying to detect health issues that already exists , although it is essential to do so , AI needs to be used to prevent these health issues .
Low-resource communities have an obstacle to reaching resources or receiving good healthcare and health education , and plans to utilize AI to reduce these issues is encouraged . The inefficiencies that exist with implementing AI in low-resource communities through health-related information awareness and health issue detection are not impossible to eliminate , but further research and thinking must be done to better use AI in situations and environments like such where there needs to be a realistic goal and implementation plan . When AI is in full application in these communities , it will bring great changes to the number of people affected by the lack of health-related information or health issue detection .
Self-driving Cars : Taking the Wheel of Freedom
It was a pleasure to read this study , and the consolidated assessment by the Study Panel on the current state of artificial intelligence and where it is going in the future . The value and potential of AI research was painted clearly and expressed in a very inspiring manner . It was difficult to challenge all or any aspect of this article , considering the quality of the ideas and the highly credible sources from which it was developed . However , one domain that I would like to attempt to challenge , specifically due to personal affection and closeness to me , is self-driving vehicles in transportation .
My affection and worry can be painted best , and in the cheesiest manner , through the quote from the movie , The Fast and the Furious , I live my life a quarter mile at a time . Nothing else matters : not the mortgage , not the store , not my team and all their bullshit . For those ten seconds or less , I 'm free . And although I do not share the same love for street racing and rebellion towards law enforcement -LRB- or so I hope -RRB- as the character who said this , I do share the same feeling of experiencing ultimate freedom from being in control of my own car , changing its speed and direction , switching the gears , and taking complete ownership and disposal throughout its lifecycle . So as a result , I , and others like me , pin the advantages of traffic optimization , ridesharing , accident rates , parking efficiency , etc. against old traditions of personal ownership and property .
And though I do not believe this was addressed in the study , I do believe that this is a silent barrier to broad acceptance of self-driving cars , and that those who share my hesitation for the same reasons is a size of considerable magnitude . It is fair to acknowledge that the move for self-driving cars is not directly forcing us freedom-of-driving-ourselves lovers to donate our vehicles and hop into the new ride , but it is the same momentum and trend shift that becomes a pressure for the change that I would personally be worried about , nonetheless . In the same manner that nondrinkers feel pressure at an event encouraging alcohol , I imagine the pressure and inherent uneasiness being the only non-self-driving car on the road , given autonomous vehicles gain considerable traction soon . In the past , everyone owned a manual , stick-shift geared vehicle , and clearly today , it is very rare and only manufactured in low volumes , overshadowed by the success of automatic transmissions .
However , as I initially mentioned , my pushback comes from personal , rather selfish tendencies , that in a formal argument , can not possibly win over the opportunity cost of increased efficiency , safety , traffic planning , and asset utilization that are quickly becoming realistic and viable due to sensing technologies and more efficient machine learning techniques for computer vision and perception . But I believe these small , natural human tendencies , in the end , are the most important thing to factor in the discussion of advancement of AI in replacing current real-world systems . I would love to learn and study more about similar arguments in either transportation or related domains , and am very excited to see what becomes of all the new technology and how we decide to implement them in the near future .

From simple cruise control to fully self-driving vehicles , car manufacturers like General Motors , Tesla , and Volvo are pushing the boundaries of how artificial intelligence exists in cars . As quickly as fully autonomous cars become a part of our everyday lives , we must have laws and regulations that govern the use of this technology . But , who is to blame when a self-driving car crashes unexpectedly ? Does the driver who chose to purchase the vehicle bear the responsibility ? Or is the manufacturer who supplied the technology on the hot seat ? The few accidents involving self-driving vehicles have settled on a case by case basis . However , experts predict 10 million self-driving cars will be on the road in the next 3 years , and inevitably result in many more mishaps and accidents . Currently , juries have held manufacturers liable for most of the damage done during a crash caused by a self-driving vehicle . This is with the intention that consumers are buying the vehicles with the confidence that they are completely safe when driving around with the manufacturer s technology . This policy also encourages companies to ensure that there are several backup safety systems , and considerable time and money invested into product development to avoid legal trouble and blood on their hands . Recently , the National Highway Traffic Safety Administration and Society of Automotive Engineers has devised a 6-level automation scale to dictate who is held responsible : 6 being a completely self-driven vehicle and 1 being a standard car with full human control . Most cars today fall into the 2nd level ; equipped with only cruise control , automatic parallel parking , and an early brake alert system , so most of the driving is done by a human , and in return the driver is held responsible during a crash . But , anything over the 2nd level , the courts would look towards the manufacturer . I do not believe that the manufacturer should bear the full cost and responsibility for a crash by one of their products . Though it does incentivize companies to strive for innovative and extremely safe technology and if the companies market a self-driving car as something the driver does need to control , then yes let s hold them responsible . But , I believe we can incentivize companies to build the safest technology possible and ensure the safety of the users without taking personal liability out of the picture . It s out of the question that self-driving cars are safer than human controlled cars , the data backs this up , so why should the manufacturers of self-driving cars bear greater liability than manufacturers of a standard car ? If I go out and crash my car , Toyota doesn t pick up the bill on the repairs , so why should Tesla have to do that for creating a safer product Competitive market pressures will cause manufacturers to invest in the safest and most trustworthy technology to earn the publics confidence and create demand for their products . When you go out and buy almost any product you are assuming the risks and adverse effects that may turn into reality . If you want to avoid these risks , then don t buy the product . But , punishing self-driving car makers for making a far safer product than the cars currently on the streets now is not logical . In conclusion , the manufacturer should not be held completely liable when a self-driving car is involved in a crash .

Sources :
https://phys.org/news/2017-06-wholl-responsible-self-driving-car.html
https://www.scientificamerican.com/article/who-s-responsible-when-a-self-driving-car-crashes/

In this article , authors try to express an idea that Artificial Intelligence -LRB- AI -RRB- will provide solutions to current society and improve living standards and wealth , counteracting fears that AI may contribute to joblessness and other societal problems . However , although authors attempt to reduce people 's fear on advances in AI , AI actually will cause enormous upheaval and evolution in not long time .
The article claims that in the near term , AI will substitute tasks rather than jobs and create new jobs meanwhile . Besides , new jobs are hard to imagine with existing jobs lost . However , the outcome is actually obvious and not ideal for most ordinary people . For example , just imagine there is a factory with more than one hundred million labors , and managers decide to substitute these labors by robots . As a result , previous workers need to learn how to control these robots and there will also be some other new jobs that surround these robots . However , only a small part of labors can handle new tasks and even only a smaller part of these smart labors are needed to complete these tasks . One main reason that we develop technology is to improve productivity and create more wealth with less human resources . Therefore , it is predictable that how new jobs will look like and they will fit only a few people . A large-scale joblessness is inevitable and will come soon .
The article also indicates although some high profile internet companies have very small number of employees , most companies will have a natural scale of human enterprise in the future as the creation accomplished by AI . This is the point because these technical companies are not the leading actors in this innovative tide caused by AI , on the contrary , they are still the upper class . Ordinary people are the true groups that will be impacted -- those organizations and institutions which have a huge scale will be mainly affected because most of their members are human labors can simply be replaced by robots . As time goes by , these huge organizations become ones with natural scale -- by the way , this natural scale must be small as most members are eliminated due to AI . This natural scale is actually an evidence that unemployment is the trend . To conclude , a massive unemployment will emerge soon and the fear is reasonable -- people should have the right to know truth and most probable situation in the future .
In my opinion , because AI revolution is the trend which can not be halted and AI does have the ability to substitute human jobs rapidly , the most important work government and technological organizations can do is not to temporarily comfort people that evolution will not come as rapidly as they think , but to provide a living guarantee for their future to help them resist AI 's impact . The serious unemployment problem should be presented because it is a predictable truth in the not distant future ; along with it , a reliable policy is needed . Most people work to fulfill their living expenses ; if these living demand becomes basic welfare provided by government , people do not need to worry about unemployment . It is a feasible breakthrough point to overcome people 's fear of losing value . As for the problem that whether people must work or whether people must achieve life value , it can be discussed in the future and is not necessary now.In the essay , the author mentioned the reason why AI has not make it into healthcare space as much as it could is the limitation of technology and the high-stake nature of the usage of such technology . Whereas the technology could be a reason for it , the human nature that carries emotion and cares about being among other beings is the fundamental cause why AI has yet made it deep into our lives .
First off , while AI is good at diagnosing with high certainty percent , it is still a tool with power and without responsibility . It could give an 88 % certainty of a disease with symptoms checklist . And then what should the patient do ? Doctors , similarly , would give a similar diagnose result based on patient s symptoms . However , with the responsibility that comes with their profession , doctors would further consolidate such diagnose with empathy and caring responsibility that s unique to human brain at this state . We could not tell if machine actually cares about a human s life or it is just purely running an algorithm to match patterns . A doctor would deeply understand the meaning of diagnosing and curing disease for a patient .
Secondly , human psychology suggests we are social beings , which means we tend to trust fellow human beings better than the algorithm that consist of math manipulation and pattern matching . Even though theatrically the algorithm , with its large dataset , could yield a better prediction than the doctors , the patient would still lean towards doctors simply because the human nature . Imagine a person following the Google Map navigation to a certain alley way . If a self-identified local resident gives an alternative way and backing it with his/her experience with the traffic , there is a high chance that person would choose the alternative route simply because a human being sounds more trustworthy than an app at current society .
Similar argument could be made towards author s claim for AI in education . The author believes lack of financial resources and technology advancement are the reason why AI is still not fully integrated into school . However , the most natural way of learning is to learn from a different human being . Our brain has been wired to learn from our parents/surrounding human beings since we were babies . Of course , the amount of resources that is being offer by AI education agent could be larger than a school teacher can offer . But the human interaction that our brain is used to requires the existence of a teacher/mentor who is emotionally understanding and intellectually competent . Needless to say , the expectation that is being casted on us from teacher serves as a drive for us to do our best . We will probably not feel the pressure from a machine telling us that it really wants us to do well .
All being said , the level involvement that AI could get into our society really boils down to how close to a human mind that AI could get . I believe unless we eventually figure out a way to duplicate or construct a human mind , we could always tell the difference between a real human being and AI . And when that happens , we would start to build trust through an emotional connection . The trend that AI will be widespread among different fields in people s life is inevitable . However , with the increasing use of AI at home or in public places , it also brings hackers convenience to take advantage of any loopholes for committing a crime . Hackers are huge threats for the development of AI . It is true that the field of AI is born initially for benefiting people s life . One application of AI can even be used for public safety and security . While , once it is used conversely by criminals , the whole public will be put in huge danger . For example , hackers can use AI for transportation planning to paralyze the whole city and control the household AI to reach some goals , such as hurt people . In this article , it does not talk about any countermeasure for this situation but it is important to put effort in the consideration .
The potential threats suggest another aspect , which is the problem of who should hold the technique , governments or companies . In the report , it indicates that the latest technology belongs to a small amount of large companies . However , the governments should concern if any researcher will leak important information to the criminals . One feasible method is that the government hire some experts for regulatory authority to supervise those companies . Furthermore , AI technology may be a measurement of national power . That different countries collaborate with each other at present for the development of AI does not mean they are willing to share in the future . If one side does not want to share the patent , AI is possible to be used in national negotiation . There may remain some problems for the future business of those AI companies as well .
In addition , for the application of AI in medical fields , some barriers hinder the way . For example , for those patients who have mental illness and need communication with professional psychological counselors , those AI-based applications may not able to do their duty for the best outcome . Those patients may not trust AI system because they are just smarter machine , not human beings , which can be a problem in mental treatment . Take a step back , even if people create some human-like robots , they are still facing the potential problem , Uncanny Valley , a theory that human-like robots can generate the fear of people . Though AI sometimes can perform better in a surgery , in some specific areas , human doctors are still irreplaceable for a very long time .
Finally , the report points out the idea that AI will affect people mostly in middle skilled work , which is not reasonable enough . The population of the whole world is decreasing by estimation , which means that the cost of labor will become more expensive especially in some lower skilled jobs . When the cost of AI machines comes below human cost in a free market , those workers will ultimately lose their jobs . At the same time , if they do not have higher ability to find other jobs , the unemployment of those people will become a big social problem , which may induce crimes and riots .
Overall , Stanford One Hundred Year Study on Artificial Intelligence is a very comprehensive report and it is easy to understand by the general public but it also ignores some essential possibilities .

After watching the movie `` The Imitation Game '' one night this summer , I started to really get into Alan Turing and how he was able to have such an impact on the way we think about computer science and technology as a whole . That movie is actually what got me to join this class . After reading the article from Stanford , I started to feel even more hopeful about the ways technology can improve and help in our everyday daily life . There was , however , a challenge which I wish was addressed more in the article . The challenge I want to make is how jobs regarding truck driving/farming will be replaced by AI , and the impact that will have on truck drivers/farmers . The thought of AI replacing jobs has me thinking back to the scene from Charlie and the Chocolate Factory -LRB- Yes , the weird new one -RRB- where the father is replaced by a robot . The resolution to this conflict was that the father was hired to repair the robot , however I do n't see this feasible in practice since there is a big difference between robotics repair and simple cognitive tasks .
Specifically regarding truck drivers and farmers , I recently read an article from NPR which showed the job title that was most present in each state . It was no real surprise to me that over half the states in the US have Truck Driver/Tractor Driver listed as their highest populated job . What scares me is that with AI becoming more and more advanced and the use of self-driving cars become a reality , how will this affect the Truck Driving Industry ? Will the higher ups in the company see it as a great way to get rid of their employees and replace them with robots that can do the driving job for free , without having to ever take breaks on the long , interstate journeys ? I really have no idea and I do n't think the people who authored this article do either .
I would like to think that at some point , maybe not in our lifetime , that there would be no need for humans to have to do manual labor or drive or any simple task , but would rather only be in charge of coming up with ideas that solve problems . AI would then be implemented to actually fix the problem . What I am trying to get at is that it would be amazing if there was no need to work a job anymore , and people would just be paid for doing no work , and could spend their money on whatever they choose . The reason being is that there are robots that have taken over the job industry anyways , so why would there be any need to work anymore ?
I am no expert on the job market , and I am not sure how many people were affected by the loss of the phone book , but I imagine that the damage would be much greater if the most popular job in over half the states in our country was to be taken away because a robot can do it better.Stanford 's one hundred year study on artificial intelligence has asserted that artificial intelligence will soon permeate in our day-to-day lives . It establishes the fact that by nature , human beings are social creatures . One aspect of this study , however , states that in eventuality , human interaction will cohabit with machinal responses . The report also believes that it will be integral in our education , relationships , and careers .

One would agree that in terms of convenience , margin of error , and balance between supply and demand , artificial intelligence would be the answer to these issues . In terms of human behavior and dependency , one would have to raise the question of its effectiveness . It has been studied that technology is the source of today 's addiction and dependency .

Cognitive sharpness rely on human interactions that no artifical intelligence can replace . According to various studies , low social support from family and friends can affect a child 's psyche and physique drastically and can remain into adult life . -LRB- https://www.brainhq.com/brain-resources/everyday-brain-fitness/social-life-brain-fitness -RRB-

The writer attests that the study understands the uncertainty and the danger of such technology , but it does not further explain that advancements of this kind will also affect and shape on how human beings will behave all over the world . The fickleness of these effects , and depending on how fast artificial intelligence will pervade the temporal fabric , may put mental and emotional development at risk .

In addition to this concern , the report does not consider outside Western culture , how different cultures can affect AI , and vice versa .

A good example is Japan on how swift artificial intelligence came to Tokyo . Real-life relationships have become less present as single people prefer being isolated and get hooked on simulated dating . So much so that more than 40 % of women ages 18 to 34 have made romance gaming become a multi-million dollar industry . -LRB- http://edition.cnn.com/2016/11/21/asia/romance-gaming-japan/index.html -RRB-

Artificial Intelligence in 2030 also touches on how opportunities will come for the job industry but does not consider third world countries like the Philippines priding itself on its 25 billion dollar BPO industry that will have to struggle and will diminish by 40 to 50 percent of 1 million Filipino employees . -LRB- http://cnnphilippines.com/news/2017/09/06/BPO-industry-call-center-Philippines-artificial-intelligence.html -RRB-

While artificial intelligence can perfect speech patterns , iterate , and replace task-based vocations , it can not successfully replicate compassion , kindness , and empathy , traits that humans can only succeed in workplaces and other environments . For example , most people still very much prefer talking to a real human being for customer support than the programs meant to remove human representatives . That same reason can also be extended into why there are still human cashiers even though self-checkout services have become popular in large chain stores . Further isolation through increased artificial intelligence may occur and one would discover too late that emotional intelligence is also quintessential to competition and global success .

While the future looks promising for artificial intelligence and the study did its valiant effort in fleshing out every pro and con out there , it still requires to look into cultures and economies outside industrial countries .

`` The measure of success for AI applications is the value they create for human lives , '' the report states . The writer believes there is one flaw in this logic -- for artificial intelligence to succeed , it has to , even if it is only a part of it , devalue human intelligence . The Stanford One Hundred Year Study on Artificial Intelligence paints a vivid picture of what Artificial Intelligence is , where it began and where it will go in the next fifteen years . The article is divided into eight sections in which the panel believes AI advances will be most prominent , describing improvements in transportation , service robots , healthcare , education , low-resource communities , public safety and security , employment and workplace , and education . Overall , the writers describe that AI has great potential , however they also state that this potential is limited in both resource availability and community acceptance . Although I agree that AI 's potential can be limited in some ways I disagree with some of the panel 's views on education , specifically the statement that `` quality education '' will always require active engagement by human teachers .
I strongly believe that Artificial Intelligence has immense potential to improve education at every stage of one 's life , and that the disadvantage of lack of social interaction in the classroom is greatly outweighed by the benefits of accessibility , learning flexibility and information availability . It has been proven that , as stated in the article , face to face interaction while learning is crucial when developing social skills and connections in the early stages of one 's life , however as one grows older and joins the workforce these skills have already been learned . This contradicts the idea that active engagement with human teachers would even be needed past the early stages of a student 's life . In addition , many classes at UW-Madison are already transitioning to a classroom style called WISCEL that allows students to learn from video lectures instead of a teacher , and to practice these learned skills alongside each other in a collaborative environment . Thus , students do n't necessarily need to interact with a human teacher to learn , allowing AI to integrate with the modern education system without disadvantages . AI 's most prominent benefit in my opinion is its accessibility to all . No matter the income , education level or location of an individual , if they have an internet connection they would be free to access learning environments such as MOOC 's and reap the benefit of personalized feedback through the use of AI . On top of this , given every individual learns differently , students would be able to study on their own time and at their own pace rather than on the set times of a traditional lecture style . The value of education would be rightfully available to everyone and as long as an individual has the drive to learn , they would be able to acquire crucial skills and join the workforce without a formal education . Given the extravagant costs of higher education , this would save many students thousands of dollars in tuition and open this opportunity to those who are n't so fortunate to attend a college . Lastly , AI clearly opens an entire world of information that many teachers or college classrooms could not offer with their resources . For example , if a student wanted to learn JavaScript , they could access an MOOC and begin learning instantly with personalized feedback according to their mistakes and learning style , whereas certain colleges or teachers may not even offer courses in JavaScript .
Overall , AI is clearly revolutionizing the world we live in and can have an incredible impact on education as we know it . With minimal disadvantages to the education system AI styled learning would offer immense benefits to students by providing a great deal of accessibility , learning flexibility and information availability that traditional settings could not .
The Stanford One Hundred Year Study on Artificial Intelligence gives interesting insights into AI 's influence on modern society . While the report remains relatively unbiased and recognizes the limitations that the discussed technology has , there are still a couple aspects of the report that I challenge . I base both challenges on my understanding of the magnitude of impact AI could have on our society in the future , and the potential for those impacts to be undesirable .

Education is a crucial part of society , thus any significant changes to it will have a rippling impact . While technology such as Intelligent Tutoring Systems and Virtual Reality sound promising for the future of education , I think this report is quick to assume that these technologies are in fact pointing society in the right direction in terms of effective education .

The report says that Natural Language Processing has enabled teachers to `` multiply the size of their classrooms while simultaneously addressing individual students ' learning needs and styles . '' While this is certainly true , it is not clear that this is truly desirable to make education better . Many people believe that the current status of education is unsatisfactory and has much room for improvement at its core level . Because it is understood that AI can not fully replace humans in tasks like teaching , I believe that providing virtual teaching aids and robots should not be incorporated until our current education system is satisfactory standing on its own .

Many of the issues presented , such as being able to double class sizes and assist students better can arguably be resolved by providing more funding and focus on the current state of education . Once this is achieved , I think AI will integrate more effectively and the transition of incorporating technology into education will be less of a risk to such an important aspect of today 's society .

Another aspect of AI technology presented in this report that I challenge is that dealing directly and indirectly with decision-making . While AI in health care has literally saved lives , I ethically struggle with some aspects of technology in the industry . Such an example is in healthcare analytics . I find it incredible that algorithms are able to determine if certain people are at risk for particular medical conditions that may otherwise go unnoticed or admitted by a doctor . This type of data analysis is tricky though . Let 's say that there is an algorithm that determines what risk patients are at for a deathly disease that has a fast onset and is hard to diagnose . The algorithm does this by determining a risk factor score that is based on electronic health records . In this case , the lives of patients are in the hands of a score that has to have some kind of decision-making threshold . For example , say patients who score a 6.0 or higher from their risk factor score are treated , while anyone lower is admitted . What happens when someone scores just below the flagged threshold and is admitted , but that person still gets fatally sick ?

Although technology like this has the potential to save the lives of more people than ever could be saved before , it is still ethically sensitive when such important decisions based on an AI algorithm determine whether or not someone who may actually be sick goes untreated -- even if that person would go untreated when diagnosed by a real doctor .


One major prospect for the future of artificial intelligence , as suggested in the Stanford One Hundred Year Study 2016 Report , is the advent of self-driving automobiles . The study asserts a prediction that the operation of such vehicles will become commonplace in the near future , to the point that flying automobiles will be introduced in 2030 . According to the study s prediction , as cars will become better drivers than people , city dwellers will own fewer cars , live further from work , and spend time differently , leading to an entirely new urban organization . Nevertheless , despite these potential advantages , it might be too early to conclude , with certainty , that self-driving vehicles will become a social pastime by the year 2030 . There are at least three noteworthy obstacles which might delay mainstream adaption of self-driving automobiles beyond the predicted year .
One obstacle is that fully autonomous vehicles will take a very long time to comprise a large share of vehicles sold in the automobile market . As Paul Carlson and Johanna Zmud noted in a recent article for Business Insider , there are currently few automobiles on the road which contain any automation features . According to their prediction , these vehicles are unlikely to appear in dealer showrooms -LRB- in large numbers -RRB- nationwide for at least a decade . Furthermore , Carlson and Zmud proceed to assert that the share of self-driving vehicles on the road will be further delayed by the common trend of people continuing to use their current cars for a long time . -LRB- Carlson & Zmud , 2017 -RRB- As with any other new automobile model , the product must be available to the public for an extensive period before it can become commonplace .
Another obstacle is the need to legislate policies adjust for the autonomous vehicles . In the absence of drivers , both localized and state governments will need to pass regulations regarding the use of self-driving vehicles . Both Carlson and Zmud predict that this phase will take place in cities first , due to the relative flexibility of municipal governments ; the authors cite the testing of robotic taxis in Phoenix , Pittsburgh and San Francisco . Nevertheless , state agencies will need to prepare regulations for these vehicles to drive across interstate highways . According to Carlson and Zmud , regulations for interstate highways are highly complex , and are more likely to be enacted long after the vehicles are technologically capable of driving across state lines . -LRB- Carlson & Zmud , 2017 -RRB- In short , fully autonomous vehicles will be prepared for the open road much more quickly than the open road will be prepared for the vehicles .
Last , but not least , cities and states will need to build the necessary infrastructure for these vehicles to operate safely on public roads . This infrastructure will be highly expensive , and thus pose a significant financial burden on public agencies . Carlson and Zmud explain that public infrastructure will be necessary to facilitate the vehicle s communication with roads , markings , signs , traffic signals and other vehicles . The authors then proceed to state that several states lack sufficient funds to repair current bridges and roads ; this lack of funds further contributes to their financial burden . -LRB- Carlson & Zmud , 2017 -RRB- . The need to establish infrastructure will further delay the popularity and prevalence of self-driving automobiles .
The findings of these authors suggest that , although self-driving vehicles are likely to make a significant impact on the market , it might not become a common product by 2030 . Therefore , it is likely that fully autonomous vehicular technology might not develop in the marketplace as quickly as the Stanford report predicts . Only time will tell to see how quickly artificial intelligence advances in the automobile industry .
Source : http://www.businessinsider.com/heres-what-the-future-of-self-driving-cars-realistically-looks-like-2017-7
There are a couple of points the article makes regarding artificial intelligence and transportation that I do not agree with . In general , I do not think AI will have the impact transportation in North America as quickly as the article is claiming . I believe there are many obstacles that will prohibit wide acceptance of AI in transportation and will prolong the process of implementing things such as self-driving cars into society . As a point in favor of the implementation of self-driving cars , the article claims , Self-driving cars will eliminate one of the biggest causes of accidental death and injury in United States , and lengthen people s life expectancy . I challenge this claim and say that self-driving cars could cause a new creator of stress the United States population does not frequently experience . Many people are familiar with the term back-seat driving , meaning someone who tells the driver what to do while they are a passenger in the car . Most people back-seat drive due to the stress and anxiety of not being in control and not trusting the driver to make the right decisions and react appropriately on the road . This anxiety and stress would only be heightened in a self-driving car , where the passenger can not communicate to the car in motion . The article claims that the passenger of a self-driving car would have more time on their commute to get work done or entertain themselves and relax , but I think driving in a car without any communication or control would cause more stress and the passenger would not be able to focus on anything else besides the road . The article does say that the trust between humans and machines would have to be built up over time , but I think the lack of communication between the human passenger and the self-driving car will prohibit complete trust from ever happening . Another claim the article makes is that I challenge is that Self-driving cars and peer-to-peer transportation services may eliminate the need to own a vehicle . Our current society places huge value on convenience with things such as same day delivery and live streaming of virtually any TV channel . For this reason , I find it hard to believe that AI would be able to provide enough self-driving cars to replace the cars that people own themselves . When people need to get to work or school , they don t want to wait for a car to be available to bring them . If someone is having a baby and needs to get to the hospital , a situation that very rarely requires an ambulance but is still urgent nonetheless , waiting the 10-20 minutes it takes for a car to arrive to them could be crucial . The article continues to suggest that shared transportation could replace the need for public transportation . I also disagree with this for similar reasoning : it is hard for me to see the availability of cars being reliable . With public transportation such as subways and trains that don t use roads , the schedule is almost guaranteed . I think taking the subway to work every day is much more reliable as far as departure times and commute durations are concerned , compared to a self-driving car on the road where construction , traffic , and accidents play a factor into time of the trip . For these reasons , I think implementation of AI into transportation will take a lot longer than the article portrays . Are you a human ? Or a machine ? I would rather not spend the next few hundred words attempting to discover whom -LRB- or what -RRB- I am writing to , so let s move past those questions . Artificial Intelligence is an exciting field to be in and the One Hundred Year Study on Artificial Intelligence does an excellent job presenting the current state of AI . It contains very little embellishment and provides the reader with a solid understanding of where we are in the booming domain of artificial intelligence . However , there are a few statements where I must disagree namely in the areas of healthcare and transportation .

The healthcare industry can benefit immensely from the integration of AI into their systems . While the report provides numerous examples and applications , it also includes several claims I don t completely agree with . For instance , in the clinical setting the report states that a small group of companies control the EHR market , and user interfaces are widely considered substandard , including annoying pop-ups that physicians routinely dismiss -LRB- Artificial Intelligence 26 -RRB- .

Last summer I completed an internship with Optum , a daughter company of United Health Group specializing in software development and data management for the healthcare industry . While working alongside industry professionals I was amazed by the quality of software Optum was developing for United Health Group . Not only were the programs polished and refined , but they also contained powerful tools for analyzing data . I did not see any evidence of annoying pop-ups that the report references . The article goes on to say that the promise of new analytics using data from EHRs , including AI , remains largely unrealized due to these and other regulatory and structural barriers -LRB- Artificial Intelligence 26 -RRB- .

United Health Group -LRB- UHG -RRB- is by no means a small company in 2017 the organization was ranked 6th on the Fortune 500 in the United States . The statement above argues that AI isn t being widely used for data analytics , however within Optum one of the largest healthcare organizations in the United States incredible amounts of resources are being allocated to AI and machine learning . As an intern , I attended Tech Talk where Dr. Richard Migliori , Chief Medical Officer of UHG , spoke about AI and its current use within the organization . He emphasized the importance of bringing artificial intelligence into the healthcare industry , making it clear that United Health Group is not standing idly by .

Transportation is an area of AI that has the potential to significantly change the way we live our daily lives . Self-driving cars are the future ; however , the Stanford report mentions AI being used in flight something I completely disagree with . Specifically , the report states that in the typical North American city in 2030 , changes won t be limited to cars and trucks , but are likely to include flying vehicles -LRB- Artificial Intelligence 26 -RRB- .

Recently I completed the necessary training to earn my private pilot license . If there is anything I learned from the FAA , it is that even regulations have regulations . The idea of human pilots landing at the same airport as unmanned aircraft using AI is not something the FAA is going to support willingly . Artificial intelligence may play select roles in aviation , but it will not replace pilots entirely by 2030 .

Artificial intelligence is an exciting technology that has a lot of potential in the years to come . For the most part , the One Hundred Year Study on Artificial Intelligence is an accurate portrayal of the technology and provides honest predictions of where AI is headed . The only questions that remain are are you a human ? Or are you a machine ?
Artificial Intelligence is defined as the ability to make machines intelligent , such that ,
they can function appropriately and anticipate and adapt to their environment . AI has advanced
in many fields such as healthcare , transport , education , employment and workplace , and at
the workplace . The Stanford AI report states that self driving cars will become common on the
roads by 2020 . According to me , this is not possible and it will take many more years for
various reasons . Firstly , rules have not been stated regarding who bears the burden if
a self driving car crashes . Companies would have to face huge burdens if only they are the victims
of the lawsuits , and this would lead to stifling innovation and confidence in self driving cars .
According to author , Phillip Tracy , American roads are n't ready for self driving cars because
of the obsolete infrastructure problems that have existed for more than 40 years . Volvo
cars failed tests at the Los Angeles Auto Show because the car could n't detect the lines on the
road as they had faded away . Research scientist , Christoph Mertz , believes if the lines fade
away in any time of the year , cars would be very prone to accidents . According to the
U.S. department of transportation , 65 percent of the U.S. roads are in poor condition . Weather conditions
could also play a fatal role with self driving cars . Direct sunlight on the signals can confuse the cars .
An accident caused the death of a man last year in his Tesla Model S car because the cars could n't
detect the side of the truck in direct sunlight and drove under the trailer . The report also
talks about transportation companies like Uber and Lyft who have helped in making transportation
easier and introduced carpooling . These companies have increased employment opportunities for
drivers but the introduction of self driving cars could cause a major rise in unemployment
in every country . Then there is a cyber threat which can be dangerous in every field . If a hacker takes
over a driving car , he can easily do anything with the car , putting the passenger at a huge risk .
These hacks might be untraceable if the car gets damaged so terrorism threat would be larger in
many countries that are prone to such attacks . Artificial intelligence has also made advances in
the field of education in the past fifteen years . The report states that teaching robots
have now been implemented to teach children.There is no guarantee if the children actually
concentrate in class because they know it 's a robot which is teaching them . Human connection
while teaching is sometimes very important for children and robots might fail to understand
what the children are feeling and what they are going through . Integrating robot teachers
in the field of education would also lead to unemployment in the field and teaching as a
profession would take a huge hit . Although AI can be a huge boon for us , most of its aspects
have many challenges which would stifle the technology more and delay it . It will be interesting
to see how Artificial Intelligence manages to become a permanent part of the most important
fields and how people adjust to it . Garrick Krol
CS540
9 September 2017
HW1


Rejoinder


As the landscape of Artificial Intelligence -LRB- AI -RRB- and its related sub-fields unfolds in the 21st century , difficult decisions will need to made regarding the relationship between existing societal infrastructures and advances in automation technology . Diagnostic medical imaging , one of the most powerful yet delicate branches of healthcare , has the opportunity to operate with increased efficiency , accuracy , and speed in disease detection from complex , multi-layered images aided by convolutional neural networks -LRB- CNNs -RRB- . The Stanford one hundred year study on artificial 2015 report claims `` Even with state-of-the-art technologies , a radiologist will still likely have to look at the images , so the value proposition is not yet compelling . '' Though sensitive and high stakes operations such as cancer detection will yield benefits much less breathtaking and noticeable than self-driving cars -LRB- chiefly because radiologists will have to double check AI findings , thus making the task only partially autonomous -RRB- , the FDA and related organizations must not underestimate the findings of a 2016 study on transfer learning in CNNs for disease detection . Though their tasks are relatively basic , such computer aids can greatly assist radiologists and significantly productivity . For example , it can take a radiologist anywhere from 1 to 5 minutes to review , report , and sign a single X-ray depending on the body part , and whether it 's normal or abnormal . Compared to complex images from Ultrasounds , CT , and MRI scans which can take up to half an hour per case , these tasks are straightforward for artificial intelligence . Because X-rays are so common and account for up to half of all cases reviewed by a radiologist , this small , rational augmentation for computer aided detection can save practitioners hours per day , allowing them to focus on and process more complex cases where higher stakes judgements are more prevalent . CNN aided detection of X-ray imaging can provide for physicians what the printing press provided for writers : the automation of menial tasks , effectively saving time for more important issues ; however , this does not eliminate the need for confirmation : radiologists will still need to double check and sign off on reports produced by the AI , but the process can be truncated and shortened . Because of the large volume of X-rays being examined per imaging company , the data necessary for CNN transfer learning can be constricted to private data sets operated in isolated regions , thus maintaining HIPPA compliance and the privacy of patients ; however , for larger and more effective data sets , regulations will need to evolve with the times and let large firms collaborate with one another and share data for a potential common CNN across the country . Though ambitious and complicated , this aspect of artificial intelligence in medicine must be understood by the FDA : full automation is not a requirement for AI to be valuable . Such research efforts can streamline a complicated medical process and mobilize automation as a genuine aid and resource saver for radiologists across the country . In closing , this passage should be understood as a different , sensible perspective in response to the sentiment illustrated by the 2015 Stanford study and the FDA with regards to the usefulness of automated detection in medicine . A simple task such as reading X-rays which can be outsourced to CNNs can yield tremendous network effects for radiologists .


Citations


Hoo-Chang Shin , Holger R. Roth , Mingchen Gao , Le Lu , Ziyue Xu , Isabella Nogues , Jianhua Yao , Daniel Mollura , and Ronald M. Summers , `` Deep Convolutional Neural Networks for Computer-aided Detection : CNN Architectures , Dataset Characteristics and Transfer Learning , '' IEEE Transactions on Medical Imaging 35 , no. 5 -LRB- 2016 -RRB- : 1285 -- 1298 .


Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 . The 100-year report has depicted the transportation as a prime example of the success of artificial intelligence with improved safety , more spare time during the commute and increased mobility of youth , elderly and disabled . However , the artificial intelligence in transportation also faces many challenges from the safety , legal reasons , and social pressure .

Due to the complex environment of real world transportation system , including the factors of pedestrians and too many unpredictable events that are not controlled , safety can be a huge problem to transportation with artificial intelligence . Self-driving can cause death to its passengers . For example , a fatal accident happened in Ohio is involved with the autonomous car from Tesla , one of the leading companies in self-driving vehicles . As told by Tesla , this accident happened because of the technical failure of the automatic braking system , and this technical failure raised the doubt of the safety of self-driving cars . Besides vehicle , safety problem of other transportation manner also attracts social attention . One crash of trains happened in 2009 was caused by trains automatically train-control system and led to injury , death , and 21 lawsuits . Based on these evidences , we can see that the safety of artificial intelligence is a problem that challenges it .

Besides the safety , the legal problem is another point challenges the implementation of artificial intelligence transportation . First , all of the current established rules and laws of transportation target to the human driving cars , therefore the cost of reestablish every detail of laws and rules would be a tremendous number for the governments of every country . Second , the law of privacy also plays a role challenging artificial intelligence in the domain of artificial intelligence . As stated in the 100-year report , government and policy maker must address privacy and ethics that public can trust , and this is difficult because the users data all connected to the internet servers . Furthermore , determining the responsibilities of self-driving car accident is demanding . Is the manufacturer responsible for the accident ? If so , should the driver be also responsible for the accident ? Depend on the situation of legal and government reasons , the artificial intelligence in the domain of transportation is still far from fully replacing the current transportation manners .

Beyond the problems faced by policy makers , social pressure also influences the implementation of artificial intelligence transportation . As mentioned in the 100-year report , artificial intelligence can replace the labors in delivery system , taxi drivers , truck drivers and so on , who can be a large portion of population . Thus , replacing them could cause an imbalance to our society and increase the social pressure . The fact in the 100-year report states that in the United States , with the advanced technologies , the median income has fallen and the employment to population ratio has decreased meanwhile . Thus , the artificial intelligence can t be successfully implemented the domain of transportation with the present situation of society .

Undeniably , artificial intelligence has many usages in transportation , but it also faces many challenges . Safety is biggest issue of transportation ; however , autonomous cars still make mistakes and can t guarantee the safety of passengers . Not only the safety challenges , but also the legal reasons have problems of artificial intelligence with the cost of reestablishing rule , privacy and ethical responsibilities . And the social pressure negatively affects artificial intelligence in the domain of transportation too , that the unemployed people caused by AI can be a really serious problem to our society . Thus , the artificial intelligence is troublesome to be implemented in transportation .
-LCB- \ rtf1 \ ansi \ ansicpg1252 \ cocoartf1504 \ cocoasubrtf830
-LCB- \ fonttbl \ f0 \ fnil \ fcharset0 Calibri ; \ f1 \ fswiss \ fcharset0 Helvetica ; -RCB-
-LCB- \ colortbl ; \ red255 \ green255 \ blue255 ; -RCB-
-LCB- \* \ expandedcolortbl ; ; -RCB-
\ margl1440 \ margr1440 \ vieww16580 \ viewh9880 \ viewkind0
\ deftab720
\ pard \ pardeftab720 \ fi320 \ ri0 \ partightenfactor0

\ f0 \ fs24 \ cf0 In the article \ ' 93Artificial intelligence and life in 2030 \ ' 94 , it envisions a promising future where the development of AI could profoundly benefit human society in the domain of transportation , home service or healthcare and so on . The articles also emphasis that AI has no imminent threat to humankind , because in the short term it is assumed that AI technology will not be rapidly developed to an intensive degree . Therefore , in the near future AI technology can exert far more advantages on our daily life . And leveraging the safety and reliabilities of AI technology creates a better and human friendly environment . However , this article may merely present an overoptimistic blueprint for AI development , because there are many factors neglected over network safety , potential loss of many jobs , and limitation of AI policy . \
According to the article , AI technologies would eventually pervade in our life , for example , self-driving cars , home device , or service robots . However , many people could blindly trust AI just like how much we trust our self-phone can securely protect all the private data . And It is common to see people or company \ ' 92s account get hacked on the news because of security loopholes . What if the system installed in self-driving car is maliciously attacked and controlled ? Then people \ ' 92s life could be on danger . In worst case scenario , ransomware attack spread on the all AI service robots and people might not even notice before their living space is intruded . Although it is crucial to support AI development , people should be attentive to the rapid progression of AI technologies . In other word , we have to aware that criminals could manipulate AI technologies to threaten people \ ' 92s living . This also could bring serious consequences we could not imagine . \
Another positive impact of AI technologies is on employment and workplace . Stone et al. -LRB- 2016 -RRB- claims that \ ' 93Ai is creeping into high end of the spectrum , including professional services not historically performed by machines \ '94 In a not distant future , many job-holders could lose their jobs because computer is taking over all sectors of job markets . Despite the fact that people could have re-training and new job will be created , the article fails to consider that public crowds have to abandon their current beloved jobs and choose a new career . So then is it meaningless to be a lawyer or construction worker ? People have to give up their jobs because AI technologies could do better work . Should people stop going to medical or law schools but instead put all their efforts into AI \ ' 92s development , since their jobs will be only \ ' 93temporary \ ' 94 ? This will raise another question whether humans are replaceable ? These questions are not answered but need to be discussed . \
Lastly , the article also acknowledge that people could use AI technologies for harmful purpose . And there are many debates about implementation of AI policy , because we have to differentiate the definition of policy from law . A policy outlines what a government ministry hopes to achieve and the methods it will use to achieve them , whereas laws set out standards , procedures and principles that must be followed . But how do we force the AI to follow certain rules if their moral standard might not align with humans \ ' 92 ? A more complex question is that should we merely consider human \ ' 92s benefits and rights but not the AI robots ? If the AI is trained to think and act like human , how do we ensure AI is willing to work for human ? And by then human already abandon their professional or fundamental skills , so should we prevent the AI be a thinker ? Therefore , there are lots of more discussion needed for future AI development . \
\ pard \ tx720 \ tx1440 \ tx2160 \ tx2880 \ tx3600 \ tx4320 \ tx5040 \ tx5760 \ tx6480 \ tx7200 \ tx7920 \ tx8640 \ pardeftab720 \ pardirnatural \ partightenfactor0

\ f1 \ cf0 \
-RCB- It is easy to see from Stanford 's One Hundred Year Study of Artificial Intelligence that AI has many , many uses . Those uses have bettered society in countless ways and research and development is being done in fields like education , healthcare , public safety and many more . It is nearly impossible to argue that the development of artificial intelligence has n't bettered society . However , with any new upcoming technology , there are always concerns with the future of the technology .
I think that one setback that is likely to slow AI advancements in the next few years that is not fully addressed in their paper will be lack of data . Recently , there has been a lot of debate around privacy for internet users . An example of this is Facebook collecting user data and running analytics on it . The general public is usually hesitant to give up so much information about themselves . Another example of how data collection is restricted is HIPAA compliance for healthcare . If researchers were to have access to larger portions of medical data , for example patient imaging , they may be able to make advances in predictive imaging to diagnose patients more accurately . Furthermore , I believe that although advancements will be made in AI in healthcare , security , surveillance , but there will be resistance because of the large amounts of data that are required for machine learning or other types of AI . I predict that more government regulations on what companies or the government can and ca n't acquire will be put into place and data collection will become more difficult . Because of this , legislation and regulations involving AI , data collection , and technology will become a bigger and bigger topic in upcoming years .
Around page thirty-nine in the paper , they discuss the possibility of humans losing their jobs to new technology developed around AI . The paper state that AI will `` gradually invade almost all employment sectors '' . Although I do believe that AI has and will continue to replace the jobs of many workers , I do not believe that it will have as significant effect on the general public as emphasized in this paper for two primary reasons . First , as AI replaces jobs , it is likely that different jobs will be created in parallel to the AI 's duties . Although the jobs created will likely not fully repair the lack of jobs that were replaced with AI , but it will lessen the severity of the loss in the long run . Another factor the will mitigate the losses created by AI are jobs that rely heavily on customer service . Although eventually there may be the technology that can provide better customer service than a human , even when that becomes the case , people may still prefer a human to make their experience feel more personal .
Although in this paper , the authors sound certain that the likelihood of anything malicious coming from AI development is likely , I believe that it should be a larger concern than is emphasised in the paper . Great minds like Elon Musk have stated their concerns about AI , machine learning , and the possibilities that they create . Although we have yet to have any major problems with artificial intelligence that we can not control , at the rate technology and research in this field is advancing , it may not be as far away as some people thing.After reading `` Stanford One Hundred Year Study on Artificial Intelligence , '' one thing that the Standing Committee overlooked during the writing of this report is the in-depth research on social life for humans in the
work force . On page 39 , AI 's `` will gradually invade almost all employment sectors , requiring a shift away from human labor that computers are able to take over . '' This means that many employees , and potentially freelancers ,
will be unemployed and will have to look for new employment , potentially under a new field . The article also mentioned that with the implementation of AI automation into the workforce , people can use their times for more
recreational purposes . Another factor that was not looked at is that for those who are still employed , but some tasks are replaced by AI automation , their hours will most likely be cut , giving them more free time , but it 's
possible that employees may have an excessive amount of free time . Us humans were n't meant to just sit around all day for a year and just relax , we were `` programmed '' to be productive and have tasks to do . Those that have
been replaced by AI automation and those hoping to find employment may start strikes , demanding for more job positions and to remove AI 's , unless the government finds a solution to pay those that have been replaced .
A good example of this unemployment predicament is the trucking and manufacturing industry : millions of drivers transporting goods from city to city . If self-driving trucks promised by Tesla 's Elon Musk arrives , yes ,
it will reduce accidents and reduce the time it takes to transport goods , but what will the millions of truck drivers do when they are replaced by AI 's ? Another example of an industry that AI will heavily impact is any
manufacturing industries : there are millions of employees were given jobs doing repetitive tasks , and if that job is automated , just like the trucking industry , the manufacturing process will be more efficient , but millions
of employees will now become unemployed . Eventually , the robotization of work will move its way into more knowledge-based jobs , such as accounting and stock traders , and even potentially , into the medical fields . On the bright
side , all those millions of employees have more free time to spend time with their loved ones and participate in activities they could n't have before because of the hours they work , but how will they achieve what they want
if they do n't have a source of income ? A possible outcome of this is that those unemployed will start a nationwide , or if AI reaches the globe , international , workers strike demanding for employment and the removal of AI
automation . CEO 's wo n't be hiring low-level workers since the use of AI automation will save them millions of dollars . For those that are able to maintain their jobs and working alongside AI , workers compensation must be
established . Just like how humans have flaws , robots and AI 's will have flaws and defects as well , and especially in manufacturing , that can cause serious harm to workers . It is also possible that with automation being used
in big corporations , trade secrets and private information may be released via hacking .
CS 540 sec 2
Thoughts after reading Stanford One Hundred Year Study on Artificial Intelligence
After reading the article , there are many thoughts come to my mind . First of all , I must
say that this article is a very comprehensive report about the current status and future drafts of AI .
I agree with the discussion about the employment of AI in different areas . Some of the area we
have already heard every day through news like self-drive cars and home-service robots , but
others like the health-care system and education system truly refresh my understanding about the
future of AI application . But in the last part the article talks about the concern of AI
implementation which I can not be agreed with . I think these problems will not be obstacles to the
improvement of AI and they can be solved easily .
In the first part of the Policy and legal consideration , the author points out that states law
and the national law may have conflicts about the definition of autonomous vehicles and which
kind of autonomous car should be permitted to use . However , in my mind , this kind of conflicts
are very normal . Just like the law of using cannabis . Although federal law has explicitly pointed
out that it is illegal to use cannabis in any functions , still , in California and other 44 states , the
medical cannabis is still being permitted to use . Therefore I believe if the state residents support
the use of autonomous vehicles and other AI devices , it is easy to find a balance between federal
law and state law .
In the next part , the author talks about the privacy issue that AI may bring . He illustrates
that when AI is making decisions and predictions , it may take private information like race into
consideration . However , in my understanding about AI technology , all the information that AI
can reach means that this information should be taken into decision making . In this way , the
decision and prediction can be most accurate and useful . If the user truly wants to take some
aspects out of consideration , then the program designer can design a user mode which let them
choose specific aspect they want to ignore . For instance , if the user wants to let AI skip the
influences of the race , he can tell AI about that before it makes the decision . After all , AI
algorithms are used to help people make decisions rather make decisions for people . The final
right is still being held by the human being .
Furthermore , the following part talks about the Liability of AI which I think is nonsense .
For civil aspect , if people do not intend to cause any harm , the AI self-protect system will
automatically prevent them from causing any damage to the society . The same idea applies to
guns . In America everyone has the right to hold guns but since there is a proper protection to
prevent people from hurting others unintentionally . We don t need to worried about being killed
by others without purpose every day . In the future , I have the confidence that we can build well -
designed protect system to avoid unintended damage . For a criminal , the same idea applies .
There is no doubt that at any time there are people want to cause harm . But this can not be the
reason for us to stop developing new technology . Though new technology may bring
unpredictable issues , human will gradually fix the issues and get huge benefits from new
technology .
Other concerns being discussed in the report such as Labor and Taxation issues should
not stop AI from being applied as well . But due to the word limit , I am not going to discuss them
further . In conclusion , I believe all the concerns we predicted now will be solved during the
development of AI , and AI can truly bring benefits to human .

In the One Hundred Year Study on Artificial Intelligence , the Study Panel generally believe that there should be no cause for concern that AI is an imminent threat to humankind -LRB- Artificial Intelligence and Life in 2030 , P. 4 -RRB- . Under this general belief , several supporting claims are made . However , this report is overall too optimistic in respect to whether AI will be a threat to human beings , and some of the claims can be challenged .
First , the report states that no machines with self-sustaining long-term goals and intent have been developed , nor are they likely to be developed in the near future . That is , AI would not be able to set its own goal and hence would not do harm to human beings . However , self-sustaining long-term goals and intent may not serve as a good criterion to judge the potential risk of machines with AI turning against humans . It is understandable that a machine with self-sustaining long-term goals and intent may develop its own goals that may do harm to human beings , but a machine does not need to have that high-level intelligence to do harm to human beings . A machine with only a specific function but performs that function to an extreme can also be dangerous . Imagine a home-cleaning robot with the short-term goal to clean all the things in the house that may bring illness . Eventually the machine may learn that humans in the house are sources of illness and hence should be cleaned up , and harms to humans may then be carried out by the robot . Therefore , a machine does not need self-sustaining long-term goals to be threatful to human beings . So , contrary to the belief of the report , people should not be too optimistic about the nature of AI , but be always mindful of the potential risks of AI . I think the essential point to prevent harms to human beings is to limit the functionality of machines when they are created . Limited functionality may impede the development of Artificial Intelligence , but this manipulation is necessary because AI is developed to benefit human beings , and there is no point to make a fast advancement of AI that may do harm to human beings .
The report criticizes the FDA s caution in approving new diagnostic software as the barrier to rapid innovation and the HIPAA -LRB- Health Insurance Portability and Accountability Act -RRB- requirements on privacy as the barrier to applications that could utilize AI technologies -LRB- P. 27 -RRB- . However , those acts are necessary to prevent AI from affecting humans negatively . Just as admitted in the report , even if it s unlikely that AI systems will autonomously choose to inflict harm on people , it will be possible for people to use AI-based systems for harmful as well as helpful purposes -LRB- P. 10 -RRB- . Without the regulations on software and privacy concerns , AI may develop faster , but the privacy information utilized by AI can also be easily exploited by people with vicious intentions . Hence , those regulations regarded as barriers to development of AI are necessary for the security of individuals , and should not be sacrificed for the development of AI . After all , AI is created to do benefit to human beings , not to make our lives more susceptible to harm .

Reference :
Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .
A CRITIQUE OF THE STANFORD 100 YEAR STUDY ON AI

The Stanford One Hundred Year Study on Artificial Intelligence is an ambitious project to chronicle the evolution of AI technologies . The first report covers a plethora of issues concerning AI technologies affecting many fields of human endeavor .

In this critique , I challenge the predictions and recommendations of the Report related to the autonomous or ` self-driving ' technologies on two fronts . Firstly , there is no mention of the need to have one common design philosophy concerning the self-driving tech . Secondly , the assumption that gaining public trust is sufficient to ensure widespread acceptance of this technology . Let us examine this one by one .

At present , major automakers and multinational corporations are pouring billions of dollars into research and development to be the first to field self-driving cars and get the early bird advantage ' in the field . While in a way this competition is good for the fast progress of the technology , the lack of a coordinated effort in developing self-driving tech may have detrimental effects . The design philosophies may vary , and therefore the characteristics and behaviors of cars from different manufacturers will differ wildly . When we have a number of these cars together jostling for space and customers on the roads , the possibilities of mishaps are many . For example , in initial phases , some manufacturers will involve a human driver as a backup for unforeseen circumstances , whereas others will adopt a different strategy . This mix of design philosophies with no guidance of which one is the right ' approach , can be quite dangerous and hamper progress towards adoption . A concerted effort towards a common design philosophy of self-driving tech is a more logical approach that needs to be adopted by all stakeholders .

Secondly , the Report assumes that the adoption of self-driving tech will be governed mostly by public trust in the technology and that they may eliminate the need to own cars . The report predicts that the technology will be highly pervasive and its impact on the transportation sector will be total . However , no emphasis is laid on the crucial Transition period ' between the time when the technology is first introduced and its ultimate universal adoption . During this period , we may have human drivers along with self-driving cars on our roads . Many factors affect the duration of this transition . One of the factors is the affordability of the self-driving tech . If the common man can not afford a self-driving car , then its adoption among the masses will be slow . Also , a lot depends on the timeframe for a complete overhaul of the public transportation system with this technology . Even if we account for all these factors , there may still be hobbyists and enthusiasts ' who may be averse to the idea of shunning traditional vehicles just because of the sheer joy of driving . At some point in time we may have to consider the question : Do we ban human drivers from our roads and stop production of such vehicles ?

Policy makers need to consider above factors and formulate of laws governing such a mix of vehicles on the roads . The SELF Drive act passed by Congress recently is a good step in this direction . This bill gives powers to the National Highway Traffic Safety Administration -LRB- NHTSA -RRB- to regulate the design , construction and performance of self-driving cars within a common framework . As per the act , to get a permit , a self-driving car needs to pass tests which are formulated by NHTSA to be deemed as safe as a human driven car and therefore fit for the roads .
While the report One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- provides a sufficiently comprehensive discussion on many aspects of AI 's potential impact on the society , I would like to challenge the perspectives and discussion on how AI will impact education in the near future . The report provides a too positive view on how much AI will help improve our education quality and simply attributes the inefficient use of AI to the lack of financial resources .

The report heavily implies that offering education at scale is beneficial to the society , but in reality , it may not be true . According to the report , AI has enabled many instructors to enlarge their class size to hundreds or thousands -LRB- p. 32 -RRB- . But the question is how effective is this type of education ? Does this type of education really motivate the students to think and grow or only force them to memorize the correct answers ? For individuals who are clear with their goals and purposes , it might be more efficient for them to learn using AI , since they are already motivated and know what they need to learn . However , for the others , learning by reading info from Wikipedia and doing some auto-generated multiple-choice questions might not be helpful . It is crucial for the instructors to offer mentorship on a personal level to guide the students . Education is not a commercial good , it is about helping individuals to explore their potentials while learning technical knowledge . Therefore , cautions should be taken when use AI to enlarge the class size .

In addition , the report emphasizes how AI can provide personalization to enhance our education at all levels -LRB- p. 31 -RRB- . First , personalization is a very broad term and it can take different forms and depth , so I am not sure how personalized the learning process can be . Also , how do we evaluate the benefits and effects of the personalization provided by AI ? How do we know whether the personalization is the best for the students to achieve their learning goals ? Different individuals have different sets of learning habits , which makes personalization a complicated process . The report claims that AI can provide personalization at scale . Almost everything works at scale don t work for some special situations . The personalized learning plan would not be an issue for those who benefit from it , but issues may arise for those whose needs are not met by the AI personalization . Another issue with personalization is it may not be standardized , which could enlarge the gap , either in the specific knowledge or the amount of knowledge , among the students .

As the report mentions in the introduction , human brains are way much more versatile than the existing AI , and it is unlikely that AI will match human thinking anytime soon . Delivering education is fundamentally different from other tasks that AI is usually used for , as AI is teaching humans in this context . The application of AI in education may bring some benefits , but it may also backfire depends on how it is specifically used by the instructors and the students .

The report , Stanford One Hundred Year Study on Artificial Intelligence , has provided an understandable and comprehensive overview of Artificial Intelligence with respect of its development , accomplishment , short-term and long-term future trend covering eight main fields , transportation , home service , healthcare , education , low resource communities , public safety and security , employment and workplace and entertainment . From personal perspective , most arguments proposed in this article are very informative and reasonable , stimulating interests and broadening eyesight for a reader as college student . However , I think that some conclusion and prediction made in two fields , transportation and employment , might need more consideration .

Firstly , within the focus on AI changing transportation industry , the writers specified two potential application aspects , self-driving vehicles and transportation planning . Recent studies and report predicted that `` self-driving cars will be widely adopted by 2020 '' . Experts also agree that autonomous vehicles would not only take the form of personal use but also ridesharing and public transportation . On the other hand , the writers introduced how AI can facilitate on-demand transportation such as Uber and Lyft by matching drivers to passengers . However , I think the writers are collecting various information without conducting critical analysis . If self-driving takes place of traditional car in the near future , which is very likely to happen , then the matching algorithm would be useless since the amount of driver will reduce sharply or even the job will disappear by then . Furthermore , it is reasonable that on-demand transportation could result from AI applying into transportation industry , but the matching will not likely to happen between the driver and passenger , but instead , between the vehicle and passenger relating to their location , surrounding traffic condition and vehicle carrying capacity . In this case , whether the reputation modelling would be true might be open to doubt . Service companies , Uber and Lyft , need to make strategic transitions and adjustments considering the rising popularity of self-driving cars and autonomous vehicles .

Besides transportation industry , there is an interesting prediction around current employment and workplace condition in the report , that `` AI will likely replace tasks rather than jobs in the near term , and will also create new kinds of jobs . '' I think the first half of the statement is too optimistic . A lot of examples mentioned in this article , such as self-driving car , intelligent tutoring system and city infrastructure design all replaced one or more job categories . In reality , AI 's abilities of language recognition and instant translation has been replacing traditional high-educated translators . Moreover , the article claims that `` Changes in employment usually happen gradually , often without a sharp transition , a trend likely to continue as AI slowly moves into the workplace '' . I assert that the time scale should be compared with the time spending on education . It is not rational that AI would cause a sharp change overnight , but might eliminate a previous employment category gradually over several years . The time period is usually not adequate to prepare education system to make appropriate response or adjustment . As a result , it is entirely possible that many well-educated individuals will be unable to get a job relating their major due to the time lag between employment market and education system , the point of which the report fail to justify .

In sum , I cast doubt to ideas mainly from transportation and workplace in that it fails to reconcile future contradicted scenarios nor consider part of current trend when stepping into prediction .

Note : all direct quotation comes from the report

Artificial intelligence is becoming a more and more prevalent science to study and test the
limits of this emerging technology . Universities , the government , and corporations alike are all trying
to get their fingers in this field with unknown limitations . The power of AI has yet to be fully
discovered and that is a dangerous thing .

AI will likely replace tasks rather than jobs in the near term , and will also create new kinds of
jobs . But the new jobs that will emerge are harder to imagine in advance than the existing jobs that
will likely be lost . Changes in employment usually happen gradually , often without a sharp transition ,
a trend likely to continue as AI slowly moves into the workplace . A spectrum of effects will emerge ,
ranging from small amounts of replacement or augmentation to complete replacement . 1 This quote is
fundamentally wrong .

Artificial intelligence will most assuredly replace jobs and not just tasks in the near future , it
will completely replace jobs and create only a few jobs for the numerous ones that they replaced .
Some changed in employment happen gradually but when artificial intelligence hits the job sector it
will be a quick and fast transition not a smooth gradual one , taking over many , many jobs in quick
succession .

Corporations and their owners will do almost anything to save money , cut costs , and raise
profits , that is how the economy works make as much money as you can for as little money put in .
When a corporations can replace 10 workers with a machine and hire one maintenance man in
replacement that is a great business move . The money saved from labor and transferred into the
machines and their upkeep would boost profits immensely . So when artificial intelligence gets to the
point where it can start replacing workers then corporations will flock to the power of artificial
intelligent minds to do the work of 10 people for one machine and one maintenance guy to make sure
everything runs smoothly . The profit margin of 5 maintenance men and 100 artificial minds compared
to 1000 workers doing the same jobs in vastly difference .

Mike Collins in his article about artificial minds taking over the work force called Will Robots
Replace Humans states that there are three limitations to artificial intelligence that we as humans
can not create yet because we do not have the understanding or physical capabilities to do so yet .
Unconscious mind , conscious mind , and emotions , these three things we lack the knowledge to put
into a machine .2 This statement does not address the key point , robots with artificial minds and
learning capabilities replacing humans in the work sector . You do not need a robot with these three
characteristics to replace a worker , you just need to write a script that learns just how the worker
learned when he himself was learning .


Artificial intelligence is still in its infancy and has countless possibilities , but when it comes to
the work force being replaced by the artificial mind beings , corporations will do so as soon as they are
able in lieu of more profits to line their pockets .






Bibliography
1 . Collins , Mike . 2014 . `` Will Robots Replace Humans ? '' Manufacturing Business Technology
http://search.proquest.com.ezproxy.library.wisc.edu/docview/1629409576?accountid=465 .

2 . Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia
Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David
Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial
Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the
2015-2016 Study Panel , Stanford University , Stanford , CA , September
2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .
Instead of focusing on any specific part of AI , I have decided to take a holistic view of the potential downfalls of AI by considering a few examples that I think are the most important factors to consider as the development of AI continues to ride the wave of popularity and funding by large investors .


Transportation is arguably one of the most popular fields of AI at the moment and rightly so . The act of driving is a very heavy task on the brain - one that requires complete concentration and focus . If the millions of hours spent driving by humans could be saved by complete automation , as the report indicates , it would effectively save millions of hours and would increase productivity of the economy . However , one thing that the report fails to fully expand upon is the dangers of leaving human lives in the hands of an internet-connected machine . Hackers that are highly experienced and skilled are able to hack into the most protected of databases and websites and leak information shockingly often . Unlike personal information which is quite valuable but is n't immediately life-threatening , having a hacker hack into a vehicle and possibly be able to control a car would be terrifying . Whether that 's locking the vehicle and demanding ransom from it 's passengers or controlling the car and driving dangerously , leaving lives in the hands of someone else even for a second would and should be unacceptable . Given today 's world , one needs to assume that the worst could and would happen , and hacking a device that connected to the internet is definitely a possibility . This begs the question , where does one draw the line between increasing one 's comfort and increased economic productivity in exchange for potentially horrendous consequences ? Sure , one could argue that driving is one of the most dangerous activities that humans perform on a daily basis , but leaving up your control to some malicious user is quite simply , a nightmare .


Public Safety is another interesting application of AI which has a large value placed on it due to increased peace of mind that a successful implementation of AI would provide . However , an important problem to consider is the models that AI would work on . AI works by learning from the situations that it encounters and as a result , there potentially could be the reinforcement of stereotypes and minorities communities being unjustly targeted by the system if the systems constantly look at those minorities performing crimes . This is actually a much bigger deal that report makes it out to be . Once these systems are in places such as airports , shopping malls and other places of public interest , it becomes essential that the system that detects potential crime sees the situation in black-and-white .
On the flip-side , as the report states , today it is quite difficult to constantly monitor the large number of video streams that is generated by security cameras that are seemingly installed in all corners of today 's cities . AI would definitely help by identifying threats to other people by recognizing suspicious activities but this technology needs to be done in a manner is irrespective of the individual 's race and background and instead focus exclusively on the mannerisms and other factors of the individuals that the cameras are looking at.In Stanford s One Hundred Year of Artificial Intelligence , it is mentioned , under the Healthcare Robotics section under the Healthcare title , that
artificial intelligence will likely not automate a large section of work in hospitals or nurseries in the near future . The report argues that while
robots will definitely infiltrate the healthcare services , it will only do so by automating low-skill labor . The reason for this is that doctors practice
many duties which are too meticulous and precise for a robot to accurately replicate . However , this is not true , and we can see many examples in the
real world right now that prove that artificial intelligence has already significantly impacted the medical field .

There are many technologies that are capable of emulating most of the work of doctors . Consider Watson , IBM s artificial intelligence robot , which is
so advanced already that it is on par with a professional radiologist , a profession which nets an annual salary of $ 400,000 . Machines like Watson are
capable of detecting diseases like Alzheimer s a decade before any symptoms surface , with an accuracy that regular practiced doctors can not match . Watson
can also predict what a patient is suffering from and create a pill with a certain combination of chemicals tailored for individual patients based on their
specific conditions . Many doctors do not do this because of the severity of a misdiagnosis , but Watson is capable of doing so very accurately .

Consider a more specific case , like the treatment of early-stage cancer . It takes weeks to identify drugs which relate to cancer-causing symptoms in
patients , but Watson can do it in under an hour , and automatically points to scientific findings and past papers detailing treatments for similar cases .
Watson is also used extensively to test research hypothesis on immunotherapy , which uses the body s own immune system to help combat cancer .
Because of this , it is much easier to conduct future research and saves a lot of time and money . Given a large test population s current health conditions ,
and a list of their previous medical histories , Watson was able to identify potential causes of cancer -LRB- such as genetic conditions and life-style choices -RRB-
which increases the likelihood of cancer .

Robots are also taking over work performed by other medical professionals besides prescription doctors , such as those of surgeons . Many machines are now
many times more precise and proficient than veteran surgeons , and don t require breaks in between nine-hour surgeries . These machines are set to enter
large-scale manufacturing in the coming years , and many experts believe they will likely enter the workforce in the next decade .

Therefore , it is not accurate to state that artificial intelligence will play a minimal role in the healthcare sector in the next coming years . If
machines like Watson are any indication , artificial intelligence will not only be able to replicate much of a doctor s work , but it will also be crucial
for the medical field , whether in research , intensive surgeries , or general prescriptions . As such , it is likely that many corporations in the healthcare
sector will invest in artificial intelligence to save time , money , and lives.This report , with its abundant details about the AI research and application , has proposed changes that might have great impact in different domains , including health , transportation and education . Although the claim made by this report is always based on many empirical studies and other technical reports , I 'm challenging the view of this report on the future education in the next fifteen years . A formal classroom especially in institutions like college will not widely adopt AI products , such as intelligent tutoring system , as predicted by the report . Its cooperation with virtual reality -LRB- VR -RRB- is not promising and the customization for different students and courses might be a big impediment for AI in education field .

The formal classroom wo n't be able to adopt VR as medium for AI . This report has pointed out couple studies , such as Stanford 's Galileo Correspondence Project to show how AI combined with VR can serve a way to create interactive experience in history learning field . Although it sounds amazing -LRB- I believe it really is when experiencing -RRB- , it requires VR , a technology that still has its inherent problems towards its mass use . Forbes in 2017 has once summoned 8 analysts to evaluate the VR , and over half agreed that VR is still far from actual use in daily life . It is not affordable to each student , because VR in current form also needs extra computer to provide content for it . It also lacks many ways of human interaction , like writing , doing on-hand practice , and social interaction , which are all provided and crucial in formal education . AI with its superior natural language process ability can be useful in the VR learning , but it ca n't help to improve other aspects of VR to make it essential to the learning in formal classroom . Thus , VR will not be a good medium for formal classroom to adopt AI .

Another impediment for AI to enter the formal classroom might be the high customization of formal classroom , instructor . In the current college education system , the content of courses is diverse , even within courses under the same title . Each instructor has its own focus on the same content , and approaches the same topic from different angles . Thus , an AI intelligent tutoring system for different formal courses needs to adapt to this variety . However an instructor may only teach a course at most 10 semesters , and generate little data . Since the AI training needs a huge amount of data , if the AI ca n't get enough data , the algorithms for the machine learning , the deep learning and reinforcement learning discussed in the paper can lose its accuracy . On the contrary , online courses where instructors record their videos and do n't change their content much can generate a lot of data when people from all of places get access to it . Then , this huge amount data can be used for learning analytic , helping AI to learn from the teacher and become a good tutor for other students in online learning . This discrepancy in the amount of data generated might foresee that AI can be useful in MOOCs but not necessary in a formal classroom setting in the next fifteen years .

In the next fifteen years , AI might be able to drive a car or save a lot of peoples ' life . However , in the traditional learning environment , AI wo n't be able to tutor a specific class . The VR proposed by the Study Panel is far from usage and the data from traditional formal class , unlike online courses , is n't enough to teach AI to be good tutor .
In my opinion , although I absolutely agree that AI will eventually influence all parts of our daily lives , I think that there will ultimately be domains where it is n't able to completely replace us humans . This is because I believe that while AI will be able to closely resemble a human brain and replicate many of our actions and thinking , I do n't believe that it will be able to resemble all of the emotions that we as humans are able to feel .

One example is in the entertainment domain . While I agree with that AI will make entertainment more `` interactive , personalized and engaging '' , I believe that there will still be voids that AI will not be able to fulfill . For example , while an AI robot will certainly be able to play soccer with a kid , it will not be able to fully replicate the emotions that are produced when the kid plays with one of his/her friend .

Furthermore , I question the statement of AI being able to create better media than humans will . Sure , an AI will be able to consume and analyze a huge amount of data in order to obtain details in a humans ' interest and taste , I do n't think that AI will be able to create media with the kind of emotions that human creators can . We watch most movies and TV shows because they engage our emotions . For example , we laugh in some movies because the comedy was created to engage our emotions thus making us feel joy . We experience sadness after watching some movies because a character that we have been attached to for a period of time died . While AI may be to produce some content that would be able to engage us , I do n't think that it would be able to produce content that would strongly engage our emotions .

Ultimately , I just can not imagine human emotions being able to be completely represented by ones and zeros . Emotions such as intense sexual love and jealousy experienced by humans in romantic relationships can not be wholly represented in math . Moreover , how can computer science ever completely define and understand emotions ? Although I may very well be proven wrong one day , I also think that deep philosophical questions would need to be ask when the line separating humans and AI are blurred so much so that there is no difference between an AI and a human other than physical differences .

Writing this essay made me think seriously of the future we may live in . How important will our `` human touch '' be ? As Aristotle once said , we humans are social animals . We survive and live by interacting with each other . I just do n't think that it is right for us to have a future where we interact more or only with AI than with our human friends , thus losing our `` human touch '' . If all of our daily tasks will be able to be achieved by artificially intelligent robots , what joy is there in living ? If we no longer need to hustle and bustle to achieve our goals , what is the point of our existence ?
The use of artificial intelligence within school systems can be extremely beneficial to both students and teachers and I believe that schools should put their resources into implementing this software into their regular curriculum . Not only has artificial intelligence allowed teachers to increase the size of their current classrooms , it has also decreased the amount of work that teachers have had to do to satisfy all of their students needs . In Stanford s One Hundred Year Study on Artificial Intelligence , it is stated that The current absence of sophisticates use of AI technologies in schools , colleges , and universities may be explained by the lack of financial resources as well as the lack of data establishing the technologies effectiveness -LRB- page 33 -RRB- . However , I disagree .
I am currently employed as a software testing intern at the Epistemic Games Group at UW Madison where I conduct quality assurance tests on educational programs . These programs are referred to as virtual internships and allow students to gain real life job experience from behind a mouse and keyboard . These programs contain high levels of artificial intelligence that help to boost students through their coursework and ultimately lead to the achievement of tasks through teamwork and collaboration . Not only have I tested these internships out , but I have been able to monitor live implementations of the programs and have seen firsthand how effective the use of artificial intelligence in a classroom is . With this being said , I must disagree with the statement that the absence of sophisticated use of artificial intelligence in education is due to the lack of financial resources . When a new school wants to try out the programs that my firm works on , yes , sometimes there is a minimal charge . In most cases , however , we supply the schools with our software for free . This is due to the fact that we are a grant funded company and it is usually in mutual interest for schools to use our software . This clearly counters the argument that artificial intelligence software is expensive , and shows that there is no reason for schools to not test out implementations of it .
As far as the argument of the lack of data establishing the technologies effectiveness goes , our firm also doubles as an educational research lab in which we collect data from every run of the program and perform tests with that data to gain insight into how students learn best . This data also is used to show teachers exactly what students chatted about during the run of the program and what connections they made within the game and with other students , thus showing the technologies effectiveness . Not only this , but we also use the data to constantly improve our software so that students have the best learning experience they can have .
With all of this being said , One question remains . Why is there currently an absence of sophisticated use of artificial intelligence technologies in schools ? I believe that the main reason for this is a lack of interest by students . Although the program my firm has developed is unquestionably beneficial to improving students learning , there has been a lack of interest/boredom through some implementations . I believe that as soon as artificial intelligence programs become more engaging and interesting to students , it will then become used widely throughout the education system.Benjamin Deetz
CS 540
9/10/2017

100 year study on Artificial Intelligence Response
While overall , the main focus of the study is accurate , the study fails to fully understand the economic effect of Artificial Intelligence . While on one hand the study devotes a lot of time to arguing that AI , while it will be helpful and replace some jobs , will also create more and as such not have an incredibly large effect on the economy . On the other hand , it is also argued that AI will change the way that wealth is perceived , and that everyone will be entitled to a piece of the efforts that come from the tireless workings of AI . However , there is a third scenario that the study fails to acknowledge , and this scenario is the most probable of them all .

Because the vast majority of the world operates in a capitalist economy , AI technologies will simply join this economic model , and as such , the gains made by AI will not trickle down to the average worker , but rather just help the bottom lines on the companies , reducing jobs and increasing profit . While normally this would just lead to the wealth gap between the rich and poor increasing , with AI allowing for so much in the entertainment industry , what this likely means is a large segment of jobs going from physical and mathematical labor into jobs which require creativity which is far beyond the scope of IA , such as producing music , art , and literature . In particular , video games , with the rapid technological advances , will likely continue to get more complex and sophisticated , and as such will require more workers for the companies , as hopefully , keep the economy somewhat stable .

However , this economic model is unsustainable . The reasoning for this is simply . There is no way for the entertainment industry to sustain itself by simply paying its employees to consume its products . It needs outside money to survive , and as such would not be able to sustain itself if its only outside money came from a , compared to today , small outside industry . As such , this likely scenario would only lead to a large economic depression , simply taking longer to reach that point than if workers were simply replaced .

Therefore , the main question becomes , how to integrate AI into the workforce and the economy without having it replace workers and hurt the economy overall . The fact of the matter is , not everyone can write computer code , and , no matter how much emphasis is put on education , not everyone will be able to handle complex technological jobs . If there were and easy answer to this , it would likely be the title of the study . But there is n't , so the best that can be done is to offer ideas . The main one is to make sure that the benefits of AI help the average worker more than the CEOs . The next idea that could be implemented is that if there is only a set amount of labor needed to keep society running , then every worker should simply cut back on their hours . If everyone only works twenty hour weeks , then there are approximately twice as many jobs as if everyone works forty hour weeks . As a benefit of this , the added free time for the population should make the original entertainment industry boom scenario look more probable and sustainable .

Overall , it is difficult to predict the effects of AI on the economy , and the response which people will have to them . However , to make sure that the introduction is beneficial for everyone , a great deal of thought should not only be given to what AI can do , but also to what AI should do .
In Stanford University 's published `` Artificial Intelligence and Life in 2030 '' article , the authors discuss AI and the inevitable issues it will run into in the United State 's court system . In the case of legal troubles , the article states that courts `` might arbitrarily assign liability to a human actor even when liability is better located elsewhere for reasons of fairness or efficiency . '' -LRB- Stanford 46 -RRB- . The article goes on to say that in cases where the court can not foresee the harm that the AI caused , liability would fall by default on the victim . In cases of criminal charges , the court would have to prove that there was an intent to commit harm . The authors state how `` courts and other legal actors will have to puzzle through whom to hold accountable and on what theory . '' -LRB- Stanford 47 -RRB- . I disagree with the authors regarding the issues that will be presented by introducing AI into the legal system , as responsibility for an AI 's actions will fall onto its creators and maintainers because they are the ones responsible for providing and monitoring its training data and testing .

While Artificial Intelligence is often seen as being a sentient being or in some cases equivalent to a human , the AI that we 'll be seeing in the near future in many of the technologies discussed in areas like healthcare , education and self-driving cars are not that . They are software with the feature of complex decision making . Like any software , the group or corporation behind maintaining it can be held liable in the case of faulty or subpar performance . Artificial Intelligence is not different . If the maintainers of the AI program document the training material that went into creating the AI , it should not be difficult for investigators to determine whether data for certain cases went into the AI 's conception and testing . Based off of that , it should be feasible to determine whether the maintaining group can be held liable in court cases .

New legislation being drafted for Artificial Intelligence also supports software manufacturers being liable for errors caused by the AI . In December 2016 , Michigan created the first law pertaining to self-driving cars . Part of the new rules are pertained to liability in the case of car crashes . In an analysis of the new law published by Vox website ReCode , Johana Bhuiyan states how Michigan 's Department of Transportation `` will require automakers that are operating a ride-hail network to take full liability for accidents in which the vehicle was driving itself and was found at fault . '' -LRB- Bhuiyan -RRB- . While this law is fairly vague and only applies to a specific subset of self-driving cars , it sets a precedent that the rest of the country may follow in the coming years .

When the authors of the `` Artificial Intelligence and Life in 2030 '' article speak about how the introduction of AI into society will require laws to change , they are correct . I disagree however on their opinion that AI will cause the need for an overhaul to our laws . New regulations are making the logical step of giving accountability of software to its developers . Over time software developers , like the companies who create physical items , will be held responsible for the items they create .

Vox article cited : https://www.recode.net/2016/12/9/13890080/michigan-dot-self-driving-cars-laws-automakers
With many promising and new technologies , government and regulatory groups can be slow to keep up . Money funneled into private research groups and large corporations dominate the field faster than government agencies can respond with regulations for safe and fair use . The article Artificial Intelligence and Life in 2030 is the result of a long-term study conducted by Stanford University in response to the widespread investments and research into Artificial Intelligence and its applications . It discusses where Artificial Intelligence is headed , but also recommends ways to ensure the safe and fair practices of these technologies as they are integrated into many parts of society . It s suggestions and implications for regulations and public policy on artificial intelligence seem oversimplified and na ve and ultimately disregard the complexities of government and lobbying corporations and institutions .
Regulations and public policy , as suggested by the study , must be made by informed personnel in the artificial intelligence and technology sector . While knowledgeable personnel should be behind the regulatory committees and policy , it is na ve to ask government officials to be up to date with all research in artificial intelligence and many other technological fields that are rapidly changing the landscape around us . Although ideal , there simply is not enough funding and resources to educate the government quick enough . That said , regulations , if any to ensure fair practice , are already late in a game where products are far in development cycles and early stages of what artificial intelligence algorithms are capable of are being deployed to help everyday workers .
Nonetheless , public policy is a major initiative to ensure the people s protection from unreasonable and reckless innovations . Self-driving cars are commonly used as an example -LRB- as seen within the article/study posted by Stanford University -RRB- . Many cases already have been reported of accidents of self-driving cars . With little policy deciding blame and responsibility for these incidents , corporations have been able to use loop holes to blame the passengers rather than their own faulty software , algorithms , and machinery -LRB- are barely loopholes because they are so blatantly obvious -RRB- . Policy must be made to protect the people from unfair practice and implementation of artificial intelligence . Handling these grey areas within the legal system will force drastic changes and rulings sooner than we expect as new technologies are release into the world .
Another challenge with regulations and policy regard artificial intelligence is that often demanding regulations can inhibit the research and development of new technology . The study contrasted the effects of policy in areas where policy was used to foster positive research practices , such as protecting users privacy and personal information , in comparison to areas with stricter regulations , where researchers followed more of a compliance mentality and focused on avoiding penalties and fines . There is a fine line between promoting safe research and over-regulating to the point of inhibiting the swift progress of research . The future of artificial intelligence lays in the hand of public officials who have the power to restrict the flow of ideas and their usages .
With Elon Musk and other science professionals warning the dangers of artificial intelligence and its potential to become self-aware and potentially destructive , it is likely that the prospects highlighted by this study will never fully develop . If public policy is made by uniformed government officials who fear artificial intelligence more than they understand it , harsh restrictions could hinder research and create this compliance mentality that forces industry conglomerates and private researchers to dance around regulation rather than protecting their consumers and ensuring the safety and reliability of their products .
Artificial intelligence technologies will continue to develop over the next decade bringing many advances , particularly in applications that are not transparent to the average consumer . However , the report significantly underestimates the retarding impact of both high consumer expectations as well as general consumer distrust . Consumers will continue to resist obvious artificial intelligence advances that either do n't meet inflated expectations fed by decades of speculative fiction , or remove an expected human component that signifies safety or standards .
Uptake of fully automated transportation will be delayed by contemporary human perception . While some early adopters will be quick to use parking assist or blind spot monitoring , individuals will in general be slow to relinquish full control of their vehicles . Individuals will continue to want the ability to override and take control of their vehicles for at least ten to fifteen years after the technology becomes more widespread . An increase in fully or partially automated vehicles traveling alongside unpredictable human drivers will result in more accidents than automated vehicles currently experience . These accident will likely be caused by humans rather than the AI `` driver '' , but this is unlikely to counter increased human distrust .
While the aging population will be more technologically inclined in 2030 than today , adoption of automated transportation wo n't be significant . Early adoption will begin with a younger population . It will likely take at least another 15 years before the elderly population sees significant adoption of automated travel options . Intelligent physical assistive devices will likely also become more widespread with an elderly population further in the future than anticipated due to distrust within that group .
Home robots will also not advance significantly in the next fifteen years . While the components that will eventually facilitate the use of service robots will continue to advance , the combination of artificial intelligence and robotics will not be sufficient to meet the expectations of consumers in terms of versatility . Artificial intelligence will be further integrated into household appliances , but new applications within robotics will be slow to expand . Consumers will be more willing to leave domestic tasks to machines than utilize automated transportation due to the smaller safety impact . However , while automated vacuum cleaners are well-suited to their individual tasks , other single-task robots are unlikely to sell due to the limited number of easily automated household tasks as well as changing expectations . Home robots will see their next significant commercial advance when they 're able to tackle a variety of complex tasks . In the meantime releasing single-task products will further thwart the expansion of home robotic assistants by making the endeavor appear economically unviable .
Educators will continue to be increasingly supported by Artificial Intelligence , but the application of these technologies will remain in an assistive role . Once again , a lack of trust from employers in terms of the value of credentials taught by an artificial intelligence will devalue the curricula from the perspective of consumers . The lower marketability of the skills learned through MOOCs and other methods supported by artificial intelligence will slow the greater adoption of these methods , which will in turn further impact their marketability .
In conclusion , the future depicted in the article is running to a much faster schedule than the rest of the world . While the outlined advances are almost certainly inevitable , the timeline suggested is unrealistic given the irrationality and fear of humans . The future of artificial intelligence will be limited by the current expectations and prejudices of today 's human beings .

On page 43 , the article5 lists three policy recommendations . The first proposes that all government officials , both local and federal , be trained to a level of expertise in AI . I disagree that this is the best route to optimize the societal benefit to harm ratio of AI s development for multiple reasons . Firstly , the proposal implicitly assumes that politicians would principally use their new capacity for purely benevolent and non self-serving purposes . This runs contrary to how most politicians act . In a world where a large majority is ignorant to most AI-related matters , this portends undesirable future outcomes . It is na ve to think a politician who understands how to leverage AI would only use that knowledge for the common good and not abuse such a technological advantage . It is natural to envisage that the first cohort of politicians armed with AI mastery would be able to predict outcomes and manipulate them in a way that the vast majority of voters would not understand . From the perspective of the public eye , this is a black box to be avoided as it has potential to perpetuate inequality and subvert democracy .

Additionally , a politician seeking AI expertise is an unnecessary endeavor that would require a drastic change in how they spend their already jam-packed days . Due to shifting a large portion of politicians finite working hours to strictly AI , politicians would likely lose competency and/or simply not have the time to address issues in other , potentially more pertinent , realms . As an organized researcher who devotes their working hours to neural network modeling does not have ample time to discuss geopolitics enough to run for office , the politician does not have time to cultivate expertise in AI . Sometimes politicians already struggle fulfilling current job descriptions .1 2 3 4 This is not to discount the importance that politicians , or any citizen for that matter , understand the ramifications of a technology as powerful as AI . But one need not understand the complete inner workings of a machine or an algorithm at expert level to make a valid prediction about the value or harm it could bring to society .

Instead , my proposal is to encourage all citizens , including politicians , to increase their level of awareness to future technologies -LRB- with AI at the forefront -RRB- and the existential problems they pose . The principle objective would not be to teach politicians about Bayesian Reasoning and deep learning -LRB- although it may be a beneficial derivative effect -RRB- while leaving the rest of the public in an even darker relative position . Rather , I would amend the policy to promote public conversations regarding :

1 . what the underlying problems and potential remedies are when an algorithm builds its heuristics rooted in discriminatory demographics .
2 . what jobs AI really can -LRB- and will -RRB- replace , and what a future best-case scenario for those currently employed in those jobs could be .
3 . the meaning people derive from their employment .
4 . scientific literacy and its importance .
5 . awareness of existential risks .

The masses need not understand how AI does what it does . The more pressing matter calls for an honest public conversation about the probable ramifications of widespread AI growth . In order to maximize the benefit to harm ratio that this powerful technology brings , the AI community should make as strong an effort as possible to include the public at all relevant stages as to current AI s capacities . In conjunction with an appraisal of societal goals and democratized decision-making power , this will create a feedback loop that opens up the optimal path to leverage AI for the benefit of the majority .

Word Count : 590

1 . Condon , S. -LRB- 2009 , June 24 -RRB- . Will Congress Read Bills Before Voting ? Retrieved September 12 , 2017 , from https://www.cbsnews.com/news/will-congress-read-bills-before-voting/
2 . Innes , W. -LRB- 2014 , December 15 -RRB- . Members of Congress Don t Believe It s Their Job to Read Bills They Pass . Retrieved September 12 , 2017 , from https://ivn.us/2014/12/15/members-congress-don't-believe-job-read-bills-pass
3 . Kolb , C. -LRB- 2017 , July 03 -RRB- . Sen. Rand Paul s Read the Bills Act Is it really too much to ask members of Congress to read legislation before they vote on it ? Retrieved September 12 , 2017 , from http://www.foxnews.com/opinion/2017/07/03/sen-rand-pauls-read-bills-act-is-it-really-too-much-to-ask-members-congress-to-read-legislation-before-vote-on-it.html
4 . Schlesinger , R. -LRB- 2017 , May 05 -RRB- . Not So Dirty Little Secret . Retrieved September 12 , 2017 , from https://www.usnews.com/opinion/thomas-jefferson-street/articles/2017-05-05/trumpcares-not-unusual-members-of-congress-often-dont-read-bills
5 . Stone , Brooks , Brynolfsson , Calo , Etzioni , , Teller . -LRB- 2016 -RRB- . Artificial Intelligence and Life in 2030 . Retrieved September 9th , 2017 , from https://ai100.stanford.edu/sites/default/files/ai100report10032016fnl_singles.pdf
Challenge aspect : Transportation

In the research , the authors note that autonomous transportation will soon be common place . I personally really like the idea of self-driving cars but I think there are some difficulties that we need to overcome . Firstly , it is the accident investigation policies when self-driving cars get into accidents . I am pretty sure that self-driving cars right now or in the future will be much safer than human drivers , but let s say , unfortunately , an accident happens for a self-driving car , then who will take on the responsibility for that accident ? Perhaps the government will blame on the company that created the self-driving car for not designing the car carefully . On the other hand , I would image that the company would blame the government for poor organization and infrastructure . However , I think as the development of AI will improve in the future , some laws will be published to solve this kind of problem .
Moreover , another issue that I can think of is that perhaps to make sure self-driving to operate normally , tech companies would demand the government to change the infrastructure in some way so that self-driving vehicles can operate smoothly . Right now , there are numerous situations that machine can hardly solve . For example , it could be that when roads do not have clear lane markings . As a human , we can rely on intuition to drive on this situation , but I personally think machines will have a hard time to do it . These problems are quite hard to solve due to the fact that upgrading infrastructure for self-driving vehicles would cost a lot of money and the government would not be very happy about this . And at the same time , perhaps until the government upgraded infrastructure , AI companies can not do much to make self-driving vehicles operate in a way that to ensure the safety of passengers as well as the smoothness of self-driving vehicles .
Furthermore , another problem that raises my concern is a willing to share information between tech companies . I personally think that the self-driving technology is pretty trendy these days , so it will not be easy for companies to open up and share their technology to each other . This is due to the fact that if they do so , they could potentially lose a number of customers due to the improvement of other companies . If tech companies are willing to open up and share their knowledge to each other , then I think we could see a huge improvement in the field of autonomous vehicles .
My last concern about autonomous transportation is about the safety of self-driving vehicles . As far as I know , self-driving cars are basically computers with connection to outside world , and same as other networked computers , they can be hacked . In the future , when there will be a lot of autonomous vehicles on the street , it would be really risky when hackers gain the ability to control those vehicles because not only they can cause accidents , but also a lot of people will be killed . Moreover , I also believe that it is pretty hard to design some kind of technology devices that will never be crashed or frozen . Right now , most of the devices I have seen could be crashed in some way or another , so I think it will take a pretty long time to develop a fully safe system so that everyone can rely upon .
Nowadays as Artificial Intelligence becomes a common source in many domains , our world becomes more efficient and consequently richer . In many aspects , it is transforming our lives for the better , but also some ethical and risky problems are emerging . After reading the Stanford One Hundred Year Study on Artificial Intelligence -LRB- 2016 by Stanford University -RRB- , I realize that there are still some issues confusing AI experts .

The article mentions one of the challenges : the difficulty of gaining trust from society . This problem includes many aspects and one is potential unemployment . Admittedly the participation of automatic machine leads to lower risk of accidents . Furthermore , automated therapists would not only increase the amount of available therapy but would also make it available for families wherever they live . As experts invent more and more automated machines to improve the working efficiency , they should also create more room for workers to assume more complex roles , moving from the physical work that dominated the pre-industrial globe to the cognitive labor that characterizes strategic work in the globalized society . The areas of human existence in which fully autonomous machines could be used and the potential benefits are almost limitless . However , if more and more companies integrate automation into various operations , millions of individuals who are currently employed would be fired , especially the majority of the workforce in developed countries . For instance , Taiwanese electronics giant Foxconn plans to automate some of its operation with robots , replacing existing Chinese workers . It s still hard for the public to accommodate the loss of manufacturing jobs in the industry . Inevitably most people who still rely on selling their time to have enough income to sustain themselves and their families maintain a bad case of post-industrial angst towards automated machine . In many developing countries , it results in job cuts greatly that some companies join the wave of smartphone vendors establishing production facilities in the promising mobile . Whether computers will indeed start to eliminate more jobs than they create remains to be seen . Maybe in the future people would find jobs in non-labor activities , while computer would engage with their communities and learn new ways to contribute to human society .

After the unemployment , furthermore , there is one thing that the article does not illustrate : inequality . Briefly , the economic system is based on compensation for contribution to the economy , often assessed using an hourly wage . The majority of companies are still dependent on hourly work when it comes to products and services . But by using artificial intelligence , a company can drastically cut down on relying on the human workforce , and this means that revenues will go to fewer people . Consequently , individuals who have ownership in AI-driven companies will make all the money . Now the widening wealth gap already exists , where start-up founders take home a large portion of the economic surplus they create . If people want to build a real post-work society , then to structure a fair post-labor economy is the most difficult part . If machines can perceive , feel and act , it 's not a huge leap to ponder their legal status , including possible income .

There are many challenges about AI , such as ethical questions , risking negative outcomes and so on . When people , not only the researchers and experts think about those existing or potential risks , technological progress always means better lives for everyone . Artificial intelligence has vast potential , and its responsible implementation is up to the whole world .

One Hundred Year Study on Artificial Intelligence is an article from Stanford University that deals with Artificial Intelligence -LRB- AI -RRB- . The main purpose of the article is to investigate about AI for long term and how it will influence humans , communities and society . Just in case for people who do not what AI is , it is an activity devoted to making machines intelligent , to enable an entity to function appropriately and with foresight in its environment -LRB- Stone et al. , 2016 -RRB- . There are some aspects of AI discussed in the article . I will be challenging transportation , home/service robots , and public safety and security of AI .
Transportation , such as cars , have been improved . Nowadays , cars come with GPS , helping with navigation , sensor , helping with parking , etc. . These are machines that help driver than making it intelligence . I think self-driving vehicle is a different story . When developing AI for the self-driving vehicle , AI has to contain speed , performance driving , sensor to check when to stop or go . The article states that self-driving can eliminate one of the biggest accidental death and injury in United States . However , there could be more accidents . For example , autopilot car was developed by Tesla , but fatal accident happened in Florida . According to Ackerman -LRB- 2016 -RRB- , the system did not stop for a tractor-trailer attempting to turn across a divided highway . With this example , the car needs to have better sensor to pick up how the other cars are going to move . Moreover , there are more circumstances than people can expect . So , it is hard to take every single circumstance into account .
Similar to transportation , home/service robots are not so great yet . For example , iRobot has introduced Roomba , it did not really help with cleaning . However , testing how Roomba works , it does not work well if there are mess everywhere on the floor . The AI sensory system is not fully developed . So , the machine has hard time finishing the job that it supposed to do . So , the home/service robots need more improvement to be thought as integrating AI .
In addition to transportation and home/service robots , public safety and security is another challenge . US Transportation Administration -LRB- TSA -RRB- is doing a project to improve efficiency and efficacy of airport security . This requires AI techniques , such as vision , speech analysis . This sounds too much because in order to obtain speech analysis , they need to gather information about people s speech . To do this , it is invading personal space and information . So , it does not seem right to use it for the security .
In conclusion , in order to use AI into people s life , communities and societies , it needs to be improved more . Transportation is not just about one s life . It connects to other people s lives as well , if the collision gets bigger and bigger . Another is home/service robots . Even though Roomba was developed to clean , it has only ability to clean only the floor and not the stairs . Last aspect is the public safety and security . For public safety and safety , it can invade personal rights by trying to gather speech analysis . Therefore , it is not good idea to use AI in transportation , home/service robots , and public safety and security .
-LRB- With the citation and this paragraph in brackets , this essay is more than 600 words but without them it s less than 600 . -RRB-

AI Offers Only Predictions , Not Explanations

One of the most cited scholars in history , Noam Chomsky , argued strongly against some current trends in the field of Artificial Intelligence . While acknowledging its engineering success , Chomsky thinks that AI direct -LSB- s -RSB- people away from the original questions . -LRB- Chomsky , 2012 -RRB- Despite the fact that AI predicts what s gon na happen outside the window next much better than the physics department , Chomsky argues , they do not add understanding to the physical world like physics does . Nevertheless , understanding and explaining how the world works has always been arguably the most fundamental motivation for scientific research . If one agrees with this argument , one will also see the essential ineffectiveness of AI solutions to fields like public policy mentioned in Stanford s study , Artificial Intelligence and Life in 2030 .

For example , the study mentioned CompStat , a system that uses machine learning to predict when and where crimes will happen and who will commit them for the New York Police Department . Since AI now defeats human in the most complex board game ever created -LRB- Go -RRB- , we can reasonably assume that CompStat does its job with very high accuracy . Also assume that it also gives the predictions without any racial or other kinds of biases , a worry mentioned in the study . Perhaps for a month New York City becomes a much safer place : its criminal rate at record low , percent of wanted criminal that are caught at record high , and much more victims get the justice they deserved since AI system in cameras and online collects more evidences to reveal the crime than before . However , if the original cause of crime in New York is not solved , public safety in New York City will return to its original state . For example , if the income gap is still wide , the public education in certain communities is still poor and as a result , the community atmosphere is still bad , those communities will challenge the law again , with ways circumventing AI , probably known as AI itself . Maybe intelligent criminals will invent cop radars that uses machine learning to accurately route themselves for getting around patrolling forces . It takes one to know one , and crimes might only disappear when no one have a reason to commit them . Eliminating crimes from the origin is a never-ending process as well but by treating the cause , rather than outcomes , we are making solid progresses in the long run . This , however , requires negotiation between people across social-economic classes , races and ethnicities . It is the art of compromises and a social and cultural process that involves public discourse and marches . To understand politics , AIs must understand at least human emotions , incentives , and languages . Currently , AIs understand none of these topics . Nonetheless , AI can facilitate this process by means like identifying preferences for every individual by their social media/shopping/search records online and provide useful data that might not be available otherwise .

In conclusion , for problems that demands explanations and understandings like science and politics rather than predictions and numbers -LRB- problems like transportation and the game of Go -RRB- , AI can only solve specific cases and alleviate the problem for a brief period . Since AI works around such problems by statistical methods and evolutionary algorithms rather than intuitive reasoning , in the long term anyone that treats AI as a panacea to all such problems will find themselves in a never-ending loop of creating new solutions to what is essentially the same problem . AI so far only offers predictions , not explanations .

Work Cited

Chomsky , N. -LRB- 2012 , November 1 -RRB- . Noam Chomsky on Where Artificial Intelligence Went Wrong -LSB- Interview by Y. Katz -RSB- . Retrieved September 11 , 2017 , from https://www.theatlantic.com/technology/archive/2012/11/noam-chomsky-on-where-artificial-intelligence-went-wrong/261637/?single_page=true
-LRB- Rep. -RRB- . -LRB- 2016 , September -RRB- . Retrieved September 11 , 2017 , from Stanford University website : https://ai100.stanford.edu/sites/default/files/ai100report10032016fnl_singles.pdf

CS540 Homework1

In the report of AI100 which is the program leading by Stanford University , the progress of the development of AI industry was described in several separate aspects such as education , autonomous transportation , natural language processing , and IoT -LRB- Internet of things -RRB- . In my point of view , the usage of AI was exaggerated in the report . Though AI may achieve a higher performance in those aspects , it may put human beings at risks in specific situations .
As we all know , the aviation industry represents the most advanced technologies that humans have ever made throughout the history . As a result , the aviation industry has adapted a series of AI technology . It brings enormous benefits to the aviation industry . The autopilot system is the most important and famous one . The autopilot system is designed to reduce the workload of pilots and reduce the fuel consumption by automatically adjust headings and air speed at the cruise attitude . The system will gather all needed data from thousands of sensors equipped on the aircraft and analyze those data . The technology seems wonderful since it can both increase the profits of airlines and reduce the workload of pilots . However , when sensors provide faulty readings , the disaster comes . On June 1 2009 , the Air France flight 447 crashed into the sea . After years of recovery and investigation , researchers found out that the crash was caused by a faulty reading of the air speed meter , which caused autopilot malfunctioned . When the autopilot was disconnected , the pilots were uncappable to troubleshoot the problem which caused the most serious air crash among French history . From it we can find out that when the industry heavily relies on AI , if the system is malfunctioned it can easily turn into a much worse situation .
Another example is the TCAS -LRB- Traffic collision avoidance system -RRB- which is a system installed on aircrafts that warns pilots when there is a chance that two airplanes may collide . When the control tower instructs completely opposite directions to pilots , it will cause problem since pilots can not know whether the TCAS or traffic control tower is correct . That s what exactly happened on July 1 2002 . Two aircrafts collided with each other and caused 71 people died .
From both cases , we can find that when autonomous transportation is growing rapidly , the security issues are being more and more concerned . Though the future of autonomous transportation has a bright future , we still need correctly trained drivers or pilots so that when systems are malfunctioned , we still have a chance to survive .
Artificial Intelligence -LRB- AI -RRB- is dominating the world and getting into everyone s life . Without them realizing , almost everyone is involved in some form of AI-related devices or events . In One Hundred Year Study on Artificial Intelligence states that AI enhances the community in different sectors ranging from governments to individuals . However , there exist some problems that may occur if AI continues to be explored and used in manufacturing and transportation . Privacy protection will also be a problem when AI is enabled in healthcare .

Firstly , job opportunity will decrease if AI machines continues to replace most jobs in manufacturing factory . The report claims that AI will create more new jobs rather than decrease the number of jobs in the future . The new jobs that emerge require people with higher education in order to develop and carry out the maintenance on AI machines to keep track of their efficiency . Unfortunately , a downside to this is that skilled workers in production factory will lose their jobs if their tasks are being replaced by AI . Furthermore , most factory workers are not well-educated , they do not have the ability to carry out these jobs . While the report suggests that people can obtain education or training on specific jobs to ensure their basic income , people will still lose their income when they are getting education and training . There might be a problem to carry out daily life because they have family expenses during no income period .

In addition to the reduction of jobs when implementing AI in manufacturing factory , implementing AI in transportation is also hazardous . Program is always written to associate with AI-related objects such as vehicles and machines . Problems might occur when the specific program is running in real life despite the program being tested perfectly during test runs . The report suggests that autonomous vehicles are convenient as it does not require human to operate which can reduce the number of accidents caused by human . This brings about the question of whether who is at fault when a serious accident occurs . Although some states have passed the law to allow autonomous vehicles on roads and autonomous vehicles system require the driver to hold their wheel to ensure the road safety , it is highly susceptible to hack for personal gain or interest .

Besides AI being dangerous in transportation , rules and regulations regarding privacy protection needs to be revised if AI are used in healthcare . The report discusses that AI plays a significant role in healthcare by helping medical professionals to communicate efficiently , but privacy protection prevents this from happening . Diagnostics can be accurate if several medical professionals make discussions together . However , in the case that the diagnostic report can not be accessed by other professionals , it will be tougher to come to a decision if they are physically far apart from each other . Recently , there are many AI-related healthcare devices in the market . These devices allow people to check their health condition such as heartbeat when they are exercising . If these data can connect with their respective professionals , it can help them to know their body condition and prevent from getting diseases .

In conclusion , the incorporation of AI into multiple sectors including that of the manufacturing field , transportation , and healthcare industry may prove to be bringing about unwanted and adverse effects . Whether it be the concerns of job security or safety concerns , AI is seemingly problematic . It is also imperative that medical privacy is to be revised for AI to improve healthcare experience . Hence , corresponding authorities and community should pay close attention to these problems and strive to overcome them to create a better future for AI .
A topic that is greatly discussed in the Stanford One Hundred Year Study on Artificial Intelligence is transportation . I agree with their claims that the implementation of AI in cars will increase safety on the road , people will shift toward using cars as a service rather than buying their own , and reduced need for parking will result in major cities changing their infrastructure . However , I reject their argument that the functionality of cars will not change significantly in the next decade . They state , Although future cars will be smarter and drones will be available widely , it is unlikely that by 2030 we will have widely adopted transportation vehicles that look and function differently than the ones we have today -LRB- p. 24 -RRB- . I believe cars will change as quickly and as dramatically as phones have changed in the last two decades and additional functions are needed to keep the consumer interested .

Fifteen years ago , phones had small black and white screens and plenty of physical buttons . They did not have the ability to take pictures , video chat , connect to/browse internet , stream videos , etc. . Today , every phone is expected to have all of these features and with very high quality . In addition , the physical look is held at a high priority for the users and phone companies . I expect cars to follow an identical trend . For today s cars , it is not the norm to have wi-fi or a color display screen . But with self-driving cars , the driver will have the freedom to do whatever they want during the commute time . The future cars will have to accommodate features that allow the user to stay engaged during this time . Furthermore , I believe competition will lead companies to make big changes in order to stand out from others . This is evident in phones , for example , Samsung decided to remove all physical buttons from the front of the phone and Apple removed the headphone jack on the iPhone 7 . This gives reason to assume that the same can happen to cars with companies such as Tesla , Audi , and BMW . It is also important to note that majority of the population owns smart phones . Therefore , the idea of cars that look and function differently from the ones today being widely adopted transportation vehicles is plausible .

Some big changes were already released in the past year that indicate what to expect from future cars . Many 2017 cars have wi-fi capabilities , which opens opportunities for features like weather updates and video streaming . Another modification is with the car interface . For example , Tesla took a minimalistic approach with their Model 3 . They removed almost all of the buttons and installed a large display that can control everything about the car . This is a big change because dials and buttons have been in cars for several decades . It is also worth mentioning that this futuristic car is in the price range of the average car owner . Therefore , a high chance for it to be commonly owned .

Studying the rapid rate of change in car design and features convinces me that cars will be dramatically different by 2030 . Just like phones , those features will become the standard and be available to the average customer .
`` The Stanford One Hundred Year Study on Artificial Intelligence '' mainly introduces the definition , various applications , and the appropriate management of artificial intelligence technology . This article claims that the success of the AI products is depends on how comfortable people feel about these AI products . However , I believe in the opposite : successful AI products should be able to make people easy to use and being comfortable with the products . The value of an existing technology may not be only determined by how great it improves people 's lives , but products should always work for people 's well-being and make contribution to people 's lives . Therefore , it is not people 's responsibility to accept and to adapt to the AI products : it is the responsibility for AI products to develop into forms that people can accept . For example , if people do not believe in autonomous car technology and assume it dangerous . Then the company should be responsible for showing people the technology they use and how these technologies help with safer driving . The company should not blame the public for not understanding the technology and not support their product . Those products that successfully designed will stay and those that failed to please people will be eliminated . The article implies that the development and success of AI products is limited by people , but it may be the case that the existing AI products are not satisfying enough so that people decline using them .
The article continues stating that the success of the AI applications is also determined by the users ' tolerance of their disadvantages . In fact , most products have their advantages and disadvantages . People would not decline a product simply because of some unpleasant experiences . Driving a car is more likely to cause a serious accident than walking while most people still want to drive because driving provides them higher speed compared to walking and they are willing to take the risk for this benefit . It is more likely for people to give up a product because it 's disadvantages outweigh it 's advantages . If the AI products actually improve people 's lives , only some unpleasant experience will not affect people 's reliance and trust in these products , thus the success of AI products is up to themselves but not the response from people .
It is also believed by this article that the unequal access to AI technologies will enlarge the social inequality . Of course many unequal access to a resource leads to larger social inequality . In this extreme condition , the claim is true , but AI technologies is not necessarily unequal to be accessed . It can also served as a possible solution to the social inequality . For example , the translation technology may not be as useful to the highly educated people as to the illiteracy . If AI technology is accessible for disadvantaged group , it can help to improve their ability and promote social equality in a great way .
The development and success of the AI applications eventually depends largely on the products themselves instead of the attitude of the society . The companies should keep improving the products and accommodating to the need of people that people may also welcome these AI products just like they did to the emerging products in the past . The one hundred-year study on Artificial Intelligence by Stanford touches some of the important as well as controversial topics such as ethical decisions in the field of Artificial Intelligence . The paper did a great job in pointing out the fields in which Artificial Intelligence might play a crucial role . The discussion of some of the fields such as Low-resource communities and Public safety and security informed me on strategies and thinking involved in making Artificial Intelligence available to majority of the population .
However , I believe that some of the arguments in transportation and self-driving vehicles -LRB- cars , truck , and flying cars -RRB- sections does not point out some of the intricate details and the way these details might hinder the development of such technology or play crucial rule in development of policies governing these vehicles . The paper mentioned that in any North American city in next fifteen years most of the transportation would be AI driven such as self-driving personal and delivery vehicles . In the paper , they also concluded that traffic jams and parking challenges would no longer be a problem . I believe that since this technology will be available in next fifteen years , it would be very advanced and most importantly expensive . Since these cars would be expensive it would be safe to assume that vehicles on the roads will be a combination of conventional human driven and self-driven vehicles . Self-driving cars are however designed to follow traffic rules perfectly without performing any kind of infractions . This process of blindly following of traffic rules and regulations along with conventional human driven cars , which does perform infractions from time to time , might constitute to increase in congestion on roads along with increasing the number of accidents . Naughton -LRB- 2015 -RRB- has claimed that autonomous cars have been involved in twice the number of accidents than any conventional car . He believes that the rise in the number of accidents is due to self-driving car s ability to blindly follow traffic rules -LRB- p. 1 -RRB- . Naughton writes that programming these vehicles to follow rules blindly might not solve the problem of traffic or accidents . Since there are no policies governing the development of such vehicles they will most probably in the future follow traffic rules perfectly . Naughton gave a perfect example on why it is essential for self-driving vehicles to perform infractions from time to time to coexist with human drivers . In the example , Naughton notes that it would be extremely hard to merge onto a jam-packed freeway by just following the traffic rules blindly . Naughton -LRB- 2015 -RRB- mentions an incident where the self-driving Cadillac car failed to merge on the freeway and required human intervention to safely merge onto the highway -LRB- p. 1 -RRB- .
Even though the technology in the year 2030 would be perfectly crafted for self-driving cars to take the roads , it is difficult to imagine that these vehicles will be able to reduce accidents while coexisting with human drivers in conventional vehicles by just blindly following the traffic rules . I believe that the article does not focus on these details and development of such policies to successfully make transition from conventional vehicles to self-driven vehicles .

Reference
Naughton , K. -LRB- 2015 -RRB- . Humans are slamming into driverless cars and exposing a key flaw .
Retrieved from https://www.bloomberg.com/news/articles/2015-12-18/humans-are -
slamming-into-driverless-cars-and-exposing-a-key-flaw

Self-Driving Cars
AI is expected to revolutionize the transportation domain in near future . Transport mechanisms that we couldn t envisage previously may soon become a reality . A prime example is self-driving cars , which are intended to make human drivers obsolete and completely change the landscape of urban mobility . Stanford s report One Hundred Year Study on Artificial Intelligence claims that As cars will become better drivers than people , city-dwellers will own fewer cars , live further from work , and spend time differently , leading to an entirely new urban organization . This claim however rests on many dubious assumptions , which may not necessarily hold true . I believe that self-driving cars , solely , will not change human lifestyle . It is humans who will have to change their lifestyle and implement systematic changes to society to be able to successfully incorporate self-driving cars into daily life .
The success of self-driving cars largely rests on the idea that people will no longer own vehicles and instead begin sharing them . Sharing vehicles will undoubtedly reduce number of cars on the road , make roads less congested , and reduce travel times . Traffic reduction will have many positive cascading effects such as reducing parking requirements , which will enable limited space to be used for better purposes and overall a new urban organization will result as the report predicts . However , the major question is will we share ? Car sharing programs have been present for a long time , yet the market for it is still relatively miniscule . This stat suggests that self-driving cars may continue being privately owned , which then completely refutes the idea that self-driving cars will bring a reduction in car numbers . In fact , car numbers and passenger miles may shoot up as people find these cars extremely convenient . Furthermore , it will also be cheaper to keep these cars moving instead of paying expensive parking in urban areas , which will further exacerbate congestion on roads . Increased congestion will dis-incentivize people to live far away from work . Therefore , the emergence of self-driving cars , in these circumstances , will yield contradicting and unfavorable results relative to those touted by the report .
Another factor that may inhibit the emergence of self-driving cars , even if they perform better than normal cars , is the unemployment they may cause . The stigma and burden of increased unemployment will instigate the government to prevent self-driving vehicles from phasing out normal vehicles . Self-driving vehicles will negatively impact people who drive for a living , for example taxi drivers . If self-driving vehicles substitute normal vehicles all at once , millions across the US would lose their job and with lack of access to re-training , may risk being unemployed for long periods . This event would greatly stoke up anti-AI sentiments among people and may create social unrest with so many people losing their livelihood . To prevent these ramifications , structural reforms are required . Scarce public funds may need to be used to re-train and re-integrate people who feel disenfranchised from society due to AI proliferation . Given budget restrictions , it is unlikely the government will be able to fund such programs and , therefore , will not allow self-driven vehicles to replace normal vehicles . The above works to debunk the premise of the report claim which is that self-driving vehicles will totally replace normal vehicles if cars become better drivers than humans .
The success of self-driving cars and AI rests on how flexible society is and is willing to be . In a rather rigid society like ours , it s unlikely we will embrace ideas that disrupt and overhaul our entire societal structure . Therefore , in these circumstances , I think that introducing self-driving cars will not bring about changes claimed by the report .


















Challenge to the 100 Year Study
The 100 year study incorrectly assesses the current state of AI in education and also the
future prospects AI has in the realm of learning on upper education levels . While the study is quite
bullish on both the current impact and an increasing role in the future , the reality is that AI in
its current form has not helped , but rather has impeded learning on an advanced level .
As any college student who has taken an online class knows , AI encourages cheating and constant
google searching , while detracting from any analytical learning and deep thinking . The crux of the
problem with AI in education is that while it is interactive and fun , it does not encourage users
to read or memorize anything , as all information will be accessible on google for future tests and
assessments . For this reason I strongly disagree with their sentiment that AI promises to enhance
education at all levels . They do very little to support this claim , and it appears to be baseless
in any sort or reliable study or data . While online education does definitely increase convenience ,
a vast majority of students and educators would admit it is far inferior to pen and paper homework .
For grade school and maybe even high school , I believe there is a place for AI to aid in the simpler
subjects that can be explained by a short video , however at the college level it does not appear to
play much of a role due to its ineffectiveness . Take Khan academy for example , it is a revolutionary
database of math subjects and explanations that has helped many conquer high school math courses in
half the time it would take them to listen to their teacher . However any calculus 2 student knows that
for anything more than surface knowledge it is essentially useless in the course , as the problems are
simply too complex and diverse for a video lecture to cover or learn from . It is in this type of
education that AI is no real match for pencil , paper , and physical in classroom lecturing .
The challenges section on education makes very little sense to me . After profusely praising how much AI
has helped increase the number of students in classrooms and enhancing learning , they excuse its lack of
implementation by saying Much of its absence can be explained by the lack of financial resources of
these institutions as well as the lack of data establishing the technologies effectiveness . If AI
truly helped expand classes for colleges and simultaneously enhanced learning for students , it would
seem far fetched for schools not to invest more in it . It would also seem trivial that expanding classes
while limiting the amount of added teachers would save the school money , not cost it more . What the study
seems to be missing is that schools are not avoiding AI because of a lack of data , but rather because in
their experiences it detracts from learning , not enhances it .
To sum up briefly , while it is impossible to predict with any sense of accuracy what AI s role in education
will be down the road , it is clear that right now it is more gimmicky than it is helpful . Online classes and
learning modules promote quick bursts of information tailored to short attention spans , and take away from
the true learning that as of right now can only be executed in the traditional classroom . For those who need to
learn base knowledge quickly , it is unmatched in combining effectiveness , convenience , and speed . However it
does not have depth , which is paramount to higher education learning and is why it s hard to see AI playing a
larger role in the college classroom in the near future .
The Stanford One Hundred Years Study on Artificial Intelligence provides a broad insight on how Artificial Intelligence -LRB- AI -RRB- has changed eight domains of the life of habitants of big cities in the past 15 years and how it is likely to change it in the next years , with special focus on the next 15 . However , some aspects discussed in the study are worth to challenge . Here I challenge two points : first , and more broadly , that the enhancements in many domains may not be affordable to all city habitants and how it would be possible to lower such costs and second , and more specifically that the advances in education at the high school level may neither be cost effective nor necessarily positive .
Regarding the affordability of AI developed products , in the past 15 years there have been two big tendencies observed : one is that most personal technologies are highly expensive -LRB- and probably not affordable to the lower classes of society -RRB- and another is that funders have underinvested in AI research lacking some commercial application . In face of the involved costs , the development of certain technologies main not benefit everyone as the Stanford Study claims , they in fact may serve to widen existing inequalities in many aspects of a society . For example , many of the technologies mentioned by the study will be available through the use of Apps in smartphones . The price for such devices runs around 700.00 USD while minimum wage in the state of Wisconsin is 7.25 USD/hour . When performing simple math , we conclude that a worker in the state of Wisconsin would have to commit virtually 100 labor hours , -LRB- other than all other living expenses he/she has -RRB- to afford buying such a product . This is just an example in terms of personal devices but many other AI developments proposed by Stanford will involve even higher costs . The high cost involved with AI developments also extend to other domains . For example , the changes proposed in transportation will be cost dependent and probably not implemented until cost is low enough . In the domain of robotics , the slow growth mentioned by the study could also be due to sales price . Even the implementations proposed for low resource communities will depend on limited government resources and would benefit from lower cost . The main question only superficially addressed by the review study is how to lower those costs making AI implementations feasible ? In my point of view , currently most developments are proposed by a few big companies and government stimulus and regulations will become essential to support smaller startups and incentivize free market competition .
Regarding the advances of AI in Education , especially at the high school level , there is no scientific evidence that robots will improve learning in face of the high costs they would impose to the system . At the same time that individualized learning can bring benefits , it also limits social interactions , impairing the development of social skills . If such limitation is imposed or facilitated , especially at a young age , it could have catastrophic results in the personal life and career of kids , particularly the ones that already present introverted behaviors . Recent studies also claim that high exposition to technology at young ages may cause neurological side effects . Since those side effects are yet not well known , I believe that the implementation of some technologies should be avoided .
Finally , AI developments have a huge potential to improve human life in many aspects , but implementations will have to be affordable and done with caution , sustained on supporting research to avoid unwanted consequences .
Artificial Intelligence , the activity that leaves the whole world spellbound , every time it comes up with new ideas , innovations and inventions . Undoubtedly , AI is improving our standard of living every now and then . From mobile phones that have become a part of us , to robots , everything has been possible because of AI only . Artificial Intelligence has brought up several new inventions in various aspects of our lives like education , security , health , robots , entertainment and many more . I believe that anything that happens for our good has it s own cost , there is always a trade-off . So , if there has been immense benefit because of AI , there might be some repercussions as well .
One aspect of Artificial Intelligence that could backfire is it s development in the field of service robots . They have already entered our homes and offices in the form of vacuum cleaners , chips etc. . The study says that in the near future robots would be able to deliver packages , clean our surroundings , and would do certain tasks that any individual can do . However , I feel that relying on robots is beneficial only to a certain extent . Recently this year , researchers at Facebook were doing an operation which involved Artificial Intelligence robots . The researchers built a chat bot in which two AI robots were made to communicate to each other in a way , mimicking human trading and bartering . However , when the bots started communicating , as Facebook didn t put any restraint on the language , these bots created their own bizarre language . The researchers said that they were unable to translate their language back to English and eventually the operation was shut down . This incident is one example which shows us that if AI robots start communicating with each other in a language , which we can t understand , then they could affect our lives in the long run in any manner they feel like .
Another aspect of Artificial Intelligence that could affect our life in an adverse way is it s development in the field of employment and workplace . The study talks about robots replacing people in certain kinds of jobs such as driving taxis , and some other tech related jobs . The study says that AI would do tasks rather than replacing jobs and would also create new jobs , but these new jobs are highly unlikely to imagine in advance than the jobs that would be replaced . If this happens in the near future , then this would lead to unemployment , which is a major concern in many countries . Taxi and truck drivers with no formal education would face a very hard time to get new jobs . Also , if tech companies start using robots to do jobs , then entry level programmers would also have difficulty in finding jobs . Therefore , unemployment will increase and if unemployment increases , it could lead to more problems like poverty , starvation , etc. . There are some driverless cars that have already been introduced by companies like tesla , but those cars won t work in every situation because they don t have the ability to think according to the situation . So , in unexpected situations it could lead to an accident .
Although , there are many challenges to the Artificial Intelligence field , but I am pretty sure that if it is deployed for the betterment of people keeping in mind the adverse effects , it could lead to a better society in the coming decades.While the Stanford One Hundred Year Study on Artificial Intelligence does showcase the tremendous promise that Artificial Intelligence holds as a tool to change the landscape of human society , I do not agree with the article s suggestion that AI s expansion into the entertainment industry can cause a degradation of interpersonal communication between people .

I am in complete agreement with the fact that the technological surge , both in terms of innovation and commercialization , in the last couple of decades has changed how people socialize and has put some form of tech device between 2 communicating people . The article contends that given the current reliance of people on technology as their source of entertainment , advances in AI will only increase that reliance which will lead to lesser and lesser human interaction . Contrarily , I believe that AI can help people become more interactive by saving them time . Developments in AI in the home with cleaning bots or in the workplace are being made with a goal to aid human functioning . Whenever unexpected opportunities to interact with other people come up , people often find themselves hard pressed in terms of their time . If AI can free up time and energy for people by taking over tasks like driving to and from work , people might just find the time talk to that friend they have not spoken to in a while , while a machine worries about the next stop sign or that jaywalking kid .

Further , the fact that the development of AI today envisions an intelligent robot in every home in the future , can only increase human interaction . There are multiple ways to look at this . Since , Artificial Intelligence seeks to replicate human intelligence into machines , the robots of the future will be made as humanly as possible . And that means you have a close to human companion to interact with at your pleasing . Secondly , AI can also help socially uncomfortable people get over their fears and insecurities thus enabling them to become better communicators which directly increases the quality of -LRB- more -RRB- human interaction . Lastly , talking about AI paints a picture of the distant future much like something out of the cartoon , The Jetsons . I can only guess but perhaps with technology and machinery occupying every nook and cranny of people s lives , people might just turn to human interaction naturally .

In the entertainment industry there is a huge scope to be creative . I strongly believe that AI in this industry , in contrast to what was proposed in the article , can become an agent for reinforcing human interaction . The HBO hit TV series , Westworld , which is based on a 1973 movie by Michael Crichton , exemplifies this belief . The series is set in a future at a time where humans have made immense leaps in AI development . So much so , that they have constructed a theme park of intelligent androids who are not only capable of functioning by themselves , they start becoming sentient too . In the show , humans pay to enter the theme park and interact with the lifelike hosts . They are privileged with the discretion to do whatever they please . If AI is perfected , I strongly believe that it can change the entertainment industry and if done the right way , it can innovate new ways to encourage human interaction.The report `` Artificial Intelligence and Life in 2030 '' gives a brief glimpse into what some pioneers of the artificial intelligence industry believe where the field is going . The report is very informative and brings up a lot of good points about the future of AI . Although the report explicitly says , `` military applications were deemed to be outside the scope of this initial report '' , I believe that military application should be heavily considered and explored .

The report states that military applications were excluded because it would not affect everyday life in North American cities . This claim is as bold as it is ahistorical . All throughout history militaries have affected everyday peoples ' lives . For example , war has always taken a toll on a nation 's economy it takes a lot of money and manpower to fund a military whether it be through labor , food , or troops . In the years following World War 2 , there were widespread food shortages due many farmers being put into prisoner of war camps during the Nazi regime . Even more recently , during the Cold War , the Interstate highway system was created so that the military would be able to move missiles across the United States in a timely manner if need be . Considering how many people use the freeway every day , it is safe to say that the military does indeed affect every day peoples ' lives . These are but a couple of examples of how military has had a large effect on a nations ' citizens whether it be for better or for worse . Also , saying that military applications of AI will not have a great impact on civilian lives in the future is naive . Many technologies that are taken for granted and widely used today were initially developed for military applications . A short list of technologies that were either invented or pioneered by the military include but are not limited to : GPS , cellular networks , TCP -LRB- Transmission Control Protocol -RRB- , IP -LRB- Internet Protocol -RRB- , digital photography , and microwaves . All these technologies have greatly transformed modern society and civilian lives . It is inevitable that some military AI technology invented in the near future will find an application in everyday life .

Even , or especially , nowadays military tensions cause a lot of unrest in the typical North American city . With the current tensions that have formed between the United States and North Korea , all it would take for nuclear fallout to be a possibility is one nuclear missile to be fired from either side . As more widespread applications of AI are being discovered and tested , what if the decision to fire an ICBM -LRB- Inter-Continental Ballistic Missile -RRB- were to fall into the hands of an AI ? If it were to fire wrongly , or even fire with due right , it would definitely cause a massive global conflict which would inevitably affect everyday life .

I believe it was wrong for the study panel on this report to omit discussing the future of AI in military applications . Military has always and will continue to affect everyday life in many ways . However , I do believe that it is tough to gauge how it AI applications in military will affect people because a lot of military research is heavily regulated and secretive . Hopefully , in the future the AI technologies that come from the military will continue to benefit society .
Rejoinders to artificial intelligence and life in 2030

Recently , Stanford University published an article named Rejoinders to artificial intelligence and life in 2030 which summarizes the development of AI to date and makes many predictions based on the trend . As to the future , I have some different opinions :
First of all , the author thinks that city-dwellers will own fewer cars , live further from work , spend time differently and make traffic jams and parking challenges become obsolete , leading to an entirely new urban organization due to self-driving vehicles . The article assumes that people may rent autonomous driving cars and share with each other so that amounts of cars will decline . Since there are only 13 years left before 2030 and only semi-autonomous driving like Tesla 's Autopilot begins to mature , it seems difficult to see the sceneries described by author in 2030 . And I think city-dwellers may own as same cars as nowadays because cars are rigid demands for work and life in North America . Compared to the public transportation , private vehicles are faster and more convenient and offer private room during driving . If people can bear the time waiting for other carpoolers and do not mind sharing one small room with others , they will choose carpool now . The decision on whether carpool or not has nothing to do with autonomous driving cars . Since amounts of cars may not decrease , traffic jams and parking challenges will still exist and trouble us in the future .

Secondly , the article is a little out of date on discussion of Healthcare analytics . Last year a Chinese scientific group consists of experts in Shanghai Jiao Tong University and Zhejiang University has developed a medical automated image interpretation system called ` Doctor Alpha ' by using the machine learning model region convolution neural network . In a competition between Doctor Alpha and three best physicians , Doctor Alpha reads 300 magnetic resonance images in 23 seconds and its accuracy is 95.22 % while human physicians spend an average time of 5 minutes to read 149 magnetic resonance images and human 's accuracy is only 93 % . Besides Doctor Alpha , IBM has a similar system Watson . Since the technology of medical image processing has been developed , we do not need to invent another wheel . If an American company want to do some AI researches on medical imaging but is impeded by the Health Insurance Portability and Accountability Act , it can go to some countries or regions where do not strictly protect patients ' privacy as America does , like China .

Thirdly , the author says that robots may be able to deliver goods to the right room in a hospital , but then require a person to pick them up and place them in their final location . If you have watched videos published by Boston Dynamics , you will find robots ' hands are not as skillful as humans ' so that robots may break glass drug bottles and hurt the aged in the hospital .

Besides , the article asserts that Machine Translation technology will
also make it easier to translate educational material into different languages with a fair degree of accuracy . However , languages are different from one to another and there is no exact match between languages from different language families . So the machine translation may not be satisfactory and needs manual interventions . Books just translated by machine may be full of errors and could mislead students . Textbooks are so important for study that it is inappropriate to just use Machine Translation technology .

All in all , the author may be a little more optimistic about AI 's development and I believe there are lots of work remained for us to accomplish before the maturity of artificial intelligence.HW 1 : Artificial Life and Intelligence in 2030 Response

Artificial intelligence has only become , and will continue to be , more and more prevalent in everyday life since its inception . From beating the world s best chess player to the emergence of self-driven cars , artificial intelligence has also become much more advanced . Near the beginning of Artificial Life and Intelligence in 2030 the paper states that the most commonly used benchmark for measuring the success of artificial intelligence has been how it compares to human intelligence . Artificial intelligence in its current form has progressed beyond this benchmark and its ability to work through complex calculations to make decisions should now be measured by how different it is than the human brain at these tasks .

For example , according to the paper artificial intelligence is driving research forward faster than ever because of its ability to work through large data sets , and draw conclusions from them , that human minds alone could not . This means that problems are being solved in a much different way . As artificial intelligence advances problems will be solved less by trial based analysis and more by robust theories produced by artificial intelligence .

Artificial intelligence operates especially differently than the human mind in situations where stress or emotion may cause a human to make an illogical decision . The most prevalent example of this difference infiltrating people s everyday lives comes in the form of self driving cars . While a human about to experience a car crash may not instinctively make the decision that keeps them safest , an artificially intelligent car would .

Artificial intelligence also operates differently than the human mind when it comes to matters of policy and public health . While artificial intelligence can make the most efficient decision when it comes to funding programs , policy makers will likely still disagree with the conclusion reached using artificial intelligence . Yes , artificial intelligence can suggest the best , most fair option for everyone , but it s still on people themselves to actually choose a course of action ; and people regularly choose incorrectly .

In line with the paper s original statement that advanced artificial intelligence is measured in relation to its similarity to human intelligence , the paper also states that interactive robots will become commonplace in people s homes . While artificial intelligence will likely become more ingrained into people s homes , it s difficult to believe that highly interactive robots will become the norm . When Apple and Google released their interactive assistant s , they were met with initial excitement , but little practical use . In most situations , it s simply either more comfortable or efficient to use the phone without speaking to it . Unless interactions with robot assistants can become nearly indiscernible from human interaction , it seems unlikely that they will become any more widely used in homes than they are on people s cell phones .

While artificial intelligence is capable of learning , like humans , its decision making processes have become so logical , efficient and inhuman that it is no longer reasonable to compare the success of artificial intelligence to that of the human mind .
Although this article attempts to perform a very thorough overview of the history , the current progress , and the future of artificial intelligence , it seems to make assumptions about the current status of the A.I. in order to predict its future . More specifically , Section II referring to AI in transportation appears to have issues in regard to handling all scenarios that a human would face . In short , there rises a question on how AI 's would handle paradoxes as a result of being forced to make ethical , split second decisions when used as modes of transportations , such as self-driving cars . The question raised today is this : in a situation where a self-driving car must make an ethical decision , should the self-driving car either 1 . -RRB- run over numerous people by going straight and saving the driver of the vehicle or to 2 . -RRB- steer away from running over numerous people and crashing into an obstacle effectively killing the driver ?
First , human biases in regard to the development and learning of artificial intelligence must be addressed . As Google as noted in one of their recent ads , every machine learning model and artificial intelligence is inherently prone to biases humans have , whether referring to the data that is fed for the A.I. to train on or the developer that 's teaching the A.I. what is right and wrong . This inherent issue in regard to biases that all A.I. 's will develop is an issue that has compounding effects on daily , consumer applications of A.I. where they will be heavily relied on . More specifically , how an A.I. is trained to perform will be the ultimate deciding factor of which ethical decision it will make . While many people might believe that A.I. should or should n't run over the individuals on the road , it is ultimately left to how the A.I. was trained , thus proving that A.I. is inherently subjective to its creator .
One may argue that an A.I. should be programmed to save the most lives as possible , thus rendering a clear and defined protocol for the A.I. to abide by . This , however , will create another ethical issue of its own . Let 's say that all A.I. are programmed to save the most lives as possible , so in the scenario provided above , all driverless cars will opt for solution -LRB- 2 -RRB- , where the driver will be killed . This might seem like choosing from the best of two evils , but as a consumer considering purchasing self-driving cars , knowing that the A.I. inside would rather kill you than save your life would effectively discourage you from buying that car . This could result in overall decreased interest in self driving cars which could have devastating effects on the progression of mankind .
However , in a more likely scenario , automobile manufacturers would foresee this issue and actually opt for and perhaps even advertise for solution -LRB- 1 -RRB- , where the driver of its vehicle will be safe as possible and that the A.I. will essentially be a servant to its driver and protect him or her at all costs . Now the issue is clear ; although saving more lives appears to be the most resolute and sound solution , at the end of the day , it will be corporate companies deciding how A.I. will be implemented in products such as cars and it is in their best interest to not save the most lives and actually only save the life of its operator . This paradox is an inherent issue which stems from the creation of A.I. that the article lacks to make mention of and as a result will have compounding effects on A.I. 's future .
Artificial intelligence -LRB- AI -RRB- is going to lead industrial innovation and have an impact on employment and workplace in manufacturing industries positively . Secondary industry company is significantly affected by labor cost and skill of workers . Meantime , many companies have been seeking better place to manufacture the products by spending low labor cost and moved their workplace from developed countries to developing countries where labor cost is low and relatively well-educated people live . While some economists and scientists anticipate dystopian future results because AI technology will replace a simple task executed by workers and deprive them of their job , the emerged computer technology have optimistic potential to enhance productivity and create new opportunity . The technology can not only allow workers to find the optimized method or process but also make new job of operating the task and inputting information on the AI system .
AI technology can lead to improve productivity of a manufacturing machines and control the fabricating process efficiently . Productivity and efficiency is most important factor to determine companies in the manufacturing industry to success or fail . So , the companies start to invest how AI or big data can be implanted on a manufacturing process and machines . The reasons why they want to implement and develop the technology is that machine implanted with AI can work like well-trained workers without any training . In addition , it does not feel a fatigue and stress . In other word , it does not require a rest to release fatigue and affected by stress result from private problem . The AI machines are not going to make a fault and a mistake , which leads zero percent defective production . Therefore , advantage of machines can improve productivity of companies and allow them to operate process efficiently .
New kind of job is required to sustain the AI environment over the manufacturing industries and educate the machines to produce goods appropriately and efficiently . Job of doing simple tasking is going to be extinct after the AI machines is fully installed all over the workplace . Fortunately , human has to oversee and maintain the machines to be operate properly , which will be essential jobs . Moreover , the automated machine can not work without initial condition and processing parameters . People are supposed to have a responsibility to input the information or let them cognize the requirements or the conditions by themselves . Many companies have tried to find a place where low labor cost is served and moved there whereas citizens who have lived in the country where the company had founded factories at the first had already lost their job . CEOs are willing to substitute previous employees into AI machines or systems unless constructing and operating factories implanted with AI are uneconomic . Companies and human to survive in this trend have to prepare the industrial innovation . Therefore , previous workers should become new type of workers who invent or develop machining processes AI machines can not produce .
In sum up , implanting AI technology on the manufacturing industries is a natural flow to enhance productivity and produce new kind of job . Workers who are threatened by AI machines have to realize the trend and be trained to be familiar with the knowledge . Companies , which are trying to adapt AI technology , also should educate their workers to survive in the environment . AI technology is going to replace conventional jobs as much as steam engines had replaced simple repeat work in the Industrial Revolution . Well-prepared workers and companies can survive and would take more chance to be success at AI era .
After reading the report , the part that confuse me most is definition of AI .
Actually the report doesn t give a precise definition of AI , but kind of gives some describe about it . In brief , report says AI should be able to enables an entity to function appropriately and with foresight in its environment and the difference between non-intellgent program or device and human brain is of scale , speed , degree of automomy and generality . The first one seems to easy to realize , a rubust internet browser that can load links on current webpage in advance can satisfy the requirements . The second just tells the difference but doesn t say what AI should achieve.The following is just what I think an AI should achieve and how that come into my mind .
We know that all programs , from the most essential aspect , are doing calculation , so what makes a difference to make the computing intellgent ?
First I want to know why we think our usual programs are thought to be not intelligent . I think it is because its function is somehow computing for people . In other words , it s just a tool like a hammer or a screwdriver just with different utility . However , if you have a pet , you train your pet with instructions like sit down , stand up , come here and so on or forbid them from entering a specific room or something else . When your pet can follow your instructions , you probobaly think the pet is clever and intelligent in some degree .
So I think the important thing should be that they can learn something and apply what they learn to their behavior , and the something should not be so specific that is limited to a certain job . Same example , if your pet can only take orders and go somewhere , you may feel it s just a voice-driven toy . Pets are certainly not as intelligent as human , but they certainly can learn a lot of things . However , in my point of view , the most applications of AI mentioned in the report is for very specific usage , which is not AI but preparation for AI . Techniche like NLP , computer vision plays an important role in a real AI .
Another thing is the way of train or teach . One can say that the computers are the best students who can follow any program you teach them . It is true , but as people , or users , we certainly don t hope that we need to train AI by modifying the code or inserting a new program when they have come into use . We want to teach them in a way more natural for us : by language , guesture behavior and so on .
At last I want to say that the way AI is designed may not have to imitate the way human intelligence is formed . I think there should be some basic system generates our intelligence , maybe it relies on physical laws with complicated structure designed by evolution . So it is not because we designed the program such that the program is taking order then it s not intelligent . On the contrary , we designed the program to be not intelligent . I think computing is another form of basic system that is able to realize intelligence with proper structure , input from all kinds of sensors and a more opening programing . However , the different basic structure may need different way to generate intelligence . Letting computer simulate our way of recognition can be costy and low efficiency .
-LCB- \ rtf1 \ ansi \ ansicpg1252 \ cocoartf1504 \ cocoasubrtf830
-LCB- \ fonttbl \ f0 \ froman \ fcharset0 TimesNewRomanPSMT ; \ f1 \ fswiss \ fcharset0 Helvetica ; -RCB-
-LCB- \ colortbl ; \ red255 \ green255 \ blue255 ; -RCB-
-LCB- \* \ expandedcolortbl ; ; -RCB-
\ margl1440 \ margr1440 \ vieww22080 \ viewh13240 \ viewkind0
\ pard \ tx720 \ tx1440 \ tx2160 \ tx2880 \ tx3600 \ tx4320 \ tx5040 \ tx5760 \ tx6480 \ tx7200 \ tx7920 \ tx8640 \ pardirnatural \ partightenfactor0

\ f0 \ fs24 \ cf0 In the Report of the 2015 Study Panel , the author mentions computer vision . As artificial intelligence application \
developing so fast in many areas such as transportation , health care and home robots , computer vision may upgrade \
AI to a more advanced level . However , computer vision causes privacy problem and ethical issue . Despite its potential \
power to improve censoring technology , image recognition and other computer perception abilities , computer vision \
technology should not be put into use before successfully address privacy and ethical problems . \
\
First of all , computer vision studies and applications can invade privacy of individuals . When researching and developing \
computer vision , large database is needed in order for the artificial intelligence to analyze . Especially in deep learning , \
computer programs require access to abundant data so that the programs could summarize some conclusions or form \
certain recognition pattern precisely . If no enough data is provided , then it is hard for computer vision to reach satisfying \
results . Now , researchers can take advantage of the internet . Social media today contains billions of peoples \ '92 information , \
and they are just perfect for computer programs to analyze . In this process , internet uses \ '92 privacy is neglected , or , in \
another word , sacrificed . Recognition of resemble pictures , for example , is one of the computer vision applications . One \
can simply upload a photo on Google to find millions of similar photos . But to develop such powerful search engine , \
computer programs must evaluate a large quantities of pictures online , including personal photos . Many programs \
-LRB- web crawlers -RRB- now allow people to legally download abundant data from websites . And programs do not distinguish \
personal information from others . As a result , personal privacy leaking is inevitable . Hence , researchers need to find \
a solution so that they can develop computer vision under the promise of protecting individual privacy . \
\
Second of all , ethical questions come along with the development of computer vision . Computer vision has already been \
used to recognize facial details in order to understand certain human behavior . With help of computer vision , technologies \
today allow government to identify who is more likely to commit crimes , and prevent crimes in the future . But the conclusion \
comes from data analyzing . If the data provided is manipulated , or biased , the result may mistakenly aim at certain group \
of people . Also , treating individuals differently just by detecting their likelihood of doing something is not fair . Though the \
percentage calculated by AI shows a potential tendency , it does not mean it has to happen in the future . A resent research \
about sexual orientation is a great example . A research group in Stanford University published a report about identifying \
individuals \ '92 sexual orientation using machine learning . The result is astonishing , with a very high percentage for computers \
to correctly determine who is homosexual by just \ ' 93looking at \ '94 people \ ' 92s photos . This report has already raised public concern . \
Certain groups may be targeted just because they share some characteristics . Then bias would appear and discrimination \
follows . Thus , regulations should be completed before any computer vision applications on peoples \ '92 behaviors and personalities . \
\
In short , although computer vision could help artificial intelligence make a great improvement and attribute so much to the \
society , it also faces urgent issues . Because artificial intelligence is still too new to human world , supervisions are not \
comprehensive . Individuals privacy and ethical problems are the two main obstacles for the development of computer vision . \
So while trying to make breakthrough on computer vision , researchers should think about how to solve those problems together \
with sociologists as well .
\ f1 \
\
\
\
\
\
\
\
-RCB- The topic of artificial intelligence -LRB- AI -RRB- is undoubtedly quite polarizing . To some , advancements in this field mark positive achievements that will someday make the world a smarter , cleaner , healthier and happier place . To others , artificial intelligence causes worry of job loss , the marginalization of humans , and even the overthrow of the human race . In reading the Stanford One Hundred Year Study on Artificial Intelligence I found myself overall very excited about the achievements thus far as well as the possibilities of AI . With this being said , I do however have some worries regarding AI continuing to penetrate into our daily lives and the degree to which people will equally be able to reap the benefits of AI . The Stanford study seems to predict that everyone , to a certain degree , will benefit equally from AI . In large , I believe that this study fell short in recognizing the potential further separation between socioeconomic classes that may result from major advancements in AI .
With the gap between the rich and the poor currently increasing , I believe it 's unrealistic that everyone would benefit similarly from AI . One key industry that I see this gap becoming visible is the automotive industry . With AI bringing about self driving cars , it is inevitable that these will be much more expensive than normal cars -LRB- this being the case at first -RRB- . My guess is that it would take quite a while for self-driving cars to become the norm and for prices to drop enough for most people that own normal cars now to own one . Furthermore , as more and more people start to use self-driving cars , I have been pondering what type of relationship normal cars will have with self-driving cars . Statistically it would seem that self-driving cars would be much safer than normal cars , which could potentially lead to comparatively higher accident rates for lower income people , whereas more affluent people would have safer rides . In addition , with better access to self-driving cars , it would be these well-off folks who would have to spend less time actually behind the wheel , having time to nap , relax , get extra work done , etc. . . This extra time for those who are already financially ahead could potentially increase the gap between the middle class/rich and the poor . While the Stanford study claims that eventually everyone should and would have equal access to the gifts of AI , I think that we must take into account situations such as those that I have just discussed .
Furthermore , the Stanford One Hundred Year Study on Artificial Intelligence assumes that the governments creating legislation , when AI becomes advanced enough to play major impacts in our lives , will be responsible enough to create the correct legislation . Obviously , in our capitalistic democracy we encourage competition . In my opinion we will need much better support for wealth distribution from our politicians in order for everyone to reap the benefits of artificial intelligence . With many of our politicians seeming generally unconcerned with helping the poor , I worry that AI will affect less people than the Stanford study accounted for , at least in the initial decades of AI becoming very prevalent . For example , if only the best and most expensive hospitals and clinics can afford to integrate AI into their healthcare systems we could see the poor receiving far less effective healthcare .
Overall , I am extremely excited about artificial intelligence improving our lives , however I believe that the Stanford One Hundred Year Study needs to take into further account the reality that perhaps not everyone will be able to reap the benefits of AI to the same degree , and we need to make sure that this initial gap of access does n't further create gaps between the quality of life of the middle class/rich far when compared to the life of the poor .
In our modern society , AI is a very familiar term in every industry . Fast development of AI is making our life faster and easier in various way . One Hundred Year Study on Artificial Intelligence report states eight major domains of AI . Some of the domains are probably unrecognized whether it was made out of AI or not , because it became so familiar to people . Some of events took place last a few years demonstrate that how much these areas has been developed and how deeply it has been affiliated in modern society . IBM s the Deep Blue beat the world chess champion , and Google s AlphaGo beat human Go champion recently . These events shocked people and brought more attentions to people .
While these phenomenal developments create spectacular technologies , many people also concern about these changes . AI s influences on employment and workplace trends is something that our society has to be more careful on developing . It is a phenomenon progress that AI system drives car in a highway without requiring any guideline from the driver , and replacement of AI can save people from dangerous positions . Also , more accurate and deliberate treatment will also save a lot of people from diseases . The article also suggests that the further development of AI in my fields will replace more and more jobs , and replace people in the near futusre .
There exist some kind of field where historically shaped and developed by humans . Art is probably the most special case that can be described as a human s creation . Most of artists , such as musicians , painter , and certain designers , pursue their entire life to find own identities , which can not be replaced by others . If these domain is also invaded by AI , anyone who are deeply engaged in Art will suffer . Human s creativeness will also produce by machine . On the other hand , a lot of people still concern on how AI will replace humans ethical and moral value correctly in some fields as well . There was a car accident in California recently , and the driver was using automatic driving system in highway . People were questioning who should take responsibility on these issues . Also , since automatic robots replace human s labor forces , it eventually raises unemployment rates . Thousands of people lost their job when giant manufactural companies adopt automatic system in their production line . Among these replacement of humans work , people will eventually lose their capabilities and diminish multitasking abilities as well . The most important factor is human will also lose ability to think on certain circumstances . Increasing .
The conceptual idea of developing AI to reduce people from dangerous and painful situation sounds good to anyone . To make it as more appropriately , creation of appropriate regulations and policies is probably more important than developing AI to avoid any restrictions or social obstacles in the future . It is now clearer that AI is something that will bring more benefits and advantages . Then , it is a relevant idea to also think how it will not be restricted by anything . Humans also have to concern about not losing their legacies .
By reading through the article Artificial Intelligence and Life in 2030 , it is obvious that the panel of researchers and experts are well-informed and took a largely unbiased and logical approach to all that they wrote about . For this reason , it is difficult to find topics or passages to disagree with . However , I took some issue with a stance they took in Section Three , under AI Policy , Now and in the Future . They consider how AI systems that take over tasks currently performed by humans will affect people s capabilities . They claim that as machines deliver super-human performances on some tasks , people s ability to perform them may wither , giving the example of calculators inhibiting children s abilities to learn simple mathematics . I disagree that having tasks taken over by computers will irrevocably hinder our capability to perform them . At the very least , I believe that even if the skills of humans are weakened by lack of use , inactivity can not destroy our capacity to think critically and inevitably reclaim our past competence .

First , it is worth deconstructing some examples of tasks that have already been replaced by artificial intelligence . The article makes use of the calculator example , claiming that by introducing them into the learning environment , students do not develop the ability to perform basic arithmetic manually . I do not believe this is the case . First and foremost , to my knowledge , teachers are still using the -LRB- now false -RRB- argument that students will not have a calculator everywhere they go and thus need to be able to do it themselves . While this may not be true , I am certain that standardized tests prohibit calculator use , forcing the environment upon the students , forcing them to develop the skill . Additionally , anyone who has ever tried to do advanced mathematics using a more advanced calculator like Wolfram Alpha can attest to the fact that such programs can only do so much ; it can handle simpler processes , but to the common user without knowledge of how to properly make use of it , it can not handle larger , conceptual questions , once again forcing the person to understand the math behind a problem .

To name a few other basic tasks taken over by computers , there is also cleaning -LRB- e.g. the Roomba -RRB- , factory jobs -LRB- e.g. automated part making , etc. -RRB- , and driving -LRB- e.g. Tesla , etc. -RRB- . The problem with the article s argument is as follows : as of yet , all everyday tasks that have been replaced by AI are simple , easily-learnable skills that could be relearned -LRB- if a person s skill withers away -RRB- with ease . The hardest of those mentioned above is likely driving , which legally takes 6 months for a person to learn -LRB- based on the person getting a learner s permit , etc. -RRB- , but could probably be sufficiently attained even quicker .

The point being made is that presently , artificial intelligence computers take over our tasks that we find so simple to learn so quickly that they become boring for us to do . If needed , we could regain these skills with little effort , but chances are , they are so ingrained in our lifestyles that we would not lose such abilities in the first place .
Artificial intelligence , as pointed out in the study , has a bad reputation in the public 's mind . Much of what the public knows about AI comes from movies and books , and almost all of these plots revolve around an intelligence whose goal is to harm humanity . The panel is right in saying that these are highly improbable situations and they rightly address these concerns by suggesting that those in the government be aware of what AI is and how it can impact the future . However , I believe they went a little overboard with their recommendations . On page ten of the study they recommend that all levels of government acquire technical expertise and talent in AI . I do not believe this is necessary because it will distract from innovation , detract from agencies that truly need the expertise , and for non critical areas it will become obsolete .
Having the government acquire talent to help develop regulations distracts from innovation . First , we must recognize that AI has just recently made its conversion from academia to being economically viable . Couple that with the fact that it 's a esoteric field with a high barrier to entry , it is unsurprising that universities only produce a handful of graduates who have studied this field well enough to make improvements in it . One can view this as a shortage of labor ; companies need these graduates to help them innovate and refine their products . But , if these graduates go to work for the government then they do not `` move the ball forward '' and thus overall innovation is slowed .
Some government agencies , however , need AI expertise . Examples of these agencies would be ones involved in economic and market regulations and well as security . Applying AI regulations to these areas makes sense and can have a positive impact for everyone . However , there agencies must have enough employees that are well versed in AI in order to create these regulations . As pointed out up above , there are a limited number of people who actually understand this stuff and its potential . It seems like a waste to me to hire someone who has achieved a high level of understanding and expertise to work for agencies who are not dealing with disruption . Also , I do n't believe that all levels of government need AI expertise . It does not make sense to me to hire an AI expert for local lawmakers . AI , much like the internet , will eventually operate on an international level . Any problems that would arise would likely affect hundreds of thousands of people , if not millions of people . Therefore it makes sense to have AI experts working for governmental bodies that have jurisdiction on a federal , national , and at the least , state level .
I also think it would be a wise idea to wait some of the this new technology out . As pointed out in the study , after the public at large becomes familiar with AI algorithms in their daily lives , they are n't considered AI any more . For example , email spam filters run on AI algorithms . they look for strange email addresses and keywords that indicate it 's a spam message . This is more or less equivalent to letting your email provider sift through your messages . Most people do n't have any concerns about this . It may be the same way for new developments in the upcoming years . Front loading regulations onto new technologies hampers development and may turn out to be obsolete in the near future . This might not seem so bad , but creating these regulations takes time and money that could be put to a better use somewhere else .
Overall , while I appreciate that this panel takes the concerns of the public seriously , My concluding thought is that what they recommended is not viable nor is it the best course of action.I challenge the viewpoint that AI-based home robots will have a promising future .
In the home AI robot session in `` Stanford One Hundred Year Study on Artificial Intelligence '' , it was said that AI robots will flourish in the next couple of years as a result of the improving technology ; however , most of the points made are based on the hardware improvement , such as more powerful CPUs , more efficient 3D sensors , and cheaper robotics arms . In my opinion , hardware development will not lead to the success of home AI ; it 's the software that matters .

To figure out how to create successful home AI , we need to first understand why we want to have an AI assistant . Personally , I want to have an AI assistant that will speed up my living efficiency , but usually , it simply slows me down .
I believe most of us have had the experience of talking to an AI assistant and hope to hear back the information we need . In advertisements and YouTube videos , AI assistants behave like a real human ; based on our input , they can answer our questions with exact information we need . If that is true in reality , I would certainly use them for every job I am doing , but that fact is , I almost never used them , except for those few days I had in my freshman year .

In the first semester of my freshman year , there was a time when I frequently used `` Google Now '' to look up weather . On each morning I got up , I would turn on my phone and asked it : `` OK , Google . What is the weather today ? '' This was cool at the beginning , because the magical voice answered from my phone . `` Here is the weather today '' , and the resulted information displayed on the screen both made me feel like a king . Nonetheless , days later , after the freshness disappeared , I realized how stupid it was . First of all , in order to start AI assistant , I had to first press the search bar on the top of the screen -LRB- it is actually faster than saying `` OK Google '' -RRB- and after it was launched , I had to get close to my phone 's microphone , and slowly speak `` What is the weather today ? '' . Next , I would wait a few seconds for the Google server to process and return information , which depended a lot on the network quality . Then , a list of information would show and finally I saw the weather . The inefficiency of this whole procedure drove me mad , especially when I was catching a class in the morning . I immediately quit using `` Google Now '' and installed a weather app instead . Now , whenever I want to see the weather , all I need is just to unlock my phone .

From my perspective , the current software support for AI assistants is far from enough and unfortunately , AI assistant appears to be the core function of nowadays home AI robots . In most of the time , AI assistants are only doing a google search for the message you put in , which is not very productive . There is no doubt that AI assistants will be useful under certain circumstances , such as when people are cooking and unable to type , but they are too constrained to make the whole industry flourish . The hardware development will not be enough for the advancement of home AI industry nowadays and better ways of operating AI assistants should be developed . Although I believe home AI robots will be indispensable for future human beings but based on the points given by the article , I would not see it happen in a near future . Stanford s One Hundred Year Study on Artificial Intelligence brought up a lot of good points about the future of AI and how it will continue to develop overtime . I do agree with a lot of the points that were made about the danger of AI and it s great potential for both good and bad uses . I also think that the article is right in saying that a great number of laws will need to change and adapt to AI , but I do not think it will be as fuzzy and unclear as they make it out to be . The article seems to suggest that eventually some AI programs could be able to guess personal information and then companies would be able to use that information however they wish . Many laws already exist to protect users personal information , and I think they are very clear and could be directly applied to AI . There are information privacy laws that prevent any sharing or misuse of sensitive personal information . I do not think companies will be able to circumnavigate these laws by using AI to guess the sensitive information instead of asking for it . I think that most legislative officials would agree that gathering personal information from users without explicit approval from the users themselves should be illegal . I do not think that companies will be allowed to use AI programs to guess personal information without the user s explicit consent , let alone go on to use that information . Lawmakers just need to adapt the current laws about private information so that they apply to AI . Obviously there will be people that use AI for malicious purposes , just like any technology . I think the hard part about this will not be deciding if what is happening is legal or not , it will be enforcing the laws , catching people that misuse AI , and giving out appropriate punishments .
The article also makes it sound like in the future laws about AI and privacy might vary from state to state . It uses the example of autonomous cars and Nevada s state laws against the National Highway Transportation Safety Administration s laws . This example has a couple of flaws . First of all , the difference between the two laws passed is not that significant . Furthermore , autonomous cars are still very new , and not at all common . There are a lot of driver assist features , but not a lot of fully self-driving cars out there yet . As they become more common more laws will be made about what is legal and what is not , and who is at fault when accidents happen . The same will happen with AI . As it becomes more and more popular , it will also be more and more regulated . Usually state laws are not made for very important issues , that s what federal laws are for . I do not believe there will be varying laws about personal information and AI from state to state in the future . There may be slight variances , like there are today , but the overall ideas will remain the same throughout the country . Overall , it was a very well written and informational article , I just disagreed with it s point about legislation on AI and personal information .
Artificial Intelligence and life in 2030

This report consists of One Hundred Year Study on Artificial Intelligence which was launched in 2014 , is a long-term investigation of Artificial Intelligence . The overarching purpose of the One Hundred Year Study s periodic expert review is to provide a collected and connected set of reflections about AI and its influences as the field advances . This report reflects upon every area of human life and its advancements with time . But they have over understood it . This report missing some important aspects of Artificial Intelligence that can be dangerous for humans .
Report defines Artificial Intelligence as an activity devoted to making machines intelligent using human as the fundamental tool for making machines intelligent . It is amazing how report approaches towards beneficial aspect of AI but it does not explain dangerous aspects of AI . Report mentions that Artificial Intelligence will replace humans . It is more likely to happen . But there will no need of employee and people will be unemployed and it will grow more and more . It will create more problems instead of removing problems . The employment level will become higher as more qualified people will be required to handle intelligent machines .
The trends in Artificial Intelligence is increasing as Deep learning , machine learning , Robotics , Natural Language Processing these research areas are providing vast opportunities to young researchers to come forward and understand the diplomatic behavior of machines . Report mentions that AI intelligence will take the charge of cars and there will be cars that needs no drivers . Yes , this is true but suppose an accident happens and passenger in the car gets injured then there will be no one in the car to take him to hospital . There will be severe risks on human health . Robots have already started helping humans . But the report did not mention anywhere that these Robots should be used for the beneficial purpose not in the situation of war , where they can produce extreme damage to humans . In healthcare , there are benefits and in education department machine learning can be helpful . AI based applications could improve health outcomes and quality of life for millions of people in the future .
It was mentioned in the article that children should start using Artificial Intelligence apps but with an early exposure of Artificial Intelligence children would be addicted to it . As earlier exposure of internet is dangerous for the children , Study Panel did not mention that AI can also cause violence among children . By playing virtual reality based games which shows a lot of violence like war games can change the behavior of children and make them aggressive . AI is expensive , the communities who can not afford it will suffer more in the future . They will not have enough resources to afford AI based machines and professionals and they will be easily attacked by other countries . Overall this study provides sufficient information about AI , but it is missing some of the important flaws of AI . Artificial Intelligence has a bright future but it should be use for the benefits of humans .

After reading the article Artificial Intelligence and Life in 2030 made me realize how much potential artificial Intelligence has in our society . A great aspect about artificial intelligence is that it can be programed to show no biases in areas where biases are shown very often . One area in the article they said they could improve on is stopping crime and predicting where crime could take place . Having AI implemented into different security settings can provide much needed safety and security .
Having AI implemented in the security area could also pose some risks that I don t necessarily agree with . Using AI to figure out and predict crimes could cause problems because I think there is a grey area in most crimes and decisions . In the article , it references the New York Police Department using a tool called predictive policing . This system analyzes and predicts where crimes can happen . Not every decision a police officer or a security guard makes is black or white , right or wrong . There is an area between the too , the so called grey area . Right now , artificial intelligence is not able to show human emotions or the process of thinking directly like a human . That is why predictive policing could lead to times where a decision is based by a machine is not correct . The paper references the movie Minority Report as an over dramatization of a system using prediction to see into the future to stop crimes from happening . Even though this is a fictional movie , something in that nature is already in place and if it is not used wisely then people could be wrongly convicted . I feel that AI needs to improve and overcome a lot of hurdles before I can see a full implementation between security and artificial intelligence in the future .
Another aspect of the paper that I challenge is the implementation of artificial intelligence in healthcare by 2030 . I can see AI being implemented in computer systems to be used as record keeper and start to analyze different areas to uncover symptoms and diseases , but I challenge the fact that AI can t replace actual health care professionals . By 2030 I see a partnership between artificial intelligence and the health care professionals . Doctors and patients will always have the question what happens if the machine and software fails during a procedure or misdiagnoses something . I think that overtime artificial intelligence will have to learn every situation , but programming every situation can t happen . I think there will come a time where a system might be able to think on its own like a human and problem solve different situations , but in the next thirteen years I don t see machines taking over every aspect of the health care system . Over the years there have been many improvements in the healthcare field from artificial intelligence , but there is still need for improvement before it is fully implemented in our health care system .
Artificial intelligence can help many different areas of our society , and the upside potential is infinite . For now , and in the near future there needs to be many improvements to fully understand what artificial intelligence has to offer .

In this report , people imagine the likely influences of AI in a typical North American city by the year 2030 . It refects the progress on AI in the past fifteen years and anticipates developments in the coming fifteen years . There are eight domains that they considered most salient : transportation ; service robots ; healthcare ; education ; low-resource communities ; public safety and security ; employment and workplace ; and entertainment . In this essay , I d like to challenge their perspective about employment and workplace . In the report , the author didn t make a clear statement about AI s impact on employment positively or negatively . For the bad side , it pointed out that people s income has stagnated , the employment to population ratio has fallen , and AI have been affecting human work . For the good side , AI will create new jobs , new markets and make existing works more efficient .
However , in my perspective , I think AI will replace human workers eventually . For starter , with more and more research and development being conducted in the field of AI , many people fear that a major job crisis will happen since many jobs can be more accurately and efficiently done with the utilization of machines . I would say this kind of fear is completely necessary , because I think AI is going to replace 50 percent of all jobs in the next 15 years .
Admitted it or not , machines will replace most if not all human workers , and It has been happening for decades , it is accelerating and it will complete within 100 to 200 years . In my perspective , AI is the wave of the future . It is an innovation that can be larger than all of the human tech revolutions added together . It is the decision engine that will eventually replace people . In many ways , AI s capabilities far exceed humanity .
I ve read an online blog that pointed out 10 jobs that are not likely to be replaced by AI in the future . Those jobs include Human Resources Managers , Sales Managers , Marketing Managers , Public Relations Managers , Chief Executives , Event Planners , Writers , Software Developers , Editors and Designers . Those are the jobs that require human-to-human interaction , innovation and creativity . However , I think AI is completely capable of doing these things . For example , Google has already tried to let AI writes songs . Last year , they launched Magenta , a research project aimed at pushing the limits of what AI can do in the arts . And they have successfully used some machine learning techniques to let machine generate its own music . This is a representation of creativity . So , why can t I imagine AI writing books , painting or coding on its own ? Maybe it s far from the reality for now , but in a few decades , I think it will become true . As a result , no existing or future job without exception is safe , simply because computers are general purpose thinking machine smarter , less error prone and more creative than humans in the long run .
To end , I think AI is really an innovative industry with endless possibilities . I could imagine that one day AI will do all the work for human and create a huge amount of wealth for mankind .
Analysis of Stanford s 100-Year Study on Artificial Intelligence

The field of artificial intelligence has countless applications across the world , yet the article seems to give a very lenient definition to what A.I. actually is . By arguing that calculators are on the spectrum of artificially intelligent , the study allows its applications of the field to be even broader . For example , applications of AI in the public safety domain , stand out to me as stretched . Additionally , predictions of advancements in transportation , come off as overly hopeful and ambitious . In this paper , I challenge the study by asking , To what extent are the authors trying to sell A.I. through the use of bold claims , unsupported evidence , and broad definitions ? I criticize the authors for becoming subjective in a study that should be entirely objective .
The first domain that the study analyzes is transportation . Here , I find some of the study s claim about the future to be overzealous . First , they cite an article stating that self-driving cars will be widely adopted -LRB- Self Driving Vehicles -RRB- by 2020 , offering no explanation or analysis of this statement . Four months away from 2018 , the world seems like it has a long ways to go before this wide adoption . Additionally , the study says that , in the typical North American city in 2030 , changes won t be limited to cars and trucks , but are likely to include flying vehicles and personal robots -LRB- Transportation -RRB- . While I fully agree that all of these things may be present in the future , I also believe we are ways away from universal fully autonomous trucks and cars , and decades from flying vehicles and actually effective personal robots . This statement is sensationalized , and strikes me as an effort to appeal to people s excitement of new technology . While it may very well prove to be true -LRB- well see in 2030 -RRB- , the study provides no hard evidence or statistics behind it and seems to just hope that it will come to pass .
The study s applications of artificial intelligence to the public safety and security domain also appear overextended . The two paragraphs that stood out to me were those discussing video surveillance and predictive policing . With video surveillance , to what extent is artificial intelligence actually applicable ? The only example given in the entire paragraph was detecting police malpractice . While this is great , the rest of the paragraph simply discusses using drones and video to solve crime . This technique has been around , independent of artificially intelligent computers , and the study uses its broad definition of the field to add to its applications . In its paragraph on predictive policing , the study states that , well-deployed AI prediction tools have the potential to actually remove or reduce human bias , rather than reinforcing it -LRB- Public Safety and Security -RRB- . Again , there was no evidence to support this claim and it seems to me that predicting who is going to commit a crime and where it is going to happen will lead to more innocent convictions , not less , a problem that is very relevant today . Additionally , this predictive technique is simply the same as looking at statistics and again the broad definition of AI comes into play .
Overall , the article makes many great points on the potential uses of AI and its progress . However , through hopeful and unsupported claims and a broad definition of AI , the authors tailor the study to reflect their hopes for artificial intelligence . Additionally , they try to sell the concept of AI to the general public , and while it is not inherently a bad thing , they overstep the bounds of the study and very clearly take sides on something that should be objective .
The article Artificial Intelligence and life in 2030 goes in depth on how AI will greatly affect our daily American lives . Many valid points have been brought up on several tasks that would highly benefit from enhancing our AI technology . However , an aspect that this article left out is the amount of electronic waste leftover if these AI robots are to become a prominent thing in our daily lives . Electronics used in our daily lives such as Ebooks , Ipads , laptops and cellphones have become a very common thing to have for family households . The devices are not even that large , but with their short lifespan and the very high demand , it generates an excessive amount of electronic waste . Electronic waste is very difficult to dispose of and only a small percentage of it is actually recyclable . Most of this electronic waste just ends up in the landfill contributing to more waste and environmental pollution . One example of an AI bot that was brought up in the article that I see heavily contributing to Electronic waste were the home service robots . Home-service robots are something that many people would be willing to buy , but how long can it last , and how much space will it take ? Assuming these home-service robots are relatively large and made out of metal , they would generate even more electronic waste than what we currently use now . In order for these robots to become a safe utility in our daily lives , there would have to be a way to either increase the lifespan of these machines , or have a safe way of disposing electronic waste , which we currently don t have . Although something like home-service robots sound great to have in our daily lives , without addressing these two key factors , they would not be sustainable in the long term . Moving onto another issue that was understated are how AI machines will heavily affect jobs associated with human labor whether it is in a positive or negative manner . It is undoubtedly a fact that AI machines will threaten the job security of many people in this group . The article states that existing jobs will be lost with new ones being created . It s also stated in the article that people would find their labor as insufficient pay on a social standing . My question is how can it be expected that these people will be able to accept and adapt to this drastic change ? For people that are used to doing their current work , this wouldn t necessarily be a positive change for them as they re used to the traditional way , there will be many people that won t be satisfied to accepting this new shift of working alongside AI bots . Right now , people are already struggling with finding jobs alone , how will they be able to cope with even more competition when other employed people lose their jobs having to seek newer ones ? Jobs related to human labor cover a large portion of the country 's workforce , therefore , replacing these jobs with AI bots would leave the public raising many questions whether it should be allowed . A future where AI live alongside humans is possible in our generation , but in order to make it a reality , there will always be several factors to consider and address.Artificial Intelligence is rapidly changing our world for the better , augmenting the way we live , and making advances in nearly every field , but that does not necessarily mean it is perfect .
When it comes to morals and ethics , putting our faith in machines is something that is still being widely debated with no guarantee of it coming to an end , or showing any sign of a winner . While this debate is acknowledged in the paper , its consequence is not discussed in detail . This dispute itself could hinder Artificial Intelligence development in general , hurting a lot of the current industries the technology is already playing a part in .
Out of all the domains , transportation and healthcare is where the above discourse s effect is widely observed . Self driving cars while gaining a lot of popularity among technology enthusiasts have been bashed by others mainly over the question , In the case of an unavoidable accident , what is the car supposed to do ? Should it minimize the loss of life or save the occupant ? Now this is not a black or white situation but lets choose each answer and look at the consequences that arise from each position . In the case it chooses to minimize the death toll , most if not all would not want to buy a self driving car because everyone values their own life dearly . This could lead to less sales , leading to low profits , which ultimately would result in the downfall of the industry . Looking at the other scenario where the car s foremost responsibility is the safety of the occupants . Now even if the number of deaths could be reduced the car would still take the route that guaranteed it s owner s well being . This will definitely bring about uproar in the public , which could result in research in such areas losing support financially and politically . This looks like a lose lose situation for the automobile industry . Currently , a research done by the Toulouse School of Economics shows that the general public believes that the car should aim to minimize the number of deaths . How this plays out is just a matter of time .
Now in the case the Artificial Intelligence does make a mistake , who is to blame ? The owners of the company behind the product ? Software engineers that worked on the project ? Those in charge of testing , or the researcher whose work , on which the algorithm was based and this hierarchy can be stretched pretty far back . This is another problem that could potentially slow the progress in the field of Artificial Intelligence as a whole . Another argument the paper makes is that , once equipped with the right hardware Artificial Intelligence will be able to thrive even more . One thing that is not taken into account to , is that no matter how advanced the machine is physically from a secure point of view there is always scope for vulnerabilities . This pattern has been constantly repeating over decades . Hackers exploit loopholes , security analysts find these loopholes and close them and the whole process repeats again . If Artificial Intelligence gets deeply ingrained within our life even small cases of hacking can cause big problems .
In conclusion , Artificial Intelligence is boon that can become a bane if the right measures are not taken .

In `` Artificial intelligence and life in 2030 '' , the Study Panel predicts the probable progress of artificial intelligence -LRB- AI -RRB- development in the next three decades and depicts the influences of AI on the social scenario of North America at the time . In the major part of the report , the Panel focuses on eight specific aspects including transportation , household robotics , healthcare , education , low-resource communities , public security , employment and entertainment to discuss AI 's impacts on people 's daily lives , bringing a broad view on the various possibilities that this newly emerged technology can deliver .
In most part of the report , the Panel demonstrates cautious optimism on the future progress computer scientists can achieve in the near future , stating that AI technology is able to bring about revolutionary yet somewhat limited changes to North Americans ' lives . Unfortunately , this carefulness turns into underestimation when it comes to the scenario of employment . The report suggests that although AI has showed the intimidating tendency of partially or even fully replacing human jobs in certain sectors , it is highly unlikely that the transition will be completed rapidly . However , considering the current level of capability that AI has gained through previous years of development and the future advancement of new types of hardware technology as its backup , there is still great chance that AI will be able to fully substitute human workers on a number of positions in 30 years .
Looking at the progress AI has made in the past decades , it is reasonable to believe that the revolutionary change in employment will likely happen in the near future . This can be exemplified by stunning breakthroughs in both cognitive and decision-making ability of AI . Since 2010 , scientists have dedicated to and eventually succeeded in building image-recognizing AIs that are able to recognize photos better than humans do , and last year , a go-playing robot even won the world 's most competent human go players with flying colors . Founded by modern machine learning technologies such as deep learning and reinforced learning , machines are running towards the limit of human intelligence at fast pace . It is likely that AI will first invade the jobs mainly comprised of simpler works such as driving and soon be capable of completing harder tasks such as text/media processing or even business decision-making .
Some may argue that even if AI has reached a high level at this time , the violent change is still unlikely in such a short amount of time since computer hardware is approaching its limit and will compromise its rapid development . They may claim that as semiconductor technology attempt to build increasingly smaller transistors , the cost of chips grows rapidly and quantum interference impairs their functionality , and hardware would thus become the bottleneck of AI development . However , this view neglects the fact that new technologies are emerging as the advancement of traditional hardware approach slows down . For example , effort has been made to develop processor specialized for neural networks , which amplifies the advantage of existing AI algorithms with closer software and hardware integration . Also , quantum computation may further help overcoming the computation throughput barrier by providing a faster solution to search problems . As the result , AI research will keep pushing the frontier given the powerful support from hardware technology .
To conclude , despite the achievement AI has accomplished in the past decades , its impact on employment is underestimated by the Study Panel . Considering the progress AI research has made and the support it will receive from hardware technology , AI will be able to fully substitute human workforce in a number of sectors .
The one hundred year study on AI outlines numerous benefits AI technology could provide the healthcare industry in urban North America . These include predictive methods to diagnose illness early , assistance in radiological diagnoses , as well as robotic automation to improve surgical procedures and care for the elderly . However , the article poses many barriers the healthcare industry has faced that have prevented the adoption of such technologies . These include poor digitalization of health records , slow approval by agencies responsible for advising the healthcare industry , and the lack of the critical human element in care provided by machines . While these barriers have proven cumbersome in the past , looking forward there is little reason to believe they will continue to prevent adoption before long . This is due to increased human interaction with machines in recent years , and reduced costs in hardware necessary to implement AI systems for healthcare purposes .
Being familiar and confident in the technology used to treat people is critical for the adoption of AI into urban North American healthcare , and recent technologies have exposed many people to their first interactions with AI . With access to AI assistants such as Google Now , Google Home , Siri , and Amazon Alexa , both healthcare professionals as well as patients have seen magnitudes more exposure to interactive AI than was common in the past . As these technologies and others become more reliable and intuitive to use , and exposure to them occurs at a younger age , the human machine interaction barrier has less and less impact on someone s overall judgement of their care , and professionals will come to trust the information a diagnostic assistant would be able to offer . In addition , this exposure can influence those who make policy for healthcare in a positive way as an example of the usefulness and reliability of such tools in their collection and use of data . This is especially important currently as a large portion of individuals who have had exposure to technology for the entirety of their lives take a greater part in society and those with less intuitive knowledge of technology reach retirement age . Coupled with the improvements in natural language processing mentioned in the article and improvements in interfaces between humans and machines the concern for displeasure or distrust of the presence of a mechanical element in treatment and diagnosis seems like it will be quite trivial in coming years .
Another issue AI faces in adoption in not only healthcare but in the mainstream is cost of systems computationally capable of using many of the techniques required for meaningful learning and language processing . However , with recent focus of hardware manufacturers and designers shifting toward designs for use in AI , higher power , lower cost systems will become available to offset financial burden caused by adopting AI techniques and moving databases to digital records . This will facilitate the adoption of AI systems and implementation of a comprehensive digital database required for deep learning and improving digital diagnoses .
AI s penetration into healthcare is met with two main obstacles , the social and the financial . With a generation heavily exposed to technology and AI implementations about to become a much greater part of society , the value of AI uses in healthcare will be more apparent to policy makers and medical professionals . Patient will trust and intuitively interact with AI services during their care , and doctors will be more skilled in leveraging help from AI uses . In addition , lower cost , higher power systems for language processing and interaction with patients and deep learning of diagnostic data will lessen the burden of creating a digital database capable of leveraging current AI techniques .


References
Peter S. , Rodney B. , Erik B. , Ryan C. , Oren E. , Greg H. , Julia H. , Shivaram K. , Ece K. , Sarit K. , Kevin L. , David P. , William P. , AnnaLee S. , Julie S. , Milind T. , Astro T. -LRB- 2010 , August 1 -RRB- . Artifical Intelligence and Life In 2030 . Retrieved from http://pages.cs.wisc.edu/ ~ jerryzhu/cs540.html
As the development of artificial intelligence , the author of `` Artificial Intelligence and life in 2030 '' predicts that self-driving vehicles will be adopted by the society not only for personal use but also for public transportation system in 2020 . However , the author overestimates the speed of the self-driving vehicle adoption progress . Security issue , incomplete legal system and high price of the self-driving vehicles can not be solved in such short time , and these three problems slow down the evolution of the new autonomous transportation system .

The process of solving and detecting security issues takes long time because the whole process requires huge amount of data collection and is limited to the technology development . Currently , self-driving vehicles developed by companies like Google and Tesla are still in testing phase . Though the author mentions that the self-driving car from Google has driven 300,000 miles safely , the data is not sufficient to prove safety . Also , whether current tests has included tests under different traffic situation , different climate weather and different road surface is not known from the article . The testers have to design thousands of different scenarios which includes extremely dangerous situation to test the safety of the driverless vehicles . Thus , to complete the data collection still has a long way to go . In addition to the data collection , the security verification process before the driverless vehicle can be used widely in society is complicated . The verification process needs to go through not only company 's own quality assurance department but also third-party insurance companies and related government department . The whole process can take for a decade to complete , before the driverless vehicles can be officially released to be the main role in transportation . At the same time , current technology restricts the ability to solve the security issues of self-driving vehicles . Self-driving vehicles requires to analyze extreme danger and intricate situation and react in a very short time to guarantee safety . It means that the vehicle system has to complete running a large program and send signals to related hardware parts on the vehicle immediately . To achieve the safety goal , more precise sensor , new algorithm and faster signal processing are the key parts . Self-driving technology needs to wait for the innovations in those fields to level up its safety .

Autonomous transportation system needs new legal system and it will take a long period for law experts and government officers to have discussion and debate . Legal system are left behind the new technology . At present , only several states in America allows the tests of self-driving vehicles in certain condition . Self-driving vehicles are not allowed in most areas and countries . It is hard to make regulation for self-driving vehicles , since it is difficult to determine who should be responsible for the traffic accidents while drivers are using self-driving vehicles . The article illustrates the scenario that if the injury is not evitable in the accident involving the pedestrian and a vehicle , whether the artificial intelligence should choose to protect the driver or the pedestrian . Questions such as this needs a long time to figure out the solution .

Establishing the whole autonomous transportation system in city is hard to realize in a short period , because self-driving vehicles are extremely expensive . The price for Google Driverless Car exceeds 300,000 dollars , which is more expensive than the luxurious automobiles . It is not affordable for most families . Also , government are not willing to invest such large amount of money to city public transportation system . Autonomous transportation system will not be built until developers find cheaper materials or technology to build the self-driving vehicles .
I agree with the premise of the document Artificial Intelligence and Life in 2030 that the measure of success for AI applications is the value they create for human lives -LRB- page 10 -RRB- and I firmly believe that the panel of experts have a far better idea than I do of what Artificial Intelligence will look like in the future . However , I challenge some of their optimism as to how quickly artificial intelligence technology will be adopted especially in applications where there is a great potential for abuse stemming from mishandling of data or risk of serious injury or loss of life . I d also suggest that much of the consumer technology they discuss ; such as home service robots will be too expensive for most consumers for the next few decades . Finally , I believe that regulations will inevitably slow progress and while the panel s predictions will come true I believe the time line is longer than they suggest .
Briefly stated in the overview at the beginning of the document and in greater detail on page 18 the article states , Autonomous transportation will soon be commonplace and the article cites a study from Business Insider with the fantastic headline 10 Million Self Driving Cars Will be on the Road by 2020 . The Business Insider article notes the difference between fully autonomous -LRB- can go from point a to point b without any input from the driver -RRB- and semi autonomous -LRB- which contain any features that allow the car to accelerate , break or steer with limited or no driver interaction -RRB- . I don t disagree that self-driving cars are on their way but I believe that the timeline is significantly underestimated . I also assert that calling a car that uses laser range finders or a camera array to maintain a cruse control speed , called adaptive cruise control which has been available on production vehicles since the late 1990s , self driving or even semi autonomous is disingenuous . Such features are certainly advancements towards self-driving vehicles and installing them in current vehicles will accelerate the development of the technology but they are far from the public idea of self-driving cars . I also believe that as autonomous vehicles become more common and more accidents inevitably happen -LRB- even if automated vehicles are safer than human drivers -RRB- regulations will prevent quick mainstream adoption .
Similarly , I also challenge whether home service robots will be adopted as quickly as the panel predicts . Roomba type cleaning robots were relatively successful yet they are still far from being common and I don t believe this will change in the next fifteen years . The article states that a major factor in the increased adoption of home robots will be the decrease in cost of the 3D sensors as well as more powerful and cheaper processing chips , I believe that the costs of all the other hardware that goes into the robot will still make them prohibitively expensive for many consumers and a poor value proposition for the consumers that are able to afford them . Privacy concerns stemming from consumers paranoia about home robots collecting data will also work against their mainstream appeal and initial adoption .
In conclusion , I believe that AI based technologies will be widely adopted just not as quickly as the survey panel states or in as many consumer facing mainstream applications , at least initially . I think automated vehicles will be used for commercial trucking applications and machines resembling home service robots will be used in factory and warehouse applications long before they become commonplace for day-to-day transportation or used in a majority of consumers homes .
The Stanford One Hundred Year Study on Artificial Intelligence postulates that AI technological advancements will be developed and fielded gradually rather than in sudden jumps . While I believe that advances will be developed gradually , I disagree that the fielding of technologies will be equally gradual in all sectors in which artificial intelligence is or will be prominent .

Autonomous transportation is a sector in which I believe this will be the case . Human failures and biases will play a large role in this outcome . As indicated in the article and through other human interactions with AI , people are often known to trust an unearning system more than they should . This is resonated by Tesla s experience with semi-autonomous transportation . Tesla was unable to prevent the first fatality involving an autonomous car even when forcing individuals to check the steering wheel at least periodically . Google had similar issues with test drivers doing other tasks , ignoring the road , and ignoring their duty to correct the system if needed when in an autonomous car . Even in the during testing , humans trusted that the system knew what to do and how to perform the tasks correctly . Some of the blame may be rooted in recent societal acceptance of computers knowing optimal driving routes -LRB- Google Maps -RRB- , which product you should buy -LRB- Amazon -RRB- , what show to watch -LRB- Netflix -RRB- , and even that computers can safely fly airplanes -LRB- autopilot -RRB- . If AI technologies designed to aid individuals are introduced gradually , people will begin to trust the system more than they should causing high risk and suboptimal performance . To avoid this issue , self-driving capabilities will be introduced to the public , not gradually , but rather in a jump to a complete system . This will help avoid unearned and unwanted trust in co-pilot technologies .

Another area in which I believe we will see a jump in fielded technologies in the workplace , specificlly as AI technologies become more advanced . Technologies will gradually be able to perform a majority of the tasks done by an employee . However , to replace employees fully as theorized in the report , I believe we will see the jump in fielded technologies . Businesses are often known to trust technology as long as there is a human to fix any errors or to verify the results . A significant jump of improvement in AI technologies , including a reduction in price , will determine if a company will invest into AI technologies to replace human employees . This becomes even more true as the idea of a universal wage , funded by taxes on a company , become more prevalent . The cost of losing an employee to AI will become costly and AI technologies must provide significant improvements to be accepted naturally leading to a jump to a complete system rather than gradual fielding of technologies as systems advance .

As stated throughout the article , AI technology heavily depends on the sector in which it is being used the fielding of technologies will be no different . Each sector has its own challenges for introducing AI . Responsible introduction of AI may require jumps in technologies as with self-driving cars or acceptance of technologies by firms may require jumps in capabilities . New technologies of such grand of scope across different sectors is rarely seen and challenges will be ubiquitous but variable in all sectors .

Sources .
Stone , P. et al. `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .

Urmson , Chris . -LRB- 2015 , March -RRB- . How a driverless car sees the road -LSB- video file -RSB- . Retrieved from https://www.ted.com/talks/chris_urmson_how_a_driverless_car_sees_the_road/details
Medical practices have developed faster than almost any professional sector within the last ten years . Deemed a public good , healthcare has one of the largest spending budgets in the United States -- with investments extending into the private sector . Just in 2015 , over 3.2 trillion dollars in government spending -- roughly 17.38 % of the US 's GDP -- went towards the health spending -LRB- cms.gov -RRB- . With this expansive budget , advancements and research in artificial intelligence have revolutionized a practice that has relied on new medical discoveries to extend the life expectancy and prevention of common diseases . In particular with the accessibility of big data , tasks such as keeping track of patients clinical records and optimizing clinicians schedules has seen major breakthroughs -LRB- ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 -RRB- . However , even with the large availability of new datasets to train AI models , computer models will not be able to provide accurate enough assessment of patient 's symptoms to even remotely automate a physician 's role by 2030 .
Data has become the big enabler for many of the major developments in the healthcare field , but deciphering the data has become one of the largest dilemma 's for AI . Supporters of the far-reaching benefits of AI use technical advancements in healthcare robotics , such as da Vinci , as their basis of the extent AI -LRB- ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 -RRB- . In some facets , advances in computer version and better algorithmic models have created robots to perform unique operations , the keyword being unique . Programming individual tools to specialize and be able to adapt to various body types for surgeries only shows the localized scope of what AI is supposed to do . What makes the healthcare field so difficult to even remotely automate is the broad scale a medical problem might entail . In the article , one of the major problems that is discussed with AI is `` not to recognize what is in an image -LRB- is this a liver or a kidney -RRB- , but rather to make a fine-grained judgment about it -LRB- does the slightly darker smudge in the liver suggest a potentially cancerous tumor ? -RRB- '' -LRB- ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 -RRB- . The fine grain judgment is what separates AI versus a human . Even within in the next fifteen years , the likelihood that radiologist will be able to keep a hands off approach to interpreting a X-ray image remains highly unlikely . Furthermore , with the limitations of AI , the interaction between humans and semi-intelligent AI will be very limited . FDA regulations will only allow AI to move as fast as it will be able to perform safely , stifling the innovation that is sometimes necessary to keep the development of an emerging field . And as long as there is regulation slowing down the development of deep learning , the likelihood of reaching a more self-sustaining AI in healthcare seems further in the distance .
AI 's breadth and scope in affecting the healthcare community has been proven in very immediate ways . For example , companies such as EPIC have been able to develop software to simplify the everyday tasks that might bog down a physician 's workflow . However , AI has shown its limitations in the solving encompassing problems . The panel 's prediction of where AI will be in 2030 , at least in the healthcare field , seems further off than anticipated .


Works Cited
Horvitz , Eric . `` ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 . '' ONE HUNDRED YEAR STUDY ON ARTIFICIAL INTELLIGENCE -LRB- n.d. -RRB- : n. pag . Web .
`` NHE-Fact-Sheet . '' CMS.gov Centers for Medicare & Medicaid Services. , 14 June 2017 . Web . The Stanford One Hundred Year Study on Artificial Intelligence seeks to outline the state of current AI research and application , as well as put forward an estimation of the impact of AI on various aspects of society in the coming 15 years . While the Stanford report covers AI in eight domains , I will focus my response to one of them : healthcare . Specifically , I will challenge two of the points made in the report concerning AI 's impact on medical image analysis .
The report lays out several barriers to advancing the current state of AI systems ' use in radiology . First , the authors comment on the difficulty of clinically relevant radiology reads : `` the problem in medicine is not to recognize what is in the image -LRB- is this a liver or a kidney ? -RRB- , but rather to make a fine-grained judgement about it -LRB- does the slightly darker smudge in the liver suggest a potentially cancerous tumor ? -RRB- . '' While it is true that small image differences are often important in identifying pathologies , to dismiss organ recognition as an unimportant task is naive . In fact , one of the largest areas of application for AI in radiology so far has been image segmentation - the careful contouring of individual organs or structures in a medical image . Segmentation has important applications in several areas of oncology , including the assessment of patient response to various cancer therapies , as well as organ at risk identification prior to radiation therapy . Without AI , segmentation is either a time-intensive task which requires a highly skilled physician to spend several hours hand contouring anatomical structures , or an automated but simplified task that uses rudimentary image intensity thresholds , or other detrimentally simplistic techniques , to identify structures . With AI , either classical machine learning or , more recently , deep learning techniques can be trained on physician-analyzed images to produce physician-quality contours without a large time investment by busy doctors . Nevertheless , AI may also help in identifying `` slightly darker smudges '' as well , but the clinical relevance of the question , `` is this a liver or a kidney ? '' and AI 's role in answering it should not be overlooked .
Second , the report comments on several challenges to the creation of large-scale medical image databases for the purpose of training AI systems , including overly-bureaucratic legislation and patient privacy laws , but they fail to state another which must also be considered : data variety . The number of degrees of freedom in medical image acquisition is enormous . Even if cooperation between healthcare organizations allows for the compilation of a single database containing all patient images acquired worldwide , the usefulness of that database will be limited by the incalculable variety and poor curation of that data . Even for a given imaging modality , the number of imaging variables is staggering . For example , consider a PET scan , where a radioactive tracer molecule is injected to map the distribution of a physiological process inside the patient . Patient specific factors such as age , weight , gender , and disease type affect the image . Acquisition parameters such as scanner model , image reconstruction algorithm , tracer uptake time , image field of view , and image resolution also play a role . Additionally , there is no guarantee of image metadata being recorded at all ! By the time all sources of variation and lack of data labelling are accounted for , the power of a large-scale image database to produce statistically significant findings may be drastically reduced . In short , yes : archaic healthcare regulations are a source of hindrance in realizing AI 's full potential in radiology , but assuming that red tape is all that stands between the field currently and the full , seamless integration of AI into clinical radiology practice is unwise .
The Stanford One Hundred Year Study on Artificial Intelligence
Public Safety and Security
The Stanford One Hundred Year Study on Artificial Intelligence talks about many aspects of this relatively new field of computer science . Out of these , the one I found the most interesting was the topic about public safety and security as it is going to directly impact each individual . The article clears up a lot of misconceptions about Artificial Intelligence and its safety concerns that are portrayed to us through Hollywood movies . It emphasizes that AI will be used not only to help solve crimes , but also prevent them before they occur . According to the article , this will be done through cameras deployed throughout the world . While this can potentially be extremely valuable to our world , I believe some aspects of this are discomforting .
My first concern with this is about innocent people being potentially targeted and arrested for a crime they weren t about to commit . In my opinion , the article tries to refute this opinion but does so poorly . There are still many concerns about this . The article states that human bias can be prevented instead of being enhanced , however it is impossible to know what is going through a person s mind . A person might be wrongfully convicted of a crime when they were only trying to defend themselves . From what I understand from the article , the AI will suspect a crime is going to occur by what it sees from the cameras . If a person is killed as an act of self-defense , it is likely the AI will target the person who was only defending themselves , and they will likely be arrested . Even if they later go through a trial and are found innocent , they will have spent a lot of time and money dealing with the mental stress of being put in jail .
Another thing that concerns me about AI being used for public safety and security is a loss of privacy . If developers are aiming towards preventing crime before it occurs , they would have to deploy potentially millions of cameras . Other than the huge amount of money this would cost , many citizens would view this as a violation of privacy . They would not feel comfortable with their every move being watched and judged by cameras , especially when it means they might be wrongfully accused of a crime . Furthermore , this would only help prevent crime in public places . Since most crimes occur in private places , the cameras would not be able to detect and prevent them so it would not be of much use . To make this system more efficient , if the government would want cameras deployed in private areas like houses too , it would bring us back to the concern of privacy violation . The public would probably not agree to have government installed cameras in their homes , watching their every move .
Overall , I enjoyed this article . It presented a lot of advantages of AI , but there were also a lot of concerns that in my opinion were not being addressed . If developers find a way around these concerns , AI could bring the most positive change to this world .
The team of authors and contributors that composed the 100-year study on artificial is understandably formed mostly of AI experts and computer science researchers . This fact , however , introduces a clear bias that permeates through the tone of the report . The authors understate the negative effects that AI is currently having on people both at the individual and societal level , and although they mention some of these effects , they often breeze over them . The authors state , Conceivably the stage is set for the emergence of media conglomerates acting as Big Brothers who are able to control the ideas and online experiences to which specific individuals are exposed . I challenge that some companies are already acting in such a manner and that the levels of manipulation , made possible by AI , have already reached levels that require closer attention .
The 100-year study is disturbingly casual about a topic that seems to be of much greater importance than they allude to . The sentence prior to the line that was quoted benignly mentions media powerhouse s ability to customize content delivery down to the individual and has a footnote leading to Digital Market Manipulation , an article by Ryan Calo . The article talks about how Market Manipulation , a term coined in 1999 , had been fairly overt and only semi-effective in increasing sales . The article continues , however , to discuss how since the advent of personal smart devices , social media , and AI technologies , these methods have evolved to become increasingly subtle , personal , and effective . These methods include , for example , sending personalized advertisements when a consumer s will power is at its lowest . The invasive nature of these marketing strategies and the implications they have on society are greatly understated by the 100-year study , and while they briefly mention potential regulations , their suggestions are vague and unconvincing .
The power and public influence with which media conglomerates have acquired via psychological research and AI technologies should not be underestimated . In a somewhat thorough examination such as the 100-year study on AI , I believe they should have spent more time discussing exactly how AI technologies are being used by media conglomerates , what the negative effects could be , and how we can avoid them become Big Brothers . Many of the areas that the study discussed as being potential impacted by AI are currently only slightly influenced by AI , whereas companies such as Facebook and Google are some of the biggest users of these technologies . The fact that they received relatively little attention in the scope of their business model is further evidence that article hoped to avoid this topic .
The writers of the study understandably make it a point to denounce fearmongering and debunk any dangerous misconceptions that the public might have . Unfounded fear of AI could be a large obstacle for further related research and therefore slow the benefits that AI could bring to society . However , understanding and addressing the effects of AI on society , both positive and negative , will be the healthiest way to approach increasingly sophisticated AI . There needs to be a balance between fearing change and making sure that the public isn t manipulated to the benefit of corporations .
The report of `` Stanford One Hundred Year Study on Artificial Intelligence '' gives a comprehensive analysis of the present state and future development of Artificial Intelligence -LRB- AI -RRB- in different domains , and prospects and recommendations for AI public policy . I will focus on the education aspect and talk about some potential challenges of AI applications in education . I think AI should be used as a complementary tool to help humans ' teaching instead of dominating education .
First , we should still hold a skeptical attitude on implementing teaching robots for children in an early age . In the report , it mentions that teaching robots such as Ozobot , Cubelets and PLEO rb can help children learn knowledge and think logically by teaching robots to think and act -LRB- Page 31 -RRB- . It seems to be a doable idea to teach children knowledge . However , is it a good way to let children spend most of their time interacting with robots in their early age ? My answer would be no . Children should spend more time interacting with nature and other humans in their young age . According to the data from some reports , children have spent much time playing indoors than playing outdoors , and `` the amount of time children ages 6 to 8 in the U.S played decreased 25 % '' -LRB- Randy , 2006 -RRB- . If children spent most of their time indoors playing with their robots , they do not have the chance to experience the nature . Research shows that `` children 's understanding of the relationship of humans to nature is both partially complete and under construction during early childhood '' -LRB- Phenice & Griffore , 2003 , cited by Randy , 2006 -RRB- . It means that we need to provide more time for children to going outside to interact with nature to develop their environmental ethic and consciousness of nature .
Second , although AI applications in education could be used by teachers to better convey knowledge and improve students ' learning outcome , they can not teach students how to think but what to think . `` What to think '' refers to knowledge itself . However , how to think is more important than what to think . Since humans provide AI with the ability of self-learning , AI 's thinking process is designed by humans and itself does not know how to think . Therefore , AI can not replace teachers to teach students because teachers can create and generalize the method of thinking or habits of mind , and can help students to develop their own thinking methods , while AI is just conveying knowledge . Since the essence of education should be to teach students how to think , AI should be used as a supplementary tool for students to improve their study outcomes .
Third , AI should not be the key point of changing the education situation of the low-resource community because the pain spot of low-resource community is not a lack of educational resources , but a lack of guidance . We could introduce many AI implemented educational products such as online learning and teaching robots to areas which have limited access to advanced educational resources . But even if we have those products , we need someone to guide the low-resource community through the process to make the full advantages of those products . Therefore , the government should take the responsibility to provide teaching training to people who are interested in becoming teachers , and improve the general environment of the low-resource community . In this way , teachers would love to come to those areas and bring the new technology of AI and popularize it among the community .
In a word , AI is currently and will continue playing an important role in education . But the essential role in education is still human , who can teach other humans how to think and help them become unique human beings .
Reference :
Randy White -LRB- 2004 -RRB- . Young Children 's Relationship with Nature : Its Importance to Children 's Development & the Earth 's Future . Retrieved from https://www.whitehutchinson.com/children/articles/childrennature.shtml
Stanford University -LRB- 2016 -RRB- . Artificial Intelligence and Life in 2030 is made available under a Creative Commons Attribution-NoDerivatives 4.0 License -LRB- International -RRB- : https://creativecommons.org/licenses/by-nd/4.0/Homework 1

Claim : Autonomous cars will not be widely adopted by 2020 and will not necessarily increase life expectancy of the average human being .
Argument : In the article `` Artificial Intelligence and Life in 2030 , '' the committee of writers make a sweeping statement that says , `` A recent report predicts self-driving cars to be widely adopted by 2020 '' -LRB- Stanford University , 2016 -RRB- . Assuming the source used in the article is credible , taking a closer look at it one realizes that the source talks about the predicted total number of self-driving cars on the road by 2020 to be 10 million -LRB- Intelligence , 2016 -RRB- . This instinctively does not indicate the wide adoption of self-driving cars . The article further mentions that the authors reached this conclusion by analyzing how car and technology companies are approaching autonomous cars , and what the market for this industry is expected to look like -LRB- Intelligence , 2016 -RRB- . In 2010 , it was estimated that there were around 1 billion motor vehicles in use -LRB- Sousanis , 2011 -RRB- . The number of cars on the road have only increased since `` 2016 was a record-breaking year for global car sales , '' -LRB- Scutt , 2017 -RRB- and the global number of cars owned by people is supposed to double by 2040 -LRB- Smith , 2016 -RRB- . Considering the 1 billion number of cars -LRB- even though data suggests that there are even more cars on the road now -RRB- , 10 million makes up only one-hundredth of the total number of cars available globally . Furthermore , it is unclear what dataset was used to make this prediction and what the origins of the dataset are . It is highly unlikely that third world countries are prepared for autonomous cars with unpredictable traffic , potholes , problematic rules and regulations , and other such issues . Therefore , although there seems to be an increase in the adoption of autonomous cars , the statement in the article takes a more hyperbolic and optimistic approach than what is realistic . Similarly , another statement in the article says , `` Self-driving cars will eliminate one of the biggest causes of accidental death and injury in United States , and lengthen people 's life expectancy '' -LRB- Stanford University , 2016 -RRB- . This is a classic causation versus correlation problem . Although accidental deaths and average life expectancy are correlated , it does not necessarily mean that an increase in life expectancy is caused by fewer car-related accidental deaths . In the article , the authors conveniently assume that since human driving mistakes will be eliminated by autonomous vehicles , there will be significantly fewer accidents , but they fail to address the new possible ways one could meet with an accident . In June 2017 , a person driving a Tesla was killed during a car-crash as he failed to respond to the warnings set off by the car -LRB- Bomey , 2017 -RRB- . Additionally , currently the cars are not equipped to operate with high level safety under all weather conditions , such as heavy rain -LRB- Auto Insurance , n.d. -RRB- . There also seems to be a problem if traffic lights do not work and a human is directing the traffic instead -LRB- which happens often in third world countries -RRB- ; self-driving cars can not interpret human signals -LRB- Auto Insurance , n.d. -RRB- . Lastly , the sensors in the car could easily fail , which could put the driver in grave danger , maybe in even more danger compared to if the driver had control over the car in the first place . Therefore , it is hard to make a claim that the life expectancy of the average human being will be increased by autonomous car adoption .

References :
Auto Insurance -LRB- n.d. -RRB- . Top 20 pros and cons associated with self-driving cars . Retrieved from https://www.autoinsurancecenter.com/top-20-pros-and-cons-associated-with-self-driving-cars.htm

Bomey , N. -LRB- 2017 , June -RRB- . Driver killed in Tesla self-driving car crash ignored warnings , NTSB reports . Retrieved from https://www.usatoday.com/story/money/cars/2017/06/20/tesla-self-driving-car-crash/411516001/

Intelligence , B. -LRB- 2016 , June -RRB- . 10 million self-driving cars will be on the road by 2020 . Retrieved from http://www.businessinsider.com/report-10-million-self-driving-cars-will-be-on-the-road-by-2020-2015-5-6

Scutt , D. -LRB- 2017 , January -RRB- . 2016 was a record-breaking year for global car sales , and it was almost entirely driven by China . Retrieved from http://www.businessinsider.com/2016-was-a-record-breaking-year-for-global-car-sales-and-it-was-almost-entirely-driven-by-china-2017-1

Smith , M. , N. -LRB- 2016 , April -RRB- . The number of cars worldwide is set to double by 2040 . Retrieved from https://www.weforum.org/agenda/2016/04/the-number-of-cars-worldwide-is-set-to-double-by-2040

Sousanis , J. -LRB- 2011 , August -RRB- . World vehicle population tops 1 billion units . Wards Auto . Retrieved from http://wardsauto.com/news-analysis/world-vehicle-population-tops-1-billion-units

Stanford University -LRB- 2016 , September -RRB- . Artificial intelligence and life in 2030 . One Hundred Year Study on Artificial Intelligence . Retrieved from https://ai100.stanford.edu/sites/default/files/ai100report10032016fnl_singles.pdf


For a long time , people have evolved to be innovative and build things that would have been thought to be unimaginable some time before they came into existence .
However , as those creations become popular , the demand puts more strain on people to mass produce them , which is burdensome and quite repetitive . One solution for this issue
was to automate the process which is efficient and less-prone to errors . An example would be the production of automobiles , most of the process involving robotics and
automation . This is just one of many areas where Artificial Intelligence plays an important part to improve lives and make an impact . The One Hundred Year Study on
Artificial Intelligence by Stanford gives a great insight on AI , its history , the part it plays in our lives and its future . However , there are a few claims made in the
article which I do not entirely agree on and hence challenged them in this essay .

Public safety and security is an important sector that is required everywhere to prevent crimes and other unfortunate incidents from happening and discourage those
who would think about doing them . Although improving the technology for better surveillance such as better cameras and drones certainly would help in bringing down crime
rates , letting AI make decisions using prediction tools to reduce human bias in the future is something that should not be researched into much -LRB- Pg . 36-37 -RRB- . Using Artificial
Intelligence as a tool to develop technology gives it the ability to learn quickly and adapt to situations fast , but would not give it the ability to understand human
emotions and their unpredictability . With AI growing rapidly , having it make decisions as a part of the public sector administration would be detrimental as they could
easily choose to deem someone to be unsuitable for society due to their emotions that would not have resulted in any harm . For instance , a person having a bad day could
be judged by AI as someone who will commit a crime soon . Movies such as Minority Report try to show these scenarios and their overall impact on society . Hence giving AI
more administrative power would be risky and can result in serious damage in the future .

AI has already become deeply rooted in our lives in the form of technology that promotes education such as smartphones and tablets , which can be used to access many
educational resources such as Wikipedia catered to our needs to learn in an efficient way -LRB- Pg . 33 -RRB- . The article claims that AI can even be used to provide good education
through the use of tools such as iPads that has many educational apps available -LRB- Pg . 35 -RRB- . However , the article does not seem to consider the fact that people can get
distracted easily while using those tools by just switching to another tab that has an entertainment app open . In this case , AI is unfortunately a double-edged sword ,
providing access to both education and entertainment at the same time . Using such tools can also negatively impact the social interactions of students and create a gap
among their peers .

Artificial Intelligence has played an important part in many lives in improving their conditions and the report accurately portrays the growth and impact of AI .
However , the study of AI should be moderate in some fields where certain risks are involved that could harm society and the people who are a part of it .
In Stanford ' one hundred years report of artificial intelligence -LRB- AI -RRB- , the Study Panel analyzes current use and future of AI . The committee believes that AI has been employed in many areas and are designed to finish many specialized work previously done by human . AI in the future will become more human-aware and trustworthy . However , the committee makes relatively positive prospect on AI and ignores some current issues . First of all , the current state of AI has not been so perfect that AI researchers could progress to make it human-interactive . Furthermore , even if disadvantages of current AI design were modified , the increasing speed of AI will not be as beneficial as the Study Panel assumes .
First of all , simple AI design through computer software are not independent enough and ready for make interactions with humans in the future . The study states that present AI are designed to finish specialized tasks . Those designs are through long-termed research and careful construction -LRB- p. 7 -RRB- . The Study Panel believes that the simple design of AI has fulfilled most basic human tasks . Therefore , the field is shifting from simply building systems that are intelligent to building intelligent systems that are human-aware and trustworthy . -LRB- p. 14 -RRB- . However , the presumption that simple models of AI are very mature is not believable . For example , the robotics in home service are able to clean house . However , they could not work independently without human care and improve with experience -LRB- Reddy , 2017 -RRB- . It means that robotics will bumper into same barriers over and over again and humans have to spend same amount time supervising them . They can hardly vacuum your living room without direction from human let alone take over the world -- and reports that the famous Turing test for AI has been passed are greatly exaggerated -LRB- Lafrance , 2016 -RRB- . Also , in data analysis , even though AI could analyze data automatically , human still have to spend enormous time uploading , backing up data . These are all basic and required tasks for AI to consider before making it more human-aware . Therefore , there are still more modifications to present AI before making prospect of its more complex and brilliant tasks .
In addition , AI actually has potential threats to humankind with continual growth over time . The Study Panel found no cause for concern that AI is an imminent threat to humankind -LRB- Stanford , 2016 -RRB- . It is true that it saves human time with AI doing tedious and repetitive tasks . While according to `` law of accelerating returns '' , when the rate at which technology improves is proportional to how good the technology is , as point might be reached where this process leads to wholesale and irreversible changes in how we live -LRB- Seth , 2014 -RRB- . Also , according to Bostrom , if one thinks of intelligence as a quantifiable unit then this acceleration will continue and move past the -LRB- small -RRB- space that marks the intelligence of humans . So , we will reach ` superintelligence ' defined as `` any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest '' -LRB- 2014 , p. 22 -RRB- . From many theories , it is obvious that the continual increasing growth of AI will eventually reach a point when human intelligence are not able to reach .
In conclusion , even though the hundred-year study of AI demonstrates a lot of useful employment of AI in many fields and thus reach a promising future of AI . With close examination of present so-called `` AI '' and many theories proposed by experts , AI may not be so dependable and requires more modifications .















Reference

Seth , A. Dec ,2014 . Why we must not stall technological progress , despite its threat to humanity . Retrieved from : https://www.theguardian.com/ commentisfree/2014/dec / 03/technological-progress-stephen - hawking-ai - artificial-intelligence

Gorhil , H. 2017 . New Trends in Artificial Intelligence & Machine Learning . Retrieved from : www.datasciencecentral.com/profiles/blogs/a-sneak - peek-at-the-future-of-artificial-intelligence-the-newes-1
Bostrom , N. -LRB- 2014 -RRB- . Superintelligence : Paths , dangers , strategies . Oxford : Oxford University Press .

Reddy , K. 2017 . Advantages and Disadvantages of Artificial Intelligence . Retrieved from : https://content.wisestep.com/advantages - disadvantages-artificial-intelligence /

Lafrance , A. May ,2016 . What Is a Robot ? Retrieved from : https : / / www.theatlantic.com/technology/archive/2016/03/what-is-a-human/ 473166 /

One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- is an article introducing what Artificial intelligence is and predicting what people 's life will be in one hundred years . It mainly describes eight areas that would be impacted by the development of AI . Although the analysis and the prediction have their own merits , they contain some flaws .

Before reaching the eight areas , the article mentions that `` the Study Panel found no cause for concern that AI is an imminent threat to humankind . '' It seems that authors of the article agree with the point of view . Nonetheless , the truth is likely to be contrary to their opinion . While browsing webpages or finding something interesting online , people do not usually expect any inappropriate messages . However , it happens .

Tay was an artificial intelligence chat robot that was released by Microsoft via Twitter . It was supposed to be a great experiment to test how AI study and learn through people besides programmers . Surprisingly and unfortunately , Tay was shut down only 16 hours after its release . Tay began posting racial discrimination messages and other extremely inappropriate messages after its launch . Microsoft had to shut the service down when it found that Tay was not behaving in ways that Microsoft expected . This is an actual example that AI can be a threat to humankind . Tay learned so many unexpected knowledges within hours through internet/people . Yet it did not understand those messages and began posting what it had learned . Since people hiding behind screens do not get punished , many of them started teaching Tay inappropriate things unscrupulously . In the future , AI might still learn things through the same way . People can hide behind screens and do whatever they want . Assuming we have police AI robots in one hundred years , if people can teach those robots or simply change the AI 's knowledge of definition of crime in the same way , it would be a great threat to humankind .

After reaching the eight areas , many counter arguments can be made to certain issues . Some areas have more issues than others . Among these areas , self-driving is a big problem . The article suggests a future that self-driving would be well accepted and gives some tips for the future . However , discussions of self-driving are vague in some aspects . For instance , the authors never discuss how self-driving works . Do all AI self-driving vehicles learn driving via the same computation system ? Do they share the same internet service while on the road ? What happens if there is an emergency ? Under the circumstance that some people have urgent events while some people do not really care how fast the car drive , do self-driving AI knows what to do ? When there is an emergency , how fast and accurate can AI react ? It is commonly known that human can react to emergencies pretty fast because unconscious mind of human always tries to keep human alive and avoid dangers . While facing emergencies , computers need to `` observes '' the event , transfer the event into data , and run calculations . This process may take a while depends on the circumstance . The judgement is an issue , too . During emergency , what judgement an AI would make ? Instant breaking may have killed the driver . On the other hand , keeping driving may have killed two other people . Would it choose to save the two people and kill the innocent driver ?

There are many more problems and flaws in the article . The authors ' positive attitude toward AI 's future should be encouraged . However , every aspect of AI should be examined and discussed . A possible bright future with AI does not mean that there is no issues or risks .
In the Stanford report One Hundred Year Study on Artificial Intelligence -LRB- AI100 -RRB- , researchers talk about
existing and potential applications of Artificial Intelligence in nearly every field . As AI continues to
improve and change our lives , we undoubtedly will see changes in our economy . These changes have potential
to benefit humans by automating basic tasks , saving us time , and lowering the price of goods and services .
However , I feel as though the report glossed over the potential negative economic impacts of artificial
intelligence . In this paper , I will talk about my concerns with AI and what action I think should be taken
to address these concerns .

AI has long produced fears of major job loss , which the article addresses in the Employment and Workplace
section . They state that most fears are overblown , and that so far AI has mostly `` been affecting workers more
in the skilled middle , such as travel agents , rather than the very lowest-skilled or highest skilled work '' .
While I agree that job loss likely wo n't be catastrophic , I also think it is foolish to assume that AI wo n't
also end up impacting low-skilled employees dramatically . While currently the cost of automating low-skill
workers is not economically feasible , AI and technology continue to advance . Perhaps it will take a few
decades , but it 's hard to for me to imagine a future in which AI-controlled robots are not cheaper and more
efficient than humans at low-skilled tasks .

Furthermore , the shrinking middle class should be a bigger cause for alarm than the report considers . With
the rising cost of a college degree and the increased importance of said degrees for middle class jobs , the
job loss due to AI will only increase the strain on this segment of the economy . Also , those who will be best
equipped to deal with AI will be college educated , so that will also increase the education gap in our society ,
and place significant barries for low-income Americans to benefit from AI advancements . Given the rising income
inequality in the United States , it seems as though the owners and investors of AI technologies are those to
stand to benefit most from the imcoming AI revolution . And also considering the fact that wealthy political
donors have incredible influence in US Politics , it 's probable that the wealthy can successfully lobby
politicians into supporting their control over the profits and wealth that AI will produce.If left unchecked ,
this could devestate opportunity the lower and middle class .

To give the report some credit , they advocate for the debate over a stronger social safety net , programs
such as universal healthcare , education , or basic income . I agree wholeheartedly with these suggestions ,
however unlikely they may seem in today 's political climate . Furthermore , I think that there will be new
jobs and industries that become available due to advancements with AI . However , since we do n't know what that
future economy looks like yet , I think we need to prepare now and be proactive in reforms to the social
safety net . Throughout the 2015 Report the claim is made many times that it is necessary to educate legislators and staff of regulatory agencies with a working knowledge of artificial intelligence in order to make informed decisions and policies . While it would be ideal for this to happen , it is not practical to expect so many individuals to educate themselves on such topics , particularly since many of these professionals are not technically versed . Even if enough people managed to be educated across enough different agencies and bodies , another large problem would arise : that of consistency . Policy and public opinion would differ between organizations and agencies , causing some areas of AI to develop and be implemented at different rates than others and hence slowing overall technological advancement drastically . A major goal of the One Hundred Year Study is to prevent exactly such stifling of progress , so alternatives must be considered .
As opposed to decentralized AI experts within organizations , a single agency ought to be considered . The proposed agency ought to be advisory in nature rather than legislative . This agency would be responsible for tracking research and development of AI across disciplines , as well as advising policymakers and legislators on major issues regarding AI . Additionally , the agency would conduct its own research on AI , allowing the federal government a simplified route to provide funding for AI research .
The main reasoning for the proposed agency being advisory rather than legislative is twofold . The first reason is the reason such an agency would exist in the first place : the problems facing AI are multidisciplinary , and as such already face regulations from various other government agencies . A legislative agency would merely slow progress of AI in other fields by allowing new rules and regulations to get caught in a sea of bureaucracy . The second reason is that an agency devoted strictly to regulating and limiting uses of AI would be perpetuating one of the main problems the AAAI hoped to avoid by creating the 100 Year Study , the problem of stifling AI through over-legislation . A centralized agency continually churning out laws and procedures would inevitably slow progress of development of AI .
There are many advantages to such an agency over having informed legislators , the main advantage being that of a central mission . Since this agency would be advising decision-making throughout the federal government it would be simple to draft legislation that optimizes the potential of AI throughout all facets of society , including but not limited to the eight regions the 2015 Report highlighted . The alternative would be having individual legislative organizations acting in their own self-interests which can lead to conflicting legislation or even the problem of over-legislation . The other main advantage of such an agency is that of standardization . Implementing standard practices in the development and deployment of AI would speed up the deployment of new technologies into industry . It can be argued that standards should be set by an organization independent of the government . Assuming another organization was in charge of standards , the proposed agency would still be an ideal way of ensuring AI is developed to benefit the majority of society .
Home/Service robots are predicted to do many tasks with advancements in artificial intelligence snd mechanics , which will make it possible for them to move freely in unstructured environments . But these robots are are not safe because they are vulnerable to security flaws . These robots have weak cryptographic systems and authentication issues . These make them unsafe to be used at homes as lot of data can be lost if these robots are hacked . For instance , robots in factories if hacked can bring down an entire assembly line . This is what happened when a ransomware attack targeted robotic assemblers in a Mexican plant .
AI is being used widely by MOOCS for automatic assignment grading.There has not been general acceptance for the use of artificial intelligence technologies within automated grading systems . The recent moves by online education organizations to use artificial intelligence technologies for high-stakes testing has raised eyebrows . This has resulted in an online petition against automatic scoring of essays by concerned academia . The argument is that machines can not measure the essentials of effective written communication like accuracy , reasoning , adequacy of evidence , convincing argument , meaningful organization , clarity and veracity . Les Perelman , a researcher at MIT , is highly critical of automated grading systems and states that `` comparing the performance of human graders matching each other to the machines matching the resolved score still gives some indication that the human raters may be significantly more reliable than machines.In June 2012 , Perelman submitted a nonsense essay to the US Educational Testing Service 's -LRB- ETS -RRB- automated grading systems called e-Rater and received the highest possible grade.ETS uses the e-Rater software , in conjunction with human assessors , to grade the Graduate Record Examinations -LRB- GRE -RRB- and Test Of English as a Foreign Language -LRB- TOEFL -RRB- , without human intervention for practice tests.Both These tests decide the entrance to US graduate schools and the latter the fate of non-English speakers wishing to study at American universities.Though MOOCS may be using machine learning and NLP for automatic grading , this practice is highly contested .
Using AI in healthcare is not completely safe.AI diagnosis work will require access to vast quantities of data in medical records . But what if it were subsequently misused ? . A report by the Royal Society and the British Academy recently concluded that the collection and analysis of data is changing so rapidly that the UK 's systems of governance can not keep up . It concluded that a new body is needed to safeguard trustworthiness and trust.The UK Information Commissioner 's Office -LRB- ICO -RRB- reprimanded the Royal Free Foundation NHS Trust over an agreement struck with Google DeepMind because the deal gave the AI company access to 1.6 million people 's medical records to develop a monitoring tool for kidney patients : the ICO ruled that they were not properly informed about the use of their data , among other shortcomings . Automation bias is another problem of using AI in medical diagnosis . Automation bias is the tendency to not search for contradictory information in light of a computer-generated solution that is accepted as correct . The study of automation bias in medicine has become relevant with the new machine learning approaches entering clinical decision support .
Over the years , improvements in technology have made way for countless new ideas and inventions . While the `` Stanford One Hundred Year Study on Artificial Intelligence '' stated many of the benefits and concerns of current and future AI advancements , it unfortunately failed to analyze and consider several concerns . The reading understated the negative effects due to unequal access to AI , replaced jobs , and increased usage of devices .
Firstly , as AI develops , there will be unequal access to the technology across the globe . In many countries today , people either do not have access to electricity or experience daily power outages . With unreliable access to power , AI may not be useful or available in such areas . This would eliminate the many opportunities that AI creates and form inequality . Although the reading briefly mentioned the possibility of AI widening the gap of inequality , it only suggested that policies be analyzed . This is not a convincing solution since inequality is growing with the technology we already have . Power is already concentrated in certain areas of the world and it is not being prevented . There needs to be better focus on how to make technology affordable and available everywhere .
Secondly , the reading mentions that AI will replace several jobs and make new jobs that require human intelligence . However , it is unknown if people will need higher education to acquire those jobs and if that education will be accessible . Those who have lost their jobs and can not afford the education may be stigmatized and discriminated by society . Moreover , as AI machines begin doing basic human tasks , the common living style may become standardized and less diverse . People might become less accustomed to differences and expect similarities among everyone 's living styles . Furthermore , losing touch with performing basic tasks may be disadvantageous in the case of emergencies where some AI technologies stop working . Today , as more self-checkout machines appear in stores , cashier jobs are slowly disappearing . This may severely affect those who can not afford higher education or get another job . If people are already affected by the AI we have now , there should be further consideration on how people will be affected as more jobs are replaced .
Thirdly , the health and environmental impacts that could arise with increasing use of AI are barely explored in the reading . One concern that is mentioned is the neurological side effects due to less face-to-face interactions between peers as more online classes are taken . In addition to these concerns , as people use AI to do everyday chores , they may spend more free time indoors with their electronics . For instance , the reading states that children seem to enjoy playing with their electronics rather than spending time with friends outside . This is concerning in that children might not get exercise and interact with people . The reading also explains how AI can bring more interactive entertainment to children . However , this may not help the situation as children may still not experience face-to-face interactions and be physically active . Moreover , as more devices are constructed , more energy may be required . If renewable energy sources are not utilized well , this could increase deforestation and carbon emissions which would severely affect our environment . The possible negative effects from spending additional time with electronics must be critically analyzed before AI becomes even more essential to life .
In conclusion , although the reading covered many of the positive and negative impacts of AI technology , it understated the negatives of unequal access , job replacement , and increases in technology usage . Since AI can be very beneficial to our life , it is important that everyone understand the negative effects to prepare for them and prevent them.Artificial Intelligence Can not Remove Human Biases
Ever since artificial intelligence was drawn into people s sight , artificial intelligence has been applied in many fields such as transportation and education . Some people believed that artificial intelligence had the potential to remove human bias , as machines are always regarded to be rational and fair . Similarly , according to Artificial Intelligence and Life in 2030 , it is feasible to apply artificial intelligence tools to lower human bias . However , artificial intelligence tools can not restrain human bias because they learn the bias from human and they can not counteract the bias purposely .
The first reason that artificial intelligence can not reduce human prejudice is that when artificial intelligence is learning from human s behaviors , it accepts the same stereotypes human hold . Human s writing or talking often conveys bias , such as the preference of pronouns when describing a job , for example , he for doctors and she for nurses . After processing human s written texts , artificial intelligence machines exhibit the same bias too . Google s artificial intelligence is biased as it sometimes translates neutral pronouns as he or she for different jobs like doctors and nurses -LRB- Hutson , 2016 -RRB- . Not only for jobs , associations between human and gender and fields appear from machines as well . A group of scientists analyzed the definition of the same word on different machines and found obvious correlations between women and arts and between men and science by evaluating the contexts in which the same word always appeared -LRB- Hutson , 2016 -RRB- . As the inputs of these machines are human written texts which may contain unobvious prejudices , and artificially intelligent machines are programmed to pick up this information and learn it in order to give satisfying feedback to human , the output that machines produce may be prejudiced , as an extension of human themselves . As a result , the artificial intelligence can not prevent prejudicing .
Another reason that artificial intelligence can not diminish human partiality is that artificial intelligence is usually not supplied with features to abate partiality consciously . When processing biased information , artificial intelligence does not have a moral-driven part to identify bias and to discard biased data . A recent study shows that machines are racists about names , when they match European American names with positive words and African American names with negative words more often , and , unless having an algorithm especially dealing with this bias , the same bias always appears -LRB- Devlin , 2017 -RRB- . To sum up , without special algorithm aiming at clearing prejudices , artificial intelligence is unable to recognize racial and gender prejudices and to separate them from the original materials , and thus can not decrease bias .
In a conclusion , artificial intelligence is unable to clear human bias because it learns from biased materials and it is unable to differentiate biased information and to discard them . Artificial intelligence is desirable , but the technique can be improved further , as in some cases the artificially intelligent machines are still making biased decisions . Therefore , researchers in the field can try incorporating human knowledge with machines to give fair feedback . Further research is also needed to implement algorithms to supervise machines and prevent machines from making biased judgments .

References
Devlin , H. -LRB- 2017 -RRB- . AI programs exhibit racial and gender biases , research reveals . The Guardian .
Hutson , M. -LRB- 2017 -RRB- . Even artificial intelligence can acquire biases against race and gender . Science .

The 100-year report has an explicit demonstration on the transformation brought by the artificial intelligence on the aspect of employment and workspace . However , I doubt that the artificial intelligence will have profound impacts on the working environment based on the current labor market condition and the estimated growth of AI .
For one thing , the article states that rather than replacing tasks , the strategies that AI used was actually to replace tasks . To be specific , it says that many `` routine '' digital technologies are driven to change the working environment . However , the portion of relatively low-level labor is indeed very high - many workers who did not receive enough education are indeed doing `` routine '' work . They are the main portion of the workforce which indeed paid for the work that they are doing . Moreover , some people are trained to gain such skills in order to do for a living . However , the introduction of robots into those skill-related factories will indeed break balance of the workforce . Some people claims that the cost for the AI on the labor market will be decreased . But if we think the problem from a global scale , the large labor introduction of labor from China indeed make the human capital a more acceptable resource for the overall working environment . As a result , I do not think that there is a need to build machines to do our tasks .
Moreover , the improvement of AI affects the workforce by `` lowering barriers to entry and increasing participation '' , thus increasing the pressure of society . The AI 's improvement makes the labor become a less important factor with the passage of time . More emphasis on intellectual capital will lead to the majority of citizens unable to pay for a general standard of living . In fact , the United States has already experienced a fall on population ratio of employment with a growth in overall GDP since 1990s . The article also admits that `` Longer term , the current social safety net may need to evolve into better social services for everyone , such as healthcare and education , or a guaranteed basic income '' .
On the other hand , AI-based employment will lack interpersonal interaction for the workforce . Imagine that `` everyone '' is doing their own tasks within settled time , they wo n't have the emotional attachment towards their job or career . Although the efficiency is improved , but they lack an incentive to create novelty on their own . The form of hierarchy will presented apparently from the workforce , and unlike human , they wo n't try their best to get promoted but instead , they will become old and need updated or even be replaced by others . Moreover , the sense of responsibility will be lost . Imagine a company is earning money for improper goals , all the workers are only completing their tasks without senses of justice to oppose the management level .
Admittedly , certain tasks will be improved including enterprise resource planning , networking , information processing , and search . If we explore more on the tasks that human have a hard time to manage , or to use like searching or storing information , AI will certainly benefit the working environment . But in regards to the current direction of development on AI , which emphasizes more on routine tasks , and the imbalance of labor market , I doubt the realization of AI will in fact benefit the overall labor market.Stanford One Hundred Year Study on Artificial Intelligence demonstrates that AI has been use in many aspects of our lives including transportation , healthcare , education and more .
Study illustrates how AI is better in these areas while it still faces some challenges and causes legal or other issues . However , the whole study introduces AI as an approachable
and beneficial technology since researchers believe that AI is not a threat to humankind because there is no self-sustaining AI likely to be developed in the future .
However , AI machines with self-conscious are likely be developed since it has not yet reached its limit yet . Moreover , other than issues that have been mentioned in the study ,
human s intelligence may have been weakened because of AI machines and solving these issues caused by AI technologies is harder than demonstrated in the study .

Contrary to Stanford s study , AI may be a threat to humankind since AI machines with self-intention are likely been developed in the future . From the latest news , recently Facebook
is developing chatbot AI and these AI chatbots had bizarre communication among themselves . Although this may happen coincidentally , intelligence of AI is undoubtfully high and
their intelligence limit has not been reached since more researcher are put more effort into developing AI machines . Therefore , in the future , it is likely to have AI with its self-conscious
and higher intelligence than humankind . If AI machines with self-intention and higher intelligence are developed , more ethnical issues will be caused .

Moreover , AI may have weakened humankind s intelligence and contributions to society over the past few years . Automatically filling text messages when users have not yet
finished typing , recommending books or movies that users may be interested in before they start searching , AI has its own intelligence to assist human while human
themselves do not have need to memorize words , literature or they will no longer spend time thinking . In the future , once AI replaces drivers , less people will be eager to learn to drive .
If AI have better education planning , teachers may not even evaluate their own students abilities and keep track of their students progress since AI machines have already got every task done .
The more convenience that AI has brought our lives , the less that human will need to do .

As people would argue , having AI to replace human to do some jobs will leave human more opportunity and space to improve their abilities and conduct better quality work .
Although it may be reasonable for some part , it is fact that humans do not have same high level of intelligence themselves . If AI replaces all taxi drivers , bus drivers , librarian , workers ,
these people need to find other jobs . Moreover , in the future , it is very likely that AI is going to take more jobs . In the study , authors state that AI will also create more jobs .
However , creating equal amount of jobs for people who lose their jobs can do is more challenging since it depends on people 's level of education and working abilities as well .

In sum , although AI has brought human more conveniences , higher life qualities and some issues that it caused may be able to solve . AI intelligence has not yet reached its
limit and it is likely to have AI self-consciousness so that it will be a threat to humankind . Moreover , AI technologies have weakened human s abilities to think and solving issues
caused by AI is harder than what Sandford s study has demonstrated .



The article Stanford One Hundred Year Study on Artificial Intelligence defines Artificial Intelligence -LRB- AI -RRB- as developing intelligent systems that can think , act rationally and humanly . While the article beautifully gives us a comprehensive account of developments in Artificial Intelligence and predictions about the future , there are some assumptions which can be debatable .

Challenge Statement : The estimate of reliability in decision making to the human measure Intelligent Systems should necessarily meet the thought process of humans to take over any human decision making tasks and intelligence in security for the deployment of AI applications .
The challenge statement in a way contradicts on the ongoing research of AI applications , scheduled for -LRB- example : autonomous cars -RRB- or existing in -LRB- example : robots aided surgeries -RRB- the market especially in the areas of transportation , healthcare and education . The metrics listed in the challenge can become a major threat for the deployment of AI applications .

Reliability in HealthCare and Transportation Systems :
Intelligence in HealthCare and Transportation systems demands 100 % accuracy in drawing inferences . From the research we know that 302 neurons have been wired and studied so far while the brain has several billions of neurons wired . There is uncertainty in understanding at what level and how -LRB- many -RRB- neurons get involved in a decision making process . This shows computers are no way close to take over human decision making process and challenges the trust on robotic surgery .
Secondly , it is important for the Intelligent Systems to understand the truthfulness of the dataset before learning . Electronic Health Record -LRB- EHR -RRB- takes roles of a listener and teller . Unlike autonomous cars , healthcare does not have rules or labels for drawing conclusions . Creation of comprehensive global guidelines is impossible as each patient will have different scenarios . Every patient is a different dataset and the system needs to learn , adapt and then act which is time consuming and expensive . Thus AI applications may widen the economic , social gaps among different classes of the society since not every person will be able to afford this facility . This in a way contradicts the objective of AI stated in the article . Robot aided surgeries might lead into issues due to lack of situation awareness or interaction of surgeons with the case . Instead more AI research in the area of low resource communities like urban planning , understanding the earth , and helping governing bodies will benefit the public more .
AI Systems infer the data that is fed or manipulated from another system . Regulation of social policies is yet another challenge for AI deployment . There are no right choices for few scenarios . For example , responsibility of any accident caused by autonomous cars or who should sacrifice their lives in case of any emergency on roads has no definite answers . The responsible entity on the loss -LRB- if any -RRB- due to wrong inferences from EHR is also tricky .

Reliability as validation :
Validation or authorization of a person can become hard due to human-aware intelligent systems . Human-aiding robots can take the place of his/her owner and authorize transactions . In education systems , it will become hard for the professor to identify if the student completed assignments or the aiding agent .

Network security :
It would have been good if the team AI and Life in 2030 and the article had determined focus on developing intelligent systems for the security of data along with other domains . Scenarios like unknowing poisoning of data , breaking the network in real time can turn hazardous for applications like autonomous driving and healthcare analytics .
Overall , I recommend developing human-aided or human assisting intelligent systems automated with morality rather than becoming or simulating humans .






# Homework 1

The Stanford One Hundred Year Study of Artificial Intelligence predicts that by
2030 the typical North American city will rely on AI solutions for monitoring
and predictive policing . While the study mentions the concerns that such AI
based solutions have the possibility of encoding human biases in AI algorithms ,
the study 's authors move past these concerns to discuss a more optimistic view
of this technology . This dangerously ignores potential flaws in both AI policing
systems and the deployment of those systems that could have terrible impacts on
future suspects .

It 's not necessary for an AI system to advance to the level of sophistication as
the Minority Report for the dangers of a mis-classification to become apparent .
While algorithms may not be programmed with explicit biases they can nonetheless
be fed data collected from humans harboring their own biases and the biased data
can manifest as a biased AI . These kinds of problems are already emerging in our
current justice system . Around the time that this study came out , ProPublica
reported on a program being used by judges during sentencing to predict which
defendants are more likely to commit future crimes . While the program 's score
is n't gospel it is a factor used by the judge to determine how harshly to
sentence a defendant . Analysis of this program revealed a number of concerning
flaws :

- When comparing the program 's estimate for how likely a defendant was to commit
further crimes , the program was only 50 % accurate .
- The program mislabeled black defendants as future criminals at twice the rate
that it mislabeled white defendants as future criminals .

It 's understandable why it can be compelling for a justice system to turn to
these kinds of programs or in the future why they might turn to AI as another
tool for fighting crime or relieving the burden on a strained justice system .
These kinds of tools take a lot of data and produce a simple digest that can
offer guidance to judges or police captains . But these systems are seductive in
that they can too easily replace difficult moral decisions with a black box that
may or may not contain dangerous biases .

The study is correct that AI techniques have the potential to remove or reduce
human biases but even with the current infantile state of AI , systems are being
used in the world that can exacerbate systemic biases . In many domains , the
problems inherent to early AI systems are perfectly acceptable . If a smartphone
voice assistant does n't understand a request that 's an acceptable if annoying
aspect of interacting with AI systems as they are developed and mature . The same
kind of attitude can not be tolerated in the justice or police systems where
the wrong decision can have permanent and life-altering consequences . While the
study provides a variety of scenarios in which AI systems can and have been
helping fight crime it seems to quickly skip past the very real scenarios of
harm AI in the justice system can do.HW1

In the article `` Artificial Intelligence and Life in 2030 '' -LRB- Stone et al. , 2016 -RRB- , authors argue that when it comes to the applications of artificial intelligence in healthcare , the development of the field is impeded by ` outdated regulations and policies ' -LRB- p. 25 -RRB- . It is further suggested in the article that the removal of these regulations are essential for artificial intelligence to step into health care and save millions of lives -LRB- pp.25-26 -RRB- .
However , I do not agree with the argument that regulations and policies are the major factors stopping artificial intelligence from saving people 's lives . Instead , appropriate regulations and policies are a good way , if not the only way , of keeping the technology in check and making sure it does no harm to human beings , especially in the field of healthcare .
One common problem people have with artificial intelligence in healthcare system is the attribution of responsibility for wrongdoing . Compared to many other fields , wrongdoings have especially serious consequences when it comes to medicare . While the authors suggested that artificial intelligence will likely serve an assisting role for medicine practitioners -LRB- p. 27 -RRB- , how much should a wrong suggestion given by artificial intelligence be hold accountable when the final decision made by the medical practitioner goes wrong ? In other words , if we recognize the weakness of artificial intelligence as stated in the article and therefore require an additional professional to do the final judgement as well as to take up the responsibility , the technology itself is not so appealing anymore .
The fact that artificial intelligence could never be hold accountable for ethical responsibilities as a human being does essentially inhibits fully automated diagnosis from becoming applicable in the real world settings . Therefore , when artificial intelligence applications finally become mature enough in healthcare setting , a great deal of clinical trials , professional evaluations , and even legislation will be required for finding and settling an appropriate role for these technologies . However , before that day comes , strict regulations are not only essential from an emotional point of view based on public 's fear of unknown technology , but also crucial from the legal and professional perspectives before the technology is well-developed and thoroughly tested .

Moreover , the article is also self-conflicting regarding the argument I pointed out . While it acknowledges the limits artificial intelligence have in current time and the near future -LRB- p. 27 -RRB- , it also claims that strict government regulations are slowing down the development of the technology -LRB- p. 25 -RRB- .
In my opinion , applications of artificial intelligence in real-world settings , especially in healthcare related field , should only be implemented if they are guaranteed to benefit the life of human beings , instead of as toy models of some research groups or ` cool product ' of new start-ups . Restrictions are made to protect the well-being of human race and should not be considered as ` obstacles ' when developing the technology that is aiming to complete the same goal .
Overall , while the article provides a good insight into possibilities of artificial intelligence 's future , it is somewhat lacking the sense that human being are the subject whose well-being we are aiming to maximize , instead of focusing on advancing the technology itself , which could possibly do more harm than help if not regulated properly .
Problems of Widespread Adoption of A.I. in Transportation
In 2016 report of Stanford s One Hundred Year Study on Artificial Intelligence , the study panel has explained the current and future applications of Artificial Intelligence in many areas of people s life and points out existing difficulties that hinder its adoption . In the past few years , A.I. has been developed rapidly in some industries including transportation , healthcare and education . Thanks to the development and progress in hardware , self-driving cars adopting Artificial Intelligence have stepped into reality . Although automatic-driving cars , as being claimed , have a great potential and many advantages that will help it perform better in many tasks than human drivers do , it still faces two realistic problems that could slow down its adoption , costs and comfortability .
John Greenough , as cited in the report , claims that automatic-driving vehicles will be widespread in 2020 -LRB- p. 20 -RRB- . However , in automobile industry , the price of self-driving cars is too high that not many people can afford . For example , Artificial Intelligence has already been adopted in some vehicles such as all models of Tesla . Tesla has already successfully launched full-autonomous hardware on their all car models , but the cheapest model , Model 3 , is over 35,000 dollars . Besides Tesla , only a small portion of cars have self-driving system and that is not fully autonomous , only applicable in parking , which is not as expected as the cars that can be driven on city roads or highways without human control . In addition , when there are only few self-driving cars in the market , customers may choose cars with better appearance , fuel efficiency and performance instead of self-driving system that does not attract them , which will waste the advantages of A.I. in transportations such as safety . Only when self-driving system becomes universal that almost every car is equipped , self-driving technology will be able to maximize its benefits .
Furthermore , the study panel indicates that self-driving cars will release drivers from the steering wheels and they will be able to work and entertain on their way , which might make them live further than before because they do not need to pay as much attention as before to surroundings while driving , which is relaxing . Nevertheless , if the road condition is bad or the traffic is crowded , people will not feel comfortable when they look at their screens , the same feeling as someone drives the car and you look at your laptop when the car is bouncing or in a traffic jam . People will feel sick under such situation . Without ensured road condition and smooth traffic , the experience of sitting in a car will not be better than driving it . Therefore , people will not be willing to spend much time on commuting and live further than they used to .
Although self-driving cars have shown their reliability and safety during tests in the past few years , there are two main problems that will hinder its widespread adoption in people s daily life , costs and comfortability . If full self-driving system is only available on expensive cars as Tesla and traffic condition is not improved , Artificial Intelligence in transportation will not be able to unleash its full potential and benefit human beings as the study panel expects .



References
Artificial Intelligence and Life in 2030 . -LRB- 2016 , September -RRB- . Retrieved from https://ai100.stanford.edu/2016-report
In modern society , electronic device has been much more popular and easier to see because of the development of the science technology . With the increasing appearance of electronic device , one of the advanced technology - Artificial Intelligence has become much more common . Artificial Intelligence is an activity to make machines intelligent in order to let them function appropriately and have the acknowledge or the foresight of the their behavior . This kind of technique could bring human many advantages in many field such as : transportation , public safety , employment and workplace . However , artificial intelligence could also bring people some other potential risks , like the possibility of being used by cyber criminals or decreasing of the job opportunities of other people .
Artificial Intelligence could be very useful when on the internet . In the article , author says that public safety and security could be protected by the artificial intelligence . AI tools may also very useful in helping police by managing crime scenes or searching events by helping commanders prioritize tasks and allocate resources . Also , artificial intelligence have the ability of predicting where and when crimes are going to happen and who may commit them . However , besides these advantages , artificial intelligence could also be used by some other cyber criminals , which is not good for public safety . These criminals may use the technology to steal others personal information or even spy others every action on the Internet , which may be the invasion of others rights of privacy . With the help of artificial intelligence , criminals can get what they want more easily and hard to be found because of the ability of prediction of the artificial intelligence . Although artificial intelligence could help police in many ways , there will always be some loopholes for criminals to utilize .
Artificial intelligence could affect employment in many ways . Artificial intelligence will influence future labor need , including the shift in skill demands . In the article , in order to ease people s worry about being marginalized by artificial intelligence , author says artificial intelligence will likely replace tasks instead of replacing jobs in the near term , and will also generate new kinds of jobs . However , these new jobs are harder to imagine than the jobs we will easily lose . Artificial intelligence will also generate new jobs , especially in some area by making certain tasks more important , and create new categories of job demands by making new modes of interaction possible . Because artificial intelligence could make labor became less important by replacing the roles which human plays in the work place , many people s daily lives will be affected .
Although artificial intelligence could bring people numerous advantages . There will always be some disadvantages for human being . Although these disadvantages may seem terrible for us , its advantages could be much more helpful for human being . Artificial intelligence will finally appear in ever corner of the world because its huge influence on human lives . Also , I believe the risks which artificial intelligence may bring will finally be eliminated in the future.The ever increasing prominence of Artificial Intelligence -LRB- AI -RRB- in our world is an exciting and remarkable phenomenon . With the prospect of self-driving cars becoming a common means of transportation , the promise of stronger AI-implemented security systems , the possibility of online education at all levels of learning , and more , the Stanford One Hundred Year Study on Artificial Intelligence presents AI as `` a boon to living standards '' , a technology that will increase the quality of human life -LRB- 39 -RRB- . While AI may certainly revolutionize our lifestyle in ways that make living more comfortable and secure , it is important to keep in mind that AI will not necessarily fix all social ills and could perhaps create new societal complications with its implementation .

One of the first domains of AI that the report focuses on is in the area of transportation , in particular self-driving vehicles . `` With self-driving car technology , '' according to the study , `` people will have more time to work or entertain themselves during their commutes , '' with the benefit of `` increased comfort and decreased cognitive load '' -LRB- 21 -RRB- . The thought of having more free time and expending less energy on menial tasks such as driving is indeed enticing at first glance . Yet , in a way , our lifestyle already provides plenty of opportunity for people to relax and be entertained . With smartphones , iPads , and other portable devices , we instinctively scroll through Facebook as we wait in line for coffee , check our email while sitting in lecture , and fiddle with what music we want to listen to when traveling from point A to point B . The added leisures of technology to our daily lives , however , have not truly made our society more content or at ease . As a country that is prone to stress and increasing rates of anxiety , the raised quality of living that comes with AI and self-driving cars -- while extremely useful and likely to benefit the population -- do not always equate to increased life satisfaction .

Similarly , the study talks about the emergence of AI-supported online learning systems that will `` expand the opportunity for adults and working professionals to enhance their knowledge and skills , '' as well as assist student learning from kindergarten to the college level -LRB- 34 -RRB- . While the implementation of AI in educational structures would surely provide additional learning resources , there is yet no guarantee that simply having more educational tools will help people learn in smarter , better ways . Even in the present time , with online resources such as Canvas , Moodle , Top Hat , and Piazza , the availability of these tools alone do not prevent students from struggling in their courses . Students first must learn how to use the tools , which takes time and effort , and then there must be incentive to continue using them . Furthermore , the introduction of AI into the classroom does not itself stop the recurring problems in the education system of cheating , plagiarism , or students feeling unmotivated to study .

As a whole , there is no doubt that as Artificial Intelligence continues to play a greater role in our day-to-day lives , our standard of living -- including comfort , leisure , and access to helpful resources -- will surely increase . At the same time , an AI-influenced lifestyle of higher quality does not imply an easier , problem-free life . On closer examination of the domains of transportation and education , AI alone does not correct societal matters including stress , discontentment , ethical issues or the struggle to excel in school . Perhaps what we truly need is not a computer-driven world of ones and zeros , but a more human approach of using technology that meets our needs as people and prevents the problems we face today from recurring in the future .
The Standard One Hundred Year Study on Artificial Intelligence describes the vision a group of artificial intelligence researchers have of how the world will be shaped by AI by 2030 . Many of their points are valid , and the foreseeable improvements are realistic in an ideal world . However , they only briefly touched on a critical component , which would hinder AI development in transportation and healthcare : security . Artificial Intelligence could certainly reach scope the article claims , yet the devices it would interface with provide a challenge .

When it comes to transportation , specifically self-driving cars , security is paramount . All it takes for a potential hacker to cause a fatal accident is one overlooked exploit , and with a self-driving car there are several different attack vectors . If the system is centralized in nature , the server , and server to car communication , is a concern . If the system is decentralized , that is a self-driving system that works peer-to-peer , then there is potential for a malicious car to enter the network and send incorrect data to other cars . All of these challenges would need to be properly addressed , and if a successful attack were to happen it could significantly lower public adoption of the technology out of fear .

When it comes to healthcare there are many ways in which AI could be used to greatly advance the field . For example in the recent Microsoft Imagine Cup 2017 , the wining team X.GLU created a smart glucose meter which utilized cloud based machine learning to create a solution that assisted children with managing their diabetes . Solutions like this are a prime example of how AI can help improve the quality of life for many patients in the health care system . However , IoT based devices which rely on cloud computing open new attack vectors , and potentially fatal ones ; a hacked smart pacemaker could be used to kill someone . That is an abundant amount of trust to put on both the software running it , and the hardware running the software .

It has repeatedly been shown that IoT devices , which could include both medical related ones and intelligent cars that rely on cloud computing AI , are often riddled with bugs . Tesla cars have been hacked at Def Con 23 , and with the recent focus of Def Con on IoT exploits , a variety of IoT devices have been hacked , even simpler things such as smart locks . While the AI running in the cloud may not be vulnerable , the devices it relies on to do actions based on the AI s evaluations are . Not only is the software a concern , but so is the hardware . At a recent Black Hat USA 2017 presentation called BREAKING THE X86 INSTRUCTION SET , a researcher shows how vulnerable processors are , and that the processor manufactures actually have been introducing many undocumented instruction codes for several years , which all have the potential for exploits not known to the public . This has the implication that at this point in time , developers can not even trust the hardware their code executes on . If there is a bug in hardware , then that bug can propagate up to any software running on it .

Ultimately the vision of the AI researches have are completely viable in terms of what the AI portion is responsible for doing . The problem arises with the devices that act as the implementers of the AIs decisions . The more they become embedded into society , and even our own bodies , the higher the damage a security exploit could incur , and that is a risk that may hold back adoption , and as a result , development .

The field of artificial intelligence -LRB- AI -RRB- has seen rapid advancement over the past decade . Several concepts and ideas from science fiction films are now realized and widespread . However , most science fiction films also present AI in a bad light , with themes of global domination and destruction due to an AI system going rogue . The study of a hundred years of AI by Stanford analyzes the state of AI , addressing both cases where AI has shown promise and where AI can be seen as a threat . The general conclusion of the study is positive and states that most AI applications will enrich humanity , and those that can cause harm will likely not result in anything drastic for a long time , if ever .
The study states that AI will lower the cost of many goods and services which would result in greater disposable income for everyone . However , there might not be a significant reduction in cost as the cost of getting current methods of production replaced with those of AI will be quite high initially . Furthermore , the costs of maintaining the AI system will be a part of the cost of production , as the study itself states that there will be a need for re-training efforts to bring employees up to speed with the technology . As firms exist to turn a profit , there is a low incentive to invest in these programs . It could take significant support from the government in the forms of subsidies and publicly funded training programs to encourage firms . This could result in a very slow decline in costs of goods and services , almost unnoticeable .
This also relates to the claim that AI can assist Low-resource communities by providing solutions to various problems that plague them . To be effective , there must be an incentive to spend the processing power and funds on such an endeavor . While it may not be the case , theoretically , firms must spend their resources in maximizing their profit . Thus , the efforts in reducing the problems affecting low-resource communities must be undertaken by public agencies . However , a government gets its funds from tax collections and thus there must be sufficient public trust in AI , which is true for almost all cases of AI mentioned in the study .
Throughout the study , AI has been most used to obtain data by analyzing public activity and behaviors over time . The biggest concern with this hoarding of data is the issue of privacy . There is the question of who is in control of this data , because if the data is in control of someone with malicious intent it could become a serious problem . With so many AI applications on the rise , it is hard to determine whether an application is safe . Distrust in organizations pops up quite often in the news due to their collecting user s private data and details , and it is often unclear to the average user exactly what is being collected . While most corporations provide clear documentation on what is being collected and how to prevent it , other corporations might now . Thus , the abundance of AI applications is not as close as the study states , as there are still several concerns that must be addressed . However , with the pace the technology is advancing , there could soon be solutions to the problems AI poses.Artificial Intelligence , or AI , has been a buzz word and one of the most discussed topic in the field of Computer Sciences in the 21st century . There has been many articles and reports published in different magazines , newspaper and academic journals discussing various aspects of AI ethics , security and quality of human life . Artificial Intelligence and Life in 2030 is a similar report published as a part of One Hundred Year Study on Artificial Intelligence , which is a long-term study of the field of AI and its impact on people and society . This study was conducted by the Standing Committee which comprises of experts in the field of AI from academia and industry from across the world . In this report , scientists and experts discuss the impact of AI in different domains or sectors of economy transportation , home robots , healthcare , education , low-resource communities , public safety , employment and entertainment by the year 2030 .

In the transportation sector , the report claims that by the year 2030 a typical North American city landscape would evolve to having self-driving cars and trucks . Furthermore , it also speculates to have aerial vehicles to commute within the city . AI and other related technologies like Machine Learning , Computer Vision and Deep Neural Network has grown in a rapid rate in the recent times but it is still far from helping us develop safe and reliable transportation network within the city for the people by 2030 . The concerns in developing technologies for self-driving vehicles is safety , reliability and ability for humans to interact with autonomous technology .

The major concern for experts in the field of AI has been of safety . This concern and fear about AI and its technology is extended to the entire public . This is mainly due to vehicular accidents involving autonomous vehicles with none or some human supervision . The Tesla accident in May 2016 , in which a man was killed when his Tesla in the autopilot mode hit a truck , questions the validity of safety in self-driving vehicles . Machine learning and Computer Vision , which are sub-fields in AI , are still young technology and must undergo rigorous testing and vast improvement in order drastically increase the safety standards in autonomous vehicles .

Along with the safety of a technology , people expect the technology to be reliable as well . Self-driving vehicles normally provide none or some features of the vehicle to be controlled by human operators . In other words , most of the functions of the vehicles is performed by vehicular algorithms and network signals . These technologies are vulnerable and could be misused for terrorism activities . It is , thus , important to test the algorithms the vehicle runs on with all the possible parameter to close all loopholes and protect the people and the society from misdemeanour activities .

The concerns with self-driving vehicles does not conclude at safety and reliability of the technology , it also required to know how people would interact and adopt to autonomous vehicles . With vehicles on autonomous mode , people would be subjected to distraction - texting on mobile , working on the laptop , talking to co-passenger and may violate certain safety precaution like wearing the seatbelts . This strongly indicates that people should undergo specialized training before operating an autonomous vehicle or the vehicle manufacturers should factor in these aspects in their design to avoid these avoidable implications .

AI is still young and growing . It has the potential to revolutionize the transportation sector but seeing self-driving vehicles on American roads is going to take much longer than 2030 . The experts in AI needs to address and solve these concerns before the transportation industry opens to autonomous vehicles .
While the Stanford One Hundred Year Study is largely informational and does not raise any particularly controversial points , I challenge the claim that `` Autonomous transportation will soon be commonplace '' -LRB- Stone et al , 2016 -RRB- and will radically change urban organization by 2030 . There are a number of challenges that stand in the way of widespread adoption of self-driving car technology , namely , the slow pace of government , and difficult moral considerations .

A major issue with autonomous transportation is the necessity for government regulations and checks on car producers . This pushes back the timeline for widespread adoption of self-driving cars , as the mechanisms for evaluating and regulating self-driving cars will need to be determined and refined . The study recommends that all levels of government should acquire technical expertise in AI . This would certainly help the government effectively communicate with and regulate producers of autonomous vehicles , but again takes time . Government officials have more pressing issues to consider , and acquiring this technical expertise will constantly be delayed .

In addition to the requirement of regulatory checks on car producers , there are serious moral questions that must be considered before autonomous transportation will see widespread adoption . Probably the most salient question is who is at fault in the case of an accident : the company that made the car , the person in the car , or some other entity ? Additionally , should the car prioritize the safety of its occupants over that of pedestrians , or vice-versa ? These are difficult societal questions that do not have a clear answer , and opinions will vary based on many criteria , such as age , race , gender , and others . Increased funding for research about societally accepted goals and principles may help resolve this issue , but it will take time and will likely not satisfy all groups . While the study uses GPS as an example of how quickly technology can be adopted , the fact that autonomous vehicles can present a serious safety hazard if implemented improperly will slow down the time table significantly for truly autonomous vehicles to reach the market . Instead , I believe that the use of automation for long-range shipping is more likely , as highway driving is lower-risk -LRB- due to lack of pedestrians and less stop-and-go traffic -RRB- and the trucks can prioritize the safety of others on the road without having to worry about an occupant .
Finally , autonomous vehicles are unlikely to radically change urban organization by 2030 . As mentioned above , I believe that true autonomous vehicles that enable drivers to do other activities while the car drives itself will be delayed significantly by regulatory and ethical concerns . These vehicles certainly have potential to fundamentally change urban organization -- the ability to perform other tasks while driving would make people more willing to live farther away from where they work . This could lead to more spread out cities and larger suburbs . However , the current autonomous technology that Tesla is implementing in their cars does not have such a strong potential to change the urban landscape , because of the requirement that the driver is alert with their hands on the steering wheel . This avoids serious problems that the self-driving car industry have to face , such as liability , but does not actually significantly change how people use and interact with their cars , and as a result , does not have potential to create large societal shifts .




Bibliography

Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 . While humans have been quick to adopt AI in the forms of curated Facebook feeds , online shopping suggestions , and useful assistants such as SIRI , there are challenges to the future of AI . In the executive summary of Stanford s One Hundred Year Study on Artificial Intelligence the challenges are listed as the difficulty of creating safe and reliable hardware , the difficulty of interacting with human experts , the challenge of gaining public trust , the challenge of overcoming fears or marginalizing humans , and finally the social and societal risk of diminished interpersonal communications . Each of these challenges represents a key sector of development . The challenge of making safe and reliable hardware is in the area of transportation and service robots . Any hardware that is going to control a car , plane , or some other vehicle is going to have to be much safer than the human equivalent . AI controlled service robots will have to be exceptionally safe , as they will be dealing with young children and the elderly . While it is simple to see the challenges listed by the study as reasonable and just , I believe that the biggest challenge to AI development is government understanding and regulation .

Different government agencies currently regulate different area of AI development . The Federal Aviation Administration is responsible for drones , the Food and Drug Administration for technologies that aid in medical diagnosis and treatment and other agencies as found to be a best fit . There is not a standard established for what levels of safety , performance , and liability are to come with the associated AI . If medical software makes a wrong diagnosis , is it the attending doctor s fault ? Can we assign blame or even immunity of guilt to a software platform that has the combined virtual experiences of thousands of doctors and millions of patients ? How do we handle a case such as this ? After an AI driven car is proven safer than the average human counterpart is , how do we assign fault when two AI cars eventually have an accident with each other ? Due to the capital costs associated with gathering the relevant data to develop robust AI systems , the stakes will ultimately be very high .

While the study does note that more experts need to be in Government positions to guide and develop future policies as new technologies emerge , the true experts will be the ones developing the technologies . The pioneers and entrepreneurs that have led to Google , Facebook , Amazon , Netflix and many others did not have counterparts of equal ability in government roles to guide useful policy . While being able to watch any and all of your favorite TV shows and movies via streaming services certain is substantial change , binge watching Netflix is now something people publically advertise as something they do regularly and enjoy . As AI technologies improve to the point that they are able to offer us things that are either too good for us to resist , or drive us away from other societal interactions will governments have the right experts in the right position ? The study already states that children prefer to play games alone to being with their actual friends outside . AI will eventually become too addictive , entertaining , and immersive in our lives . I believe the relevant governments in charge will not have the expertise to help guide us to make the right choices for ourselves . I hope that the large companies that control the data and the intellectual capital to develop such AI act with a well guided ethical and moral compass .

This next century will bring with it exciting and new technologies that will change the world in more ways than one . Already since the invention of the computer and Internet , the world has come a long way in terms of technological as well as social advances . We are able to share information in ways people a hundred years ago never thought possible and with that , have access to more data than we ever thought useful . This data has allowed us to do incredible things like model the earth and all the buildings on it in 3 dimensions , create machines that we can interact with and they interact with us in return , and know the population of Kazakhstan in 3 seconds . Many of these advances are the result of our efforts to replicate the human thought and learning process in the form of a machine that has magnitudes more throughput ability than the human brain . These efforts are colloquially known as AI and its affects , possibilities , and abilities are in a position to grow exponentially in the next 100 years .
The article `` Artificial Intelligence and Life in 2030 '' lays out not only the advances that they see AI making in the next 30 years , but the social changes that it will bring along with it . This article makes some interesting points and is quite a realistic look at how AI may advance within the next 10 years and how we must be ready for it . The parts of the article that I find most fascinating is how it tries to explain and warn for the social changes that will take place in a society with AI being a natural presence . This article has a much more positive outlook on the future with AI in it than most of society has . Even men well versed and truly innovators for the subject , such as Elon Musk , have a much more grim view on a society with humans and AI interacting and working with each other . In my opinion , this is where the article fails most . Much of the positives laid out in the article imply , and require , a massive change in the way our society functions . The benefits of AI are at the forefront of the discussion and while it does lay out a compelling argument for how AI can and will improve the lives of millions , it neglects the innate selfishness of human nature and the way that American society perpetuates and encourages it . A prime example of this short coming is when the article talks about the financial benefits reaching all of society as AI is naturally much cheaper for businesses to maintain than human labor . While this is promising , it would require regulations to stop the business owners and CEOs from taking home most of those cost savings in the form of more wages and bonuses for them . This issue is kind of addressed in the last section of the article by laying out the necessary regulations and societal changes that are necessary if we are going to get the most we can out of AI , however , the researchers also argue that too many regulations will stifle the development and reach that AI will have in our society . So while I feel this was an insightful article , I feel that the true benefits of AI will never be seen until we , as a society , gives up on the selfishness that is so ingrained in us .
The One Hundred Year Study seems to suggest that the general public has a negative perception of AI . Also , in the study they suggest that
all layers of government should gain technical expertise in AI and then they will be able to make informed decisions on AI that benefit society .
I want to challenge both of these aspects of the study . I feel that in general the public is optimistic about the future of AI and that it would not
be feasible for all layers of the government to gain technical expertise in AI and even if they did , they would not be able to stay up to date with
current research .

Throughout the study they mention several times that the majority of the general public does n't trust AI and that public trust has to be gained for
the field to grow . In a study conducted by Northstar Research Partners Ltd on behalf of ARM , 61 % of the respondents said that they feel society will
become better due to AI and automation . In the study they also found that currently over half the respondents would trust an autonomous car to drive
their family if accident rates were demonstrably better and 70 % would trust an autonomous car to drive their car by 2027 . In June 2016 , Weber Shandwick
and KRC Research surveyed 2,100 consumers online in five global markets -LRB- the U.S. , Canada , the UK , China , and Brazil -RRB- on their feelings about AI . In
their study they found that 52 % of the respondents said AI will have a positive impact on their lives . In the same study they found that two-thirds
or more said they would trust AI with handling medication reminders , travel directions , entertainment , targeted news , and manual labor and mechanics
and more than 50 % of respondents trust AI to provide elder care , health advice , financial guidance , and social media content creation . The results of
both these studies shows that even though not everyone is aware of the intricacies of AI , the public perception of AI is positive and not heavily
influenced by the portrayal of AI in movies .

Another aspect of the study that I want to challenge is the suggestion that if all layers of government gain technical expertise in AI , they will be able
to make decisions regarding the regulation of AI . Firstly , I feel that it would not be feasible for all layers of the government to gain the level of
technical expertise in AI which would be required to make appropriate decisions regarding regulation of AI . Secondly , politicians in the government might
curb the growth of AI technologies simply because a specific application of AI might hurt their political agenda . The field of AI is growing rapidly and
it would be impossible for all layers of the government to stay up to date with the current research in AI . I feel that the appropriate way to make
decisions regarding regulation of AI is to appoint a team composed of experts in AI from different fields to have the final say on all AI related regulation .
The team should ideally have a balance of experts that support tough regulation of AI such as Elon Musk as well as experts that feel AI should not be heavily
regulated . I feel that only such a group of experts would be able to make decisions regarding AI regulation which would be beneficial for the society .
After reading the Stanford One Hundred Year Study on Artificial Intelligence , I felt like the Artificial Intelligence is one of the most powerful science that can most profound influence on human society science right now and developing AI should be treated more than a science but an ethics study . In addition , there are two aspects I want to challenge : one is work positions ; another is AI policy . If we do not handle these issues appropriately , AI could be the last scientific area that human ever explore .
There is no doubt that Al can be benefit for human-being more than 8 areas -LRB- transportation ; service robots ; healthcare ; education ; low-resource communities ; public safety and security ; employment and workplace ; and entertainment -RRB- that the report mentioned . However , with the help of AI , many human working positions in those areas might be replaced by computers or robots ; because machines can do the same work cheaper , quicker and even better . People who originally work those positions become unemployed , which can lead to the group of social instability . They need to raise their family and pay the debt , however , when their work positions are replaced by the machines , they lost financial supports and hope of living ; this can turn normal people to robbers , rappers or even murderers . The world might be chaos then . At this time , we ca n't ask a question like this : what kind of jobs will not be replaced by computer ? I think the answer is the positions filling with creativity and inspiration such as arts and designs . The job positions of less consciousness and creativity participation will most likely to be replace , for example , typists , truck drivers , cashiers . Even if involving complex road conditions determining and programming work , with the aid of computational efficiency is greatly higher than that of the human brain to complete the robot . Because computers are extremely good at computation , they are fast and precise . The reason why people will think about this questions is they felt threatened . And this is what AI developers should consider more .
The article also mentions that people could use AI technologies to do the bad things as well . And there are many debates about implementation of AI laws or ethics , because if everyone has this super power to benefit themselves , this world will be a mess . The laws should set out standards , procedures and principles that everyone must be followed to keep orderly . But how do we force the AI to follow those laws if they are intelligent enough to make decision s or their moral standard might not align with humans ' ? A more complex question is that should we merely consider human 's benefits and rights but not the AI robots ? If the AI is trained to think and act or even emotions like human , should we suppose to treat AI as human ? And by then human already abandon their professional or fundamental skills , so how should we prevent the AI be a thinker ? How should we stop AI destroy the human-being with their more powerful body ? Can we still rule them by that time ? Therefore , there are lots of more discussions needed for future AI development . We really should think more about the ethics issues and how to control them than giving them more and more power . With the development of technology , we also need to improve our cognitive thoughts .

The 100-year study on artificial intelligence made countless eye-opening insights about the progress of artificial intelligence in the past , and where the field is heading . The section considering how AI is affecting education makes many clever points including the ideas that AI will enable instructors to multiply the size of their classrooms , can enhance education by providing personalization at scale , and will allow for a blended online and in-classroom experience . With that being said , it seems as though the report fails to acknowledge one of the main reasons that sophisticated use of AI technologies in education systems around the world is not as prevalent as it could be , which is that many education professionals are skeptical , and even scared of what AI might do to their jobs .
The authors choose to explain the absence of AI in schools using two other factors , that may not be the true cause . The report states , The current absence of sophisticated use of AI technologies in schools , colleges , and universities may be explained by the lack of financial resources as well as the lack of data establishing the technologies effectiveness . The article did recognize that formal education will not disappear . Although when attempting to explain the absence of AI technologies in schools today , it should be acknowledged that education policy makers , and education professionals might not be open to bringing in these technologies if they fear that their jobs might be taken , that they won t be able to engage in parts of their jobs that they love , or that the public appreciation for their professions could lessen . So , the thought that AI is currently absent in schools due to lack of funding may not be the true cause . Rather , a main reason it is absent in schools is because education professionals may be skeptical of it , even if the funding is there . To be clear , it is certainly suitable to say that a lack of financial resources and data can be to blame for AI not having a larger presence in education systems everywhere , but it should not be overlooked that there are many human aspects to teaching that can not be copied by simulating intelligence artificially . In particular , teachers need to think creatively in situations , especially with young students , where by-the-book teaching is not working effectively . Elementary school teachers are relied on to build personal relationships with their students , and to understand where kids are coming from in any given situation through a shared human experience . Moreover , humans are conscious , and they will always be able to identify with other humans on an emotional level where robots lack . It is for these reasons that education policy makers and professionals might be skeptical about adopting new AI technologies in schools , even if they have sufficient funding to do so .
In turn , it is unreasonable to attribute the absence of advanced AI technologies in schools mainly to a lack of data and financial resources . The reasons mentioned above shine light on how education professionals and policy makers , especially those who are less informed about AI , might be reluctant to funding new AI software in schools , even when it might be in the best interest for a student s learning , and the school s financial state . To conclude , the 100-year study on artificial intelligence may not be attributing the absence of AI in schools for the right reasons . It is the skepticism of those who are making the decisions to bring AI software into schools that may be behind the lack of funding , and driving the absence of AI in schools and universities everywhere .
CS 540 .
Homework - 1
Word Count - 582


This essay will be challenging the Stanford One Hundred Year Study on Artificial Intelligence 's view on AI in employment and workplace . While the study claims that AI will have a profound impact on employment and the workplace , it tries to give a positive outlook on the impact that AI will have on jobs in the future . A major point the study tries to make is `` AI will likely replace tasks rather than jobs in the near term , and will also create new kinds of jobs . But the new jobs that will emerge are harder to imagine in advance than the existing jobs that will likely be lost '' -LRB- `` Artificial Intelligence And Life in 2030 '' , September 2016 -RRB- . This is a general statement and might not necessarily apply in the real world . In the present world there are many specific tasks that are still being performed by humans , and as soon as AI learns to do such tasks there will no longer be a need for a human in that job . The automation of toll gates in some highways is a suitable example - five to ten years ago many highways in the US had manned toll gates , the people working at such toll gates had specific tasks -LRB- to collect toll -RRB- . As soon as the process got automated -LRB- sensors on highways to detect usage of cars -RRB- there was no longer a need for people at toll gates . Thus , once the task of collecting toll got automated , there was a direct impact on the jobs that involved performing those tasks . Similarly , in the real world once a task gets automated there will no longer be jobs corresponding to such tasks . Therefore , while the essay claims that AI will replace tasks rather than jobs , there is ample evidence that automation of tasks will likely lead to the loss of jobs involving such tasks .

In addition , the study claims that the new jobs that will be created are harder to imagine in advance than the existing jobs that will be lost . This is a very optimistic way of looking at the scenario . Many eminent individuals in the industry think otherwise , the jobs that might be created by AI are likely to be few compared to the jobs that AI will replace . Elon Musk for example , believes that the job disruption caused by AI is one of the scariest problems that we might face in the future . Also while the study claims that there will be some jobs that will be created by AI , such jobs might be extremely few and might also be applicable to only some elite few . Another point that the study states is `` Changes in employment usually happens gradually , often without a sharp transition , a trend likely to continue as AI slowly moves into the workplace '' -LRB- `` Artificial Intelligence And Life in 2030 '' , September 2016 -RRB- this is also something that many experts in the field disagree with . As AI develops expertise in certain areas or fields , most jobs in such sectors might be automated . Such a shift is not likely to happen gradually but is likely to cause a disruption in the respective sectors . For example , once self driving cars become a reality , the jobs of ` drivers ' and ` chauffeurs ' will be replaced very quickly . This is because in a capitalist economy most private cooperations look to make profits and therefore might not hesitate to layoff massive amounts of workers in short periods of time , once their job can be done by AI or computers .

In recent years , Artificial Intelligence -LRB- AI -RRB- has become such a hot topic that anybody even with the minimum interest in technology industry seems should have heard about it at least once in their life . It is true that AI is increasingly becoming prevalent in our society , and more substantial usage of it is expected in the future . According to the article `` Stanford One Hundred Year of Study on Artificial Intelligence '' , AI would not involve into dreadful threat to our life but rather serves for human good in longer term . I have no intent to negate such aspect , depicting horrifying Hollywood-like scenarios of AI completely taking over the role of human . Neither do I want to challenge the private security in AI technology , since in my own perspective such problem could be adequately solved , as solid policies are implemented accompanied with AI 's development itself . What this essay going to challenge is rather a nuance problem relatively ignored in the article : the inequality that AI would bring to overall human society . Since it is quiet broad topic , I would mainly focus on discussing about education domain .

One assumption underlying my argument is that almost every technological improvement has made our world be more and more polarized . It is to say , while the advent of fancy technologies undoubtedly provides millions of people convenience in their life , it also drags certain groups of people who are unable to get access of those technologies into a disadvantaged position . In other words , our current technologies are paradoxical in their existences that while they make more and more people feel closer , they also automatically get certain people segregated , and the two tails are getting more and more remoted as technologies getting advanced . Same situation happens on AI as well . In education domain , the study panel are expecting to see AI provides more personalized education to each student , since the emergence of massive scale of online courses guaranteed ample data sets to be collected . However , the question is to what extent are those online resources prevailed in various areas ? And in turn how much would those personalized education courses fit to students if they are out of consideration even at the beginning when those AI algorithms are invented ?

To be more specific , in the article , it says online resources would offer people opportunities for better education in the area where the broad population are facing difficulty to get education . Note the article also points out that this could happen only when the population have the tools to access those resources . But what is the possibility that people can get tools for online courses if a wild range of population are even hard to obtain fundamental education ? Admittedly , there exist several areas like mid-west America where students find it more suitable for homeschooling , and online courses advanced by AI algorithms would benefit them without doubt , since AI enables teaching to be more personalized to its target . However , in most of the cases , people unable to get education are less likely to even get in touch with such online resources . Not to mention personalized education developed by AI , in some remote rural area of China , where internet is not even guaranteed , local governments are struggling to provide children with most fundamental education infrastructures . Students in such areas hardly know about iPad , which currently a lot of education apps are developed based on it . The major concern is , before those children even get access to the online education , they have already been excluded by training data sets for AI development . If this is the case , how can people claim AI enhanced education by providing more specialized schooling ?
AI is clearly an ever-expanding field of interest . Today the use of AI is being used ever more widely for
public safety and security by certain countries respective police and military forces . The points I will challenge
is the general direction AI will be used in this area of society presented in this article as well as the statement
that AI gaining public trust is crucial .
The article narrowly focuses on the use of AI as a more data analysis tool for security forces . This will
only be a small part to the collage of applications that will capitalize on AI . For example , a couple of months ago
the US military finished testing swarm drones . The test had about one-hundred small drones released from a fighter
jet to then converge on a moving target . The test was successful . AI enabled all the drones to communicate and plan a
route towards the target . Today , if desired , the drones could be given explosives to destroy enemy forces whether they
be a systems or people . AI systems are also being tested to be able to search for enemy forces with land vehicles on
enemy soil . In the end , these systems could make the killing of warfare even more efficient . Yes , these systems will
be able to crunch more data than a human to possibly save lives , but other systems also utilizing AI will be able to
take the air , ground and sea to take lives at the same time .
Therefore , trusting these systems will not be so straight forward . There may be respect at times for these
powerful tools , but there will always be some fear due to the power they can wield under the right hands . There is an
even further danger in the possibility of certain wealthy individuals procuring many of these weaponized AI systems to
create a substantial army to wield at his or her own discretion . This will help deteriorate public trust while adding
to the publics fears . These private drone armies of course will not be an issue in stable regions where there are
strong and united armies preventing the rise of these fractions , but in places of conflict , this will create even more
danger . Warlords could produce more death and destruction with these more advanced tools . ISIS is already using drones
to strike some of their targets , but thankfully these drones have no AI to assist them . People will adapt to the
conditions present with both the positive and negative possibilities looming . Society should not grow to blindly trust
these devices , but rather respect these devices for whatever power AI can enable .
The future of this technology is unknown , but the possibilities are expansive , both for good and for bad .
Realistically any prediction about the future of AI will not be precise , but the prediction can help plan for certain
possibilities . The public will have to grow to respect this technology for both its beneficial services that can be
provided as mentioned in the article , as well as the possible negative outcomes that may be produced which is not
mentioned in the article . The Stanford One Hundred Year Study on Artificial Intelligence 's greatest failing is the omission of a discussion on the effect of AI on war waged by North American governments . The risk of new smarter machines making government more dangerous , immoral , and undemocratic is too large a menace to be left out of any comprehensive analysis of artificial intelligence . The most critical example of this danger is the use of unpiloted `` drones '' to carry out surveillance and assassinations in the War on Terror . This essay will briefly cover the current state of the drone warfare and its impacts , followed by a recommendation about how the One Hundred Year Study should address this issue in the future .
One of the most startling trends in modern warfare of the last ten years in the increased use of unpiloted flying machines known as drones . Indeed President Obama , not known to be especially militant , carried out ten times more drone strikes than his predecessor -LRB- Obama 's covert drone war in numbers : ten times more strikes than Bush , The Bureau of Investigative Journalism , 1/17/17 https://www.thebureauinvestigates.com/stories/2017-01-17/obamas-covert-drone-war-in-numbers-ten-times-more-strikes-than-bush , Accessed 9/13/17 -RRB- . These drones strikes , primarily used in countries where the United States was not officially at war , has caused the deaths of hundreds of civilians -LRB- ibid -RRB- . Thus drones are not only used at increasing rates , but to deadly effect . On top of the ease that drones can be used for physical violence , what is especially dangerous is the way they can change the political calculus of war . Thus American politicians are now able wage war with all its horrors -LRB- murder , destruction , and terror -RRB- without one of its primary political costs -LRB- dead American soldiers -RRB- -LRB- The History of Drone Warfare , The Bureau of Investigative Journalism , https://www.thebureauinvestigates.com/explainers/history-of-drone-warfare , Accessed 9/13/17 -RRB- . How could this not lead to the proliferation of violence abroad ? What will the future hold as more sophistical drones are developed : machines that are able to fight and kill , without the input of a human conscience ? These are the type of questions the One Hundred Year Study should be addressing .
In order to raise awareness of the growing threat that military drones pose , the authors of the One Hundred Year Study should put ethical use of military AI front and center in its report . Their analysis should include a review of current practices of AI on the battlefield , the costs and benefits associated with those uses , and an examination of future trends , including risks to human rights and democracy .
The Stanford One Hundred Year Study on Artificial Intelligence does a fine job summarizing the commercial , consumer and research impacts of trends in the field of artificial intelligence . However simply stating that `` ... military applications were deemed to be outside the scope of this initial report '' -LRB- p. 3 -RRB- is unconvincing . And failing engage with the emerging use of AI and robots by North American governments to wage war is unconscionable . This revolution on the battlefield has direct consequences not only for the unlucky individuals who happen to inhabit Somalia , Pakistan or Yemen but for the politicians who wage these wars and for the public which consents to them . In other words , the very citizens of North American cities upon whom the report sets its focus.The Stanford One Hundred Year Study on Artificial Intelligence makes bold assertions about the influence of Artificial Intelligence -LRB- AI -RRB- on many aspects of society . One of these areas is that of transportation . AI has already become very widely used in transportation even today . Many current models of cars have features such as a lane departure warning system , adaptive cruise control , or blind spot monitoring . The study postulates that over the next 15 years , self-driving vehicles will become incredibly commonplace . So much so , that traffic jams will no longer exist and no one will have trouble finding parking . It also says that AI-controlled trucks , flying vehicles , and personal robots will be traveling around most North American cities by 2030 . While all of these possibilities will most likely come to pass at some point in the future , it is very unrealistic to propose such a dramatic overhaul of urban transportation within the next 15 years .

There are two main reasons why these changes are not likely to be affected within the next 15 years : the cost can be prohibitive , and some people are reluctant to accept new technology .

At this point in time , a semi-autonomous car is very expensive . Tesla has announced that it plans to sell a more affordable car with some semi-autonomous features . Other companies will follow suit . It is obvious that self-driving cars will eventually be somewhat affordable , but still not for years to come . Even once they are affordable , not everyone will immediately upgrade . Most people will continue to use their current cars for quite a while , and only after will they buy an autonomous car . This is especially true for companies with fleets of vehicles , such as taxi companies , trucking companies , or other delivery services . Having invested a significant amount of money in their vehicles , they will want to use them for as long as possible before replacing them with autonomous vehicles . Therefore , even after autonomous cars become more affordable several years from now , there will still be a delay before people and companies switch over . This makes the 15-year estimate seem unlikely .

In addition to the prohibitive nature of the cost of autonomous vehicles , another impediment to their adoption will be humans reluctance to change . There are still many people driving private vehicles or running transportation services who grew up without being exposed to Artificial Intelligence , and are distrustful or wary of it . These people will actively resist the transition to autonomous vehicles . Many key regulators also are uninformed on the subject of AI . They could also potentially slow down the transition to autonomy with regulation . In order to work around this element of fear regarding AI , these people will either need to be educated about AI , or adoption will have to wait until they have been replaced by a younger generation , more accustomed to and less fearful of AI .

Because of these reasons , it is likely that we must wait more than 15 years to see a world where roads are so heavily populated by autonomous vehicles that traffic jams and parking struggles are eliminated , and regulations are loose enough that Artificially Intelligent drones and robots can roam our cities .
The Stanford One Hundred Year Study on artificial intelligence by and large does an excellent job of articulating what the current and future roles of AI look like in our society . It explores what technologies have been instrumental in accelerating growth in the field and what barriers exist to gain full integration in the real world . There is , however , one main issue with the study : it fails to mention the financial sector among the eight domains with the potential to be most significantly revolutionized by artificial intelligence .

While it may seem like a stretch to argue that leaving out the financial sector is truly a major issue with this study , the panel 's attempt to comprehensively evaluate the future of AI falls flat without , at the very least , an acknowledgement of the game-changing potential of large-scale machine learning applications in financial markets . This snub indicates that the panel did not believe AI to be nearly as impactful in global/domestic finance as the other areas , such as education for example , which is an extremely narrow-minded perspective . At the center of AI development in the financial sector are quants , or quantitative analysts , who specialize in applying statistical methods to financial problems . The presence of quants on Wall St has exploded , particularly in the last five years . In 2013 , they were responsible for about 14 % of all US stock trades , that figure is now up to 27 % in 2017 . For reference , trades made by individual investors account for approximately 29 % of all trading volume . Not only has the quantity of quant-based trades increased , the quality has as well . Over the past five years , quant-focused hedge funds gained about 5.1 % a year on average , while the average hedge fund rose 4.3 % during the same time period .

The true future of financial artificial intelligence , however , lies in machine learning which will eventually enable computers to develop their own predictive algorithms for the market without reliance on human support . This technology would be incredibly disruptive in the financial sector and has the potential to structurally alter the way we trade/invest . AI research and development in finance is supported heavily by ample funding and access to massive amounts of useful data . Funding for finance-focused artificial intelligence ventures are plentiful due to the high potential for value creation and the nature of the industry . More importantly perhaps , the financial sector creates and logs an enormous amount of data every day . Much of this data is accessible and complete making it optimal for use in training large-scale machine learning algorithms . The main factor inhibiting AI from being even more present in modern-day financial markets is its technical limitations . The fact is , current-day machine learning is still not at a point , from both a development perspective and an effectiveness perspective , that it could truly start to be the dominant form of stock trading in the US . However , based on the field 's exponential growth , that may not necessarily be the case five years from now .

In conclusion , the One Hundred Year Study panel 's decision to not include the financial sector as one of the eight main areas revolutionized by AI is a significant flaw in the study . This is based on the sheer magnitude of the opportunity to disrupt an institution as fundamental as the US stock market and the potential socioeconomic impacts that could come along with it . The One Hundred Year Study on Artificial Intelligence considers a realistic model of how the development of Artificial Intelligence will affect the world in regular units of time . The 2015 Study , released one year ago , therefore attempts to predict the advances of AI between now and the year 2030 . The article is thorough and realistic , critiquing alarmist predictions and instead basing its forecasts on current trends . As such , any flaws in the article are not easily forthcoming , as the authors had both more experience and more data than available to the average student . Particularly interesting , however , is the article s prediction regarding a transportation renovation .
The Study notes extreme advances in navigation technology , best seen in the incredibly popular Google Maps app on smartphones . Google Maps has recently acquired the ability to react to developing traffic situations , rerouting dozens of cars in real time to avoid traffic on major roads . The Study also notes a massive increase in cars capable of performing autonomous tasks , and even several prototype self-driving cars . Because of these , and because deep-learning techniques that respond to massive amounts of data have proven so successful , the 2015 Study predicts that Self-Driving cars will be common by the year 2030 .
This prediction is hard to argue with , but one weak element does stand out . The Study worries about Societal Reactions to Self-Driving Cars , especially Who is to Blame in collisions . In particular , it cautions that society might delay a very beneficial transition to self-driving technology out of lack of trust for AI . I suspect that the very opposite will happen . A self-driving car has every potential to be safer than a human driver . With faster reaction time , the ability to communicate instantly with other nearby self-driving cars , the potential for city-wide coordination , and many other benefits , the trustworthiness of AI drivers will soon be undeniable . The few flaws in AI driving are also easily corrected by the massive development and improvement of the field . For example , the collision of the Tesla Car in June 2016 was the result of a sensor not distinguishing between a section of road and an oddly colored truck ; this is easily remedied .
And so my prediction is that , far from society reacting to AI driving cars with mistrust , the development of AI drivers will instead make human drivers not only obsolete but also illegal . Human drivers lack the ability to coordinate at the speeds which will become possible for self-driving cars , are much more easily distracted , and can enter states of fatigue , drunkenness , or road rage . AI also can sense in all directions at once , and can process many more types of data than humans can . Most collisions with even existing Google Self-Driving cars , for instance , are the result of human error , not AI error . The AI will become only more reliable as technology increases .
I believe that the 2015 Study is exactly correct in predicting that self-driving cars will renovate the urban landscape in a great variety of ways . But while the study is concerned about human society and governments slowing this process , I think that the safety and capabilities of self-driving AI will result in hastening the process instead . By the year 2030 , I easily can predict a world where a driving license requires an almost prohibitively difficult set of abilities and human drivers are actively discouraged by government and society .
In most cases , `` Artificial Intelligence and Life in 2030 '' approaches societal changes that may result
in North American cities from the advancement of artificial intelligence with little runaway speculation and
few outlandish assertions . However , there are several instances of speculation on the past and future effects
of artificial intelligence on entertainment media that stick out as a departure from the survey 's usual level-headedness .
Additionally , in the final policy proposals , the survey does not go far enough in demanding accountability for civil AI systems .


`` Artificial Intelligence and Life in 2030 '' makes the the following
remark regarding the possible effects of the proliferation of digital entertainment
on human social interaction : `` The enthusiasm with which humans have responded to
AI-driven entertainment has been surprising and led to concerns that it reduces
interpersonal interaction among human beings '' -LRB- Stone 40 -RRB- . `` Artificial Intelligence and Life in 2030 ''
does not directly assert here that it agrees with this view 's proponents , but goes on to state : `` Few predicted that
people would spend hours on end interacting with a display '' -LRB- Stone 40 -RRB- . This comes across as an overstatement of the
role AI played in the initial adoption digital media . Widespread adoption of digital media existed long
before AI techniques were meaningfully applied to digital entertainment , and AI remains restricted to limited roles .
The question of how digital media consumption affects social interaction is not so much a question of AI 's
specific effect , but a question of how the quality of digital media affects individuals selection between
social and nonsocial activities . AI is only relevant in the sense that it may affect the quality and
availability of digital media . It has not been shown that artificially intelligent systems are capable of
providing a meaningful and complete surrogate to human socialization . Additionally , interacting with digital systems for entertainment or leisure is often
a social activity , and AI applied to the realm of affective computing may actually increase the fidelity with which emotional
intent is transmitted to other individuals . This may increase the quality and availability of social experiences ,
rather than detracting from them .


While the second policy goal , outlined in `` Artificial Intelligence and Life in 2030 '' , provides an elegant starting
point to ensure artificial intelligence has a positive and fair impact on society in both the public and private sectors ,
it fails to deliver an explicit standard of transparency for public sector AI . This could be rectified by extending the second policy
goal to suggest that all intelligent systems used in governmental non-military applications are required to be open-sourced to the public .
This could help to protect against hidden biases in applications such as classification and prediction systems that make decisions directly
affecting individuals , based on information about the individuals . Applications where transparency is critical include
conviction , sentencing , and financial aid allocation . A open decision making system is a vital part of the
democratic process , and remains so even when such decisions are made by non-sentient intelligent systems .


Works Cited


1 . Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg ,
Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee
Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . ''
One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University ,
Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 . CS540
Homework 1
Healthcare and AI

The authors of the Stanford study have a rather optimistic outlook for AI in the
next fifteen years . Indeed there are many reasons to be optimistic about the future of AI .
The incredible pace at which computer science is progressing coupled with the ever
increasing prevalence of sources of data leaves potential for AI to make a serious impact
on society . Nonetheless , there many reasons to be cautious when make predictions about
AI 's impact over the coming years . In particular , one should be cautious with making
predictions about AI and healthcare , where there a serious obstacles posed by data
gathering , regulation , and security . Ultimately , AI will continue to have an impact on
society and healthcare but the authors of the Stanford Report are far too optimistic about
AI 's potential in healthcare currently .

The first practical obstacle for AI in healthcare is the massive amount of data
collection that would be required for any sort of system to be useful . This issue is
addressed in the report when the authors mention that healthcare software is often
substandard and dated -LRB- Stone et al. 26 -RRB- . These are certainly valid points , however it is
far from the only problems with data collection . Healthcare software is implemented in a
variety of programming languages , which means streamlining data to a central AI system is
no small task . Furthermore , although there are standardized codes for ICD-9 and ICD-10 ,
not all software uses them -LRB- Paulsen -RRB- . Beyond this , there is the vast amount of information
that is currently stored in patient records as unstructured text . The natural language
processing needed to use this data is extremely complex and to be useful would need to be
extremely accurate to make this a viable data source .

Even if there was infrastructure to make such data collection possible , there is
still strict regulation of EHRs currently in place by HIPAA and healthcare privacy laws .
This is also addressed by the authors to which they propose can be solved with policy
change -LRB- Stone et al. 25 -RRB- . This too seems far too optimistic , as legislation lags behind
technology more frequently than not . Making the changes which would allow for mass data
collection in the next 15 years would be a serious challenge .

Finally , perhaps the most problematic aspect of their predictions and proposals is
security . Integrating massive amounts of medical data would require creating a huge
network which would be incredibly difficult to secure . Although not frequent , even some of
the most well designed and secured networks get hacked -LRB- the NSA for example , which lead to
`` WannaCry '' ransomware -LRB- Anderson -RRB- -RRB- . To assume that this network would be invulnerable to
attacks is completely unrealistic . Moreover , the consequences of this network being
breached could be devastating to healthcare infrastructure .

In light of the obstacles which are present in implementing the use of AI in
healthcare , it is quite clear that the authors of the Stanford Study are overly optimistic
about the next fifteen years . The problems mentioned above are but a small subset of
obstacles which need to be overcome in order to effectively use AI in healthcare data
integration . Egro , while not impossible , we are still a long way off from seeing wide
spread use of AI in healthcare data .


Works Cited

Anderson , Ross . `` Bad malware , worse reporting . '' Light Blue Touchpaper , University of
Cambridge , May 13 , 2017 , www.lightbluetouchpaper.org/2017/05/13/bad-malware-worse -
reporting / . Accessed September 10 2017 .

2017 . Paulsen , Derek M , and Jeff . `` Optum Informational Interview . ''
21 Aug. 2017 .

Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni ,
Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit
Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie
Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in
2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the
2015-2016 Study Panel , Stanford University , Stanford , CA , September
2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 8 , 2017 .
The Stanford One Hundred Year Study prioritizes topics including the advancement of research and economic concerns over the health and well being of people in the discussion of societal affairs that must be addressed before artificial intelligence advances and integrates further into society . While these two topics must be discussed and debated as AI progresses , it should be obvious that the effects of AI on the health and lifespan of humans should be the number one thing to be carefully deliberated , as human lives are a fragile and delicate matter , both literally and figuratively .
The study discusses the impacts of AI in the healthcare analytics realm . It states `` If regulators -LRB- principally the FDA -RRB- recognize that effective post-marketing reporting is a dependable hedge against some safety risks , faster initial approval of new treatments and interventions may become possible '' -LRB- 27 -RRB- , a statement that is problematic . The study panel seems to imply that regulators should consider the benefits of predictive analytics research over human health and safety . While this type of research is certainly beneficial , no research is worth a loss in the quality of life . Human lives are not something to be played with so carelessly in an effort to advance research .
The study talks about the water crisis in Flint , Michigan later in the article -LRB- 35 -RRB- and points out that predictive models are currently being put in place to assist children at risk of lead poisoning . The study panel 's concern for human safety with the water crisis is directly contradicting their views on the regulation of potentially harmful software . To remain in alignment with the their views on Flint , they should want regulation of the AI software to be rigorous in order to prevent another crisis of human health and safety from occurring .
Their laissez-faire attitude on human safety continues with their views on the value of emerging healthcare imaging software . The study states , `` Even with state-of-the-art technologies , a radiologist will still likely have to look at the images , so the value proposition is not yet compelling '' -LRB- 27 -RRB- . The study panel believes that going through two steps , both important in the accurate diagnoses of patients , is an economical waste of time , and thereby , lacking value .
This statement is puzzling in two ways . First , the authors are prioritizing the economic value of a technology over the human verification that many AI technologies simply require in order to uphold medical safety standards . Second , they iterate several times throughout the article that AI technology is used most advantageously in complement with human skills . Expressing that the work of a radiologist in pair with AI software is not valuable is hypocritical to their opinions in the rest of the study .
I agree with the study panel in their worry that artificial intelligence research will create privacy issues , and may even create issues of racial bias and micro aggressions . Nonetheless , it is perplexing to me why the authors care a great deal about the social issues AI technology may perpetuate but not the biological issues it may cause if we prioritize research and economic gain over health and safety . There are some risks not worth taking .

Bibliography : 2015 Study Panel . `` Artificial Intelligence and Life in 2030 . '' Stanford 's One Hundred Year Study of Artificial Intelligence , Sept. 2016 , pp. 1 -- 52 . CS 540
HW1
Jon Ide


The Stanford One Hundred Year Study on Artificial Intelligence report of September 2016 correctly identifies autonomous vehicles as an AI technology likely to enjoy rapid near-term development and adoption . There are , however , a number of probable unintended consequences and side-effects of that technology that the study fails adequately to address . While development and implementation of the technology itself will almost certainly proceed smoothly and rapidly , its adoption will also cause very significant social turbulence , especially in view of the rapidity with which the changes will occur . The technical problems are easily solved ; the societal ones perhaps not .

For example , one of the first applications of autonomous vehicles will be for long-haul trucking via interstate highways , since such highways present an enormously simplified environment compared to city driving . In addition , interstate trucking is an application where the economic incentives are substantial , so we can expect adoption to proceed rapidly . Intra-state and intra-city trucking will follow close behind . Currently , according to the American Trucker Association , some 3.5 million Americans make their living driving trucks . -LSB- 1 -RSB- Millions more make their living providing services to human drivers : restaurants , motels , and so on . In the majority of US states , truck driver is actually the most common occupation . -LSB- 2 -RSB- And it is an occupation that pays well , better than most other occupations not requiring a college degree . -LSB- 1 -RSB- Within a generation , perhaps sooner , truck driving as an occupation may largely cease to exist . Millions of people will be hurt . The result may be a political backlash that makes the current red state-blue state divide seem pale in comparison .

The demise of trucking , cab driving , etc. , will cause resentment against the technology itself , at least among those hurt by it . Another possible source of such resentment may arise when autonomous vehicles become available for ride-sharing services like Lyft and Uber . The result is likely to be a desperate race to establish market share since the economic stakes will be enormous . If this leads to a glut , the resulting situation may be akin to the situation with GPS-equipped shared bicycles in Chinese cities recently reported in the New York Times . -LSB- 3 -RSB- According to the Times , more than 16 million such bicycles clog Chinese cities , as more than 70 companies wage a `` fierce battle for market share . '' In Shanghai , there is one shared bicycle for every 16 people . Bikes are abandoned in tangled heaps on sidewalks and roadways . Rickshaw drivers and taxi drivers , upset by the bicycles ' threat to their livelihood , sabotage them . In addition , the Times writes , `` Thieves have taken them by the tens of thousands , for personal use or selling them for parts . Angry and mischievous vandals hang them in trees , bury them in construction sites and throw them into lakes and rivers . '' In the case of Lyft/Uber self-driving cars , there will also be the cars ' inevitable use by some passengers to engage in a variety of activities that leave the car in an unwanted state for the next passenger . How will the Ubers of the future handle this kind of problem ? Perhaps by installing cameras or other sensors to monitor passengers ' behavior , further fueling resentment and motivating sabotage .

In time , the technology will be commonplace , a commodity that seems unremarkable . In the meantime , however , there are likely to be very significant upheavals , and the transition will not be all smooth sailing .

-LSB- 1 -RSB- https://medium.com/basic-income/self-driving-trucks-are-going-to-hit-us-like-a-human-driven-truck-b8507d9c5961
-LSB- 2 -RSB- http://www.npr.org/sections/money/2015/02/05/382664837/map-the-most-common-job-in-every-state
-LSB- 3 -RSB- https://www.nytimes.com/2017/09/02/world/asia/china-beijing-dockless-bike-share.html?mcubz=1

Homework 1
Technology has rapidly developed ever since the Second Industrial Revolution in the 20th century . One of the most astonishing technology that has come out should be the Artificial Intelligence -LRB- AI -RRB- . Although AI may not really mean that computer has intelligence , however , computers now can have the abilities to make the machine learning and to solve problems based on their data base . And AI starts to be used in all kinds of areas in people 's real life now and it is changing people 's life style as well . AI has been used in the transportation , education , medication , and human interaction and communication .

AI has better calculation skills and faster information analyzing skills . All these features that AI has make people 's life more convenient and easier . AI can finish certain dangerous and boring work , rather than needing human capitals to work on these things anymore . However , is AI totally beneficial for human beings ? And should people totally rely on AI ? As AI is widely used in real life , the problems of security , unemployment and ethnics may arouse .

The first problem that may come to people 's mind will probably be security problem . In people 's daily transportations , AI is used as auto-driving , auto-parking and other systems in the cars . It may help people to drive more safely and comfortably . However , what may happen if bad people hack into the computer system in the cars ? It may cause severe disasters . Bad people can do anything like assassinating someone with just looking like a car accident . And when the system breaks down , people still need their own skills to drive rather than totally depending on AI technology . AI is also used as home robots to do the cleaning and serving work at home . Home robots have lots of sensors and hardwares inside . They are collecting all kinds of data in the room for all the time . There will be serious privacy problems if some people plug virus and trojan into the home robots . Then , the housing robots will just become a hidden bug inside house , with monitoring everything and everyone for all the time .

Beside the security problems of using AI in our real life , there will also be the unemployment issues . Although the trend of employment market is changing to technology area , however , the employment in manufacture area is still taking a large portion of the total employment market . If AI gets widely used in the manufacture area and takes the place of human labor force , it will lead to large amount of people losing their job . And due to the lack of college education , these people may not be able to find a job in the technology area easily . It may take quite long time for these people to get employed again . Thus , they have to depend on the government unemployment insurance program , which will put huge stress on the social economy system . It may possibly crash down the society 's economy system and lead to further severe social problems .

The third problem of AI will be ethnics problem . AI will be used in medical area in the future . At that time , AI will be the one that diagnose people 's illness and provide treatment advice . But here is the problem . If AI makes a mistake about diagnosing the illness and provide patient with a wrong treatment , who should be responsible for this ? Although AI can make diagnosis faster than human beings do and sometimes maybe makes more accurate diagnosis , there is still certain risk to let people fully rely on AI for medication . What people should do may possibly be using AI to assist doctor to make the diagnosis and decide the treatment rather than totally letting AI be the one that makes the decision . People still need human doctors to monitor and supervise the AI . And human doctors are the only one who can take responsibilities for their patients rather than AI does .

In conclusion , AI does make people 's life better but it is still necessary for people to depend on their own in life with using AI as an assistant rather than fully depending on AI for living . Otherwise , one day , AI will beat human 's intelligence and human beings will become slaves of AI .
The issues that I found with the One Hundred Year Study On Artificial Intelligence article is that , specifically on the subject of healthcare , it fails to address the topic of limited data sets . On page forty nine , the article says that many advancements in AI come from `` growth and analysis of large data sets enabled by the Internet , advances in sensory technologies '' , and deep learning . What this overlooks is that sensory technologies , no matter how advanced , will only see what we are using them to look for .
Current datasets that can be pulled from health services are limited in many ways . The article specifically mentions how the FDA and HIPPA are barriers to accessing data , but a much more dangerous one is that often times , the data will not exist . Due to the precise nature of medicine , when the article says that there is an extensive record of patient scans , it means very little . In medicine , unlike web-browsing , only the minimum that is thought to be necessary is done . Doctors simply can not ethically or practically take note of the entire state of being that their patient is in . In the case of cancer that is mentioned in the article , we only have what we already know causes cancer in the scans . This means that we have very specific images of very targeted areas that a specific doctor asked for , there is n't a full workup , including unrelated statistics , of each patient who comes in for cancer treatment . For all we know , oils in the hair or something else seemingly unrelated to cancer could be beneficial to AI testing for cancer , but that data simply does not exist as doctors can not make use of it and so it is n't collected .
This is a limitation that is unique to the medical field . When programming a driverless car , you can attach as many cameras as you think is necessary to achieve the goal of `` not crashing '' . This creates an absolute wealth of information from which to build and with which to decide how to move forward . In medicine , the information that you can gather is limited by the patient and by the doctors gathering the information . Fortunately , when looking at more granular AI this becomes less of an issue .
In the article there is no mention of this human constraint to AI where it becomes limited not by what it can be trained to do , but by what humans have already discovered . Yes it will be able to increase the rate of correct diagnoses in patients , but it will not be able to take that next step and improve .
One other issue is when dealing with health AI is that many issues present themselves indistinguishably from each other . The hope of having an AI in a mobile app that can help with preventative measures is flawed . There are not ways of measuring human physiology in a precise enough manner to be useful . Unless the mobile app will have the authority to order more tests move people to a hospital to get said tests , it will be unable to collect the data necessary to have a meaningful impact on the lives of its users making it commercially inviable . Ultimately this article fails to deal with the issue of non-existent data in medical and that the cost of obtaining it is likely to be more prohibitive than legal barriers . Artificial Intelligence will continue to grow in its influence of our everyday lives . The Stanford 100 Year Study certainly supports this and shares both current and predicted trends for Artificial Intelligence as it relates to eight key domains . While the writers certainly report truthfully about current happenings with AI , the projections they make for the AI 's future are to be scrutinized and challenged .
One of the domains the writers discuss is AI 's roles in employment and the workplace . The writers claim that as AI takes the place of human labor , the cost of goods and services will go down , `` effectively making everyone richer '' -LRB- pg . 39 -RRB- . This statement is not completely invalid . Certainly a computer can be employed at far less the cost of a real human . However , as AI continues to develop in the coming decades , we must remember that there will still be humans behind the computers ' work . AI research and development certainly comes at a cost , and it 's a steep one at that as those qualified in the field make higher wages than the blue collar laborers their work will replace . This cost will certainly be factored into the price of the goods AI produces potentially keeping them at or above their current cost . Hopefully , as time goes on , AI will be more self-sustained and the initial cost of development will factor less into the price of goods and services . A study done by the Economic Policy Institute shows that while productivity increased by 80.4 % from 1973 to 2011 , the median compensation for workers has only increased by 10.7 % . Therefore , it is unlikely that everyone will be made richer as a result of the initial replacement of human labor . Workers replaced by AI will certainly become poorer while those developing AI technologies will reap the true reward .
Another section of the paper discusses AI 's impact on education . The writers propose that AI will continue to `` blur the line between formal , classroom education and self-paced , individual learning '' -LRB- pg . 34 -RRB- . Rather than blur the line between the classroom and individual , it is more likely that the two will become more contrasted . Students are already able to take online courses with little human interaction . These courses provide certificates which are accepted by a multitude of employers . I predict that a greater divide will separate classroom-taught and self-taught individuals . As tuition costs increase , lower income students will study online while higher income students will continue to study in the classroom , an activity which will hold a new kind of social status . In addition , as NPR points out , in a world where computers are taking more and more jobs , it is no longer as beneficial for humans to `` memorize facts and figures , or simple rules for problem solving . '' Rather we 'll be faced with a push to learn more difficult tasks that AI may not be prepared to teach thus keeping a demand for classroom instruction .
There is great change in store for the future as AI takes center stage , both positively and negatively , in our lives . It 's important that one stays current on AI affairs so he can properly engage in this ever changing field .


The article goes into detail on the prediction that by 2030 autonomous beings -LRB- AI robots/appliances -RRB- becoming heavily intertwined in human society . It mentions the possible functions of robots in different domains ; transportation , healthcare , homecare to name a few .
I agree that AI will play a much greater part in society by the year 2030 , for example the possible shift to all forms of transportation becoming autonomous . I however disagree regarding robots taking active positions in more privacy sensitive domains , such as healthcare , education , and even homecare .

The thought of a personal robotic maid or a robotic clinical assistant is very interesting , however , as mentioned in the article , these advances are hindered by traditional ideals and fear of change . I believe that by the year 2030 we may possess the technology required for developing and deploying these sorts of robots but we will not have the mindset to do so .
AI will take a more subdued approach to integrating with society , such as self-driving cars , autonomous thermostats , and smart appliances .

A reason for this , I think , will be jobs . If robots took a more active role in society , many jobs would be lost and unemployment rates would increase significantly . Currency has been around for about 1000 years and 100 years will not be enough to develop a financial system around the takeover of so many jobs by autonomous beings .

In addition , humans are , in my opinion , very traditional and enjoy interacting with other humans . This emotional factor would need to be replicated by the robots , especially the ones in healthcare and education , for the switch to AI to be possible . And even with robots capable of emotions , people would be skeptical and prefer actual human contact .

The biggest issue surrounding the future of AI is the fact that these systems are not actually intelligent on their own . Implementing AI requires enormous amounts of data which is used to essentially train systems to function as intended ; machine learning .
For many of the outlined uses for AI , to train the machines to function properly , society would have to give up personal and possibly sensitive data .

In industries such as healthcare , a doctor is responsible for maintaining a patient s privacy and secrets . While a robot will surely be able to do the same , no matter how many security measures , a robot or database will always be able to be hacked ; leaking of personal information and invasion of privacy .
AI systems in financial institutions are under the same concerns as possible breaches would be devastating .
These possible information leaks are threats today , however with the massive amount of data required by AI to function properly , one leak could end up exposing a person s entire life to the public . The process of obtaining the data itself would be an issue as well . The concept of privacy could disappear entirely with cameras and sensors everywhere to monitor and record data .

The movement towards AI systems is going to happen . Many of the possibilities outlined by the study , however , will not be implemented in the next 100 years . The sheer amount of data that would be required to train such systems to function properly along with the loss of privacy and security concerns regarding the data will make it very difficult for AI to progress at such a fast pace .
2016 's edition of Stanford 's One Hundred Year Study on Artificial Intelligence -LRB- AI -RRB- highlights the field of Artificial Intelligence as a whole and evaluates its prospects for the next thirty years . Throughout the paper , the rapid advancements of telecommunication and the internet were mentioned as catalysts for AI 's rapid improvement over the past decades . Only a decade ago , natural language processing and conversational inference were only vague ideas in the minds of computer scientists . Now , simply speaking , `` Hey Siri '' , `` Ok , Google '' , or `` Alexa ... '' prompt responses from all hosts of computing devices ; most of which fit in our pockets . The rapid advancement of this , and many other types of AI technology is exciting and just wets the appetites of AI researchers and consumers . This breakneck speed of AI 's advancement however , should certainly be met with some degree of concern . In Stanford 's One Hundred Year Study of Artificial Intelligence , the researchers recommend removing perceived and actual impediments to research surrounding Artificial Intelligence . Decreased regulation could certainly spur growth in AI , and more advanced AI systems implemented in ways that benefit society would proffer many positive effects . Human nature , however , carries with it inherit biases , and self-interests . Without proper attention during development , many of these more advanced AI systems could fall victim to misuse and corruption .

The paper does a good job of illustrating the many positive impacts that AI could lend towards society as a whole . However , it often only qualifies the many positives with offhanded remarks on it being up to developer implementation . To paraphrase ; the world could have refined robot surgeons , and drone crime prevention surveillance , which could maybe have negatives if developers do something wrong . This qualification is largely understated . The role a developer plays in the creation and molding of computing platforms is enormous . Coupled with a developer being in charge of leading how an AI system learns and interprets the world , and room for human bias to enter increases exponentially . But , as the paper states , given proper attention , this could be avoided . The question that should be raised is that if regulation and oversight were not in the way of AI development , what corners would be cut in the name of progress ? Regulation adds barriers that push researchers and developers to refine their systems to near perfection . Without this mediating factor , more cracks would form , and crucial safety checks could be missed . Wide-spread education surrounding Artificial Intelligence should spur incremental improvements , that gradually push the industry forward . The alternative is a system where human bias and self-interest could creep in and corrupt efforts to solve problems it attempts to address .

Given safe advancement of Artificial Intelligence , there is little need for public concern . Any concern should lie particularly , in proper advancement of pivotal technologies like autonomous driving systems , and medicine . These two in particular highlight the need for safe , responsible development as they involve life and death decisions being made not by a human , but by AI . Instilling proper safety measures are critical to help guide AI in making correct decisions . However , at the end of the day , humans should still have ultimate control over the systems and the functions they provide . There are ultimately some problems AI can not address with absolute certainty , but if AI is developed incrementally , thus eliminating corruption and self-interest , AI can make safer decisions , therefore contributing to overall prosperity in society .


AI has been developing significantly over the past few decades in many fields , and its application can be seen almost everywhere in the world . In the article One Hundred Year Study on Artificial Intelligence , many applications and future blue prints are mentioned . Although various kinds of excellent thoughts are expressed throughout the paper , there might also be some flaws within the analyses that are worth considering . In this essay , I would like to challenge one point made by the authors . In the field of Education , the authors state that minor utilization of sophisticated AI technologies across schools and universities results from shortage of financial resources and lack of data that are used to set up effectiveness of technologies . Instead , I think the reason is that AI can not subjectively infer the attitude of students or the actual level of mastery of knowledge of students to provide targeted personal learning plans .

First of all , AI has not necessarily featured complicated subjective inference so far . Humans can subjectively complete inferences in a miraculous way . For example , if my friend and I were to set up a meeting time , I would be likely to say , `` let 's meet at 4 o'clock . '' Here comes the problem . Would my friend come to meet me at 4 am or 4 pm ? As is known to all , people are usually asleep at 4 am , so it is not likely that my friend would meet me at 4 in the morning . Instead , 4 pm is an ideal time to meet . Thus , my friend would definitely come at 4 pm for the meeting . However , how would a computer know whether the meeting is at 4 am or 4 pm ? If the AI was programmed using 24-hour clocks , would it just assume the meeting time being 4 in the morning ? Someone may argue that it is easy to include such logic when programming AI technologies - people just need to feed a large set of daily life conversations to machines and let them figure out what to do . Nevertheless , what if the logic behind becomes complicated ? Will AI technologies still be powerful to figure out the inferences quickly and accurately ? I believe this remains to be questioned .

Since AI is not necessarily powerful enough to deal with complicated subjective inference according to what is mentioned above , AI technologies implemented in the field of education can not tell whether a student really wants to learn , or whether a student needs a different learning plan . Especially at school , some kids do not like studying at all . Teachers can tell whether their students want to spend time studying or not easily through observing students ' words and actions in daily life . However , AI machines can not have access to enough information to make inferences on whether students are interested in studying by only recording their actions on the screen while they are doing homework . Such inference must be made through a huge set of data collected from each student 's daily life . Therefore , so far only teachers can really provide targeted personal learning plans effectively enough for students ' future development .

Admittedly , AI technologies have been developing rapidly in recent years . The reason why so few AI technologies are used in schools and universities is not due to lack of either financial resources or data collection . Instead , it is the lack of ability to perform complicated inference that hinders AI being wide-spread . Only when AI machines can perform inference upon what students ' attitude is towards studying and personalize individual learning plans accordingly without using too many data can AI technologies replace the work of teachers in schools and universities . In a field as new as artificial intelligence , it is expected to have a long list
of unanswered questions both technical and ethical . Although artificial
intelligence likely will benefit society in many ways , it is impossible to tell
whether the application of these technologies will be a net positive or a
negative to society . The Stanford One Hundred Year Study suggests that as
artificial intelligence improves and proper government regulation is put in
place , the transportation problems in cities will be largely reduced . In some
cities , this is likely to be the case however , the study fails to acknowledge
that some of the world 's largest and busiest cities do not have the road
infrastructure in place that would be necessary to truly leverage new artificial
intelligence technology assuming it functions to an acceptable standard .
New York city is a city that is overpopulated . The public transportation system
is overwhelmed by both tourists and daily commuters . Often , people would have to
wait on the platform for the next subway train to arrive as the previous train
would only be able to hold half the people waiting on the platform . This forces
many people to hire taxis to quickly travel throughout the city . If self-driving
cars were driving on the streets of Manhattan , New York 's overcrowded
infrastructure would still be far from solved . Perhaps , instead of calling a
taxi , people would be able to call their own car to drive them whether they must
go , but the logistics of having so many cars in the city is a problem that
can not be ignored . The current infrastructure is bad and put simply , New York is
not a car friendly city . Whether the cars are self-driving or not does not
change the fact that New York has trouble supporting automobiles . Another city
infrastructure issue is parking and even with advances in artificial
intelligence , parking will remain an issue . A possible solution to the
overabundance of cars in Manhattan could be ride sharing but as the study
mentions , ridesharing applications have failed to gain traction .
Saint Petersburg , Russia is another example of a city that would struggle to
benefit from adopting self-driving cars into their city infrastructure . Because
Saint Petersburg is a network of five districts that are separated by canals ,
cars must drive over bridges to travel between the districts . Due to ship
traffic in the canals , the bridges all rise early in the morning . This
creates a massive logistical problem for the free movement of autonomous
vehicles . What are the vehicles expected to do during the window that the
draw bridges are open ? Surely they can not be expected to park and wait
until the bridges open as that would be horribly inefficient . What happens
if many of the cars are stuck on one island and ca n't be summoned for a
ride for a few hours ? These are questions that must be answered before
this technology can benefit the city infrastructure and reduce overall
traffic while increasing transportation efficiency .
As the technology continues to advance in artificial intelligence , we need
to focus on how we will effectively apply the new technology so that
society can reap the benefits . It is difficult to predict how artificial
intelligence will fit in our society but with proper planning , it likely
will be net positive . While the Stanford One Hundred Year Study
illustrates many applications for artificial intelligence in a variety of
industries , it fails to address that issues associated with city
infrastructure are complex problems that will not be easily fixed .
I challenge where the report states with computers/AI taking over
human labor jobs , the cost of many goods and services will be reduced . My argument is
that while the absolute price of goods and services may be lowered , the relative
price would remain constant and may not be remedied by potential new job openings
created by AI .

While it is very likely that AI in near future will be capable of performing basic
functions -LRB- held by human labors -RRB- in various fields , it does not necessarily `` reduce ''
the cost of many goods and services produced . One could argue that it is AI is most
likely more efficiently and less prone to erroneous operations , thus the cost of
manufacturing goods or providing services are lower , which in turn reduces the
price at which the goods are offered to people . However , those people replaced by AI
would lose their source of income and thus become incapable of purchasing any good
regardless of its price . Furthermore , Albeit that most people work to be able to
purchase goods and services , there are others who are truly passionate about their
jobs and would be petrified once their life goal or motivation has been taken away .
One may also claim that with the replacement of a portion of tasks that are previously
performed by human labors , AI is likely to create new kinds of jobs . It is perhaps
natural to think that there is a way to relocate those whom are replaced to a new
job market . It is hard to imagine , however , that any of these new jobs created by AI
would have nothing to do with AI itself . Some of these people may be middle-age workers
who has been accustomed to perform tasks the old fashion way -LRB- i.e. either unwilling or
have great difficulties transitioning to handle a brand new job -RRB- , while some other
people possibly have no interest towards the technology and thus would not be an ideal
candidate for the new job position . Let us assume that those whom lost their jobs now
can potentially receive aids from the government and just do whatever they really
desire to accomplish instead of pursuing a career which perhaps was only a mean to
provide for themselves . The government fundings nevertheless are hardly going to be
sufficient . It is always going to be relative to the price of the goods and services .
With AI lowering the costs of goods and services , the government aids most likely
will not be enough to support the living standard a person used to have when he or she
had a job . Ultimately , different individuals would have different opinions on
whether they would be content living their life in such way .

In conclusion , even though it is obvious for us to realize having human
task capable AI perform many goods and services could effectively reduce the cost of
manufacture , it may not necessarily distributed resources evenly to people as some
people who are replaced would have a hard time adapting to the new trend . Therefore
it is not clear to people that having AI replacing human labor tasks would
necessarily be a boon to the society overall . The Stanford One Hundred Year Study on Artificial Intelligence provides a detailed insight into the current progress of the field of AI and attempts to provide guidance for future directions in AI . In the recent years , Artificial Intelligence -LRB- AI -RRB- has been under the spotlight for a myriad of reasons , of which , the powers of AI and its potential as a threat to humans seemed to be of concern to the general populations .
The 2016 study seems to particularly focus on this aspect ; the report stated that there was no cause for concern that AI is an imminent threat to humankind . It goes on to state that there are have not been and there are no intentions to build a machine with self-sustaining long-term goals . This statement seems to be problematic as it fails to consider the implication and the possibility of the creation of a machine that self-learns to be sufficient unbeknownst to its creators .
The report appears to focus mainly on the benefits of implementation and utilization of AI but fails to consider the long-term consequences of a potential rogue AI system , where humans have no control of . While the report suggests that strict governmental regulations should be put in place to monitor the progression of AI and to cope with the changing legal landscape brought upon , it fails to discuss the necessity of finding and creating a robust solution to retaining full control of all AI systems . This concern is also raised in the Open Letter on Artificial Intelligence signed by industry leaders of AI where other challenges such as verification , validity and security are also raised . This notion of retaining full control over AI is to ensure that future goal-based AI programs do not resist modifications to goal specifications from engineers after launch .
Creation of a friendly artificial intelligence is more important and crucial at this point ; practicality and constraints towards building an ethically behaved AI should be explored . Supporters of friendly AI call for it as they believe in its creation as a form of mitigating existential risks that advanced AI might pose . This idea of creating a friendly AI is to explicitly counteract any sufficiently advanced AI system from exhibiting undesired behavior . Consider the recent Facebook AI program that invented its out language ; a research algorithm that deviated from human language , which showcased the possibility of what can happen with unconstrained feedback . Similarly , suggestions from machine ethics researcher , Bruce Schneier , recommends the adoption of a security mindset ; by which preparing for the failure of a system is of greater importance than the success of the system . This mindset similarly echoes Isaac Asimov s Three Laws of Robotics where he proposed safety measures to prevent robots from harming humans .
Overall , the study provides a decent insight into the developments of AI , but perhaps a more detailed consideration of the aspects of friendly AI is necessary to sooth worries . It might be speculative to focus on the existential risk from AI , however , it is important for engineers and AI developers to acknowledge these potential risks and practice precaution while putting in place systems of checks and works towards prevention .

In Artificial Life and Intelligence in 2030 the authors discuss the current technologies made possible through Artificial Intelligence -LRB- AI -RRB- and their hopes for its progress in the future . They go one to offer a few recommendations for policy change and raise ethical questions to consider moving forward . One aspiration for future AI technology is its use in law and financial decision-making . The authors pose that AI technology would significantly reduce human biases in critical decision-making such as who is lent money or who is sent to jail .
I am reluctant to have as strong of faith in a machine to make such decisions for ethical reasons . I think there is a certain level of emotion and humanity involved in critical decision-making . For example , I had recently seen a video of a woman who had been issued five parking tickets and had incurred a hefty fine of $ 400 . It was evident she was guilty of the charge , and they had been issued a few years ago and had remained unpaid . Based on these facts , it seemed apparent to penalize the woman for her misdemeanor . The judge asks her to explain why she did not handle the tickets in a timely manner . The woman goes on to explain she had been unexpectedly fired from her job and shortly after , her son had been murdered . Without much money saved and no income , she used most of what she had to pay for her son s funeral . Some of the parking tickets she had incurred had been in the pursuit of trying to find another job . The judge sympathized with the woman s story and decidedly excused all her parking tickets . The decision was not motivated by logic , but the woman was incredibly grateful and the judge received much praise for his kindness . A computer would not be capable of making a decision such as this , or certainly not in the near future . In fact , in some circumstances human biases may be what we need to make the moral call . Perhaps even vital to who we are as humans . We are able to consider something deeper than a machine could , and for this reason I think we should be very reluctant to use AI technology for such matters .
Additionally , it will be very difficult to synthesize a purely reasonable decision-making machine . The author mentions in order to propel AI s advantageous opportunities it will require significant funding some from private sources . As we have too often seen , large corporations and individuals can use their resources to create circumstances which are ideal for them . There is already fear that biases have been created in our current AI technologies . For example , the author mentions the computers likelihood of selecting an African American as a criminal . Another note that surprised me was that speech recognition technologies do not work well for women and people with accents . As Artificial Intelligence -LRB- AI -RRB- begins to encompass more of our daily lives it is important to consider the initial motivations in creating it and what its consequences may be . Computers are not inherently biased , but are created by humans who have the potential to be . If we are to rely on these tools for critical decision making we must ensure they are designed with good intent for everyone .
Artificial Intelligence if programmed correctly has the potential to be free of biases . If we are to use these tools in important decision-making scenarios , we must ensure the programs are not tainted with personal agendas . Artificial Intelligence can be a catalyst for social change if used and created by those who strive for progression .


The first aspect of the study challenged by this essay is the committee 's decision to limit the study 's focus only on a typical North American city . The next aspect of the survey that the essay challenges is about the proliferation of self-driving vehicles .

Focus on North American city :
It is understandable that the study panel is limited in its capacity to conduct an elaborate study on cities and rural areas alike . But my primary challenge is regarding the focus on a city in western world country -LRB- North America -RRB- . In North American cities technology has proliferated into people 's lives in many aspects unlike the cities in developing or underdeveloped countries . Moreover , the infrastructure in the American cities is far more advanced than the developing cities . For example , in contrast to American cities , cities in India do n't have properly separated lanes in roads -LRB- with the exception of intercity freeways -RRB- . In such contexts , it is unclear how and whether we can expect a self-driving car to be successful . In such cases , what are the technological challenges regarding the algorithm developed or hardware used ? A discussion of how unplanned cities without proper infrastructure could prepare itself to reap the benefits of AI in the coming years would have been equally helpful for researchers in such countries .

The proliferation of self-driving vehicles :
The study predicts that self-driving vehicles will proliferate American cities by 2030 and that the number of cars owned will come down . I find these two aspects quite contradicting . The proliferation of these vehicles will result in an increase in the usage of cars ; for example , an underage teen who can not legally drive a car can now own a car and use it . A person using public mode of transportation to avoid driving for a long time might now prefer to ride in a self-driving car and get some useful work done during the commute . These factors might thus increase the number of cars and thus might lead to more congested roads . Alex Eichstaedt
Fall 2017
CS540 - Section 2
One Hundred Year Study on Artificial Intelligence Reflection

Challenging AI timelines for Transportation Integration

Transportation , a major focus in the integration of Artificial Intelligence , `` is likely to be one of the first domains in which the general public will be asked to trust the reliability and safety of an AI system for a critical task , '' according to Stanford 's One Hundred Year Study on Artificial Intelligence . The study predicts by 2030 that AI technology will be integrated into trucks , planes , and drones , as well as cars for personal and commercial use . This prediction I find highly vague and challenge that it will take slightly longer for integrated personal use and less time for integrated commercial use .

From my standpoint , Stanford 's study on AI ignores a large sector that will play a vital role in AI integration : the insurance industry . Although it is great to see on television `` AI test drives , '' insurers will need adapt with the growing technologies and provide coverage plans for autonomous driving vehicles . This factor I believe pushes autonomous driving vehicles ' integration for personal use closer to 2040 .

Who is liable in the event on an autonomous driving vehicle accident ? How should insurers cover drivers that still wish to drive manually ? What happens in the event of a major hack to these autonomous driving softwares - is the car useless ? These are just three of an endless number of questions insurance companies will need to answer for people and businesses . The process will involve working with government , and I personally see that taking more time to iron out the legislation and regulations .

On the other hand , I see its prediction for commercial business use to be a bit pessimistic . Already in Michigan , semi-trucks have driven autonomously while carrying real cargo across the state . For companies that routinely make similar shipments and deliveries , I see them integrating AI use into the shipping industry within the next 5 years . Truck driving unions may slow its integration , but I see self-driving semi-trucks coming to our roads sooner than later . For example , Amazon is pushing the e-commerce industry into incorporating heavy drone use . I do n't see it taking long for them to incorporate into their business strategy moving product between warehouses autonomously .

In conclusion , the most difficult part of AI integration is earning `` public trust . '' As the study says , movies have portrayed AI technology as the end or evil . This is why I see it taking longer than by 2030 for the general consumer to trust autonomous-driving technology . One mis-calculated step , or one tragedy could doom the entire market and drain its investments . It will be crucial for companies to tirelessly test their technology . At the same time , simple tasks like transporting cargo in-state I see being incorporated into daily use relatively soon . AI integration will be a slow process , there 's no avoiding it . The key will be to introduce only the safest and easiest of its integrations first . The Stanford One Hundred Year Study on Artificial Intelligence -LRB- AI -RRB- provides an expansive look at the current research/uses , trajectories of research and development , and misconceptions about AI , as well as suggestions for future policy proposals to help guide informed regulatory practices over such technology . As a whole , the review provides a rational framework by which we can begin to tackle the challenges of emerging technologies from both personal and societal perspectives . One area of particular interest to the committee is the implementation of regulations that , from the authors ' standpoints , can provide safety and privacy oversight , but also have the potential to stifle innovation in both the public and private sectors . Although the authors ' are clear that regulation should be evaluated on a case-by-case , sector-by-sector basis , they make potentially dangerous assumptions about particular regulatory bodies and policies , in particular the Food and Drug Administration -LRB- FDA -RRB- and the Health Insurance Portability and Accountability Act -LRB- HIPAA -RRB- . More specifically , they tend to overlook important issues regarding patient rights and privacy that are of utmost importance to the future of health care and health care-related technologies .
AI has the potential to revolutionize how we diagnose and treat disease , based on the increasing ease of health data collection and storage on a mass scale . However , as this ease increases , so do concerns about maintaining patient privacy and a patient 's right to have their personal health information -LRB- PHI -RRB- removed from mass storage and use for research . The report states that `` Research and deployment have been slowed by outdated regulations and incentive structures '' -LRB- p. 25 ; under `` Healthcare '' -RRB- , which is laden with potentially false assumptions about not only the motives of professionals in the health care industry , but also with regard to how often regulations are updated . Without an exhaustive review of current regulation of and potential financial conflicts of interest within the healthcare industry , such speculation is dangerous and may increase the chances that patient rights may be infringed at the behest of innovation . The report also states that `` Unfortunately , the FDA has been slow to approve innovative diagnostic software , and there are many remaining barriers to rapid innovation . HIPAA ... requirements for protecting patient privacy create legal barriers to the flow of patient data to applications that could utilize AI technologies . '' -LRB- p. 27 ; under `` Healthcare analytics '' -RRB- , a claim made with neither citable nor anecdotal evidence made in its defense . Health care regulation , and the process by which it is changed , is made to be slow and incremental by design due to the severe consequences of making fast decisions without deliberate thought of the unintended consequences . When patient 's safety and privacy are at stake , decisions should not be made in haste based on what the author 's deem as `` rapid innovation '' . Instead , thorough testing of PHI-utilizing applications should be conducted in order to maintain the highest degree of patient safety and privacy .
Although the authors do point out potential issues that significant health regulations may pose , including the risk of higher rates of misdiagnoses and inappropriate treatment , as well as no regulatory body to govern the sharing of PHI from institution to institution -LRB- p. 27 ; under `` Healthcare analytics '' -RRB- , this does n't therefore mean the industry should forego important regulations underlying patient privacy . These issues should , of course , be evaluated case-by-case , however the authors should avoid lofty and potentially misguided suggestions about the health care industry as a whole and make specific policy recommendations if they feel regulations are too strict and/or are in need of revision
Will Artificial Intelligence Help Improve Healthcare ?

As a student of computer science , I have always believed that most of the modern-day tasks can be performed by computers provided there is someone smart enough to design an algorithm for the said task . However , when it comes to healthcare I strongly believe we should be wary of using AI techniques that may replace a physician by autonomously diagnosing an ailment without any human intervention , since precious human lives will be at stake . Moreover , very stringent regulations will be needed to determine whether such tools should be available to untrained users , which I believe will only hinder other necessary technological developments that may benefit humanity .

With the help of online resources such as WebMD , general populace tries to self-diagnose their ailments which often leads to wrong diagnosis and use of improper medicines which further worsens the disease and in some cases the delay in getting right medication can be fatal . While AI based diagnostic tools may only be designed to assist clinicians , it won t be long before mass population start using the tools themselves for diagnosis and prescription without involvement of any medical professional which can be catastrophic . Because such tools will only be meant to augment a clinician s decision-making process and not replace one . Strict regulations may prevent the mass availability of those tools but there will then always be other illegal means to gain access to them , or due to severe regulations and restrictions development of such tools may become very expensive which in-turn might increase the overall cost of healthcare .

It is suggested in the study that with increased availability of EHR -LRB- Electronic Health Records -RRB- , personalized treatments will be made possible based on numerous factors such as a patient s ethnicity , genetic information , geographical information etc. . While this approach of personalized treatment can be very effective , one should ponder upon the possible misuse of openly available electronic health data by corporations and blackmailers .

Presently , health insurance companies charge premium based on an individuals personal and family health history . However , with development of AI techniques and easily available health data insurance providers can pick out certain at risk individuals and then may charge very high insurance premium or even deny providing coverage . Furthermore , big pharma companies will start marketing drugs targeted towards a group without any medical relevance only to pad their bottom line .

On one hand deployment of advanced intelligent robots such as Da Vinci for assisting in complicated surgeries will improve standard of healthcare manifold but when it comes to personal care in hospitals I strongly believe that a human element is a necessary intangible component in the process of healing . No robot can match the delicate touch and compassion of a human being be it for a menial task such as bringing in food tray or more complicated task of helping a patient rehabilitate to walk again after a major invasive procedure . Therefore , while few contributions of robotics in assisted surgery may be beneficial but a large-scale deployment of robots for patient care may not be helpful to achieve better healthcare standards .

At this point of time it is difficult to estimate whether development of artificial intelligence techniques will help improve and subsidize healthcare or make it even more expensive and complicated , shrouded in complex regulations . With appropriate regulatory oversight and human judgement in developing right tools it may turn out to be useful .
I think the paper glosses over the issue of achieving widespread adoption of self-driving cars , as well as the speed at which it will occur . It references a report that predicts the widespread adoption of self-driving cars by 2020 . The paper does not specify whether `` widespread adoption '' refers to a large portion of the general public accepting and trusting the technology and its implications , or to the widespread use of autonomous vehicles on roads , or to both . When it comes to the former , I think that the media and general lack of knowledge on the subject could hinder acceptance of the technology , and in the case of the latter , I think the price of such technology will form a sizable barrier to such adoption . And that is all assuming that self-driving technology has advanced to the point that it 's ready for public consumption by 2020 .

Statistics and studies done on the safety and effectiveness of autonomous vehicles will likely be enough to persuade many people , but it 's difficult to gauge how many may remain unconvinced that they should trust and switch to self-driven cars , especially those adverse to change . Accidents that are the fault of the self-driven car will also likely be blown out of proportion by the media , and could negatively affect the general public 's opinion of self-driving cars , even though in reality they will be much safer and less accident-prone than traditional cars .

Even if the vast majority of people agree with and trust the concept of a completely self-driven car , the large barrier of price still remains . Self-driving cars will almost certainly cost more than traditional cars . The LIDAR , the component that sits on top of an autonomous vehicle and maps the surrounding terrain and objects using lasers , still costs between $ 8,000 and $ 30,000 , and that 's after Waymo , the creator company , took steps to reduce its cost by more than 90 % . And that 's only one of the various components that will be needed in a fully autonomous car . Tesla uses radar , not LIDAR , and claims their self-driving equipment costs are around $ 8,000 . However , Tesla cars are only capable of semi-autonomous driving , and that $ 8,000 likely does not reflect how much it will cost to fully autotomize a car . Given this , I think the transition to many self-driving cars being on the roads will take longer than three years . First , the technology must mature to the point that it 's viable , which will also require plenty of testing given that a large number of lives will be at hand . Following that , a brand new car is usually a purchase that the average person makes once every few years , if not less frequently . And to facilitate the widespread use of self-driving cars , they need to be purchased widespread . While a fully autonomous car would definitely give incentive for the average person to purchase a brand new car more often than usual , it 's not a purchase that many will be able to quickly make once the technology is being sold to the public . Additionally , some people may enjoy driving to the point that they wish to continue driving traditional cars , which would also affect the number of self-driving cars on the road .

I think the paper addresses many points regarding self-driving cars and its barriers to widespread adoption , but that the important topics of price and public opinion on the technology are either mentioned only briefly , or not at all .
As this study was written by field experts in Artificial Intelligence , I find it difficult to challenge any area of it . However , I do somewhat question how they chose to define intelligence . The definition given in the first section of the article states `` ... intelligence is that quality that enables an entity to function appropriately and with foresight in its environment . '' This definition is extremely broad , and I feel could be improved . From the list of definitions given by Wikipedia , definitions vary from `` goal-directed adaptive behavior '' , one of the most specific , to an extremely vague `` deal with cognitive complexity '' . The definition given by Howard Gardner is most similar to how I 've personally always viewed intelligence : as a person -LRB- or thing 's -RRB- ability to solve problems . This definition is not perfect , however . It works very well for humans and animals . People able to solve complex problems , like Stephen Hawking for his theoretical physics work , are seen as more intelligent than most . This extends well to animals . The octopus , for example , is viewed as one of the most intelligent animals for its ability to manipulate its environment in a near human-like way , including escaping from its tank . The other non-human apes are also seen as intelligent due to their use of tools and ability to learn very simplified language . Computers , however , are not capable like this . Instances of artificial intelligence are often extremely specialized , and are only able to perform a small number of tasks at a high level . For example , game-playing intelligences like AlphaGo are well-suited for the complex problem of playing go , but incapable of doing anything else . Similarly , a calculator , mentioned at the start of the article , can perform mathematical operations with much greater speed and accuracy than a human brain , but can not do anything else . The article here suggests in `` Defining AI '' that one degree of autonomy and generality should be considered when deciding if a thing is intelligent , and with this I can strongly agree . While not much emphasis is placed on these , in favor of specificity and efficiency , they are important qualities to eventually create an intelligence rivaling that of a human mind .

The Stanford One Hundred Year Study on Artificial Intelligence says that , `` It may even be proposed , as a rule of thumb , that any activity computers are able to perform and people once performed should be counted as an instance of intelligence '' -LRB- 13 -RRB- . However , I find this statement to be rather misleading and possibly incorrect . We should not be saying that anything computers can do that humans can also do is an example of intelligence . The idea that matching human ability is a sufficient condition for intelligence is flawed because of brute forcing correct results .
There is a theorem known as the `` Infinite Monkey Theorem '' which states that a monkey typing random keys on a typewriter will eventually write out all of Shakespeare 's works . Bringing this back to artificial intelligence ; if we were to use the idea that matching human ability for any task constitutes as intelligence , then this monkey on a typewriter -LRB- or random character generator -RRB- would be considered intelligent . Shakespeare was a human and the character generator was able to replicate all of his work without any prior knowledge of it . If one was to run a test on both a random number generator and an advanced AI , with the goal being to beat a human in chess , both would eventually win a game . The advanced would take a much more efficient path and use its resources to come up with answers faster , but the random number generator would eventually produce a series of moves which would be comparable to a chess professional .
However , obviously , the character generator does n't possess anything even close to human intelligence , and a random number generator picking the perfect set of moves in a chess game against a human may never happen in the lifetime of the universe even if left running continuously . Because of this scenario , it could be argued that solving problems quickly and reliably is what makes a system intelligent . But if that 's the case , consider solving math equations .
At the most fundamental scale , the task that all computers do to `` think '' is do boolean logic , store data , and solve math equations . Once again , we will use the idea posed by the study saying that if a computer can perform the task that a human just did , then that computer is considered to possess some form of intelligence . The study itself also mentions that using this classification , this `` places the calculator within the intelligence spectrum '' -LRB- 12 -RRB- . If we look at the most basic calculator , the full adder circuit , then we know that calculations are nothing more than cause and effect . Since calculators are on the intelligence spectrum , does that mean that anything involving cause and effect possesses some sort of intelligence ? If this is the case , we can say that everything in the universe possesses intelligence to some degree , which in my opinion is absurd .
Essentially , what can be deduced from this , is that matching human ability is not a sufficient condition for intelligence as that idea can be used to say that everything in the universe has intelligence . I feel as though this condition is not relevant in determining artificial intelligence , at least as how it is written in the study .










Bibiliography :


Peter Stone , Rodney Brooks , Erik Brynjolfsson , Ryan Calo , Oren Etzioni , Greg Hager , Julia Hirschberg , Shivaram Kalyanakrishnan , Ece Kamar , Sarit Kraus , Kevin Leyton-Brown , David Parkes , William Press , AnnaLee Saxenian , Julie Shah , Milind Tambe , and Astro Teller . `` Artificial Intelligence and Life in 2030 . '' One Hundred Year Study on Artificial Intelligence : Report of the 2015-2016 Study Panel , Stanford University , Stanford , CA , September 2016 . Doc : http://ai100.stanford.edu/2016-report . Accessed : September 6 , 2016 .


Émile Borel -LRB- 1913 -RRB- . `` Mécanique Statistique et Irréversibilité '' . J. Phys . 5e série . 3 : 189 -- 196 .


Geoffrey A. Lancaster -LRB- 2004 -RRB- . Excel HSC Software Design and Development . Pascal Press . p. 180 . ISBN 9781741251753 . As demonstrated by the Stanford One Hundred Year Study on Artificial Intelligence , the tide of the artificial Intelligent is irresistible . In order to adjust to the new change , people are expected to establish a new way to connect with the machines . The study mainly talks about the AI development in eight areas , including transportation , service robot , education , healthcare , low-resource community , public safety and security , employment , and entertainment , as well as its corresponding influences and challenges . However , I don t agree with some statements it made in the area of transportation and employment .
It is hard to deny the progress that the artificial intelligent made in the transportation . Especially that the advances in sensing technology and machine learning have made Google s autonomous vehicles and Tesla s semi-autonomous vehicles drive successfully on streets . Self-driving vehicles have definitely brought convenience to the public , and decreased the accidental rate . However , the safety of the self-driving can not be ensured . Firstly , google autonomous vehicles are tested in a restricted condition . It is possible that they would fail to drive successfully if the weather is bad , as self-driving car is supported by the sensing technology , and when the heavy rain happens to appear , the sensor could be broken , and thus the self-driving car can not work as expected . In addition to that , if the traffic light is off by accident , those self-driving car will not be able to read the signs with each other and communicate correspondingly .
Even though people consume because of the intrinsic value of the good and service , and the labor weighs a large portion in the costs , it is not appropriate to conclude that with the help of AI innovation , which replaces the human task , the cost of the merchandise goes down , and thus saves people s money . Firstly , in the perspective of the company , they exist to make profits , at least not to suffer the deficit . The sunk cost to the AI innovation is high by itself , and it is very likely that it costs more for company to install the AI technology than to hire human labor . Moreover , as indicated by the report , huge amount of the job will be replaced by the AI , and thus make a lot of people unemployed , and how could be possible for those people be rich without the income .
Moreover , as stated in the study , like the automation replaces the routine manufacturing job , artificial intelligent will replace the cognitive human job . Artificial intelligent will one day make a large portion of people lose their jobs . As a consequence , the income disparity will increase dramatically , just like the gap between the wealth and the poor has already increased in the past few years with the development of technology . Once the phenomenon of polarization exacerbated , hundreds of social problems will arise . Even though the social debate on the distribution of the profits made by the AI technology will be discussed by ahead of the time , once the technology replaces human completely in the workspace as stated in the study , people who own the machine will dominate the social fortune , and thus increase wealth disparity .

CS 540 Essay 1
As a rapid growing trend in the computer science industry nowadays , Artificial Intelligence has been demonstrated by Stanford One Hundred Year on Artificial Intelligence -LRB- September , 2016 -RRB- to be implemented in various subfields . It touched on the improvements that personal self-driving cars have already progressed . It also mentions more public changes such as the likelihood that on-demand transportation like Uber and Lift will be shifted towards self-driving vehicles and so on . While it brings several benefits to transmitters , researchers and city planners may need to come up with more balanced plans to reconcile traditional carpooling and self-driving services as well as personal cars instead of stop making progress on traditional vehicles .
One of the most obvious challenge is self-driving vehicles threat to job opportunities in the already shrinking on-demand transportation industries . Meanwhile the taxi industry has been largely intimidated by the overwhelming population of Uber drivers and the growing trend of car sharing such as Zipcar , the self-driving vehicles seem to have the potential to take away more citizen s job who used to rely on transporting people around . Some organization representatives like John Tomassi , the president of the Upstate Transportation Association , holds the view that the job opportunities driver-less car creates will be outweighed by the job loss predominantly if self-driving cars become prevalent . -LRB- CNN , 2017 -RRB- Researchers needs to address the issue by either better implement human drivers in on-demand vehicles in a non-traditional , more service focused way or manage to alter the public transportation structure smoothly so that the job transition can alter in a less painful process . Another potential drawback for implementing self-driving cars is it is not easy for riders to trust vehicles that are completely without human drivers . According to the studies by Brandon Schoettle and Michael Sivak -LRB- University of Michigan , 2014 -RRB- , the majority of citizens have high concerns for the performance of fully autonomous vehicle concerning its performances and functionality . It is thus still pendant for pioneer engineers to resolve the consequences ensue both for human drivers and urban transmitters .
Despite the concerns getting touched on in the report , too much focus on implementing AI on self-driving cars may unintentionally lead to a decline in development of traditional cars as well which are usually models geared specifically toward human drivers . There are populations of people in North American cities who favor vehicles due to the unique driving experience that a vehicle can produce . According to the studies by Daniel Howard and Danielle Dai -LRB- University of California Berklee , 2014 -RRB- , people who value driving as an experience and choose to purchase a car for its image are more likely to be reluctant of buying self-driving cars . For those people , a car is not simply way to transport , but with other social or personal interpretations . If the company managers place their bet solely on self-driving vehicles , it is likely that the lack of traditional car models may actually backfire the market of the car industry .
The idea of implementing self-driving cars in our transportation system has long been discussed and although there has been great progression on the technology , researchers still needs to consider circumstances such as regulation issues and the concerns raised in the above article . It is exciting that AI based vehicles is going to benefit transmitters and delivery services as a whole , while at the same time traditional vehicle industry should get the spare effort to promptly transformate to adapt to the futuristic trend rather than being somehow abandoned .





References :
http://money.cnn.com/2017/01/10/technology/new-york-self-driving-cars-ridesharing/index.html
https://deepblue.lib.umich.edu/bitstream/handle/2027.42/108384/103024.pdf?sequence=1&isAllowed=y
https://www.ocf.berkeley.edu/~djhoward/reports/Report%20-%20Public%20Perceptions%20of%20Self%20Driving%20Cars.pdf
After reading through the report Stanford One Hundred Year Study on Artificial Intelligence , I have a deeper understanding of how artificial intelligence has affect our daily life in different domains . It is undoubted that artificial intelligence does make much progress and bring much convenience to the society . Nevertheless , I also have many concerns to some points that are stated in the article .

One aspect that I want to challenge is that , in this report , it states that the progress made by artificial intelligence in the fields of transportation will lead to a different life because of fewer cars and fewer people living in the urban area for their work . From my perspective , People may not own fewer cars because there will be a lot of people who are still interested in the manually-controlled cars . Even based on the assumption that more and more people began to accept the autonomous cars , we can not conclude that they will live further from work since people may have many other reasons that make them choose to live around the area where they work . For example , if a person s company is at the downtown area and he or she has lived there for some years , then the person would not decide to move to somewhere further from the company just because of the new transportation method provides by the autonomous vehicles . Thus , people can not expect for a completely different urban organization just because of the progress of artificial intelligence in transportation .

It is also mentioned in that report that cars will be better drivers than people . However , in my opinion , cars may not be better than people in driving , especially when dealing with things that happened unexpectedly . Then , there comes the problem that the accident rate may arise and that will directly lead to other sophisticated problems involving risk taking and responsibility for the accidents . This kind of social problems are also mentioned in the reports so that before these concerns being solved , autonomous vehicles may not make huge change to the society and may not be commonplace in our daily life .

I also doubt that , in the education domain , the teaching robots can provide personalized teaching service for students . As we all know that the instructors in colleges may usually have a class with more than 50 students , some even exceeding 100 students . For a robotic instructor , it surely can not provide personalization for so many students during normal lecture since it can only teach in some fixed patterns . Students can not learn things better if they are taught by a teaching robot that , for example , can not react properly to students with respect to their different situations . Furthermore , there is the concern that teaching robots may not have the same influence on students as human professors or instructors because they are not humans . If students have little or no respect for the robotic teachers , they may not follow the instruction from them . Then their efficiency in learning will largely decrease . Thus , I think using artificial intelligence in education , especially in teaching students face-to-face , may not replace the role of human instructors .

Overall , I think the main problem that hinder the artificial intelligence from getting into our daily life is that it involved many moral and ethical issues . In addition , people still need more time to get used to those robotic and autonomous stuff . There is a long way to go before people fully trust and understand the service that the artificial intelligence can provide us . I believe that the future development of artificial intelligence is brilliant and far beyond our imagination .
In this essay , I will challenge three aspects of the article . Two of them involves the potential dangers of AI , and the third is about functionality and look of autonomous vehicles .
One argument that Artificial Intelligence and Life in 2030 makes is that there is no need to believe that AI will be an `` imminent threat to humankind '' -LRB- pg . 4 -RRB- . While it might be implausible , the article is flawed to strictly remove the possibility of such a scenario . The imminent threat scenario , which most likely refers to AI enslaving or killing of humankind , is an edge case scenario . However , there should always be a plan , if such an edge case scenario were to ever arrive . The article most likely makes this statement to remove the fear of AI to the uninformed public , and while the public should embrace all the potential good AI can bring , the potential negatives must be considered and discussed as well .
A second argument that the article makes is that it does n't believe it would be likely for an AI system to `` choose '' to harm people -LRB- pg . 10 -RRB- . The article believes AI will not go against its creator or their wishes . If artificial intelligence does harm to another person , it is due to the malice of its creators , not a misinterpretation by the AI itself . However , this argument is disproven by the software created today . For example , if a piece of software has a bug that manages to end up causing an explosion , that error could be considered as a program `` choosing '' to cause harm . A counterargument is that computers only follow what the software engineer writes to a computer , so AI did not intend to hurt someone but was just following orders . In other words , it is not the computer 's fault that the program caused harm , it was the programmer that wrote the error in the first place . However , if an Artificial Intelligence decides to harm a person , one might find it reasonable to blame the AI for making such a decision , like how a person that grows up in a hostile environment can be influenced to make a bad decision .
A third argument makes is that the smarter cars of the future will look and function almost like the cars of today -LRB- p. 24 -RRB- . However , if autonomous vehicles become more common place in the future , than I propose that they will both function and look different . A change that autonomous cars will make is how the operator of a vehicle interfaces with the controls . For example , instead of manipulating the car using a steering wheel and gas pedal , the car could be operated instead with a digital interface , such as a touch screen . By removing the need for a steering wheel or a gas pedal , a car manufacturer might decide to put more crumple space where the steering wheel used to be located , changing the look and functionality of the interior of a car . Another point that can be made , is that during the transition from non-autonomous to autonomous cars , drivers of non-autonomous cars will want to know which cars are self-driving and which ones are not . In this scenario , there could be outwardly facing aspects added to self-driving cars to distinct themselves from other types of vehicles .
While I don t think enough can be said about the importance AI will play in the future of humanity , I think the One Hundred Year Study on Artificial Intelligence downplays the potential of bad actors wielding malicious and powerful AI . It is one thing to discuss the impact AI will have in countries with well-balanced governments . However , an entirely different discussion arises when countries with supreme rulers are considered . A poor intentioned dictator might leverage AI to spy on every citizen in his/her country . AI makes this increasingly easy . In the past , vast resources -LRB- people , money , and time -RRB- had to be invested to spy on the citizens of a country . The increasing power/scalability of AI makes it orders of magnitude easier to know much about each citizen . This is already happening in countries like Iran where deep packet inspection is being used to intercept and record as much personal information as possible . The president of Zimbabwe hasn t lost an election since the government mandated internet service providers save information about users in a national database . Abuses such as these will be used by oppressive governments , or simply paranoid leaders who want to spy on political opponents .

The solution to an abuse of AI is not easy or clear cut . One solution might use AI against oppressive dictators -LRB- and potential future ones -RRB- . I think the paper needs to place more emphasis on using AI to develop ultra-secure methods for humans to communicate . If researches become aware of present and future abuses , they will be more likely to take actions that could save thousands of lives . It will be hard to push the conversation forwards , however , since governments tend to be against advances in privacy and security measures . Such measures will not be popular with government officials , but citizens in countries with controlling regimes need an easy , mainstream way to communicate without any government or company intruding .

The paper agrees with the assertion that it is never too early to start discussing important ramifications for AI and I think this is a vital discussion to have . Whatever the solution might be , considering future abuses of AI has to be an important part of the conversation while technologies are moving forwards at such a rapid pace . With so many publicly available methods , it might be possible for a group of hackers -LRB- with enough processing power -RRB- to cause great damage . What if the group creates an AI that finds vulnerabilities in software , exploits the vulnerabilities , then uses them to wreak havoc ? Maybe the malicious group uses AI to find people on social media -LRB- posing as someone the victim would likely friend -RRB- , then uses this insider access to steal the identity of the victim . All of this could happen without any interaction from the hacker .

The potential of AI is huge and I welcome the advances with open arms . However , I think more of an emphasis needs to be placed on furthering security/privacy . The paper properly responds to those that think AI will become sentient and take over the world , but I believe it does not correctly address the very real threat of humans abusing specialized AI to take away the rights of citizens across the globe .

One Hundred Years of Artificial Intelligence is truly a landmark study on the influences of the AI on the people and the various spheres of life around them . The predictions made by the paper is more or less consistent with the general perception of the AI and hits it right on target on almost all predictions except the two cases which are highlighted below .

Firstly , in the case of the self-driving cars , the study incorrectly predicts that the advent of self-driving cars may eliminate the need to own a car and be used as a shared autonomous vehicle . The self-driving cars though autonomous can never be used as a shared resource always . This is as good as booking a cab sharing service through any mobile application and along with it comes all the associated negative impacts . You may have to wait for the cab to come , wait for co passengers , and sometimes may never get a cab on time . This leads to a situation where one can travel only after careful planning even to minutest details . Another flawed prediction the study makes is that the self-driving cars may eliminate the need for public transport or it may evolve to some form of personal rapid transit . This is also a bit too much of a leap to a conclusion . In my opinion , AI can be a blessing in disguise for public transportation . Would n't a self-driving bus or trains be a better mode of transportation than self-driving cars ? The public transport reduces the dependence on resources , removes the human bias all the while improving the quality of life as well . A well connected intelligent public transport may be in many ways a better alternative than self-driving cars .

Secondly , in the case of AI causing loss of cognitive jobs , the study predicts that education and inventing new goods and services might be good enough only in the short run . Improving the social safety net with better educational facilities , better health care or guaranteed basic income is the long-term solution . In my opinion , education holds the key in the long run as well . Expanding the safety net or providing a guaranteed income is a highly short-sighted solution and thereby would never be an answer to the dearth of jobs . It will never equip the people who had lost jobs to gain skill sets required to survive in the new world . The key here is to use AI itself to mitigate the issues caused by AI . A lot of new jobs and services will be created to cater the needs of the new world which will require a different set of skills and knowledge . A reasonable solution is to leverage the use of collaborative filtering and recommender systems for targeted education to equip the society with skill sets suited for a post-AI world . A tool that suggests you the best job available based on interests and knowledge , and providing with information regarding the required skills , and then suggesting a course tailor made for you to gain a job of interest in a post-AI world while simply browsing is not a farfetched idea . In this way , AI can act as a guiding light to the society rather than leaving them out and be asking them to fend on their own . We can even use AI in finding disadvantaged people in the society and help them out specifically . In the cases of an emergency , we can always fall back to a welfare state like policies for the protection of the citizens , but only as a last resort .

Despite the differences in opinion about the predictions made on a post-AI society , the 100 years of AI study manages to be bang on target on most issues . The issues raised on public policy making , ethical and privacy issues are concerns which will become more and more relevant in the years to come . I sincerely hope the public policy makers would be far sighted enough to let the AI grow in leaps and bounds while addressing the various concerns of the society .
Humans interest of artificial intelligence is growing rapidly these days . More and more resources and efforts are put on the study and development of artificial intelligence . According to the Stanford 100 years report , although our study on artificial intelligence is still at the beginning stage , we have already proposed some domains where technologies generated from artificial intelligence can be used at . These domains include transportation , home/service robots , healthcare , education , low-resource communities , public safety and security , employment and workplace and entertainment . The report provides a lot of facts of the current status of some artificial intelligence technologies and also expectations of their future development . It is definitely true that we have made a great start on artificial intelligence but some of the expectations are too optimistic . There are some gaps between artificial intelligence and a real person s brain and these differences may never be eliminated .
According to the report -LRB- p. 20 -RRB- , the self-driving car technology may lead to a complete change in transportation in the future . For example , the performance of self-driving cars will exceed the performance of human drivers in the future and human drivers will be replaced completely . As a result , traffic accidents will decrease and people may never need to buy their own cars when artificial intelligence algorithm can arrange everyone s traffic demand efficiently with public transportation . However , this future is very difficult to reach and it may never come true . First of all , for some people , driving is not a burden or a necessary tool of traffic but a personal interest and hobby . These people will probably drive by themselves even when their cars have self-driving technology . In this circumstance , these vehicles are more difficult for AI drivers to calculate . There comes the most important concern of AI drivers : are self-driving cars truly safe . The development and preparation of self-driving cars have started since 2005 and Google s and Tesla s self-driving cars have already traveled in cities . The self-driving AI seems to be very accurate and reliable with both the complex algorithm to analyze the traffic situation behind the AI and the information gathered through sensors placed in the cities -LRB- p. 22 -RRB- . However , there are many possible situations which may happen on the road and AI can not respond to these accidental events as reasonably as human brain does if these events are not anticipated by programmers . For example , in 2016 May 7 , a Tesla Model S self-driving car crashed on a white truck during the Autopilot mode and the driver on Tesla is dead . The possible explanation to this tragedy is that the camera of autopilot system can not gather the full view of the truck since it is large while the truck is white , therefore the autopilot system considered the truck as cloud or just simply ignored it . The real problem lies beneath this accident is that the database of self-driving AI to identify objects is too small compared with all the possible situations in the real world . The influence of this problem may be reduced if we keep improving self-driving AI and its database . However , the potential danger will always exist .
Other than the safety concern , another potential problem of self-driving cars is private information . If the self-driving system wants to reach the greatest efficiency as the report suggests , it is necessary for the whole network to gather both traffic information and people s transportation plans . There comes possibilities that those personal information , including traffic plans and home addresses , may be released since they are all accessed by self-driving AI .
Personalize and Information Redundancy

The article provides an AI future full of confidence , and distributes responsibilities of negative influences to all other stakeholders . I believe AI is changing our world and will continue to change it in the future , but I have to admit sometimes it makes life harder instead of more convenient . One of the most obvious troubles , which is mentioned a lot of times proudly in the article , is the personalization . We are just trying so hard to make AI provide more personal service , including personal education , personal customer service , personal entertainment etc. . But I would like to point out one thing I am worrying is the information redundancy going through with personalization .

One example comes from a few days before . I was trying to reach out an Internet service for my apartment I just moved in . I thought it was all about a call , however , it takes me two calls about forty minutes each . Every time it takes me a long time to find the real customer service , which is a guy . I have to talk with a robot and listen it 's tedious slowly voices , and if I happened to speak something wrong or push the wrong button , I have to start over and listen to the voice again . This makes me feel that we are going too far in making AI personalize . The information redundancy can happen at any time when we are trying to make the services personalize . The article says AI will make education more focus towards different students , and I think it is totally horrible . I may have to go through a bunch of tests before reach the knowledge , which really makes sense to me , even though , I still can not get answers to some questions because AI think I should not ask . I do not think AI can be a right tool to answer questions or categorize people .

One reason I think AI can never achieve personalization is that our brains are so complex . As a person , one can be versatile , which means one can appreciate art , music , and also math , philosophy . It is not hard for AI to be versatile , but it is hard to build connections within objects . A people in favor of art have how much connection with he or she 's favor of music ? Peoples ' connections between objects have a complex relationship with emotions and personalities , and that is why Hollywood movies would not come true or even possible in the future as the article claims . However , they are trying to make products meet people 's personality , which is a bad try in my perspective .

My advice is to leave the options there . Steve Jobs said , `` people do n't know what they want until you show it to them '' . I would say people 's preference is always undetectable , even by themselves . Instead of asking a lot of questions and deal with huge amount of data analysis to figure out what people want to do or want to have , it is always worth to spend more time on our imagination , and to make it come true . Human should have more confidence in themselves , what we like and what we want is most likely the major preference of the public . I guess the one who develops the automatic customer service of the phone never try to use it achieve all services , and calculate the time waste through it . What if we set the real person for a direct choice and maybe a long line , but they can always choose automatic service ?

The report Artificial intelligence and life in 2030 by the 2015 study panel provides a commendable investigation on the current status of Artificial intelligence and the future prospects in the field . However , the report has failed in having a holistic view in the domains of employment , entertainment and transport that could hinder the development of AI .

Primarily , the report claims that AI would replace tasks rather than jobs in the near future and create new types of jobs . Moreover , the report also says that the future jobs that would emerge are harder to imagine in advance and the existing jobs are likely be lost . However , the report fails to give complete details about the jobs that would be lost and , whether the people who would lose their employment are qualified to take up the new jobs that would be created in the future . In the current scenario , most of the tasks in a job are carried out by people and automation would definitely lead to loss of employment / decreased wages . This would in turn lead to lower standards of living which is contrary to the primary aspect of AI in providing better standards of living . Unless clear picture of the new job opportunities and the situation of workers who would lose their jobs are given , it is highly improbable to gain people s trust in deploying AI for doing tasks .

AI has bought up several sophistications and advancements in the field of entertainment . The report has considered only the positive aspects and has stated that Children often appear to be genuinely happier playing at home with their devices rather than playing outside with friends . When viewed blindly the statement seems to be appropriate . However , looking deep would help to realize that AI has been hindering the growth of children to a greater extent . Children might be happy playing with their devices , but this has got adverse effects . It has been shown in several researches that children s physical activity plays a vital role in their development . On the same note , it has been observed that parents have started to restrict their children from using their devices . Unless , parents get convinced on how AI could help the children to grow mentally and physically , the future of AI seems to be bleak in the domain of children entertainment .

In the field of transportation , the report has stated that cars will become better drivers than people and people will start owning fewer cars and live farther from work , thus creating a new urban organization . This argument seems to be completely unwarranted . If the cars are automated , there is no assurance that people would stay further from the workplace . This is primarily because automation of cars could not reduce the distance travelled . There would be no change in the total travel time . To reduce transportation time , people would prefer to stay near their workplaces . Furthermore , the report has claimed that the people would start using public modes of transport when the transportation vehicles are automated . In most underdeveloped and developing countries , public mode of transport is the primary means of transport providing huge employment opportunities . Automating in those countries would be huge challenge and requires more time frame than expected in comparison with the developed countries .

Though , the report is good at presenting the development of AI over the years , it has made several unstated assumptions in deciding the future prospects of AI in few fields as discussed above . Such issues should be considered on a serious note to ensure substantial development of AI .

